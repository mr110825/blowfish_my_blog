
[{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/tags/aws/","section":"Tags","summary":"","title":"AWS","type":"tags"},{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/tags/terraform/","section":"Tags","summary":"","title":"Terraform","type":"tags"},{"content":" 今日学んだこと # 前回の記事でファイルレイアウトによる環境分離を学んだが、ステージングと本番で同じコードを重複して書く問題が残っていた。今回はTerraformモジュールを使って、DRY原則をインフラコードに適用する方法を学んだ。\nモジュールとは # フォルダ内にあるTerraform設定ファイル（.tfファイル）の集まり = モジュール\nつまり、これまで作成してきたディレクトリも「モジュール」といえる。\n種類 説明 ルートモジュール terraform applyを直接実行するフォルダ 再利用可能なモジュール 他のモジュールから呼び出されるフォルダ 基本構文 # module \u0026#34;\u0026lt;NAME\u0026gt;\u0026#34; { source = \u0026#34;\u0026lt;SOURCE\u0026gt;\u0026#34; # 設定（入力変数など） } sourceにはローカルパス、GitHub URL、Terraform Registryなどを指定できる。\nディレクトリ構成の変更 # 前回のstage/のみの構成から、モジュールを分離した構成に変更。\nch4/ ├── modules/ # 再利用可能なモジュール │ └── services/ │ └── webserver-cluster/ │ ├── main.tf │ ├── variables.tf │ ├── outputs.tf │ └── user-data.sh │ └── live/ ├── stage/ # ステージング環境 │ └── services/ │ └── webserver-cluster/ │ └── main.tf └── prod/ # 本番環境 └── services/ └── webserver-cluster/ └── main.tf ディレクトリ 役割 modules/ 環境に依存しない再利用可能コード live/stage/ ステージング環境のルートモジュール live/prod/ 本番環境のルートモジュール モジュールの構成要素 # プログラミングの関数と対比すると理解しやすい。\nTerraformモジュール プログラミング 説明 モジュール 関数 再利用可能なコードの塊 variable 引数 モジュールに値を渡す locals ローカル変数 モジュール内部の計算・定数 output 戻り値 モジュールから値を返す 参照方法の比較 # 種類 文法 例 入力変数 var.\u0026lt;NAME\u0026gt; var.cluster_name ローカル値 local.\u0026lt;NAME\u0026gt; local.http_port モジュール出力 module.\u0026lt;MODULE\u0026gt;.\u0026lt;OUTPUT\u0026gt; module.webserver_cluster.asg_name パス参照 path.\u0026lt;TYPE\u0026gt; path.module 入力変数（variable） # なぜ必要か # 前回のコードにはハードコードされた値が多い。\nハードコード 問題 instance_type = \u0026quot;t2.micro\u0026quot; prodでは大きいインスタンスが必要 min_size = 2 環境ごとにスケールを変えたい key = \u0026quot;stage/...\u0026quot; prodで使うとstageのDBを参照 定義例 # modules/services/webserver-cluster/variables.tf\nvariable \u0026#34;cluster_name\u0026#34; { description = \u0026#34;クラスターリソースの名前\u0026#34; type = string } variable \u0026#34;instance_type\u0026#34; { description = \u0026#34;起動するEC2タイプの種類\u0026#34; type = string } variable \u0026#34;min_size\u0026#34; { description = \u0026#34;EC2インスタンスのASGの最小値\u0026#34; type = number } variable \u0026#34;max_size\u0026#34; { description = \u0026#34;EC2インスタンスのASGの最大値\u0026#34; type = number } variable \u0026#34;db_remote_state_bucket\u0026#34; { description = \u0026#34;S3バケットの名前（データベースのリモートステート）\u0026#34; type = string } variable \u0026#34;db_remote_state_key\u0026#34; { description = \u0026#34;S3でのデータベースのリモートステートのパス\u0026#34; type = string } 呼び出し側での値の指定 # live/stage/services/webserver-cluster/main.tf\nprovider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } module \u0026#34;webserver_cluster\u0026#34; { source = \u0026#34;../../../modules/services/webserver-cluster\u0026#34; cluster_name = \u0026#34;webservers-stage\u0026#34; db_remote_state_bucket = \u0026#34;tf-state-backend-20251128\u0026#34; db_remote_state_key = \u0026#34;stage/data-stores/mysql/terraform.tfstate\u0026#34; instance_type = \u0026#34;t2.micro\u0026#34; min_size = 2 max_size = 2 } live/prod/services/webserver-cluster/main.tf\nmodule \u0026#34;webserver_cluster\u0026#34; { source = \u0026#34;../../../modules/services/webserver-cluster\u0026#34; cluster_name = \u0026#34;webservers-prod\u0026#34; db_remote_state_bucket = \u0026#34;tf-state-backend-20251128\u0026#34; db_remote_state_key = \u0026#34;prod/data-stores/mysql/terraform.tfstate\u0026#34; instance_type = \u0026#34;m4.large\u0026#34; # より大きいインスタンス min_size = 2 max_size = 10 # スケールアウト可能 } ローカル値（locals） # variable との違い # 種類 外部から設定 用途 variable 可能 モジュールのAPI（外部に公開） locals 不可 モジュール内部の定数・計算 ポート番号など変更されたくない値はlocalsで定義する。\nlocals { http_port = 80 any_port = 0 any_protocol = \u0026#34;-1\u0026#34; tcp_protocol = \u0026#34;tcp\u0026#34; all_ips = [\u0026#34;0.0.0.0/0\u0026#34;] } resource \u0026#34;aws_security_group_rule\u0026#34; \u0026#34;allow_http_inbound\u0026#34; { type = \u0026#34;ingress\u0026#34; security_group_id = aws_security_group.alb.id from_port = local.http_port # 80 to_port = local.http_port protocol = local.tcp_protocol cidr_blocks = local.all_ips } マジックナンバー 80 より local.http_port の方が意図が明確。\n出力（output） # なぜ必要か # 本番環境のみにスケジュール設定を追加したい場合、モジュール内のASG名を外部から参照する必要がある。\nmodules/services/webserver-cluster/outputs.tf\noutput \u0026#34;asg_name\u0026#34; { value = aws_autoscaling_group.example.name description = \u0026#34;The name of the Auto Scaling Group\u0026#34; } output \u0026#34;alb_security_group_id\u0026#34; { value = aws_security_group.alb.id description = \u0026#34;ALBのセキュリティグループID\u0026#34; } live/prod/main.tf（本番のみスケジュール追加）\nresource \u0026#34;aws_autoscaling_schedule\u0026#34; \u0026#34;scale_out_during_business_hours\u0026#34; { scheduled_action_name = \u0026#34;scale-out-during-business-hours\u0026#34; min_size = 2 max_size = 10 desired_capacity = 10 recurrence = \u0026#34;0 9 * * *\u0026#34; # 毎日9時 autoscaling_group_name = module.webserver_cluster.asg_name # 出力を参照 } 注意点1: ファイルパス # 問題 # 相対パス \u0026quot;user-data.sh\u0026quot; はルートモジュールからの相対パスとして解釈される。モジュール内のファイルを参照できない。\n解決策: path.module # # Before（動かない） user_data = base64encode(templatefile(\u0026#34;user-data.sh\u0026#34;, { ... })) # After（正しく動く） user_data = base64encode(templatefile(\u0026#34;${path.module}/user-data.sh\u0026#34;, { ... })) パス参照 指す場所 path.module モジュール定義があるディレクトリ path.root ルートモジュールのディレクトリ path.cwd terraform applyを実行したディレクトリ 注意点2: インラインブロック # 問題 # セキュリティグループのingress/egressには2つの書き方がある。\nインラインブロック\nresource \u0026#34;aws_security_group\u0026#34; \u0026#34;alb\u0026#34; { name = \u0026#34;${var.cluster_name}-alb\u0026#34; ingress { # リソース内に直接書く from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } 別リソース\nresource \u0026#34;aws_security_group\u0026#34; \u0026#34;alb\u0026#34; { name = \u0026#34;${var.cluster_name}-alb\u0026#34; } resource \u0026#34;aws_security_group_rule\u0026#34; \u0026#34;allow_http\u0026#34; { type = \u0026#34;ingress\u0026#34; security_group_id = aws_security_group.alb.id from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } モジュールでは別リソースを推奨 # 方法 柔軟性 理由 インラインブロック 低 呼び出し側でルール追加不可 別リソース 高 呼び出し側で追加ルール定義可能 別リソースにすれば、ステージング環境のみテスト用ポートを追加、といったカスタマイズが可能。\n# live/stage/main.tf - テスト用ポートを追加 resource \u0026#34;aws_security_group_rule\u0026#34; \u0026#34;allow_testing\u0026#34; { type = \u0026#34;ingress\u0026#34; security_group_id = module.webserver_cluster.alb_security_group_id from_port = 12345 to_port = 12345 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } モジュールのバージョン管理 # 問題 # ローカルパス参照では、モジュールを変更すると全環境に即座に影響する。\n解決策: GitリポジトリとSemVer # モジュールを別リポジトリに分離 Gitタグでバージョンを付与 git tag -a \u0026#34;v0.0.1\u0026#34; -m \u0026#34;First release\u0026#34; git push --follow-tags 環境ごとに異なるバージョンを参照 # stage: 新バージョンをテスト source = \u0026#34;github.com/user/modules//services/webserver-cluster?ref=v0.0.2\u0026#34; # prod: 安定版を維持 source = \u0026#34;github.com/user/modules//services/webserver-cluster?ref=v0.0.1\u0026#34; GitHubでソースURL指定方法：github.com/user/repo\nセマンティックバージョニング # 変更内容 バージョン バグ修正 PATCH（v0.0.1 → v0.0.2） 後方互換のある機能追加 MINOR（v0.0.2 → v0.1.0） 破壊的変更 MAJOR（v0.1.0 → v1.0.0） エラー対応メモ # terraform init の実行場所 # Terraform initialized in an empty directory! → .tfファイルがあるディレクトリ（ルートモジュール）で実行すること。\nbackend設定がモジュール内に残っている # Error: Failed to get existing workspaces: S3 bucket does not exist. → providerとterraform { backend }はルートモジュールのみに書く。再利用可能なモジュールからは削除。\nモジュールに含めるべきもの # 設定 modules/ live/ provider - 必須 terraform { backend } - 必須 resource 必須 任意 variable 必須 任意 output 必須 任意 locals 任意 任意 まとめ # 学んだこと 内容 モジュールの基礎 フォルダ = モジュール 入力変数（variable） 環境ごとの違いを吸収 ローカル値（locals） 変更されたくない内部定数 出力（output） 外部から参照可能な値 ファイルパス path.moduleで正しく参照 インラインブロック 別リソースの方が柔軟 バージョン管理 Git + SemVerで安全なデプロイ モジュール化のメリット # DRY原則: 同じコードを複数環境で再利用 保守性: 1箇所の修正で全環境に反映 柔軟性: 入力変数で環境ごとのカスタマイズ 安全性: バージョン管理でテスト済みコードのみ本番適用 参考 # 詳解 Terraform 第3版 - Yevgeniy Brikman著、松浦隼人訳、オライリージャパン、2023年 Terraform公式ドキュメント 前回の記事: ファイルレイアウトとterraform_remote_state ","date":"2025年 11月 29日","externalUrl":null,"permalink":"/posts/251129154214_terraform-reusable-infrastructure-modules/","section":"Posts","summary":"","title":"Terraformモジュールで再利用可能なインフラを作る","type":"posts"},{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/tags/%E3%82%A4%E3%83%B3%E3%83%95%E3%83%A9/","section":"Tags","summary":"","title":"インフラ","type":"tags"},{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/tags/%E3%83%8F%E3%83%B3%E3%82%BA%E3%82%AA%E3%83%B3/","section":"Tags","summary":"","title":"ハンズオン","type":"tags"},{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/","section":"毎日.log","summary":"","title":"毎日.log","type":"page"},{"content":" キャッシュメモリのアドレスマッピング方式とは？ # 主記憶上の格納位置とキャッシュメモリ上の格納位置とをどのように対応させるかを決める方式として、ダイレクトマップ、フルアソシエイティブ、セットアソシエイティブがある。\nダイレクトマップ # 主記憶のアドレスからキャッシュメモリ上の格納位置（ブロック番号）が一意に決まる方式\n主記憶のアドレスの一部（下位ビット）をインデックスとして使用し、格納先を決定 回路構成が単純でコストが低い 主記憶上の異なるアドレスが、キャッシュメモリ上の同じ場所に割り当てられる「コンフリクト」が発生する可能性がある コンフリクトはキャッシュヒット率が低下する原因にもなる フルアソシエイティブ # 主記憶のブロックをキャッシュメモリ上のどのブロックにも格納することができる方式\nコンフリクトが発生しにくく、キャッシュヒット率が高い 検索にCAM（Content Addressable Memory：連想メモリ）を使用するため、回路が非常に複雑で高コスト 小容量のキャッシュ（TLBなど）で使用されることが多い セットアソシエイティブ # キャッシュメモリをいくつかの「セット」と呼ばれるグループに分け、主記憶のアドレスからはまず特定のセットが決定される。そのセットの中であれば、どのブロックにでも格納することができる。\nダイレクトマップとフルアソシエイティブの中間的な存在 現在の主流の方式（コストとパフォーマンスのバランスが良い） n-way セットアソシエイティブ: 1つのセット内に格納できるブロック数を「n」で表す 2-way: 1セットに2ブロック格納可能 4-way: 1セットに4ブロック格納可能 nが大きいほどフルアソシエイティブに近づき、ヒット率は上がるがコストも増加 3方式の比較 # 方式 格納位置の自由度 回路の複雑さ コスト ヒット率 ダイレクトマップ 低（1箇所固定） 単純 低 低 フルアソシエイティブ 高（どこでも可） 複雑 高 高 セットアソシエイティブ 中（セット内で自由） 中程度 中 中 参考リンク # 応用情報技術者過去問道場：令和4年春期 問10 出典：応用情報技術者：令和4年春期 問10 ","date":"2025年 11月 29日","externalUrl":null,"permalink":"/posts/251129115424_cache-memory-address-mapping/","section":"Posts","summary":"","title":"キャッシュメモリのアドレスマッピング方式","type":"posts"},{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/tags/%E3%83%A1%E3%83%A2/","section":"Tags","summary":"","title":"メモ","type":"tags"},{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/tags/%E5%BF%9C%E7%94%A8%E6%83%85%E5%A0%B1%E6%8A%80%E8%A1%93%E8%80%85/","section":"Tags","summary":"","title":"応用情報技術者","type":"tags"},{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/tags/%E5%85%A5%E9%96%80/","section":"Tags","summary":"","title":"入門","type":"tags"},{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/tags/%E3%81%BE%E3%81%A8%E3%82%81/","section":"Tags","summary":"","title":"まとめ","type":"tags"},{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/tags/%E5%BF%9C%E7%94%A8%E6%83%85%E5%A0%B1%E6%8A%80%E8%A1%93%E8%80%85%E8%A9%A6%E9%A8%93/","section":"Tags","summary":"","title":"応用情報技術者試験","type":"tags"},{"content":" 問題 # 出典：応用情報技術者平成26年春期問18 仮想記憶方式において、論理アドレスから物理アドレスへの変換を行うのはいつか。\n選択肢\nページを補助記憶にページアウトするとき ページフォールトが発生したとき 主記憶に存在するページをアクセスするとき ページを主記憶にページインするとき 正解：主記憶に存在するページをアクセスするとき # 基本的な仕組み # 論理アドレスから物理アドレスへの変換は、CPUがメモリアクセスを行うたびに実行されます。\n担当ハードウェア: MMU（メモリ管理ユニット） 使用する対応表: ページテーブル 実行タイミング: 主記憶上のページへアクセスするとき（毎回） 処理速度: 高速（ハードウェア処理） 他の選択肢が不正解な理由 # ページアウト # 主記憶の空き容量確保のため、使用頻度の低いページを補助記憶に退避する処理 OSによるメモリ管理動作であり、アドレス変換処理そのものではない ページフォールト # アドレス変換を試みた結果、失敗したときに発生する例外（割り込み） 変換が行われるタイミングではなく、変換失敗の結果発生する事象 ページイン # ページフォールト発生後、補助記憶から主記憶にページを読み込む処理 ページイン完了後に、改めてアドレス変換が行われる Q\u0026amp;A：よくある誤解 # Q1. ページイン・ページアウトでも変換が発生する？ # A. いいえ、厳密には異なります。\nアドレス変換はCPUの命令実行に伴う処理であり、ページイン・ページアウトの最中に行われるわけではありません。\nQ2. アドレス変換が失敗したらどうなる？ # A. 以下の流れで処理されます。\nアドレス変換失敗 ↓ ページフォールト発生 ↓ OS介入（ページイン処理） ↓ 変換成功（メモリアクセス実行） 詳細：各処理とアドレス変換の関係 # アドレス変換が行われるタイミング # CPUがプログラムを実行し、メモリアクセスするたびにMMUが論理アドレスを物理アドレスに変換します。これは主記憶上のページが存在する場合に毎回実行される高速処理です。\nページインとアドレス変換 # ページインはアドレス変換の失敗がきっかけで発生します。\nCPUが論理アドレスにアクセス → MMUがアドレス変換を試行 ページが主記憶に存在しない → 変換失敗 → ページフォールト発生 OSが補助記憶装置から必要なページを主記憶に読み込む（ページイン） ページテーブル更新 中断していた命令を再開 → MMUが再度アドレス変換を試行 → 成功 ページアウトとアドレス変換 # ページアウトは、ページインのための空き領域確保を目的としたOSのメモリ管理動作です。\nページフォールト発生 → ページイン必要 → 主記憶に空きがない OSがページの置き換え対象を決定 選ばれたページを補助記憶装置に書き出す（ページアウト） CPUによるアドレス変換処理そのものではありません。\nまとめ # 処理 役割 アドレス変換との関係 アドレス変換 MMUによる論理→物理アドレス変換 主記憶アクセス時に毎回実行 ページフォールト アドレス変換失敗時の例外 変換失敗の結果 ページイン 補助記憶→主記憶へのページ読み込み 完了後に変換が再実行される ページアウト 主記憶→補助記憶へのページ退避 変換処理ではない（メモリ管理） 仮想記憶の処理フロー # 1. アドレス変換の試行 ├─ 成功 → メモリアクセス実行 └─ 失敗 → 2へ 2. ページフォールト発生（例外割り込み） └─ OSに制御移行 3. OS処理 ├─ ページ検索（補助記憶装置） ├─ 空き領域確保（必要なら4へ） └─ ページイン実行 4. ページアウト（空き容量不足時） ├─ 置き換え対象選択 └─ 補助記憶へ退避 5. ページテーブル更新 6. 処理再開 → 1へ戻る（今度は成功） 重要ポイント: ページイン・ページアウトは、アドレス変換を円滑に動かすためのOSによる裏方の管理作業です。\n","date":"2025年 11月 29日","externalUrl":null,"permalink":"/posts/251129114929_virtual-memory-address-translation/","section":"Posts","summary":"","title":"仮想記憶のアドレス変換","type":"posts"},{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/tags/vscode/","section":"Tags","summary":"","title":"VSCode","type":"tags"},{"content":" VSCode マルチカーソル編集とは？ # 複数箇所を同時編集できる便利機能。 変数名の一括変更やインデント調整など、繰り返し作業を大幅に効率化できる。\nショートカット一覧 # 操作 Windows Mac 任意の位置にカーソル追加 Alt + クリック Option + クリック 上下に連続カーソル追加 Ctrl + Alt + ↑/↓ Cmd + Option + ↑/↓ 矩形（ボックス）選択 Alt + Shift + ドラッグ Option + Shift + ドラッグ 行頭へ移動 Home Cmd + ← 同じ単語を全選択 Ctrl + Shift + L Cmd + Shift + L 使い分け # シーン 推奨操作 飛び飛びの行を編集 Alt + クリック 連続した行を編集 Ctrl + Alt + ↓ で一気に追加 縦に揃った範囲を編集 矩形選択 実践例 # 連続行の先頭にコメント追加\n最初の行の先頭にカーソルを置く Ctrl + Alt + ↓ で下方向にカーソルを増やす // を入力 → 全行に一括挿入 練習用テキスト # 下記のテキストでマルチカーソル編集を試してみよう：\n例1: 行頭に const を追加してみよう\nname = \u0026#34;Alice\u0026#34; age = 25 city = \u0026#34;Tokyo\u0026#34; email = \u0026#34;alice@example.com\u0026#34; 例2: 行末に ; を追加してみよう\nimport React from \u0026#39;react\u0026#39; import useState from \u0026#39;react\u0026#39; import useEffect from \u0026#39;react\u0026#39; 例3: 各行を console.log() で囲んでみよう\nuser.name user.age user.email ","date":"2025年 11月 29日","externalUrl":null,"permalink":"/posts/251129112924_vscode-multi-cursor-editing/","section":"Posts","summary":"","title":"VSCode_マルチカーソル編集","type":"posts"},{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/tags/%E3%83%84%E3%83%BC%E3%83%AB/","section":"Tags","summary":"","title":"ツール","type":"tags"},{"content":"","date":"2025年 11月 29日","externalUrl":null,"permalink":"/tags/%E5%AE%9F%E8%B7%B5/","section":"Tags","summary":"","title":"実践","type":"tags"},{"content":" 今日学んだこと # 前回の記事でワークスペースによるステート分離を学んだが、本番環境の分離には不十分だった。今回はファイルレイアウトによる分離を実践し、RDSとWebサーバーを別々に管理しながらterraform_remote_stateで連携させる方法を学んだ。\n前回の振り返り: ワークスペースの限界 # Part1でワークスペースの欠点を確認した。\n欠点 説明 同一バックエンド 全環境が同じS3/DynamoDBを使用（権限分離が困難） 可視性が低い 今どのワークスペースにいるか分かりにくい 誤操作リスク terraform workspace select prod を忘れて本番を破壊する可能性 これらの問題を解決するのがファイルレイアウトによる分離。\nファイルレイアウトによる分離とは # 環境ごと・コンポーネントごとに別のディレクトリで管理する方法。\nterraform-project/ ├── stage/ # ステージング環境 │ ├── data-stores/mysql/ # DB層（変更頻度: 低） │ └── services/webserver-cluster/ # App層（変更頻度: 高） └── prod/ # 本番環境（完全に別管理） ├── data-stores/mysql/ └── services/webserver-cluster/ なぜコンポーネントも分離するのか # レイヤー 変更頻度 リスク VPC/ネットワーク 月1回程度 高（全体に影響） データベース 週1回程度 高（データ損失） Webサーバー 1日数回 低（再デプロイ可能） 頻繁に変更するWebサーバーと、めったに変更しないDBを同じステートで管理すると、Webサーバーの変更時に誤ってDBを破壊するリスクがある。\n分離されたコンポーネント間の連携 # 問題: RDSとWebサーバーが別プロジェクトになると、WebサーバーはRDSの接続情報をどうやって知るのか？\n解決: terraform_remote_stateで別プロジェクトのステートからoutputを参照する。\n[mysql/] [webserver-cluster/] │ │ └── outputs.tf で address/port を出力 │ │ │ └──────────────────────────────┼──→ terraform_remote_state で参照 Step 1: RDSの構築 # ディレクトリ構成 # mkdir -p stage/data-stores/mysql cd stage/data-stores/mysql variables.tf # variable \u0026#34;db_name\u0026#34; { description = \u0026#34;データベース名\u0026#34; type = string default = \u0026#34;example_database\u0026#34; } variable \u0026#34;db_username\u0026#34; { description = \u0026#34;データベースのユーザー名\u0026#34; type = string sensitive = true } variable \u0026#34;db_password\u0026#34; { description = \u0026#34;データベースのパスワード\u0026#34; type = string sensitive = true } sensitive = trueを指定すると、terraform planやterraform applyの出力でマスクされる。\nmain.tf # provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } terraform { backend \u0026#34;s3\u0026#34; { # 重要: keyはRDS専用のパスにする key = \u0026#34;stage/data-stores/mysql/terraform.tfstate\u0026#34; bucket = \u0026#34;tf-state-backend-20251128\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true } } resource \u0026#34;aws_db_instance\u0026#34; \u0026#34;example\u0026#34; { identifier_prefix = \u0026#34;terraform-up-and-running\u0026#34; engine = \u0026#34;mysql\u0026#34; allocated_storage = 10 instance_class = \u0026#34;db.t3.micro\u0026#34; skip_final_snapshot = true db_name = var.db_name username = var.db_username password = var.db_password } outputs.tf（重要） # Webサーバーから参照するために、接続情報をoutputとして公開する。\noutput \u0026#34;address\u0026#34; { value = aws_db_instance.example.address description = \u0026#34;データベースの接続エンドポイント\u0026#34; } output \u0026#34;port\u0026#34; { value = aws_db_instance.example.port description = \u0026#34;データベースのポート番号\u0026#34; } デプロイ # terraform init terraform apply # var.db_username: admin # var.db_password: yourpassword123 RDSの作成には5-10分かかる。完了したらterraform outputで接続情報を確認できる。\nStep 2: Webサーバークラスタの構築 # ディレクトリ構成 # mkdir -p stage/services/webserver-cluster cd stage/services/webserver-cluster terraform_remote_stateとは # なぜ必要なのか # ファイルレイアウトで分離すると、RDSとWebサーバーは別々のTerraformプロジェクトになる。それぞれが独自のステートファイルを持つため、通常の方法では互いのリソース情報にアクセスできない。\n[mysql/] [webserver-cluster/] terraform.tfstate terraform.tfstate │ │ └── RDSのaddress/portを保持 └── RDSの情報が必要だが...？ WebサーバーがRDSに接続するには、RDSのエンドポイント（address/port）が必要。これを解決するのがterraform_remote_state。\n仕組み # terraform_remote_stateは読み取り専用のデータソースで、別プロジェクトのステートファイルからoutputで公開された値を取得する。\n[mysql/] [webserver-cluster/] │ │ ├── outputs.tf で address/port を公開 │ │ │ │ │ ▼ │ │ S3に保存されたステート ◀─────────────────────┤ │ (stage/data-stores/mysql/ │ │ terraform.tfstate) │ │ │ │ │ │ terraform_remote_state で読み取り │ │ └──────────────────────────────────────▶ db_address, db_port として使用 重要: terraform_remote_stateで読み取れるのはoutputで明示的に公開された値のみ。ステートファイル内の全リソース情報にアクセスできるわけではない。\n基本構文 # data \u0026#34;terraform_remote_state\u0026#34; \u0026#34;db\u0026#34; { backend = \u0026#34;s3\u0026#34; # バックエンドの種類 config = { bucket = \u0026#34;tf-state-backend-20251128\u0026#34; key = \u0026#34;stage/data-stores/mysql/terraform.tfstate\u0026#34; # RDSのステートのkey region = \u0026#34;ap-northeast-1\u0026#34; } } 属性 説明 backend 参照先のバックエンド種類（s3, gcs, azurerm等） config.bucket S3バケット名 config.key 参照先プロジェクトのステートファイルのkey config.region S3バケットのリージョン 参照方法 # # outputs.address を参照 data.terraform_remote_state.db.outputs.address # outputs.port を参照 data.terraform_remote_state.db.outputs.port ハードコードとの比較 # 方式 コード例 問題点 ハードコード db_address = \u0026quot;terraform-xxx.rds.amazonaws.com\u0026quot; RDS再作成時に手動更新が必要 terraform_remote_state db_address = data.terraform_remote_state.db.outputs.address 自動的に最新値を取得 # NG: ハードコード db_address = \u0026#34;terraform-xxx.rds.amazonaws.com\u0026#34; # → RDSを再作成するとアドレスが変わり、手動更新が必要 # → 複数環境で異なる値を管理する必要がある # OK: terraform_remote_state db_address = data.terraform_remote_state.db.outputs.address # → RDSが変わっても terraform plan/apply 時に最新のアドレスを取得 # → 環境ごとにkeyを変えるだけで対応可能 注意点 # 注意点 説明 keyの一致 terraform_remote_stateのkeyは、参照先プロジェクトのbackend設定と完全に一致させること outputの公開 参照したい値は参照先でoutputとして定義する必要がある 依存関係 参照先（RDS）を先にデプロイしてからWebサーバーをデプロイすること 読み取り専用 ステートの読み取りのみ可能。変更はできない templatefile関数 # 外部ファイルを読み込み、変数を埋め込む関数。\nuser_data = base64encode(templatefile(\u0026#34;user-data.sh\u0026#34;, { server_port = var.server_port db_address = data.terraform_remote_state.db.outputs.address db_port = data.terraform_remote_state.db.outputs.port })) HCLとbashを分離することで可読性が向上し、スクリプト単体でのテストも可能になる。\nuser-data.sh # #!/bin/bash cd /home/ec2-user cat \u0026gt; index.html \u0026lt;\u0026lt;EOF \u0026lt;h1\u0026gt;Hello, World\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;DB address: ${db_address}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;DB port: ${db_port}\u0026lt;/p\u0026gt; EOF nohup python3 -m http.server ${server_port} \u0026amp; 注意: このコードは terraform_remote_state の動作確認用サンプルです。ブラウザでアクセスするとDBの接続情報が画面に表示されます。実際の運用環境では、このような機密情報をHTMLページに表示せず、アプリケーション内部でのみ使用してください。\nvariables.tf # variable \u0026#34;server_port\u0026#34; { description = \u0026#34;HTTPリクエストを受け付けるポート番号\u0026#34; type = number default = 8080 } variable \u0026#34;alb_name\u0026#34; { description = \u0026#34;ALBの名前\u0026#34; type = string default = \u0026#34;terraform-asg-example\u0026#34; } variable \u0026#34;alb_security_group_name\u0026#34; { description = \u0026#34;ALB用セキュリティグループの名前\u0026#34; type = string default = \u0026#34;terraform-example-alb\u0026#34; } variable \u0026#34;instance_security_group_name\u0026#34; { description = \u0026#34;EC2インスタンス用セキュリティグループの名前\u0026#34; type = string default = \u0026#34;terraform-example-instance\u0026#34; } main.tf # provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } terraform { backend \u0026#34;s3\u0026#34; { bucket = \u0026#34;tf-state-backend-20251128\u0026#34; key = \u0026#34;stage/services/webserver-cluster/terraform.tfstate\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true } } # ----------------------------------------------------------------------------- # Data Sources # ----------------------------------------------------------------------------- data \u0026#34;aws_vpc\u0026#34; \u0026#34;default\u0026#34; { default = true } data \u0026#34;aws_subnets\u0026#34; \u0026#34;default\u0026#34; { filter { name = \u0026#34;vpc-id\u0026#34; values = [data.aws_vpc.default.id] } } # RDSの状態をリモートステートから取得 data \u0026#34;terraform_remote_state\u0026#34; \u0026#34;db\u0026#34; { backend = \u0026#34;s3\u0026#34; config = { bucket = \u0026#34;tf-state-backend-20251128\u0026#34; key = \u0026#34;stage/data-stores/mysql/terraform.tfstate\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; } } # ----------------------------------------------------------------------------- # Launch Template \u0026amp; Auto Scaling Group # ----------------------------------------------------------------------------- resource \u0026#34;aws_launch_template\u0026#34; \u0026#34;example\u0026#34; { image_id = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; instance_type = \u0026#34;t2.micro\u0026#34; vpc_security_group_ids = [aws_security_group.instance.id] user_data = base64encode(templatefile(\u0026#34;user-data.sh\u0026#34;, { server_port = var.server_port db_address = data.terraform_remote_state.db.outputs.address db_port = data.terraform_remote_state.db.outputs.port })) } resource \u0026#34;aws_autoscaling_group\u0026#34; \u0026#34;example\u0026#34; { vpc_zone_identifier = data.aws_subnets.default.ids launch_template { id = aws_launch_template.example.id version = \u0026#34;$Latest\u0026#34; } target_group_arns = [aws_lb_target_group.asg.arn] health_check_type = \u0026#34;ELB\u0026#34; min_size = 2 max_size = 10 tag { key = \u0026#34;Name\u0026#34; value = \u0026#34;terraform-asg-example\u0026#34; propagate_at_launch = true } } # ----------------------------------------------------------------------------- # Security Groups # ----------------------------------------------------------------------------- resource \u0026#34;aws_security_group\u0026#34; \u0026#34;instance\u0026#34; { name = var.instance_security_group_name ingress { from_port = var.server_port to_port = var.server_port protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } resource \u0026#34;aws_security_group\u0026#34; \u0026#34;alb\u0026#34; { name = var.alb_security_group_name ingress { from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } # ----------------------------------------------------------------------------- # Application Load Balancer # ----------------------------------------------------------------------------- resource \u0026#34;aws_lb\u0026#34; \u0026#34;example\u0026#34; { name = var.alb_name load_balancer_type = \u0026#34;application\u0026#34; subnets = data.aws_subnets.default.ids security_groups = [aws_security_group.alb.id] } resource \u0026#34;aws_lb_listener\u0026#34; \u0026#34;http\u0026#34; { load_balancer_arn = aws_lb.example.arn port = 80 protocol = \u0026#34;HTTP\u0026#34; default_action { type = \u0026#34;fixed-response\u0026#34; fixed_response { content_type = \u0026#34;text/plain\u0026#34; message_body = \u0026#34;404: page not found\u0026#34; status_code = 404 } } } resource \u0026#34;aws_lb_target_group\u0026#34; \u0026#34;asg\u0026#34; { name = var.alb_name port = var.server_port protocol = \u0026#34;HTTP\u0026#34; vpc_id = data.aws_vpc.default.id health_check { path = \u0026#34;/\u0026#34; protocol = \u0026#34;HTTP\u0026#34; matcher = \u0026#34;200\u0026#34; interval = 15 timeout = 3 healthy_threshold = 2 unhealthy_threshold = 2 } } resource \u0026#34;aws_lb_listener_rule\u0026#34; \u0026#34;asg\u0026#34; { listener_arn = aws_lb_listener.http.arn priority = 100 condition { path_pattern { values = [\u0026#34;*\u0026#34;] } } action { type = \u0026#34;forward\u0026#34; target_group_arn = aws_lb_target_group.asg.arn } } outputs.tf # output \u0026#34;alb_dns_name\u0026#34; { value = aws_lb.example.dns_name description = \u0026#34;ロードバランサーのDNS名\u0026#34; } output \u0026#34;asg_name\u0026#34; { value = aws_autoscaling_group.example.name description = \u0026#34;Auto Scaling Groupの名前\u0026#34; } デプロイ # terraform init terraform apply Step 3: 動作確認 # terraform consoleで確認 # terraform console \u0026gt; data.terraform_remote_state.db.outputs { \u0026#34;address\u0026#34; = \u0026#34;terraform-up-and-running-xxx.rds.amazonaws.com\u0026#34; \u0026#34;port\u0026#34; = 3306 } \u0026gt; exit ブラウザで確認 # # ALBのDNS名を取得 terraform output alb_dns_name # curlで確認 curl http://\u0026lt;ALB_DNS_NAME\u0026gt; 「Hello, World」と「DB address」「DB port」が表示されれば成功。\nクリーンアップ: 依存関係と削除順序 # なぜ削除順序が重要なのか # Terraformリソースには依存関係がある。依存されているリソースを先に削除しようとするとエラーになる。\n[Webサーバー] ──依存──→ [RDS] │ │ │ └── 接続情報（address/port）を参照 │ └── terraform_remote_state でRDSのステートを参照 [S3/DynamoDB] │ └── 全プロジェクトのステートを保管・ロック 正しい削除順序: 依存する側 → 依存される側\n# 1. Webサーバー（RDSに依存） cd stage/services/webserver-cluster terraform destroy # 2. RDS cd ../../../stage/data-stores/mysql terraform destroy # 3. S3/DynamoDB（全体のバックエンド）- 必要な場合のみ 逆順で削除しようとした場合:\nS3を先に削除 → Webサーバーのステートにアクセスできずエラー RDSを先に削除 → Webサーバーの terraform_remote_state がエラー 構築したアーキテクチャ # ┌─────────────────────────────────────────────────────────────────┐ │ S3 Backend │ │ ├── stage/data-stores/mysql/terraform.tfstate ← RDSの状態 │ │ └── stage/services/webserver-cluster/terraform.tfstate │ └────────────────────────────────────────────────────────────────┘ │ │ terraform_remote_state で参照 ▼ ┌─────────────────────────────────────────────────────────────────┐ │ Webサーバー │ │ ┌──────────────────┐ ┌──────────────────┐ │ │ │ ALB (port 80) │───▶│ ASG (EC2 x2) │ │ │ └──────────────────┘ └──────────────────┘ │ │ │ │ │ │ DB接続情報を取得 │ │ ▼ │ │ ┌──────────────────┐ │ │ │ RDS (MySQL) │ │ │ └──────────────────┘ │ └─────────────────────────────────────────────────────────────────┘ 完成形のコード # ディレクトリ構成 # stage/ ├── data-stores/ │ └── mysql/ │ ├── main.tf │ ├── variables.tf │ └── outputs.tf └── services/ └── webserver-cluster/ ├── main.tf ├── variables.tf ├── outputs.tf └── user-data.sh stage/data-stores/mysql/ main.tf\nprovider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } terraform { backend \u0026#34;s3\u0026#34; { key = \u0026#34;stage/data-stores/mysql/terraform.tfstate\u0026#34; bucket = \u0026#34;tf-state-backend-20251128\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true } } resource \u0026#34;aws_db_instance\u0026#34; \u0026#34;example\u0026#34; { identifier_prefix = \u0026#34;terraform-up-and-running\u0026#34; engine = \u0026#34;mysql\u0026#34; allocated_storage = 10 instance_class = \u0026#34;db.t3.micro\u0026#34; skip_final_snapshot = true db_name = var.db_name username = var.db_username password = var.db_password } variables.tf\nvariable \u0026#34;db_name\u0026#34; { description = \u0026#34;データベース名\u0026#34; type = string default = \u0026#34;example_database\u0026#34; } variable \u0026#34;db_username\u0026#34; { description = \u0026#34;データベースのユーザー名\u0026#34; type = string sensitive = true } variable \u0026#34;db_password\u0026#34; { description = \u0026#34;データベースのパスワード\u0026#34; type = string sensitive = true } outputs.tf\noutput \u0026#34;address\u0026#34; { value = aws_db_instance.example.address description = \u0026#34;データベースの接続エンドポイント\u0026#34; } output \u0026#34;port\u0026#34; { value = aws_db_instance.example.port description = \u0026#34;データベースのポート番号\u0026#34; } stage/services/webserver-cluster/ main.tf\nprovider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } terraform { backend \u0026#34;s3\u0026#34; { bucket = \u0026#34;tf-state-backend-20251128\u0026#34; key = \u0026#34;stage/services/webserver-cluster/terraform.tfstate\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true } } # ----------------------------------------------------------------------------- # Data Sources # ----------------------------------------------------------------------------- data \u0026#34;aws_vpc\u0026#34; \u0026#34;default\u0026#34; { default = true } data \u0026#34;aws_subnets\u0026#34; \u0026#34;default\u0026#34; { filter { name = \u0026#34;vpc-id\u0026#34; values = [data.aws_vpc.default.id] } } data \u0026#34;terraform_remote_state\u0026#34; \u0026#34;db\u0026#34; { backend = \u0026#34;s3\u0026#34; config = { bucket = \u0026#34;tf-state-backend-20251128\u0026#34; key = \u0026#34;stage/data-stores/mysql/terraform.tfstate\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; } } # ----------------------------------------------------------------------------- # Launch Template \u0026amp; Auto Scaling Group # ----------------------------------------------------------------------------- resource \u0026#34;aws_launch_template\u0026#34; \u0026#34;example\u0026#34; { image_id = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; instance_type = \u0026#34;t2.micro\u0026#34; vpc_security_group_ids = [aws_security_group.instance.id] user_data = base64encode(templatefile(\u0026#34;user-data.sh\u0026#34;, { server_port = var.server_port db_address = data.terraform_remote_state.db.outputs.address db_port = data.terraform_remote_state.db.outputs.port })) } resource \u0026#34;aws_autoscaling_group\u0026#34; \u0026#34;example\u0026#34; { vpc_zone_identifier = data.aws_subnets.default.ids launch_template { id = aws_launch_template.example.id version = \u0026#34;$Latest\u0026#34; } target_group_arns = [aws_lb_target_group.asg.arn] health_check_type = \u0026#34;ELB\u0026#34; min_size = 2 max_size = 10 tag { key = \u0026#34;Name\u0026#34; value = \u0026#34;terraform-asg-example\u0026#34; propagate_at_launch = true } } # ----------------------------------------------------------------------------- # Security Groups # ----------------------------------------------------------------------------- resource \u0026#34;aws_security_group\u0026#34; \u0026#34;instance\u0026#34; { name = var.instance_security_group_name ingress { from_port = var.server_port to_port = var.server_port protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } resource \u0026#34;aws_security_group\u0026#34; \u0026#34;alb\u0026#34; { name = var.alb_security_group_name ingress { from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } # ----------------------------------------------------------------------------- # Application Load Balancer # ----------------------------------------------------------------------------- resource \u0026#34;aws_lb\u0026#34; \u0026#34;example\u0026#34; { name = var.alb_name load_balancer_type = \u0026#34;application\u0026#34; subnets = data.aws_subnets.default.ids security_groups = [aws_security_group.alb.id] } resource \u0026#34;aws_lb_listener\u0026#34; \u0026#34;http\u0026#34; { load_balancer_arn = aws_lb.example.arn port = 80 protocol = \u0026#34;HTTP\u0026#34; default_action { type = \u0026#34;fixed-response\u0026#34; fixed_response { content_type = \u0026#34;text/plain\u0026#34; message_body = \u0026#34;404: page not found\u0026#34; status_code = 404 } } } resource \u0026#34;aws_lb_target_group\u0026#34; \u0026#34;asg\u0026#34; { name = var.alb_name port = var.server_port protocol = \u0026#34;HTTP\u0026#34; vpc_id = data.aws_vpc.default.id health_check { path = \u0026#34;/\u0026#34; protocol = \u0026#34;HTTP\u0026#34; matcher = \u0026#34;200\u0026#34; interval = 15 timeout = 3 healthy_threshold = 2 unhealthy_threshold = 2 } } resource \u0026#34;aws_lb_listener_rule\u0026#34; \u0026#34;asg\u0026#34; { listener_arn = aws_lb_listener.http.arn priority = 100 condition { path_pattern { values = [\u0026#34;*\u0026#34;] } } action { type = \u0026#34;forward\u0026#34; target_group_arn = aws_lb_target_group.asg.arn } } variables.tf\nvariable \u0026#34;server_port\u0026#34; { description = \u0026#34;HTTPリクエストを受け付けるポート番号\u0026#34; type = number default = 8080 } variable \u0026#34;alb_name\u0026#34; { description = \u0026#34;ALBの名前\u0026#34; type = string default = \u0026#34;terraform-asg-example\u0026#34; } variable \u0026#34;alb_security_group_name\u0026#34; { description = \u0026#34;ALB用セキュリティグループの名前\u0026#34; type = string default = \u0026#34;terraform-example-alb\u0026#34; } variable \u0026#34;instance_security_group_name\u0026#34; { description = \u0026#34;EC2インスタンス用セキュリティグループの名前\u0026#34; type = string default = \u0026#34;terraform-example-instance\u0026#34; } outputs.tf\noutput \u0026#34;alb_dns_name\u0026#34; { value = aws_lb.example.dns_name description = \u0026#34;ロードバランサーのDNS名\u0026#34; } output \u0026#34;asg_name\u0026#34; { value = aws_autoscaling_group.example.name description = \u0026#34;Auto Scaling Groupの名前\u0026#34; } user-data.sh\n#!/bin/bash cd /home/ec2-user cat \u0026gt; index.html \u0026lt;\u0026lt;EOF \u0026lt;h1\u0026gt;Hello, World\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;DB address: ${db_address}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;DB port: ${db_port}\u0026lt;/p\u0026gt; EOF nohup python3 -m http.server ${server_port} \u0026amp; まとめ # 学んだこと # 項目 内容 ファイルレイアウト分離 環境・コンポーネントごとにディレクトリを分けて完全分離 outputs.tf 他プロジェクトに公開したい値を定義 terraform_remote_state 別プロジェクトのoutputを参照 templatefile 外部ファイルに変数を埋め込む 削除順序 依存する側 → 依存される側の順で削除 ワークスペース vs ファイルレイアウト # 観点 ワークスペース ファイルレイアウト 設定の手軽さ 簡単 ディレクトリ構成が必要 権限分離 困難（同一バックエンド） 可能（別バックエンド） 可視性 低い 高い（ディレクトリ名で明確） コード重複 なし あり（ch4のモジュールで解決） 推奨用途 個人開発・実験 本番環境・チーム開発 チェックリスト # 各コンポーネントのkeyは一意か RDSのoutputs.tfでaddress/portを出力しているか terraform_remote_stateのkeyはRDSと一致しているか 削除は依存関係の逆順で行っているか 参考 # 詳解 Terraform 第3版 ―Infrastructure as Codeを実現する 著者：Yevgeniy Brikman 訳者：松浦 隼人 出版社：オライリージャパン 出版年：2023年 Terraform公式ドキュメント Terraformステート管理 Part1 - S3リモートバックエンドとワークスペース ","date":"2025年 11月 28日","externalUrl":null,"permalink":"/posts/251128193149_terraform-file-layout-separation/","section":"Posts","summary":"","title":"Terraformステート管理 Part2 - ファイルレイアウトとterraform_remote_state","type":"posts"},{"content":" 今日学んだこと # Terraformのステート管理について、S3リモートバックエンドの構築からワークスペースによる環境分離まで実践した。途中でステートファイルの上書き事故も経験し、その復旧作業から多くの教訓を得た。\nTerraformステートとは # Terraformはインフラの現在状態をterraform.tfstateというファイルに記録している。terraform planやterraform applyを実行すると、このステートファイルとAWSの実際の状態を比較して差分を検出する。\n{ \u0026#34;version\u0026#34;: 4, \u0026#34;terraform_version\u0026#34;: \u0026#34;1.6.0\u0026#34;, \u0026#34;serial\u0026#34;: 42, \u0026#34;resources\u0026#34;: [] } 個人開発ではローカル保存で問題ないが、チーム開発では以下の課題が発生する\n課題 問題点 共有 メンバー間でステートを共有できない ロック 同時編集で競合が発生する セキュリティ 機密情報がローカルに残る これを解決するのがリモートバックエンド。\nStep 1: リモートバックエンド用のS3・DynamoDBを作成 # ディレクトリ作成 # mkdir -p ~/terraform-state-study cd ~/terraform-state-study main.tfを作成 # # main.tf provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } # S3バケット（ステートファイル保管用） resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;terraform_state\u0026#34; { # 重要: バケット名はAWS全体でグローバルに一意にすること bucket = \u0026#34;tf-state-backend-20251128\u0026#34; # 誤削除防止（学習時はコメントアウト） # lifecycle { # prevent_destroy = true # } } # バージョニング有効化（ロールバック可能に） resource \u0026#34;aws_s3_bucket_versioning\u0026#34; \u0026#34;enabled\u0026#34; { bucket = aws_s3_bucket.terraform_state.id versioning_configuration { status = \u0026#34;Enabled\u0026#34; } } # サーバーサイド暗号化 resource \u0026#34;aws_s3_bucket_server_side_encryption_configuration\u0026#34; \u0026#34;default\u0026#34; { bucket = aws_s3_bucket.terraform_state.id rule { apply_server_side_encryption_by_default { sse_algorithm = \u0026#34;AES256\u0026#34; } } } # パブリックアクセスブロック resource \u0026#34;aws_s3_bucket_public_access_block\u0026#34; \u0026#34;public_access\u0026#34; { bucket = aws_s3_bucket.terraform_state.id block_public_acls = true block_public_policy = true ignore_public_acls = true restrict_public_buckets = true } # DynamoDBテーブル（ロック用） resource \u0026#34;aws_dynamodb_table\u0026#34; \u0026#34;terraform_locks\u0026#34; { name = \u0026#34;tf-state-locks\u0026#34; billing_mode = \u0026#34;PAY_PER_REQUEST\u0026#34; hash_key = \u0026#34;LockID\u0026#34; # 大文字小文字を完全一致させること attribute { name = \u0026#34;LockID\u0026#34; type = \u0026#34;S\u0026#34; } } デプロイ # terraform init terraform validate terraform apply 最初にtf-state-backendというバケット名で試したところ、既に他のユーザーに使われていてエラーになった。S3バケット名はグローバルで一意である必要があるため、日付を追加して解決した。\nlifecycleは誤削除を防止することが目的なので、リソース削除時はコメントアウトが必要。\nlifecycle { prevent_destroy = true } Step 2: ステートをS3に移行 # この時点ではステートはまだローカルに保存されている。S3に移行するためにbackend設定を追加する。\nbackend.hclを作成（部分設定） # backendブロックでは変数が使えないため、共通設定を外部ファイルに切り出す。\n# backend.hcl bucket = \u0026#34;tf-state-backend-20251128\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true main.tfにbackend設定を追加 # terraform { backend \u0026#34;s3\u0026#34; { key = \u0026#34;global/s3/terraform.tfstate\u0026#34; } } ステートを移行 # terraform init -backend-config=backend.hcl 「既存のステートをS3にコピーするか？」と聞かれるのでyesを入力。\nS3コンソールでglobal/s3/terraform.tfstateが作成されていることを確認できた。\nStep 3: ワークスペースによる分離を体験 # 同じコードで複数の環境（default、staging、prodなど）を管理する仕組み。\nワークスペース用ディレクトリ作成 # mkdir -p ~/terraform-state-study-workspace cd ~/terraform-state-study-workspace main.tfを作成 # provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } resource \u0026#34;aws_instance\u0026#34; \u0026#34;example\u0026#34; { ami = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; instance_type = \u0026#34;t2.micro\u0026#34; } terraform { backend \u0026#34;s3\u0026#34; { # 重要: Step 1（リモートバックエンド用）と異なるkeyを使用すること！ key = \u0026#34;workspace-example/terraform.tfstate\u0026#34; bucket = \u0026#34;tf-state-backend-20251128\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true } } ワークスペースの操作 # terraform init terraform apply # 現在のワークスペース確認 terraform workspace show # =\u0026gt; default # 新しいワークスペース作成 terraform workspace new example1 terraform apply # 別のEC2が作成される # さらに作成 terraform workspace new example2 terraform apply # 一覧確認 terraform workspace list # default # example1 # * example2 # 切り替え terraform workspace select example1 S3には以下のパスでステートが保存される：\ns3://bucket/ ├── workspace-example/terraform.tfstate # default └── env:/ ├── example1/workspace-example/terraform.tfstate └── example2/workspace-example/terraform.tfstate クリーンアップ # # 各ワークスペースでdestroy terraform workspace select example1 \u0026amp;\u0026amp; terraform destroy terraform workspace select example2 \u0026amp;\u0026amp; terraform destroy terraform workspace select default \u0026amp;\u0026amp; terraform destroy 実際に起きたトラブルと教訓 # 事故: 同じkeyを使い回してステートが上書きされた # Step 3（ワークスペース）でterraform applyを実行した際、最初はStep 1と同じkey（global/s3/terraform.tfstate）を使ってしまった。\nその結果：\nStep 1で作成したS3・DynamoDBリソースのステートが上書きされた Step 3のコードにはDynamoDBの定義がないため、Terraformは「削除すべきリソース」と判断 DynamoDBテーブルが削除された 以降のTerraform操作でロックが取れずエラー Error: Error acquiring the state lock ResourceNotFoundException: Requested resource not found 復旧方法 # # 緊急時のみ: ロックをスキップしてdestroy terraform destroy -lock=false S3バケットはバージョニングが有効なため、全オブジェクトバージョンを削除しないと削除できない：\n# オブジェクトバージョン確認 aws s3api list-object-versions --bucket \u0026lt;バケット名\u0026gt; --region ap-northeast-1 # 全バージョン削除後、バケット削除 aws s3 rb s3://\u0026lt;バケット名\u0026gt; 教訓 # 教訓 対策 keyは必ず一意にする 各プロジェクトでproject-name/terraform.tfstateのように分ける バックエンドのインフラは慎重に S3・DynamoDBが破壊されると全てに影響する -lock=falseは緊急時のみ 競合リスクがあるため通常は使用しない ファイルレイアウトによる分離（概要） # ワークスペースには以下の欠点がある：\n全環境で同じバックエンドを使用（権限分離が困難） どのワークスペースにいるか分かりにくい 誤操作で本番環境を破壊するリスク より堅牢な分離には、環境ごとにディレクトリを分ける方法が推奨される：\nterraform-project/ ├── stage/ # ステージング環境 │ ├── data-stores/mysql/ # DB層 │ └── services/webserver-cluster/ # App層 └── prod/ # 本番環境（完全に別管理） 分離したコンポーネント間（例: RDSとWebサーバー）で情報を共有するには、terraform_remote_stateデータソースを使用する。\n詳細な実装手順（RDS構築、terraform_remote_stateによる連携、templatefile関数の活用）はPart2で解説。\n完成形のコード # ディレクトリ構成 # ~/terraform-state-study/ # Step 1: リモートバックエンド用 ├── main.tf └── backend.hcl ~/terraform-state-study-workspace/ # Step 3: ワークスペース検証用 └── main.tf Step 1: リモートバックエンド用（~/terraform-state-study/） main.tf\nprovider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } # S3バケット（ステートファイル保管用） resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;terraform_state\u0026#34; { bucket = \u0026#34;tf-state-backend-20251128\u0026#34; # lifecycle { # prevent_destroy = true # } } # バージョニング有効化 resource \u0026#34;aws_s3_bucket_versioning\u0026#34; \u0026#34;enabled\u0026#34; { bucket = aws_s3_bucket.terraform_state.id versioning_configuration { status = \u0026#34;Enabled\u0026#34; } } # サーバーサイド暗号化 resource \u0026#34;aws_s3_bucket_server_side_encryption_configuration\u0026#34; \u0026#34;default\u0026#34; { bucket = aws_s3_bucket.terraform_state.id rule { apply_server_side_encryption_by_default { sse_algorithm = \u0026#34;AES256\u0026#34; } } } # パブリックアクセスブロック resource \u0026#34;aws_s3_bucket_public_access_block\u0026#34; \u0026#34;public_access\u0026#34; { bucket = aws_s3_bucket.terraform_state.id block_public_acls = true block_public_policy = true ignore_public_acls = true restrict_public_buckets = true } # DynamoDBテーブル（ロック用） resource \u0026#34;aws_dynamodb_table\u0026#34; \u0026#34;terraform_locks\u0026#34; { name = \u0026#34;tf-state-locks\u0026#34; billing_mode = \u0026#34;PAY_PER_REQUEST\u0026#34; hash_key = \u0026#34;LockID\u0026#34; attribute { name = \u0026#34;LockID\u0026#34; type = \u0026#34;S\u0026#34; } } terraform { backend \u0026#34;s3\u0026#34; { key = \u0026#34;global/s3/terraform.tfstate\u0026#34; } } backend.hcl\nbucket = \u0026#34;tf-state-backend-20251128\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true Step 3: ワークスペース用（~/terraform-state-study-workspace/） main.tf\nprovider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } resource \u0026#34;aws_instance\u0026#34; \u0026#34;example\u0026#34; { ami = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; instance_type = \u0026#34;t2.micro\u0026#34; } terraform { backend \u0026#34;s3\u0026#34; { key = \u0026#34;workspace-example/terraform.tfstate\u0026#34; bucket = \u0026#34;tf-state-backend-20251128\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true } } まとめ # 学んだこと # リモートバックエンド: S3 + DynamoDBでステート管理とロックを実現 部分設定: backend.hclで共通設定を切り出してコピペを削減 ワークスペース: 簡易な環境分離だが、可視性が低く誤操作リスクあり ファイルレイアウト: 本番環境の分離には環境ごとのディレクトリ分割が推奨（Part2で実践） チェックリスト # S3バケット名はグローバルで一意か DynamoDBのプライマリキーはLockID（大文字小文字一致）か 各プロジェクトのkeyは一意か 参考 # 詳解 Terraform 第3版 ―Infrastructure as Codeを実現する 著者：Yevgeniy Brikman 訳者：松浦 隼人 出版社：オライリージャパン 出版年：2023年 Terraform公式ドキュメント Terraformステート管理 Part2 - ファイルレイアウトとterraform_remote_state ","date":"2025年 11月 28日","externalUrl":null,"permalink":"/posts/251128185824_terraform-state-management-intro/","section":"Posts","summary":"","title":"Terraformステート管理 Part1 - S3リモートバックエンドとワークスペース","type":"posts"},{"content":" はじめに # 本記事は「詳解Terraform」のch2で学んだ内容を参考にしてハンズオン形式でまとめたものです。 Terraformを使って、ゼロからAWS環境を構築し、最後にすべて削除するまでを一気に体験します。\n最終的に作るもの # [ユーザー] → [ALB:80] → [ASG] → [EC2 × 2台:8080] ALB（Application Load Balancer）でトラフィックを受け付け Auto Scaling Group（ASG）で2台のEC2を管理 各EC2はポート8080でWebサーバを起動 1. 事前準備 # 1-1. AWSアカウントの作成 # AWSアカウントがない場合は、AWS公式サイトから作成してください。\n作業用のIAMユーザーを作成し、適切な権限を付与することを推奨します。\n1-2. AWS CLIの設定 # # AWS CLIをインストール（Ubuntu/WSL） sudo apt update sudo apt install -y unzip curl curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install # バージョン確認 aws --version # 認証情報を設定 aws configure # → Access Key ID, Secret Access Key, Region(ap-northeast-1)を入力 1-3. Terraformのインストール # # Ubuntu/WSL sudo apt update \u0026amp;\u0026amp; sudo apt install -y gnupg software-properties-common # HashiCorpのGPGキーを追加 wget -O- https://apt.releases.hashicorp.com/gpg | \\ gpg --dearmor | \\ sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg \u0026gt; /dev/null # リポジトリを追加 echo \u0026#34;deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] \\ https://apt.releases.hashicorp.com $(lsb_release -cs) main\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/hashicorp.list # Terraformをインストール sudo apt update \u0026amp;\u0026amp; sudo apt install -y terraform # バージョン確認 terraform version 1-4. 作業ディレクトリの作成 # mkdir terraform-handson cd terraform-handson 2. サーバ1台だけデプロイ # まずは最もシンプルな構成から。EC2インスタンス1台をデプロイします。\nなぜこの工程から始めるのか？ Terraformの基本であるprovider（どのクラウドを使うか）とresource（何を作るか）の概念を理解するため。また、init → plan → applyという基本ワークフローを体験することで、IaCの「コードでインフラを定義し、コマンドで構築する」流れを掴む。\n2-1. main.tfを作成 # provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } resource \u0026#34;aws_instance\u0026#34; \u0026#34;example\u0026#34; { ami = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; # Amazon Linux 2023（2025年11月時点） instance_type = \u0026#34;t2.micro\u0026#34; tags = { Name = \u0026#34;terraform-example\u0026#34; } } 2-2. Terraformの基本コマンド # # プロバイダのダウンロード（初回のみ） terraform init # 実行計画を確認（何が作られるか） terraform plan # 実際に作成 terraform apply # → \u0026#34;yes\u0026#34; と入力 2-3. 確認 # aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:Name,Values=terraform-example\u0026#34; \\ --query \u0026#34;Reservations[].Instances[].{ID:InstanceId,State:State.Name}\u0026#34; \\ --output table ここまでで学んだこと # 要素 説明 provider どのクラウドを使うか resource 何を作るか terraform init 初期化（プロバイダのダウンロード） terraform plan 実行計画の確認 terraform apply 実際に適用 3. Webサーバ1台のデプロイ # EC2を起動しただけではアクセスできません。セキュリティグループを追加し、Webサーバを動かします。\nなぜセキュリティグループが必要なのか？ AWSのEC2はデフォルトでインバウンド・アウトバウンドの両方のトラフィックを許可していない。外部からWebサーバにアクセスするには、セキュリティグループで明示的にポートを開放する必要がある。\nなぜポート8080を使うのか？ 1024以下のポート（80など）でリッスンするにはroot権限が必要。セキュリティ上、一般ユーザー権限で起動できる8080を使用する。\nなぜuser_dataを使うのか？ EC2起動時に自動でスクリプトを実行できる。手動でSSH接続してコマンドを打つ必要がなく、インフラ構築を完全に自動化できる。\n3-1. main.tfを更新 # provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } resource \u0026#34;aws_instance\u0026#34; \u0026#34;example\u0026#34; { ami = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; # Amazon Linux 2023（2025年11月時点） instance_type = \u0026#34;t2.micro\u0026#34; vpc_security_group_ids = [aws_security_group.instance.id] user_data = \u0026lt;\u0026lt;-EOF #!/bin/bash cd /home/ec2-user echo \u0026#34;Hello, World\u0026#34; \u0026gt; index.html nohup python3 -m http.server 8080 \u0026amp; EOF user_data_replace_on_change = true tags = { Name = \u0026#34;terraform-example\u0026#34; } } resource \u0026#34;aws_security_group\u0026#34; \u0026#34;instance\u0026#34; { name = \u0026#34;terraform-example-instance\u0026#34; ingress { from_port = 8080 to_port = 8080 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } 3-2. 適用と確認 # terraform apply # パブリックIPを取得 PUBLIC_IP=$(aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:Name,Values=terraform-example\u0026#34; \u0026#34;Name=instance-state-name,Values=running\u0026#34; \\ --query \u0026#34;Reservations[].Instances[].PublicIpAddress\u0026#34; \\ --output text) # アクセス確認 curl http://$PUBLIC_IP:8080 # → \u0026#34;Hello, World\u0026#34; が表示されればOK ここまでで学んだこと # 要素 説明 user_data 起動時に実行するスクリプト aws_security_group ファイアウォール設定 リソース参照 aws_security_group.instance.idのように他リソースを参照 4. 設定変更可能なWebサーバのデプロイ # ポート番号がコード内に散らばっています。変数化してDRY原則を守ります。\nなぜ変数化が必要なのか？ 現状、ポート番号8080がセキュリティグループとuser_dataの2箇所に書かれている。これはDRY原則（Don\u0026rsquo;t Repeat Yourself）に違反しており、変更時に片方だけ修正し忘れるリスクがある。変数化することで、1箇所の変更ですべてに反映される。\n出力変数（output）の用途は？ terraform apply後にパブリックIPなどの情報を自動表示できる。AWS CLIで毎回確認する手間が省け、他のTerraform構成の入力としても利用可能。\n4-1. 変数を追加 # variable \u0026#34;server_port\u0026#34; { description = \u0026#34;The port the server will use for HTTP requests\u0026#34; type = number default = 8080 } 4-2. 変数を使う # セキュリティグループを修正：\nresource \u0026#34;aws_security_group\u0026#34; \u0026#34;instance\u0026#34; { name = \u0026#34;terraform-example-instance\u0026#34; ingress { from_port = var.server_port to_port = var.server_port protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } user_dataも修正：\nuser_data = \u0026lt;\u0026lt;-EOF #!/bin/bash cd /home/ec2-user echo \u0026#34;Hello, World\u0026#34; \u0026gt; index.html nohup python3 -m http.server ${var.server_port} \u0026amp; EOF 4-3. 出力変数を追加 # output \u0026#34;public_ip\u0026#34; { value = aws_instance.example.public_ip description = \u0026#34;The public IP of the web server\u0026#34; } 4-4. 適用と確認 # terraform apply # 出力変数を確認 terraform output public_ip ここまでで学んだこと # 要素 説明 variable 入力変数の定義 var.xxx 変数の参照 ${var.xxx} 文字列内での補間 output 出力変数（apply後に表示） 5. Webサーバのクラスタのデプロイ # 1台だけでは単一障害点です。Auto Scaling Group（ASG）で複数台を管理します。\nなぜASGが必要なのか？ サーバ1台のみの運用は単一障害点（SPOF）となり、障害発生時にサービスが完全停止するリスクがある。ASGを使えば、複数台のEC2を自動管理し、障害時も自動復旧できる。\nなぜデータソース（data）を使うのか？ ASGはEC2を複数のサブネット（アベイラビリティゾーン）に分散配置する。既存のVPC/サブネット情報をTerraformで取得するためにdataブロックを使用する。これにより、1つのAZに障害が発生しても他のAZで稼働を継続できる。\nLaunch Templateとは？ ASGが新しいEC2を起動する際のテンプレート。AMI、インスタンスタイプ、セキュリティグループ、user_dataなどを定義する。\n5-1. データソースを追加 # VPCとサブネットの情報を取得：\ndata \u0026#34;aws_vpc\u0026#34; \u0026#34;default\u0026#34; { default = true } data \u0026#34;aws_subnets\u0026#34; \u0026#34;default\u0026#34; { filter { name = \u0026#34;vpc-id\u0026#34; values = [data.aws_vpc.default.id] } } 5-2. Launch Templateを追加 # ASGが起動するインスタンスの設定：\nresource \u0026#34;aws_launch_template\u0026#34; \u0026#34;example\u0026#34; { image_id = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; # Amazon Linux 2023（2025年11月時点） instance_type = \u0026#34;t2.micro\u0026#34; vpc_security_group_ids = [aws_security_group.instance.id] user_data = base64encode(\u0026lt;\u0026lt;-EOF #!/bin/bash cd /home/ec2-user echo \u0026#34;Hello, World\u0026#34; \u0026gt; index.html nohup python3 -m http.server ${var.server_port} \u0026amp; EOF ) } 5-3. ASGを追加 # resource \u0026#34;aws_autoscaling_group\u0026#34; \u0026#34;example\u0026#34; { vpc_zone_identifier = data.aws_subnets.default.ids launch_template { id = aws_launch_template.example.id version = \u0026#34;$Latest\u0026#34; } min_size = 2 max_size = 10 tag { key = \u0026#34;Name\u0026#34; value = \u0026#34;terraform-asg-example\u0026#34; propagate_at_launch = true } } 5-4. 古いEC2リソースを削除 # aws_instance \u0026quot;example\u0026quot; ブロックは削除してください。ASGがEC2を管理するようになります。\n5-5. 適用と確認 # terraform apply # 2台のインスタンスを確認 aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:Name,Values=terraform-asg-example\u0026#34; \u0026#34;Name=instance-state-name,Values=running\u0026#34; \\ --query \u0026#34;Reservations[].Instances[].{ID:InstanceId,IP:PublicIpAddress}\u0026#34; \\ --output table ここまでで学んだこと # 要素 説明 data 既存リソースの情報を取得（読み取り専用） aws_launch_template EC2の起動設定 aws_autoscaling_group 自動スケーリング設定 6. ロードバランサのデプロイ # 複数台のEC2に1つのエンドポイントでアクセスできるよう、ALBを追加します。\nなぜロードバランサが必要なのか？ ASGで複数台のEC2を起動しても、ユーザーは各EC2のIPアドレスを知らない。ロードバランサを使えば、ユーザーは1つのDNS名（エンドポイント）にアクセスするだけで、トラフィックが自動的に複数のEC2に分散される。\nALBの構成要素\nリスナ：特定のポート（80）とプロトコル（HTTP）でリクエストを受け付ける ターゲットグループ：リクエストを転送する先のEC2群。ヘルスチェックで正常なインスタンスのみに転送 リスナルール：リクエストのパスやホストに基づいて、どのターゲットグループに転送するか決定 なぜALB用のセキュリティグループが別途必要なのか？ ALBもAWSリソースなので、デフォルトでトラフィックを許可しない。ユーザーからのHTTPアクセス（インバウンド80）と、EC2へのヘルスチェック（アウトバウンド全ポート）を許可する設定が必要。\n6-1. ALB用の変数を追加 # variable \u0026#34;alb_name\u0026#34; { description = \u0026#34;The name of the ALB\u0026#34; type = string default = \u0026#34;terraform-asg-example\u0026#34; } variable \u0026#34;alb_security_group_name\u0026#34; { description = \u0026#34;The name of the security group for the ALB\u0026#34; type = string default = \u0026#34;terraform-example-alb\u0026#34; } 6-2. ALB用セキュリティグループを追加 # resource \u0026#34;aws_security_group\u0026#34; \u0026#34;alb\u0026#34; { name = var.alb_security_group_name # インバウンド：HTTP許可 ingress { from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } # アウトバウンド：すべて許可 egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } 6-3. ALB本体を追加 # resource \u0026#34;aws_lb\u0026#34; \u0026#34;example\u0026#34; { name = var.alb_name load_balancer_type = \u0026#34;application\u0026#34; subnets = data.aws_subnets.default.ids security_groups = [aws_security_group.alb.id] } 6-4. ターゲットグループを追加 # resource \u0026#34;aws_lb_target_group\u0026#34; \u0026#34;asg\u0026#34; { name = var.alb_name port = var.server_port protocol = \u0026#34;HTTP\u0026#34; vpc_id = data.aws_vpc.default.id health_check { path = \u0026#34;/\u0026#34; protocol = \u0026#34;HTTP\u0026#34; matcher = \u0026#34;200\u0026#34; interval = 15 timeout = 3 healthy_threshold = 2 unhealthy_threshold = 2 } } 6-5. リスナとルールを追加 # resource \u0026#34;aws_lb_listener\u0026#34; \u0026#34;http\u0026#34; { load_balancer_arn = aws_lb.example.arn port = 80 protocol = \u0026#34;HTTP\u0026#34; default_action { type = \u0026#34;fixed-response\u0026#34; fixed_response { content_type = \u0026#34;text/plain\u0026#34; message_body = \u0026#34;404: page not found\u0026#34; status_code = 404 } } } resource \u0026#34;aws_lb_listener_rule\u0026#34; \u0026#34;asg\u0026#34; { listener_arn = aws_lb_listener.http.arn priority = 100 condition { path_pattern { values = [\u0026#34;*\u0026#34;] } } action { type = \u0026#34;forward\u0026#34; target_group_arn = aws_lb_target_group.asg.arn } } 6-6. ASGにターゲットグループを紐付け # ASGリソースに2行追加：\nresource \u0026#34;aws_autoscaling_group\u0026#34; \u0026#34;example\u0026#34; { vpc_zone_identifier = data.aws_subnets.default.ids launch_template { id = aws_launch_template.example.id version = \u0026#34;$Latest\u0026#34; } target_group_arns = [aws_lb_target_group.asg.arn] # 追加 health_check_type = \u0026#34;ELB\u0026#34; # 追加 min_size = 2 max_size = 10 tag { key = \u0026#34;Name\u0026#34; value = \u0026#34;terraform-asg-example\u0026#34; propagate_at_launch = true } } 6-7. 出力変数を追加 # output \u0026#34;alb_dns_name\u0026#34; { value = aws_lb.example.dns_name description = \u0026#34;The domain name of the load balancer\u0026#34; } 6-8. 適用と確認 # terraform apply # ALBのDNS名を取得 terraform output alb_dns_name # アクセス確認（ALB起動に数分かかる） curl http://$(terraform output -raw alb_dns_name) # → \u0026#34;Hello, World\u0026#34; が表示されればOK ここまでで学んだこと # 要素 説明 aws_lb Application Load Balancer aws_lb_listener どのポートでリクエストを受けるか aws_lb_target_group リクエスト転送先のグループ aws_lb_listener_rule ルーティングルール 7. 後片付け（環境削除） # IaCの大きなメリット：作った環境を一発で削除できます。\nなぜterraform destroyが重要なのか？ AWSリソースは起動している限り課金が発生する。学習やテスト後は必ず削除してコストを抑える。手動で削除すると関連リソースの削除漏れが発生しやすいが、terraform destroyならTerraformが依存関係を考慮して正しい順序で全リソースを削除してくれる。\nIaCの真価 main.tfさえあれば、terraform applyでいつでも同じ環境を再構築できる。「環境構築手順書」が不要になり、環境の作成・削除が数分で完了する。\n7-1. 全リソースを削除 # terraform destroy # → \u0026#34;yes\u0026#34; と入力 7-2. 確認 # aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:Name,Values=terraform-asg-example\u0026#34; \\ --query \u0026#34;Reservations[].Instances[].{ID:InstanceId,State:State.Name}\u0026#34; \\ --output table # → terminated または空 まとめ # Terraformの基本ワークフロー # terraform init → terraform plan → terraform apply → terraform destroy (初期化) (計画確認) (適用) (削除) 今回構築したリソース # リソース 用途 EC2 Webサーバ Security Group ファイアウォール Launch Template EC2の起動設定 Auto Scaling Group EC2の自動管理 ALB ロードバランサ Target Group ALBの転送先 IaC（Infrastructure as Code）のメリット # 再現性：main.tfがあればいつでも同じ環境を構築可能 可視性：インフラ構成がコードとして明確 効率性：環境の作成・削除が数分で完了 バージョン管理：Gitで変更履歴を管理可能 コマンドチートシート # コマンド 用途 terraform init 初期化 terraform plan 実行計画確認 terraform apply 適用 terraform destroy 全削除 terraform output 出力変数表示 terraform validate 構文チェック 完成版コード # クリックして展開：最終的なmain.tf provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } # --- 変数 --- variable \u0026#34;server_port\u0026#34; { description = \u0026#34;The port the server will use for HTTP requests\u0026#34; type = number default = 8080 } variable \u0026#34;alb_name\u0026#34; { description = \u0026#34;The name of the ALB\u0026#34; type = string default = \u0026#34;terraform-asg-example\u0026#34; } variable \u0026#34;alb_security_group_name\u0026#34; { description = \u0026#34;The name of the security group for the ALB\u0026#34; type = string default = \u0026#34;terraform-example-alb\u0026#34; } # --- データソース --- data \u0026#34;aws_vpc\u0026#34; \u0026#34;default\u0026#34; { default = true } data \u0026#34;aws_subnets\u0026#34; \u0026#34;default\u0026#34; { filter { name = \u0026#34;vpc-id\u0026#34; values = [data.aws_vpc.default.id] } } # --- セキュリティグループ --- resource \u0026#34;aws_security_group\u0026#34; \u0026#34;instance\u0026#34; { name = \u0026#34;terraform-example-instance\u0026#34; ingress { from_port = var.server_port to_port = var.server_port protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } resource \u0026#34;aws_security_group\u0026#34; \u0026#34;alb\u0026#34; { name = var.alb_security_group_name ingress { from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } # --- Launch Template \u0026amp; ASG --- resource \u0026#34;aws_launch_template\u0026#34; \u0026#34;example\u0026#34; { image_id = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; # Amazon Linux 2023（2025年11月時点） instance_type = \u0026#34;t2.micro\u0026#34; vpc_security_group_ids = [aws_security_group.instance.id] user_data = base64encode(\u0026lt;\u0026lt;-EOF #!/bin/bash cd /home/ec2-user echo \u0026#34;Hello, World\u0026#34; \u0026gt; index.html nohup python3 -m http.server ${var.server_port} \u0026amp; EOF ) } resource \u0026#34;aws_autoscaling_group\u0026#34; \u0026#34;example\u0026#34; { vpc_zone_identifier = data.aws_subnets.default.ids launch_template { id = aws_launch_template.example.id version = \u0026#34;$Latest\u0026#34; } target_group_arns = [aws_lb_target_group.asg.arn] health_check_type = \u0026#34;ELB\u0026#34; min_size = 2 max_size = 10 tag { key = \u0026#34;Name\u0026#34; value = \u0026#34;terraform-asg-example\u0026#34; propagate_at_launch = true } } # --- ALB --- resource \u0026#34;aws_lb\u0026#34; \u0026#34;example\u0026#34; { name = var.alb_name load_balancer_type = \u0026#34;application\u0026#34; subnets = data.aws_subnets.default.ids security_groups = [aws_security_group.alb.id] } resource \u0026#34;aws_lb_target_group\u0026#34; \u0026#34;asg\u0026#34; { name = var.alb_name port = var.server_port protocol = \u0026#34;HTTP\u0026#34; vpc_id = data.aws_vpc.default.id health_check { path = \u0026#34;/\u0026#34; protocol = \u0026#34;HTTP\u0026#34; matcher = \u0026#34;200\u0026#34; interval = 15 timeout = 3 healthy_threshold = 2 unhealthy_threshold = 2 } } resource \u0026#34;aws_lb_listener\u0026#34; \u0026#34;http\u0026#34; { load_balancer_arn = aws_lb.example.arn port = 80 protocol = \u0026#34;HTTP\u0026#34; default_action { type = \u0026#34;fixed-response\u0026#34; fixed_response { content_type = \u0026#34;text/plain\u0026#34; message_body = \u0026#34;404: page not found\u0026#34; status_code = 404 } } } resource \u0026#34;aws_lb_listener_rule\u0026#34; \u0026#34;asg\u0026#34; { listener_arn = aws_lb_listener.http.arn priority = 100 condition { path_pattern { values = [\u0026#34;*\u0026#34;] } } action { type = \u0026#34;forward\u0026#34; target_group_arn = aws_lb_target_group.asg.arn } } # --- 出力 --- output \u0026#34;alb_dns_name\u0026#34; { value = aws_lb.example.dns_name description = \u0026#34;The domain name of the load balancer\u0026#34; } 参考 # 詳解 Terraform 第3版 ―Infrastructure as Codeを実現する 著者：Yevgeniy Brikman 訳者：松浦 隼人 出版社：オライリージャパン 出版年：2023年 Terraform公式ドキュメント AWSプロバイダドキュメント ","date":"2025年 11月 28日","externalUrl":null,"permalink":"/posts/251128004323_terraform-aws-environment-setup-and-teardown-hands-on/","section":"Posts","summary":"","title":"TerraformでAWS環境を構築して削除するまで - 入門ハンズオン","type":"posts"},{"content":"","date":"2025年 11月 28日","externalUrl":null,"permalink":"/tags/%E3%83%81%E3%83%A5%E3%83%BC%E3%83%88%E3%83%AA%E3%82%A2%E3%83%AB/","section":"Tags","summary":"","title":"チュートリアル","type":"tags"},{"content":" はじめに：Terraformとは？ # TerraformはHashiCorp社が開発したオープンソースのInfrastructure as Code（IaC）ツール。\nサーバ、ネットワーク、データベースなどのインフラをコードで定義し、自動的に構築・変更・バージョン管理できる。\nTerraformはIaCツールの中でどこに位置するか # IaCツールは大きく5つに分類される\n分類 主な用途 代表例 アドホックなスクリプト シンプルな自動化 Bash, Python 設定管理ツール 既存サーバの設定 Ansible, Chef サーバテンプレーティング イメージからサーバ構築 Docker, Packer オーケストレーション コンテナ管理 Kubernetes プロビジョニングツール インフラ全体の作成 Terraform, CloudFormation Terraformはプロビジョニングツールに分類される。\nサーバ「上」に何かをインストールするのではなく、サーバ「自体」を作成するツール。\nTerraformの特徴 # 動作の仕組み # TerraformはGo言語で書かれたOSS。\n各端末のterraformバイナリから、AWSやAzureなどのクラウドプロバイダへAPIコールして動作する。\n他のIaCツールとの違い # 比較軸 Terraform Ansible CloudFormation ツール種別 プロビジョニング 設定管理 プロビジョニング インフラの扱い イミュータブル ミュータブル イミュータブル 言語スタイル 宣言型 手続き型/宣言型 宣言型 言語 HCL（DSL） YAML JSON/YAML マスタサーバ 不要 不要 不要（AWS管理） エージェント 不要 不要 不要 マルチクラウド ◯ ◯ ✕（AWS専用） Terraformを選ぶ理由 # エージェントレス：クラウドプロバイダのAPIを直接呼び出すため、各サーバにエージェントをインストールする必要がない マスタレス：マスタサーバの運用・メンテナンスが不要 宣言型言語：「こうなってほしい」を書くだけで、Terraformが差分を計算して適用してくれる マルチクラウド対応：AWS、Azure、GCPなど複数のプロバイダを同じ言語で管理できる 実際の使われ方 # Terraformは単体で使うこともあるが、他のツールと組み合わせることが多い：\nPacker + Terraform：Packerでサーバイメージを作成 → Terraformでそのイメージを使ってインフラ構築 Docker + Kubernetes + Terraform：Terraformでインフラ構築（K8sクラスタ含む） → Kubernetesでコンテナ管理 まとめ # Terraformはインフラをコードで管理するプロビジョニングツール 宣言型・マスタレス・エージェントレスという特徴を持つ クラウドプロバイダのAPIを直接呼び出すシンプルな仕組み 他のIaCツール（Docker、Kubernetesなど）と組み合わせて使われることが多い 参考資料 # 詳解 Terraform 第3版 ―Infrastructure as Codeを実現する 著者：Yevgeniy Brikman 訳者：松浦 隼人 出版社：オライリージャパン 出版年：2023年 ","date":"2025年 11月 27日","externalUrl":null,"permalink":"/posts/251127233855_what-is-terraform/","section":"Posts","summary":"","title":"Terraformとは？","type":"posts"},{"content":"","date":"2025年 11月 26日","externalUrl":null,"permalink":"/tags/chrome/","section":"Tags","summary":"","title":"Chrome","type":"tags"},{"content":" はじめに # 仕事の効率化のために、Googleドライブ内の検索をもっとスマートにできないかなと考えて、 Chromeのアドレスバーから直接検索できる機能を実装しました。 その結果、資料へのアクセスが劇的に向上したので、設定方法をメモします。\nChromeカスタム検索エンジンの設定手順 # ステップ1：設定画面を開く # 以下のいずれかの方法で設定画面を開きます\n方法A：URLchrome://settings/searchEnginesへ直接アクセス\n方法B：メニューから操作\nChromeの右上の「⋮」（3点メニュー）をクリック 「設定」を選択 左側メニューから「検索エンジン」を選択 「検索エンジンとサイト内検索を管理する」をクリック 注意：Chromeのバージョンによって表記が「サイト検索を管理」など微妙に異なる場合があります\nステップ2：検索エンジンを追加 # 「サイト内検索」セクションの「追加」ボタンをクリックし、以下の項目を入力します\n項目 説明 例 検索エンジン名 管理用の名前（任意） Drive Title Search ショートカット アドレスバーで使う短縮コマンド d URL（%s=検索語句） 検索用URL（%sが検索キーワードに置き換わる） https://drive.google.com/drive/search?q=title:%s ステップ3：動作確認 # Chromeのアドレスバーにショートカット（例：d）を入力 スペースまたはTabを押す → 検索モードに切り替わる 検索キーワードを入力してEnter カスタム検索一覧 # 自分が実際に登録した設定一覧が下記です。\nGoogleドライブ検索 # コマンド 設定名 URL 用途 d Drive Title Search https://drive.google.com/drive/search?q=title:%s タイトル検索 da Drive All Search https://drive.google.com/drive/search?q=%s 全文検索 ds Drive Sheets https://drive.google.com/drive/search?q=type:spreadsheet+%s スプレッドシート限定 dd Drive Docs https://drive.google.com/drive/search?q=type:document+%s ドキュメント限定 URL内の+はスペース扱いになります（例：type:spreadsheet+%s → type:spreadsheet 検索語）\nAI検索・開発ツール # ショートカット 検索エンジン名 URL 用途 pa Perplexity AI https://www.perplexity.ai/?q=%s AI対話型検索 gh GitHub https://github.com/search?q=%s リポジトリ・コード検索 qi Qiita https://qiita.com/search?q=%s 技術記事検索 wiki Wikipedia https://ja.wikipedia.org/wiki/Special:Search?search=%s Wikipedia内検索 検索演算子の活用 # 以下の演算子を組み合わせることで検索の精度を上げることができます。\ntitle: - タイトル限定検索 title:VPN：ファイル名に「VPN」を含むものだけを表示 \u0026quot;\u0026quot; - 完全一致検索（フレーズ検索） \u0026quot;エラー 503\u0026quot;：その並び順のフレーズしかヒットしない - - 除外検索 VPN -旧手順 -2023：「旧手順」「2023」を含むファイルを除外 他のサービスをカスタム検索に追加する方法 # URLの調べ方 # 追加したいサイトで実際に検索を実行（例：「test」で検索） 検索結果ページのURLをコピー URL内の検索キーワード部分（testなど）を%sに置き換える まとめ # Chromeのカスタム検索エンジン機能を活用することで、アドレスバーから直接検索できる環境を構築しました。\n実現できたこと # Googleドライブ検索の高速化\nタイトル検索（d）、全文検索（da）、ファイル種別検索（ds, dd）を設定 資料へのアクセス時間を体感10～15秒短縮 AI検索・開発ツールへの即座アクセス\nPerplexity AI、GitHub、Qiita、Wikipediaなどを登録 情報収集・技術調査の効率化 検索演算子との組み合わせ\ntitle:, \u0026quot;\u0026quot;, - を活用して検索精度を向上 ノイズの多い検索結果から必要な情報を素早く抽出 ","date":"2025年 11月 26日","externalUrl":null,"permalink":"/posts/251126031004_implement-custom-search-feature-in-chrome/","section":"Posts","summary":"","title":"Chromeにカスタム検索機能を実装する方法","type":"posts"},{"content":" はじめに # Terraformの勉強のために「詳解Terraform」を購入。 すこしずつ内容をTILとしてアウトプットして知識を定着させます。 今回のテーマは「IaC（Infrastructure as Code）の5つの分類」 ※IaCとは、インフラなどの環境をコードで記述できるようにしたツール全般を指す。\n書籍情報 # 詳解 Terraform 第3版 ―Infrastructure as Codeを実現する 著者：Yevgeniy Brikman 訳者：松浦 隼人 出版社：オライリージャパン 出版年：2023年 5つの分類 # IaCツールは以下の5つのカテゴリに分類されます。これらは対立するものではなく、それぞれ異なる役割を持ち、実際の開発現場では組み合わせて使用することが一般的です。\nアドホックなスクリプト 設定管理ツール サーバテンプレーティングツール オーケストレーションツール プロビジョニングツール アドホックなスクリプト # 作業や処理をpythonやshファイルとして作成して実行するスクリプト\n最もシンプルな自動化の方法 単純な処理を実装するなら向いているが、サーバ設定からデプロイまで処理するような複雑な 処理を実装する場合は、一から自力でコードを書く必要があるため、労力がかかる。\n設定管理ツール # 既存のサーバ上にソフトウェアなどをインストールするためのツール\n例：Chef・Puppet・Ansible コーディング規約によりファイル内容に一貫性を持たせることが可能 冪等性がある 1回限りの処理であればアドホックなスクリプトでも十分だが、何度実行しても同じ結果をもたらす冪等性が必要な場合は、Ansibleなどの設定管理ツールのほうが向いている Ansibleのモジュールには冪等性が組み込まれているため 配布 コードの配布により、ローリングデプロイなど複数のリモートサーバをまとめて管理することが可能。 サーバテンプレーティングツール # OSやソフトウェアをパッケージ化したイメージを作成し、そのイメージから環境を構築するツール\n例：Docker・Packer・Vagrant 「スナップショット」と呼ばれるOSやソフトウェアなどを含んだイメージを作成して、このスナップショットを使ってサーバ環境を構築する イメージを扱うツールには大別すると2つのカテゴリがある。\n仮想マシン\nハードウェアを含むコンピュータシステム全体をエミュレートする仕組み 例：VMware・VirtualBox ハイパーバイザを動かしてCPUやメモリなどを仮想化する これによりハイパーバイザ上で動かす仮想マシンイメージからは仮想化されてハードウェアのみ見えるようになる。 仮想環境とホストマシンを分離することが可能 仮想マシンイメージはPackerやVagrantなどのツールで定義可能 コンテナ\nOSのユーザスペースをエミュレートする仕組み プロセスやメモリなどを分離するためにDockerなどのコンテナエンジンを動作させる必要がある コンテナはユーザスペースのみ見えるようになる。 仮想マシンとコンテナの違い\n仮想マシン：ハードウェアレベルで仮想化・高度な分離性があり、セキュリティやコンプライアンス面で有利 コンテナ：OSレベルで仮想化・メモリ消費が少ない イミュータブルインフラ 一度構築・デプロイされたインフラ環境（サーバやコンテナなど）を変更せず、更新が必要な場合は新しい環境を丸ごと作り直して既存環境と入れ替える運用思想\nサーバテンプレーティングツールにおいて重要な考え プロビジョニングツール（Terraformなど）と組み合わせることで、インフラ全体のイミュータブル化も実現可能 オーケストレーションツール # 複数のシステムやサービス、アプリケーション間で行われる多数のタスクや ワークフローを自動的に統合・管理し、効率的に実行するためのソフトウェア\n例：Kubernetes プロビジョニングツール # サーバ自体を作成するようなツール\nインフラに関係しているたいていのものを作成できる（サーバ、データベース、ネットワーク構成、ロードバランサーなど） 例：Terraform・CloudFormation まとめ：IaCの概要 # IaCとは、インフラ環境をコードで記述・管理できるツール全般を指す。大別すると5つのカテゴリがある。\n各ツールの特徴と使い分け # ツール分類 主な用途 代表例 向いている場面 アドホックなスクリプト シンプルな自動化 Bash, Python 1回限りの処理、単純な作業の自動化 設定管理ツール 既存サーバの設定・ソフトウェアインストール Ansible, Chef, Puppet 複数サーバへのソフトウェアデプロイ、冪等性が必要な設定作業 サーバテンプレーティングツール イメージからサーバ環境を構築 Docker, Packer, Vagrant 環境の再現性確保、イミュータブルインフラの実現 オーケストレーションツール 複数システム・サービスの統合管理 Kubernetes コンテナの起動・停止・スケーリング、マイクロサービス管理 プロビジョニングツール インフラ全体の作成・管理 Terraform, CloudFormation サーバ・ネットワーク・DB等のインフラリソース作成 ツール選択の基本方針 # シンプルな自動化：アドホックなスクリプト 既存環境の設定変更：設定管理ツール 環境の再現性重視：サーバテンプレーティングツール コンテナ管理：オーケストレーションツール インフラ全体の構築：プロビジョニングツール（Terraform等） 実際の開発現場では、これらのツールを組み合わせて使用することが多い。 例：Terraformでインフラを構築 → Ansibleでソフトウェアをインストール → Dockerでアプリケーションを動かす → Kubernetesで管理\n","date":"2025年 11月 24日","externalUrl":null,"permalink":"/posts/251124162641_iac-five-classifications/","section":"Posts","summary":"","title":"IaC（Infrastructure as Code）の5つの分類","type":"posts"},{"content":" はじめに # 本屋で何気なく読んでみて、成長しないケースとして「スキルマニア」が紹介されていた。思いっきり自分に当てはまるなと考え、刺さった。この成長しないスキルマニアからどうすれば成長するようになれるかを知りたくてこの本を購入した。\nこのメモの目的：成長しないスキルマニアから成長できる人物へ変わるための具体的なアクションを知る\n書籍情報 # BCGの育つ力・育てる力 著者：木村亮示・木山聡 出版社：日経BP 出版年：2024年 BCGとは？ # アメリカを本拠地としている有名なコンサルティンググループ\n基本情報技術者試験でも出題される「PPM」はここが発案したらしい そもそもスキルマニアとは？ # 技術や資格だけを集めて、満足しているタイプの人\nいわゆる優等生タイプがなりやすい コレクション型：いろいろな資格を入手する 突き詰め型：特定の分野を深堀りしつづける 自分の振り返り：コレクション型だと思う。資格を集めているが、実務に活かせているかとなると疑問点がある 成長するために必要なのは？ # マインドセットとスキルの2つが必要。 スキルが不要というわけではない。ただし、スキルだけでは不足。\n具体的なマインドセット # 思いやり：自分だけを満足させることでは直ぐに限界が来る 素直さ：自分の行動を分析・反省して行動する 折れない心：できるかできないか不安でも、やるしかない 本の例え話（野球のピッチャー） # 球速を上げたり、変化球を覚えるだけでは勝てない。使い方を学ぶべき。 実務経験を積みながら試行錯誤して成長していく必要がある。 中身となるアイデアや思いがないといくらスキルがあっても意味ない。\n実践に向けたアクション # 実務での試行錯誤を重視する\n資格勉強で得た知識を実務で試し、反省と改善を繰り返す 職場の実際の課題に対して学んだスキルを適用してみる 資格・学習の位置づけを見直す\n資格勉強はあくまで知識やスキルの入門として位置づける 「資格を取ること」ではなく「学んだことを活かすこと」を目標にする 他者への貢献を意識する\nチームや組織の課題を見つけ、解決に取り組む 学んだ知識を同僚と共有し、チーム全体のレベルアップに貢献する 参考資料 # Wikipedia：ボストン・コンサルティング・グループ ","date":"2025年 11月 23日","externalUrl":null,"permalink":"/posts/251123232747_bcg-ikiru-chikara-sodateru-chikara-skill-mania-karano-dasshutsu/","section":"Posts","summary":"","title":"【読書メモ】BCGの育つ力・育てる力：スキルマニアからの脱却","type":"posts"},{"content":"","date":"2025年 11月 23日","externalUrl":null,"permalink":"/tags/%E3%82%AD%E3%83%A3%E3%83%AA%E3%82%A2/","section":"Tags","summary":"","title":"キャリア","type":"tags"},{"content":"","date":"2025年 11月 23日","externalUrl":null,"permalink":"/tags/%E8%AA%AD%E6%9B%B8%E3%83%A1%E3%83%A2/","section":"Tags","summary":"","title":"読書メモ","type":"tags"},{"content":" はじめに # ヘルプデスク・監視運用でTeratermを使ってログ調査を行う際のコマンドを備忘録としてまとめる。\n前提条件 # サービスログは.logファイルとして保管 1日経過したログは.gz形式で圧縮保存 実施したこと # 特定のエラーメッセージ(ERROR)がログに含まれているか確認したい。\nサンプルファイルの内容 # service.log (通常のログファイル) # 2024-11-20 10:15:32 INFO Application started successfully 2024-11-20 10:15:45 INFO User login: user_id=12345 2024-11-20 10:16:03 WARN High memory usage detected: 85% 2024-11-20 10:16:15 INFO Processing request: /api/users 2024-11-20 10:16:28 ERROR Database connection timeout 2024-11-20 10:16:30 ERROR Failed to execute query: SELECT * FROM users 2024-11-20 10:17:12 INFO Request completed: status=200 2024-11-20 10:18:45 WARN Response time exceeded threshold: 3.5s 2024-11-20 10:19:03 INFO User logout: user_id=12345 2024-11-20 10:20:15 ERROR Network unreachable: host=192.168.1.100 2024-11-20 10:21:30 INFO Backup process started 2024-11-20 10:22:45 INFO Backup completed successfully ファイルの一覧表示 # $ ls -lh service.log* -rw-r--r-- 1 root root 696 Nov 23 13:03 service.log -rw-r--r-- 1 root root 375 Nov 23 13:03 service.log.gz 使用コマンドと実行例 # 1. 通常のログファイル(.log)からERRORを検索 # コマンド:\ngrep ERROR service.log 実行結果:\n2024-11-20 10:16:28 ERROR Database connection timeout 2024-11-20 10:16:30 ERROR Failed to execute query: SELECT * FROM users 2024-11-20 10:20:15 ERROR Network unreachable: host=192.168.1.100 2. 圧縮ログファイル(.gz)からERRORを検索 # コマンド:\nzgrep ERROR service.log.gz 実行結果:\n2024-11-20 10:16:28 ERROR Database connection timeout 2024-11-20 10:16:30 ERROR Failed to execute query: SELECT * FROM users 2024-11-20 10:20:15 ERROR Network unreachable: host=192.168.1.100 💡 .logでも.gzでも同じ結果が得られる!\n3. 行番号付きで検索 # コマンド:\ngrep -n ERROR service.log 実行結果:\n5:2024-11-20 10:16:28 ERROR Database connection timeout 6:2024-11-20 10:16:30 ERROR Failed to execute query: SELECT * FROM users 10:2024-11-20 10:20:15 ERROR Network unreachable: host=192.168.1.100 4. 複数パターンを同時に検索 (ERROR または WARN) # コマンド:\ngrep -E \u0026#34;ERROR|WARN\u0026#34; service.log 実行結果:\n2024-11-20 10:16:03 WARN High memory usage detected: 85% 2024-11-20 10:16:28 ERROR Database connection timeout 2024-11-20 10:16:30 ERROR Failed to execute query: SELECT * FROM users 2024-11-20 10:18:45 WARN Response time exceeded threshold: 3.5s 2024-11-20 10:20:15 ERROR Network unreachable: host=192.168.1.100 5. 検索結果の件数をカウント # コマンド:\ngrep -c ERROR service.log 実行結果:\n3 よく使うgrepオプション # オプション 説明 使用例 -n 行番号を表示 grep -n ERROR service.log -i 大文字小文字を区別しない grep -i error service.log -c マッチした行数をカウント grep -c ERROR service.log -v マッチしない行を表示 grep -v INFO service.log -A 数字 マッチ行の後ろN行も表示 grep -A 3 ERROR service.log -B 数字 マッチ行の前N行も表示 grep -B 2 ERROR service.log -C 数字 マッチ行の前後N行を表示 grep -C 2 ERROR service.log -E 拡張正規表現を使用 grep -E \u0026quot;ERROR|WARN\u0026quot; service.log moreとlessの違い # 項目 more less スクロール方向 前方のみ(下方向) 前後自由(上下両方向) 検索機能 限定的 充実(前方/後方検索可能) ファイル読み込み 全体を読み込む 必要な部分のみ読み込む 大容量ファイル 遅い 高速 操作 シンプル 高機能(viライク) 終了時の表示 画面に残る 画面から消える 主な操作方法 # more:\nSpace: 次のページ Enter: 1行進む q: 終了 less:\nSpace/f: 次のページ b: 前のページ ↑/↓: 1行ずつ移動 /文字列: 前方検索 ?文字列: 後方検索 n: 次の検索結果 N: 前の検索結果 q: 終了 lessでの検索実例 # less service.log less内で:\n/ERROR # 「ERROR」を前方検索 n # 次のERRORへジャンプ N # 前のERRORへ戻る 使い分けのポイント # more: シンプルに前から順に見たい場合 less: 大きなログファイルの調査、検索が必要な場合 💡 豆知識: \u0026ldquo;less is more\u0026quot;という言葉遊びから、moreの改良版としてlessが誕生した\n各コマンドの説明 # コマンド 説明 対象ファイル grep テキストファイルから文字列を検索 .logなど zgrep 圧縮ファイルを一時的に解凍して検索（解凍ファイルは作成しない） .gz less ページ単位でファイルを表示(検索機能付き) .logなど zless 圧縮ファイルをlessで表示 .gz more シンプルなページャー(前方スクロールのみ) .logなど よくある間違い # ❌ パイプの誤用\nmore service.log | zgrep ERROR → zgrepは圧縮ファイル専用。パイプで渡されたデータは圧縮されていない\n⭕ 正しい使い方\n# 通常ファイル grep ERROR service.log # 圧縮ファイル zgrep ERROR service.log.gz ❌ 大きなログファイルにmore\nmore huge_file.log # 読み込みが遅い ⭕ lessを使う\nless huge_file.log # 高速に起動 学んだこと # 圧縮ファイルにはz系コマンド(zgrep, zless)を直接使う方が効率的 lessはmoreより高機能で検索も可能 ログ調査ではlessの方が実用的(前後に移動できるため) grep -nで行番号を表示すると、lessで該当行にジャンプしやすい -A, -B, -Cオプションで前後の文脈も確認できる 参考: よく使うログ調査パターン # # パターン1: エラーログを抽出して別ファイルに保存 grep ERROR service.log \u0026gt; error_only.log # パターン2: 最新のエラーを確認 grep ERROR service.log | tail -5 # パターン3: エラーとその前後2行を表示 grep -C 2 ERROR service.log # パターン4: 複数ファイルからエラーを検索 grep ERROR service*.log # パターン5: 圧縮ファイルも含めて検索 zgrep ERROR service.log.gz ","date":"2025年 11月 23日","externalUrl":null,"permalink":"/posts/251123221331_log-investigation-more-less-grep-zgrep/","section":"Posts","summary":"","title":"ログ調査_more・less・grep・zgrep","type":"posts"},{"content":" はじめに # オブジェクト指向について、講師役として解説する機会があるため、 振り返りとしてオブジェクト指向を再学習する。\nオブジェクト指向とは？ # データと関連する処理を「オブジェクト」という単位にまとめて管理するソフトウェア開発手法 オブジェクトは、クラスから生成される実体（インスタンス） （一部のプログラミング言語（Python、Rubyなど）ではクラス自体もオブジェクトとして扱われるが、このメモではオブジェクト=インスタンスとする） オブジェクト指向が誕生した経緯 # 1960～1970年代は「手続き型プログラミング」が主流。 データと処理を別々で記述する手法で、各データや処理のコーディングに集中できる反面、プログラムが大規模化すると、データと処理の関係性を把握するのに多大なエネルギーを必要としていた。 構造化プログラミングは制御構造（順次・選択・反復）を整理する手法として同時期に発展したが、データと処理の管理については別の課題として残っていた。 この問題を解決するために「データ」と「処理」をまとめて管理する「オブジェクト」が誕生。このオブジェクトの管理に主眼を置いたのがオブジェクト指向である。 クラス・インスタンス # オブジェクト指向を成立させるための基本的な概念がクラスとインスタンス\nクラス：設計図やテンプレート インスタンス：クラスから生成される実体（オブジェクト） 車で例えると、設計図から車を製造するようなイメージ\nクラス：車の設計図 インスタンス：製造された車 基本用語 # オブジェクト指向を理解する上で重要な基本用語を説明します。\nプロパティ（属性） # オブジェクトが持つデータ・状態を表す変数 車の例：色、速度、走行距離、燃料残量など 例：car.color = \u0026quot;red\u0026quot; （車の色は赤） メソッド # オブジェクトができる動作・処理を表す関数 車の例：走る、止まる、クラクションを鳴らす、給油するなど 例：car.drive() （車を運転する） コンストラクタ # オブジェクトを生成する際に初期化処理を行う特別なメソッド 新しい車を製造する際の初期設定のようなもの 車の例：製造時に色、エンジンタイプ、シート数などを設定 例：car = Car(\u0026quot;red\u0026quot;, \u0026quot;hybrid\u0026quot;, 5) （赤いハイブリッド5人乗りの車を作る） オブジェクト指向の3大要素 # 継承 カプセル化 ポリモーフィズム クラスとインスタンスを使って上記の3要素が実現できる。\n継承 # 親クラスから内容を引き継いで新しい子クラスを作成する。\n例えば、親クラスとして「車」があるとした場合、子クラスとして「乗用車」「トラック」「バス」を設定可能。 さらに「乗用車」から「タクシー」や「パトカー」を作ることもできる。 このとき、「トラック」には「荷物を積む」、「バス」には「乗客を乗せる」などの個別機能を実装できる。\nカプセル化 # データと処理を外部から隠蔽して保護する機能\n車の例を引き続き利用すると、「車の走行距離記録（オドメーター）」がある。 このオドメーターは手動でいじることは違法行為にあたる。走行距離をしっかり測定する必要があるので、 「車の走行距離記録（オドメーター）」に対して、直接アクセスできないようにして、「車で運転」した場合のみ 「オドメーター」に追加するようにする。この処理をカプセル化で実現できる。\nポリモーフィズム # 同じ命令で、対象によって異なる動作をする機能\n車の例：「サイレンを鳴らす」という同じ命令でも\nパトカー → 「ウーウー」 救急車 → 「ピーポーピーポー」 消防車 → 「ウーカンカン」 それぞれ違う音が鳴る。\nこれが便利な理由は、「サイレンを鳴らす」という共通の命令を覚えるだけで、 車種ごとの細かい違いを意識せずに使えることである。\nオブジェクト指向のメリット・デメリット # メリット # 再利用しやすい\n一度作った「車」クラスから、何台でも車を作れる 修正が楽\n「車」クラスを修正すれば、全ての車に反映される 現実世界に近い\n車、人、建物など、身近なモノとして考えられる デメリット # 小さなプログラムには大げさ\n簡単な計算だけなら、クラスなしの方が早い 最初は難しい\n概念の理解に時間がかかる 設計ミスの影響が大きい\nクラスの作り方を間違えると、大幅な修正が必要 まとめ # オブジェクト指向 # データと関連する処理を「オブジェクト」という単位にまとめて管理するソフトウェア開発手法\nクラスとインスタンス # クラス：設計図・テンプレート インスタンス：クラスから生成された実物 オブジェクト指向の3大要素 # 継承：既存のクラスを拡張して再利用 カプセル化：データと機能をまとめて、外部から保護 ポリモーフィズム：同じ操作で異なる振る舞い さらに深く学ぶために # オブジェクト指向開発の初期に活躍した「アラン・ケイ」によるオブジェクト指向の解説を読むと オブジェクト指向について深掘りできると思います。内容が難しいので、このメモでは詳細にまとめないが、参考としてリンクを紹介します。\nnote：アラン・ケイのオブジェクト指向プログラミング Dr. Alan Kay on the Meaning of “Object-Oriented Programming” Qiita：アラン・ケイのオブジェクト指向とは何だったか？元哲学者のエンジニアがまとめてみた 参考資料 # いちばんやさしい基本情報技術者 絶対合格の教科書＋出る順問題集 著者：高橋 京介 出版社：SBクリエイティブ 出版年：2024年 Qiita：[Python] Pythonでオブジェクト指向を完全理解してみる ","date":"2025年 11月 23日","externalUrl":null,"permalink":"/posts/251123211627_object-oriented-programming-introduction-memo/","section":"Posts","summary":"","title":"オブジェクト指向の入門用メモ","type":"posts"},{"content":"","date":"2025年 11月 23日","externalUrl":null,"permalink":"/tags/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0/","section":"Tags","summary":"","title":"プログラミング","type":"tags"},{"content":" はじめに # メモをまとめる方法として、「ツェッテルカステン」を勉強するためにこの本で学習。\n書籍情報 # 書籍名: TAKE NOTES!――メモで、あなただけのアウトプットが自然にできるようになる 著者: ズンク・アーレンス（翻訳：二木 夢子） 出版: 日経BP、2021年10月 出版社ページ 本書の要点 # ツェッテルカステンとは # 社会学者ルーマンが実践したメモ術。小さな単位のメモを作り、\n相互にリンクさせることで知識のネットワークを構築する手法。\nメモの処理フロー # 走り書き・文献メモ: 日常のアイデアや読書内容を一時記録 永久保存メモ: 自分の言葉で再構成した独立したメモ 関連づけ: 既存メモとリンクし、知識体系を育てる アウトプット: 蓄積したメモから文章や研究へ展開 重要な考え方 # アウトプット前提のインプット: 常にアウトプットを意識して情報を取り込む 自分の言葉で書く: 理解度を確認し、思考を深める つながりを意識: メモ同士の関連性を整理することが洞察につながる 所感 # メモ術に関する自己啓発書。システマティックにメモを蓄積することで質の高いアウトプットが可能になるという提案は有益だが、具体的なハウツーより概念的な説明が中心。メモの意義を再確認し、モチベーションを高めるのに適している。\n実践する3つのアクション # 日常的なメモ取りの習慣化 メモ間のつながりを意識した整理 自分の言葉での言い換えの徹底 ","date":"2025年 11月 20日","externalUrl":null,"permalink":"/posts/251120230822_take-notes-output-naturally-with-memos/","section":"Posts","summary":"","title":"【読書メモ】TAKE NOTES!――メモで、あなただけのアウトプットが自然にできるようになる","type":"posts"},{"content":"","date":"2025年 11月 20日","externalUrl":null,"permalink":"/tags/%E3%83%A1%E3%83%A2%E8%A1%93/","section":"Tags","summary":"","title":"メモ術","type":"tags"},{"content":"","date":"2025年 11月 20日","externalUrl":null,"permalink":"/tags/claude/","section":"Tags","summary":"","title":"Claude","type":"tags"},{"content":" 前回のセッションは引き継げるのか？ # 回答としては 不可 毎回のセッション毎に新しく会話内容などが更新される。\nもしも前回のセッションの内容を引き継いでほしい場合は\n前回のセッションの内容をメモや議事録にまとめて、\n新しく始めたセッションにて「このメモを読んで続きを」という旨を指示する必要がある。\nセッションのトークン量が少なくなってきたら、メモにまとめて、\n次のセッションで再開できるようにする必要がある。\nTodoWriteツールとは？ # 度々、Claudeにて「TodoWriteツール」という文言がでてくるため、claudeへ質問してみた。 claudeの内部管理用ツールらしい。（claudeにもToDo管理ツールってあるんだ。）\nClaudeより Claudeが内部的に使うタスク管理ツール 複雑なタスクを進める際、進捗を可視化 あなたの画面に □ → ◐ → ✓ で表示される セッション終了で消える（継続したいならメモに転記） あなたは何もしなくていい（Claude が自動で使う）\n","date":"2025年 11月 20日","externalUrl":null,"permalink":"/posts/251120225449_claude-specification-session-continuity-check/","section":"Posts","summary":"","title":"Claudeの仕様確認：前回のセッションは引き継げるのか？","type":"posts"},{"content":"","date":"2025年 11月 20日","externalUrl":null,"permalink":"/tags/%E4%BB%95%E6%A7%98%E7%A2%BA%E8%AA%8D/","section":"Tags","summary":"","title":"仕様確認","type":"tags"},{"content":"","date":"2025年 11月 20日","externalUrl":null,"permalink":"/tags/git/","section":"Tags","summary":"","title":"Git","type":"tags"},{"content":" はじめに # git commitを実行する際のコミットメッセージを作成するために\n変更内容を確認するコマンドや手順を整理してメモとする。\n状況確認コマンド # # 全体把握 git status # すべての変更を確認 git diff HEAD --stat # まだ git add していない変更を確認 git diff --stat # git add した変更を確認 git diff --staged --stat git diff --cached --stat 変更を確定するコマンド # # コミット git commit -m \u0026#34;...\u0026#34; # リモートリポジトリへプッシュ git push 日本語ファイル名の表示設定 # デフォルトでは日本語ファイル名がエスケープされて表示される問題を解決 実行後、日本語ファイル名が正常に表示される。\n# グローバル設定（全リポジトリに適用） git config --global core.quotePath false # または、このリポジトリだけ設定 git config core.quotePath false その他の有用な設定（オプション） # # 日本語コミットメッセージも正常表示 git config --global core.pager \u0026#34;less -R\u0026#34; # git log で日本語を正しく表示 git config --global i18n.logOutputEncoding utf-8 まとめ # コミット前の変更確認には git diff HEAD \u0026ndash;stat が便利 ステージング済みの変更は \u0026ndash;staged オプションで確認 日本語表示問題は core.quotePath false で解決 ","date":"2025年 11月 20日","externalUrl":null,"permalink":"/posts/251120224617_git-change-check-commands/","section":"Posts","summary":"","title":"Gitコミット前の変更確認ガイド","type":"posts"}]