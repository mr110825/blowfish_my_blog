
[{"content":" DFDとは？ # DFDとは、業務を構成する処理と受け渡されるデータの流れを3つの要素（プロセス・源泉と吸収・データストア）およびデータフローを図式表現したもの\nDFDの使用用途 # デマルコによって提唱された「構造化分析法」はシステム機能間のデータの流れに着目してシステム要求を可視化する技法である。\nこの構造化分析においてDFD(Data Flow Diagram：データフローダイアグラム)を用いて単にデータとプロセスを図式表現するだけでなく、構造化仕様書を作成していく。\n構造化分析 # 現物理モデル 現論理モデル 新論理モデル 新物理モデル コンテキストダイアグラム # 最上位のプロセスを記述したDFD\nDFDの構成要素と記号 # 記号 名称 意味 ○ プロセス（Process） データを処理・変換する機能や手続き。「～する」という動詞で表現される。（例：受注登録する） → データフロー（Data Flow） データの流れそのもの。矢印で向きを示す。「～データ」「～伝票」といった名詞で表現される。（例：注文データ） ＝ データストア（Data Store） データの保管場所。ファイルやデータベースを指す。「～台帳」「～ファイル」といった名詞で表現される。（例：顧客マスタ） □ 外部実体（External Entity）（源泉と吸収） システムの外部にあって、データの発生源（源泉）や最終的な送り先（吸収）となるもの。人や部署、他システムなど。（例：顧客、取引先） DFDのレベル分解 # レベル0（コンテキストダイアグラム） # システム全体を1つのプロセスとして表現 外部実体とシステムの入出力関係を明示 最も抽象度が高い レベル1 # レベル0のプロセスを主要な機能単位に分解 システムの主要機能の流れを表現 レベル2以降 # レベル1のプロセスをさらに詳細に分解 より具体的な処理内容を表現 DFD作成のルール # プロセスの番号付け: 階層的に番号を付ける（1.0 → 1.1, 1.2\u0026hellip;） データフローのバランス: 親プロセスの入出力と子プロセスの入出力は一致させる データストアの接続ルール: データストアはプロセスを経由して接続（データストア同士、外部実体とデータストアの直接接続は禁止） 外部実体同士の直接接続禁止: 外部実体同士は直接データフローで結ばない データフローの命名: データの内容が明確に分かる名詞で表現する 具体例：ECサイトの注文処理 # 【レベル0】 ┌────────┐ │ 顧客 │─────注文情報────→┌──────────────┐ └────────┘ │ 注文処理 │ │ システム │ ┌────────┐←────出荷通知─────│ （全体） │ │ 配送業者│ └──────────────┘ └────────┘ │ 在庫照会/更新 ↓ ┌──────────────┐ │ D1:在庫DB │ └──────────────┘ 【レベル1】 顧客 → 1.注文受付 → D1:注文DB ↓ 2.在庫確認 ← D2:在庫DB ↓ 3.出荷指示 → 配送業者 ","date":"2025年 10月 7日","externalUrl":null,"permalink":"/scraps/1759821280_dfd_data_flow_diagram/","section":"スクラップ","summary":"","title":"DFD（Data Flow Diagram）","type":"scraps"},{"content":"","date":"2025年 10月 7日","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"このセクションには、学習過程で作成したメモや短いスクラップが含まれています。技術的な内容から読書メモまで、様々な学習記録を整理しています。\nPython関連 # Python概要とインストールなど pyenvでPythonバージョン管理｜インストールから切り替えまで 仮想環境venv入門 virtualenv入門 pipコマンド入門 requirements.txt入門 NumPy入門 Pandas入門 Python入門ハンズオン Python基礎ハンズオン Hugo・Blowfish関連 # Hugo+Blowfish｜ダークモードに固定する設定方法 Hugo+Blowfish｜mainSections設定でコンテンツ分離する方法 Hugo・BlowfishでカスタムCSS適用 読書メモ # 【書評】TAKE NOTES! 【書評】指示通りができない人たち 応用情報技術者試験 # 【応用情報技術者試験】テクノロジ系学習メモ 【応用情報技術者試験】マネジメント系学習メモ 【応用情報技術者試験】ストラテジ系学習メモ 学習メモ：情報セキュリティ10大脅威 2025（組織編） JIS_Q_21500:2018 EVM ホワイトボックステスト（命令網羅・条件網羅など） UML（Unified Modeling Language） ","date":"2025年 10月 7日","externalUrl":null,"permalink":"/scraps/","section":"スクラップ","summary":"","title":"スクラップ","type":"scraps"},{"content":"","date":"2025年 10月 7日","externalUrl":null,"permalink":"/tags/%E5%BF%9C%E7%94%A8%E6%83%85%E5%A0%B1%E6%8A%80%E8%A1%93%E8%80%85%E8%A9%A6%E9%A8%93/","section":"Tags","summary":"","title":"応用情報技術者試験","type":"tags"},{"content":"","date":"2025年 10月 7日","externalUrl":null,"permalink":"/","section":"技術的デジャブ回避メモ帳","summary":"","title":"技術的デジャブ回避メモ帳","type":"page"},{"content":" UMLとは # システムやソフトウェアの「設計図」を描くための記法\nUMLには様々な種類があるが、大別すると「構造図」と「振る舞い図」に分けられる\n構造図：システムの静的な構造、つまり、どのような要素で構成されているかを表す図 （例: クラス図、コンポーネント図） 振る舞い図：システムの動的な振る舞い、つまり、時間と共にどのように動作し、変化するかを表す図 （例: シーケンス図、ユースケース図、アクティビティ図） UMLダイアグラムの解説 # コミュニケーション図 # オブジェクト群がどのようにコラボレーションを行うか記述できる図\nシーケンス図と同様にオブジェクト間の相互作用を表現できるが、時間軸がない。 オブジェクト間の**連携関係（コネクション）**に焦点を当てている。 クラス図 # クラスの仕様と，クラスの間の静的な関係（汎化，集約，関連など）が記述できる図\nクラスが持つ属性（データ）と操作（メソッド）、およびクラス間の関係性を表現 シーケンス図 # オブジェクト間で送受信するメッセージによる相互作用が表せる図\nオブジェクト間のメッセージのやり取りを、時間軸に沿って表現するのが最大の特徴 オブジェクト図 # ある時点でのオブジェクト（インスタンス）の状態や関係性を記述できる図\nクラス図を具体化したもの 特定の時点における、オブジェクト（クラスのインスタンス）の状態や関係性を表すスナップショットのようなイメージ ユースケース図 # システムの振る舞いを表現する図で、システムに要求される機能を、ユーザーの視点から示した図\nステートマシン図 # 一つのオブジェクトの状態が、イベントの発生などによってどのように変化（遷移）するかを記述できる図\n例えば、「注文」オブジェクトが「受付済」→「発送準備中」→「発送済」と変化していく様子を表現できる コンポーネント図 # システムのコンポーネント間の物理的な関係が記述できる図\n物理的な要素（コンポーネント）と、それらの依存関係を表現する コンポーネントとは、ライブラリファイル（DLLなど）や実行ファイル（EXEなど）といった、物理的な部品を指す。 アクティビティ図 # 多くの並行処理を含むシステムの，業務や処理の「流れ（フロー）」を表現する図\n業務や処理の流れ（フロー）、特に分岐と並行処理を表現する 参考リンク # 応用情報技術者過去問道場 令和07年【春期】【⁠秋期】応用情報技術者 合格教本 ","date":"2025年 10月 7日","externalUrl":null,"permalink":"/scraps/1759819417_uml_unified_modeling_language/","section":"スクラップ","summary":"","title":"UML（Unified Modeling Language）","type":"scraps"},{"content":" ホワイトボックステスト # ホワイトボックステストにおける下記の条件などについて整理する\n網羅基準 テスト強度 概要 命令網羅 弱い すべての処理文を1回は実行する 分岐網羅 ↓ すべての分岐の真/偽を1回は実行する 条件網羅 中程度 すべての個々の条件の真/偽を1回はとる 判定条件・条件網羅 ↑ 分岐網羅と条件網羅の両方を満たす 複数条件網羅 強い 個々の条件の真/偽の全組み合わせを実行する 命令網羅 # すべての処理文を1回は実行するテスト\nIF (A \u0026gt; 5) THEN 処理X // ←ここを1回通す END IF 処理Y 上記の例の場合、A=10 のようなテストケースを実行すれば、処理Xと処理Yの両方が実行されるため、命令網羅を達成する。\n分岐網羅 # すべての分岐の真/偽を1回は実行するテスト\nIF (A \u0026gt; 5) THEN // 分岐1 処理X END IF テストケース1: A=10 → 分岐1の**真（True）**のルートを実行 テストケース2: A=3 → 分岐1の**偽（False）**のルートを実行 この2つのテストケースで、分岐網羅率100%を達成 複雑な条件式（ANDやORで結ばれた条件）の内部は確認しない。例えば IF (A \u0026gt; 5 AND B == 10) の場合、A \u0026gt; 5 がTrueかFalseか、B == 10 がTrueかFalseか、個々の条件の組み合わせまではテストしない。 条件網羅 # すべての個々の条件の真/偽を1回はとるテスト\nIF (A \u0026gt; 5 AND B == 10) THEN ... // 条件1: A \u0026gt; 5 // 条件2: B == 10 テストケース1: A=10, B=10 → 条件1がTrue, 条件2がTrue テストケース2: A=3, B=0 → 条件1がFalse, 条件2がFalse この2つのテストケースで、条件1と条件2がそれぞれTrue/Falseを経験するため、条件網羅100%を達成 注: 条件網羅では、判定条件全体の真偽は考慮しない（個々の条件がTrue/Falseを経験すれば良い） 判定条件・条件網羅 # 分岐網羅と条件網羅の両方を満たすテスト\nIF (A \u0026gt; 5 AND B == 10) THEN ... // 判定条件全体: (A \u0026gt; 5 AND B == 10) // 条件1: A \u0026gt; 5 // 条件2: B == 10 テストケース1: A=10, B=10 判定条件全体 → True 条件1 → True, 条件2 → True テストケース2: A=3, B=10 判定条件全体 → False 条件1 → False, 条件2 → True テストケース3: A=10, B=0 判定条件全体 → False 条件1 → True, 条件2 → False これで判定条件のTrue/False、および各条件のTrue/Falseがすべて網羅されます。 複数条件網羅 # 個々の条件の真/偽の全組み合わせを実行するテスト\nIF (A \u0026gt; 5 AND B == 10) THEN ... // 条件①: A \u0026gt; 5 // 条件②: B == 10 条件が2つなので、2の2乗 = 4通りの組み合わせをテストする テストケース1: 条件①=True, 条件②=True (A=10, B=10) テストケース2: 条件①=True, 条件②=False (A=10, B=0) テストケース3: 条件①=False, 条件②=True (A=3, B=10) テストケース4: 条件①=False, 条件②=False (A=3, B=0) 参考リンク # 応用情報技術者過去問道場 令和07年【春期】【⁠秋期】応用情報技術者 合格教本 ","date":"2025年 10月 7日","externalUrl":null,"permalink":"/scraps/1759804420_whiteboxtest/","section":"スクラップ","summary":"","title":"ホワイトボックステスト（命令網羅・条件網羅など）","type":"scraps"},{"content":" EVMとは？ # プロジェクトの進捗やパフォーマンスを金銭価値に置き換えて管理する手法\nEVMにおける主な3つの指標 # 略称 名称 意味 PV Planned Value（計画価値） 【計画】 ある時点までに完了させる予定だった作業の予算額 EV Earned Value（出来高価値） 【実績（出来高）】 ある時点までに完了した作業の（計画時の）予算額 AC Actual Cost（実コスト） 【実績（コスト）】 ある時点までに実際にかかった総コスト その他の指標 # 指標（略称） 正式名称 計算式 簡単な特徴・意味 CPI Cost Performance Index（コスト効率指数） EV / AC コストの効率性を測る指標。1より大きいと効率が良く（予算内）、小さいと非効率（予算超過）。 SPI Schedule Performance Index（スケジュール効率指数） EV / PV スケジュールの効率性を測る指標。1より大きいと順調（計画より前倒し）、小さいと遅延している。 BAC Budget At Completion（完成時総予算） （計画値のため計算式なし） プロジェクト開始前に計画された全体の総予算。コスト評価の基準点となる。 TCPI To Complete Performance Index（残作業効率指数） (BAC - EV) / (BAC - AC) 予算内で終えるために 「今後」必要となるコスト効率の目標値 現在のCPIと比較し、目標達成の難易度を判断する。 参考リンク # 応用情報技術者過去問道場 令和07年【春期】【⁠秋期】応用情報技術者 合格教本 ","date":"2025年 10月 7日","externalUrl":null,"permalink":"/scraps/1759800890_earned_value_management/","section":"スクラップ","summary":"","title":"EVM（Earned_Value_Management）","type":"scraps"},{"content":" JIS Q 21500:2018とは？ # プロジェクトマネジメントの「手引書」\n正式名称は「プロジェクト，プログラム及びポートフォリオマネジメント－プロジェクトマネジメントの手引」 国際規格である「ISO 21500:2012」を基に作成されている。 プロジェクトマネジメントの知識体系であるPMBOKをベースにしているため、共通点が多い 応用情報技術者試験で押さえるべき2つの軸 # JIS Q 21500について応用情報技術者試験では、「5つのプロセス群」と「10の対照群」が頻出\n5つのプロセス群 # プロセス群 説明 プロセス 立上げ プロジェクトを開始し、目標を定義し、プロジェクトマネージャに権限を与えるために使用 プロジェクト憲章の作成・ステークホルダの特定・プロジェクトチームの編成 計画 プロジェクトの目標を達成するための作業方針を確立し、計画を策定するために使用 全体計画の作成・スコープの定義・WBSの作成 実行 計画に従ってプロジェクトの作業を遂行し、成果物を作成するために使用 作業の指揮・ステークホルダの管理 コントロール（管理） プロジェクトの進捗を監視・測定し、計画との差異を是正するために使用 変更の管理・資源の管理 終結 プロジェクトやフェーズを正式に完了させるために使用 プロジェクトの終結・教訓の整理 10の対象群 # 対象群 説明 統合 プロジェクト全体の様々な要素を調整・統合 ステークホルダ プロジェクトに関係する人々を特定し、その要求や期待を管理 スコープ プロジェクトで実施すべき作業（と実施しない作業）を定義し、管理 資源 プロジェクトに必要な要員や設備などを計画し、管理 時間 プロジェクトのスケジュールを作成し、進捗を管理 コスト プロジェクトの予算を見積もり、管理 リスク プロジェクトの不確実性（リスク）を特定、分析、対応 品質 プロジェクトの成果物が要求事項を満たすように保証・管理 調達 外部から製品やサービスを購入・獲得するためのプロセスを管理 コミュニケーション プロジェクト情報を適切に計画、作成、配布、保管、管理 過去問 # 応用情報技術者試験平成31年春期の午前問題問51\n問題文 # JIS Q 21500:2018(プロジェクトマネジメントの手引)によれば，プロジェクトマネジメントの\u0026quot;実行のプロセス群\u0026quot;の説明はどれか。\n選択肢 # ア：プロジェクトの計画に照らしてプロジェクトパフォーマンスを監視し，測定し，管理するために使用する。 イ：プロジェクトフェーズ又はプロジェクトが完了したことを正式に確定するために使用し，必要に応じて考慮し，実行するように得た教訓を提供するために使用する。 ウ：プロジェクトフェーズ又はプロジェクトを開始するために使用し，プロジェクトフェーズ又はプロジェクトの目標を定義し，プロジェクトマネージャがプロジェクト作業を進める許可を得るために使用する。 エ：プロジェクトマネジメントの活動を遂行し，プロジェクトの全体計画に従ってプロジェクトの成果物の提示を支援するために使用する。\n正解と解説 # 選択肢エが正解\nその他の選択肢は下記\n選択肢ア：管理のプロセス群 選択肢イ：終結のプロセス群 選択肢ウ：立ち上げのプロセス群 参考リンク # 応用情報技術者過去問道場 令和07年【春期】【⁠秋期】応用情報技術者 合格教本 問題冊子・配点割合・解答例・採点講評（2019年度、平成31年度、令和元年度） ","date":"2025年 10月 7日","externalUrl":null,"permalink":"/scraps/1759799499_jis_q_21500_2018/","section":"スクラップ","summary":"","title":"JIS_Q_21500:2018","type":"scraps"},{"content":" 概要 # 応用情報技術者試験のマネジメント系学習メモを集約する。\n参考資料 # 応用情報技術者過去問道場 令和07年【春期】【⁠秋期】応用情報技術者 合格教本 学習メモ # WBS（Work Breakdown Structure） # プロジェクトチームが実行すべき作業を、成果物を主体に階層的に要素分解したもの\nワークパッケージ # WBSにおける最下層に位置する個々の部分\nCMMI（Capability Maturity Model Integration：統合能力成熟度モデル） # 組織におけるプロセス改善をガイドするモデル\nCMMIにて定義されている5つのレベル # レベル1: 初期_場当たり的で無秩序な組織として最も低い状態 レベル2: 管理された_プロジェクト管理のための基本的なプロセスが備わっている状態 レベル3: 定義された_組織内に標準化された一貫性のあるプロセスが定義されている状態 レベル4: 定量的に管理された_定量的な品質目標が存在し、プロセスはデータに基づき予測可能である状態 レベル5: 最適化している_継続的な改善プロセスが常に機能している状態 フェーズ・ゲート # プロジェクトの開始、組織編成と準備、作業の遂行、プロジェクトの完了などの各プロジェクト・フェーズの終了時に実施するレビュー\nPMBOKにて記載されている プロジェクトマネジメントオフィス（PMO：Project Management Office） # 企業内のプロジェクトを横断的に支援する専門部署\n企業内で並行して実施されている個々のプロジェクトのマネジメント業務の支援、プロジェクトマネージャのサポート、部門間の調整などプロジェクトが円滑に実施されるように支援を行う専門の部署 ファストトラッキング技法 # 当初の計画では順番に行う予定だったアクティビティを並行して実施することによってスケジュール短縮を図る手法\nアローダイアグラム総余裕日数の計算方法 # アローダイアグラム総余裕日数 = 最遅結合点時刻 - 最早結合点時刻\nサービスマネジメントシステム(SMS) # 自社のITサービスや管理の特性に応じた体系的な仕組み\n是正措置 # 検知した不具合などの原因を除去・再発防止を防ぐ処置\n継続的改善 # パフォーマンス向上のために繰り返し実施される活動\nJIQ Q 20000-1:2020 # サービスマネジメントシステムについて、実施・維持・改善するために、組織に対する要求事項を示したもの\n変更管理 # ITサービスを構成する要素(ハードウェアやソフトウェア)に対する全ての変更を管理するプロセス\n変更管理の実施手順 # 変更管理方針: 変更管理の方針を確立 変更管理の開始: 変更要求(RFC)を記録・分類する 変更管理の活動: RFCの承認および優先度を決定 承認された変更を試験 試験結果にて失敗した場合は切り戻しなど実施 成功した場合は稼働環境へ展開 重大な変更の場合: RFCはCABの審議にかけられる\nCAB(Change Advisory Board(変更諮問委員会)) # ITサービスに対する変更要求（RFC：Request For Change）を評価・判定する組織\nCABのメンバーは固定ではなく、変更内容に応じて変更される RFC(Request For Change) # サービス・サーボスコンポーネントに対する変更の提案\nシステム監査基準 # 監査人が従うべき行動規範\n全般統制 # 組織や集団全体を対象とした統制\n業務処理統制 # 個々の業務が対象の統制\n監査サンプリング # 監査人が監査対象となった母集団全体に関する結論を導き出すための合理的な基礎を得るため、 母集団内のすべてのサンプリング単位に抽出の機会が与えられるような方法\n使用されるタイミング: 母集団内の100%未満の項目に監査手続を適用する場合\n監査サンプリングにおける許容逸脱率 # 受け入れることができる所定の内部統制からの逸脱率であり，監査人がサンプルの件数を決めるときに用いられる指標\nシステムインテグレーション契約 # 顧客（ユーザー企業）が抱える課題を解決するために、情報システムの企画、設計、開発、導入、運用、保守までを一貫して、またはその一部を請け負う契約\nコンフィギュレーション・マネジメント # コンフィギュレーション・マネジメント（構成管理）とは、システムやソフトウェア、\nITサービスを構成する要素（ハードウェア、ソフトウェア、ドキュメントなど）の情報を正確に把握し、 一貫性を保ちながら管理・維持するための体系的な活動\nプロジェクト憲章 # プロジェクトの背景や目的、実施要綱、方針などを最上位レベルで明記し、当該プロジェクトを正式に立ち上げる際に作成される文書\nパラメトリック見積り # 関連する過去のデータとその他の変数との統計的関係を用いて，プロジェクトにおける作業のコストを見積もる。\nファンクションポイント法やCOCOMO及びプログラムステップ法もパラメトリック見積りの一種 標準タスク法 # WBSに基づいて，成果物単位や処理単位に工数を見積もり，ボトムアップ的に積み上げていく方法\nRACIチャート # 責任分担表(RAM)の一種で、2次元の表の各軸に要員名と作業を設定し、\nそれぞれの要員が担う役割および負う責任を作業別に一覧にしたもの\nR（Responsible）：実行責任 A（Accountable）：説明責任 C（Consulted）：相談対応 I（Informed）：報告先、情報提供 ","date":"2025年 10月 6日","externalUrl":null,"permalink":"/scraps/1759704789_ap2025_manage_study_memo/","section":"スクラップ","summary":"","title":"【応用情報技術者試験】マネジメント系学習メモ","type":"scraps"},{"content":" 概要 # 応用情報技術者試験のストラテジ系学習メモを集約する。\n参考資料 # 応用情報技術者過去問道場 令和07年【春期】【⁠秋期】応用情報技術者 合格教本 学習メモ # SoE(Systems of Engagement) # 企業システムのうち、顧客や企業との関係性を深めるために構築されるシステム\n具体例として、SNSやモバイルアプリ、Webサイトなどが挙げられる。 ユーザーとの接点となり、人と人との繋がりを生み、それを維持していくことを主眼とする。\nSaaS(Software as a Service) # ソフトウェアの提供者がインフラ、OS、ミドルウェア、アプリケーション全ての管理責任を負うサービス形態\nメリット：セキュリティパッチの調査・適用作業が不要 例：Office 365、Salesforce ROE(Return On Equity) # 自己資本に対してどれだけ効率的に利益を上げたかを示す指標\nROEの計算式 # ROE（%） = 当期純利益 ÷ 自己資本 × 100\nSECIモデル # 「共同化→表出化→連結化→内面化」という4つのプロセスを経ることで組織の共有の知識となることを示している\n共同化 暗黙知から暗黙知 個人から組織 表出化 暗黙知から形式知 組織から個人 連結化 形式知から形式知 個人から組織 内面化 形式知から暗黙知 組織から個人 graph TD S[共同化\nSocialization\n暗黙知から暗黙知へ] E[表出化\nExternalization\n暗黙知を形式知に変換] C[連結化\nCombination\n形式知の連結と体系化] I[内面化\nInternalization\n形式知を暗黙知に変換] S --\u003e E E --\u003e C C --\u003e I I --\u003e S サービスプロフィットチェーン # 従業員満足度・サービス・顧客満足度・利益の因果関係を表したモデル\n従業員満足度が向上すれば、顧客へのサービスレベルも向上して、それが顧客満足度の向上へつながって、利益を生むことを示している。 ハーバード大学のベスケット教授らが提唱 flowchart TD ES[従業員満足度] --\u003e ESrv[サービスの質] ESrv --\u003e CS[顧客満足度] CS --\u003e CL[顧客ロイヤルティ] CL --\u003e Profit[利益] ES --\u003e ESrv2[従業員生産性] ESrv2 --\u003e Profit バリューチェーン分析 # 企業の活動を5つの主活動(購買、製造、出荷、販売、サービスなど)と4つの支援活動に分類し、 価値(マージン)がどの活動で生み出されるかを分析するフレームワーク\n構成要素 # 主活動(5つ): 購買物流: 原材料・部品の調達・入庫・保管 製造: 原材料を製品に加工・組立 出荷物流: 製品の出荷・配送・在庫管理 販売・マーケティング: 営業活動・広告・市場開拓 サービス: アフターサービス・保守・顧客サポート 支援活動(4つ): 全般管理(インフラストラクチャ): 経営管理・財務・法務 人事・労務管理: 人材採用・教育・評価制度 技術開発: 研究開発・製品改良・特許管理 調達活動: 設備・システム・サービスの調達 マージン: 総価値と総コストの差がマージン(利益)となる。どの活動で価値が生み出されるかを特定することが重要\n頻出ポイント: 主活動と支援活動の分類は頻出テーマ、競争優位性を持つ活動の特定、ERP導入時の影響分析(標準化による強みの喪失リスク)\nパーミッションマーケティング # 同意を得た顧客に対して直接的にパーソナルな売り込みを行う手法\nバイラルマーケティング # 口コミやインターネットでの情報共有を促進する仕組みを構築して、情報を自然発生的に周知することで認知度を向上させる手法\n多角化戦略の類型 # アンゾフの成長戦略における多角化戦略の類型\n多角化戦略の類型とは？ # 多角化戦略は「既存技術との関連度」や「市場の類似性」によって、4つに分類される。\n既存技術との関連度が高い 既存技術との関連度が低い 市場の類似度がある 水平型 垂直型 市場の類似度がない 集中型 集成型 水平型多角化戦略 # 既存技術と関連性の高い新製品を既存と類似した市場へ投入 例：食品会社が異なる種類の食品市場に進出する\n垂直型多角化戦略 # 既存技術と関連性の低い新製品をサプライチェーンの上流・下流に位置する市場へ投入 例：自動車会社が下請けの部品メーカーをM\u0026amp;Aする\n集中型多角化戦略 # 既存技術と関連性の高い新製品を異なった市場へ投入 例：写真フィルムで培った材料・画像技術を核に医療機器やバイオ化粧品へ展開\n集成型多角化戦略 # 既存の技術や市場とは全く異なった事業に進出 例：リース事業や不動産、プロ野球球団経営など展開しているオリックス\nSWOT分析 # 自社のリソース(資金力や技術力など)に関連する事項を「強み」と「弱み」、 外部の環境から受ける影響を「機会」と「脅威」にそれぞれ分類して分析する手法\nSWOT分析の分類方法 # 内部環境 強み（Strength）：自社の武器になる内部要因 弱み（Weakness）：自社の弱点になる内部要因 外部環境 機会（Opportunity）：自社のチャンスとなる外部要因 脅威（Threat）：自社の脅威となる外部要因 クロスSWOT分析 # クロスSWOT分析はSWOT分析で把握した「強み」「弱み」「機会」「脅威」の4つの要素をクロスさせることで戦略の方向性を導き出す手法\n機会 脅威 強み 推進戦略（SO戦略：機会に強みを投入） 差別化戦略（ST戦略：強みで差別化して脅威を回避する） 弱み 弱点強化戦略（WO戦略：弱みを克服し機会を逃がさない） 専守防衛・撤退戦略（WT戦略：脅威の最悪の事態を回避・撤退する） ","date":"2025年 10月 6日","externalUrl":null,"permalink":"/scraps/1759704766_ap2025_srs_study_memo/","section":"スクラップ","summary":"","title":"【応用情報技術者試験】ストラテジ系学習メモ","type":"scraps"},{"content":" 概要 # 応用情報技術者試験のテクノロジ系学習メモを集約する。\n参考資料 # 応用情報技術者過去問道場 令和07年【春期】【⁠秋期】応用情報技術者 合格教本 学習メモ # 基数変換問題で無限小数を素早く判定する方法 # 基数変換問題で無限小数を判定するような問題では分母の素因数分解で判定できる。\n手順:\n判定対象の数値を分数に変換 この分数の既約分数(約分してこれ以上割れない形)にする 分母を因数分解する このとき、分母が対象の基数のべき乗のみ場合は有限小数。基数のべき乗以外の場合は無限小数と判断できる 具体例:\n0.05 0.125 0.5 上記の3つの10進数小数のうち、2進数に変換すると無限小数になるのは? 手順に則ってそれぞれ分母を因数分解すると 0.05 = 5/100 = 1/20 = 1/2^2*5 0.125 = 125/1000 = 1/8 = 1/2^3 0.5 = 5/10 = 1/2 = 1/2^1 「1:0.05」で分母に「5」が紛れていることがわかる。よって、「0.05」が無限小数と判定できる。 リスト # 順序付けられたデータの並び。主なデータ構造として、配列と連結リストが存在する。\n配列 # 個々の要素の位置を固定して、要素が格納されている番地(アドレス)を簡単に計算できるようにしたデータ構造\n特徴\nダイレクトアクセス(任意の要素への直接参照)が可能 要素の挿入・削除には非効率 当該位置の要素を一つずつ前後に移動させる必要があるため 予め最大データ数に対応した領域を確保する必要がある 連結リスト # 各要素をポインタでつないだデータ構造\nポインタの接続方法で3種類に分類できる 単方向リスト（線形リスト・片方向リンク） # 各要素は次の要素へのポインタを持つ\n双方向リスト（双方向リンク） # 各要素は前後両方の要素のポインタを持つ。\n単方向リストとの違いとして、途中要素への挿入・削除は双方向が容易である。 循環リスト # 末尾の用が先頭要素へのポインタを持つ単方向リスト\n配列と連結リストの違い # 記憶域: 1つのデータあたりの必要な記憶域は連結リストのほうが大きい\n連結リストでは「データ + ポインタ」で管理されるため 追加・削除: 要素の追加・削除においては連結リストのほうが容易\n連結レストでは、配列と異なり、番地が固定されていないため、ポインタの値変更のみで済むため 記憶域の変化: 連結リストでは必要な記憶域は動的に変化して、データ数に比例する\n連結リストにおける要素の追加・削除 応用情報技術者試験ではHead(先頭要素へのポインタ)・Tail(末尾要素へのポインタ)について出題される Head・Tail・E1～E5のリストを具体例に解説する。 具体例: graph LR Head --\u003e E1; subgraph \"Singly Linked List\" E1 --\u003e E2 --\u003e E3 --\u003e E4 --\u003e E5 --\u003e Null([null]); end Tail --\u003e E5; style Head fill:#f9f,stroke:#333,stroke-width:2px style Tail fill:#ccf,stroke:#333,stroke-width:2px style Null fill:#eee,stroke:#333,stroke-dasharray: 5 5 要素E0を先頭に追加する場合\nE0のポインタ部でE1を設定 HeadでE0のアドレスを設定 要素E6を末尾に追加する場合\nTailからたどったE5のポインタ部でE6を設定 TailでE6のアドレスを設定 要素E1を先頭から削除する場合\nHeadからたどったE1のポインタ部の値である「E2のアドレス」をHeadに設定 要素E5を末尾から削除する場合\nHeadから順番にE4までたどる E4のポインタ部にNULLを設定 TailにE4のアドレスを設定 マージソート # データを最小単位(要素が1つ)になるまで半分に分割し、その後、それらを正しい順序で「マージ(併合)」していくことで全体のソートを完成させるソート方法\n値呼び出し # 引数の渡し方において、関数内で変数の値を上書きしても元の変数の値には反映されない。\n参照呼出し # 引数の渡し方において、関数内で変数の値を上書きすると元の変数の値に反映される。\n再入可能プログラム（リエントラントプログラム） # 複数のタスクから同時に呼び出されても、それぞれに対して正しい結果を返すことができるプログラム\n再入可能プログラムの実現方法 # プログラムを「手続部分」と「データ部分」に分離する 複数のタスクで共有するのは「手続部分」・「データ部分」は各タスク単位で用意することで再入可能プログラムを実現できる。 再帰プログラム（リカーシブプログラム） # 手続きの中で自分自身を呼び出して使うことができるプログラム\n自分自身を呼び出すことができる 実行途中の状態はスタックを用いてLIFO方式で制御 再入可能 再使用可能プログラム（リユーザブルプログラム・逐次再使用可能プログラム） # 一度実行したプログラムをロードし直さずに再度実行しても、正しい結果を返すことができるプログラム\n再配置可能プログラム（リロケータブルプログラム） # プログラムを主記憶上のどのアドレスに配置しても実行できるようにしたプログラム\n多くの場合、ベースアドレス指定方式などを用いて、プログラムが配置された先頭アドレス(ベースアドレス)を軸にアドレス計算を行い、命令やデータへのアクセスが可能になっている。 ニモニックコード（表意コード） # 商品の略称や記号など、記憶しやすいように意味を持たせたコード\n具体例：「B5」→ B5用紙 VLIW（Very Long Instruction Word） # プログラムのコンパイル時に、一つの命令語で複数の命令を同時に実行する手法。\nCPUのオーバーヘッドが減り高速化が可能 複数の処理を一つの命令に記述するため1命令が非常に長くなる ページング # メモリ領域を「ページ」と呼ばれる固定サイズの区画に分割して仮想記憶を管理する方式\n仮想アドレス空間と物理アドレス空間をページ単位で対応付けて管理する ページ置換の基本的な流れ # ページフォールトが発生 ページフォールト:CPUがアクセスしようとしたページが主記憶上に存在しないときに発生するハードウェア割り込み 主記憶に空きがなければ、置換アルゴリズム(LRU、FIFO等)により主記憶上から補助記憶装置に移すページを決定 手順2で決定したページを補助記憶装置に移動(ページアウト) ページアウト:主記憶上のページを補助記憶装置(ディスク)に書き出す処理 必要なページを補助記憶装置から主記憶に読み込み(ページイン) ページイン:補助記憶装置上のページを主記憶に読み込む処理 LRU(Least Recently Used) # 最も長い間参照されていないページを置換するアルゴリズム\n動作: 最後に参照されてから最も時間が経過しているページを追い出します。 プログラムが特定の領域を集中してアクセスするという「参照の局所性」の原理に基づいています。 長所: 一般的にFIFOよりも効率が良く、性能が高い傾向にあります。 短所: どのページがいつ参照されたかをすべて記録しておく必要があるため、実装が複雑になり、システムのオーバーヘッドが大きくなる可能性があります。 FIFO(First In First Out) # 最も古く読み込まれたページを置換する最も単純なアルゴリズム\n動作: メモリに最初に入ってきたページ（最も古くから存在するページ）を最初に追い出します。 長所: 実装が非常に簡単です。 短所: 頻繁にアクセスされる重要なページであっても、古くからメモリにあれば追い出されてしまいます。 物理メモリのサイズを増やしたにもかかわらず、ページフォールト（必要なページがメモリ上にない状態）が増えてしまう「ベラディの異常（Belady\u0026rsquo;s Anomaly）」と呼ばれる現象が発生することがあります。 ベラディの異常 # 仮想記憶システムにおいて、プロセスのために割り当てる物理メモリのページフレーム数を増やしたにもかかわらず、かえってページフォールトの発生回数が増加してしまうという、直感に反する現象\nLFU(Least Frequently Used) # 「最も使用頻度が低い」ページを置き換えるアルゴリズムです。\n動作: これまでの参照回数が最も少ないページを追い出します。 長所: 長期間にわたって頻繁に参照されるページをメモリに保持し続けることができます。 短所: 各ページの参照回数を記録・管理する必要があるため、実装が複雑です。 過去に集中的にアクセスされたページが、その後全く使われなくなっても、参照回数が多いためにメモリに残り続けてしまうという問題があります。 ###　LIFO (Last-In, First-Out)\n「後入れ先出し」とも呼ばれ、スタック構造で利用されるアルゴリズム\n動作: 最後にメモリに入ってきたページを最初に追い出します。 特徴: 実際のページ置き換えアルゴリズムとしてはほとんど使用されません。理論的な比較対象や、データ構造の概念として重要です。応用情報技術者試験では選択肢として出題される場合があります。 フラグメンテーション # 主記憶や補助記憶装置にて使用されない記憶領域の断片が多く存在した状態になる現象\nスラッシング # メモリ容量が不足している状態で、要求されるメモリ量が多すぎるために、メモリと補助記憶装置間でのデータの入れ替え(ページイン・ページアウト)が非常に頻繁に発生し、システムの処理速度が著しく低下してしまう現象\n発生するケース: 主記憶の容量が十分でない場合、プログラムの多重度を増加させると、システムのオーバーヘッドが増加するため、発生しやすい。\nキャッシュメモリにおけるダイレクトマップ方式 # 一つのメモリブロックをキャッシュ内の単一のロケーションに割り当てる。\nメモリのデータ転送速度の計算（H31春午前問10） # 問題要件\nバス幅:16bit メモリサイクルタイム:80ナノ秒 求められる解答:このメモリのデータ転送速度は何Mbyte/秒 計算式\n1秒間のデータ転送回数 1秒/80ナノ秒 16bit = 2byte 「1秒間のデータ転送回数」*「2byte」 25Mbyte/秒 正答:\n25Mbyte/秒 オブジェクトストレージ # 「オブジェクト」という単位でデータを格納・管理する記憶方式\n（具体例：Amazon S3）\nイミュータブルストレージ # 一度書き込んだデータの変更・削除が不可能な「不変」の特性を持つストレージ\n用途: ランサムウェア対策としてバックアップデータの保護\n効果: 攻撃者に侵入されてもバックアップデータの改ざんを防ぐ\n3層クライアントサーバシステム # システムを3層(プレゼンテーション層・ファンクション層・データベースアクセス層)に分けたシステム\nプレゼンテーション層: GUIなどユーザーインターフェース処理を担当 ファンクション層: データ処理を担当 データベースアクセス層: データベース処理を担当 メリット\n業務ロジックに変更が生じても、クライアントへの影響が少ない アプリケーションの修正などが頻繁なシステムでは導入効果が高い 各層の独立性が高いため、開発作業を並行して実施できる グリッドコンピューティング # PCから大型コンピュータまで，ネットワーク上にある複数のプロセッサに処理を分散して，大規模な一つの処理を行う方式\nCAP定理 # 分散処理システムにおいては、一貫性・可用性・分断耐性の3つの特性のうち、最大でも同時に2つまでしか満たすことができないとする定理\n一貫性(Consistency): データの整合性が常に保たれていること\n可用性(Availability): 利用したいときに求める分だけ利用できること\n分断耐性(Partition Tolerance): データを複数のサーバに分散して保管していること\nMTBF(Mean Time Between Failure / 平均故障間隔) # 故障してから次に故障するまでの平均時間\nMTTR(Mean Time To Repair / 平均修理時間) # 故障時に修理が完了するまでの平均時間\n稼働率の計算 # 計算式: MTBF / (MTBF + MTTR)\n計算式が成り立つ理由 故障してから次の故障するまでの時間を1つのサイクルとする 1つのサイクルの時間 = MTBF + MTTR サイクル中にシステムが正常に稼働している時間はMTBFと等しい 上記より、稼働率の計算式は「稼働率 = 正常にシステムが稼働している時間 / 1つのサイクルの時間」が成り立つ 故障率の計算 # 計算式: 1 / MTBF\n計算式が成り立つ理由 例として、「1000時間稼働させると平均1回故障する部品」があるとする。 故障率は「1時間あたりに何回故障するかという指標」 この例におけるMTBFは「1000時間」 上記より、故障率の計算式は「1/1000」つまり、「1/MTBF」が成立する 補足 「単位」に着目するとより明確になる MTBFの単位: 時間/回 (1回あたりの時間) 故障率の単位: 回/時間 (1時間あたりの回数) フォールトトレランス # 故障してもシステム全体として必要な機能を維持させようとする考え方\nフォールトトレラントシステム # フォールトトレランスの考えが反映されたシステム\nフォールトアポイダンス # 構成要素個々の品質を高めて、故障そのものの発生を防ぐこと\nフェールソフト # 故障発生時に、性能の低下を受け入れて、システム全体を停止させずに稼働を維持させる考え方\nフォールバック(縮退運転) # フェールソフトにおいて、機能低下状態で稼働をつづけること\nフェールセーフ # 誤作動や故障時の影響を最小限にとどめて、システムを安全に制御するという考え方\n具体例: 信号機の故障時にすべての信号を赤信号の状態にする。\nフェールオーバ # 障害発生時に別システムに自動的に引き継がせて利用者に故障などを悟らせないという考え方\n障害回復時に元のシステムへ戻すことを「フェールバック」と呼ぶ。 フォールトマスキング # 障害が発生しても、影響が外部に出ないようにする考え方\nフールプルーフ # 誤った操作などされても、システムに異常が出ないように設計する考え方\nインタロック # 安全を確保する「連動した制約」\nより詳細な定義: ある一定の条件が満たされない限り、次の操作ができないようにする、あるいは特定の動作をさせないようにする仕組み\n具体例: 電子レンジについて、ドアが完全に閉まっていないと、マイクロ波の照射が始まらない。\nカーネル # OSとしてコンピュータやアプリを制御するための基本的な機能のみを実装したソフトウェア\nより詳細な定義:\nカーネルはOSの中核(コア)で、主にハードウェア(CPU、メモリ、デバイス)と\nアプリケーション(プロセス)の橋渡し役を担い、重要なリソース管理やプロセス管理などの基本機能を持つソフトウェア\n「基本的な機能」の補足: 基本的な機能とは、プロセス管理、メモリ管理、デバイス管理、ファイルシステム管理、ネットワーク管理などを指す\nタスクのスケジューリング方式 # 複数のタスクを並列処理する場合の処理方法\n分類:\nノンプリエンションなスケジューリング方式 到着順番方式 プリエンプションなスケジューリング方式 優先順位方式 ラウンドロビン方式 フィードバック待ち行列方式 処理時間方式 ノンプリエンション（協調的マルチタスク） # 一度CPUの使用権を得たタスクが、自らの処理を終えるか、I/O待ちなどで自発的にCPUを解放(手放す)するまで、他のタスクにCPUを横取りされない方式 特徴: - OSがタスクを強制的に中断させない - CPUを独占するタスクがあると、他のタスクが全く実行できない\nプリエンプション（強制的(プリエンプティブ)マルチタスク） # OSのスケジューラが、より優先度の高いタスクが来た場合や、一定の時間が\n経過した場合などに、現在実行中のタスクを強制的に中断させ、\n別のタスクにCPUの使用権を割り当てる方式\n特徴:\nOSのスケジューラがタスクの切り替えを実施する このとき中断されたタスクが再開されるとき中断された状態から再開される 到着順番方式（FCFS(First Come First Served)） # タスクには優先度が設定されず、実行可能状態になったタスクから処理される方式\n優先順位方式 # タスクに割り当てられた優先度の高い順に実行する方式\n優先順位方式の種類 # 静的優先順位方式:優先度をあらかじめきめて変更しない方式 特徴:スタベージョンが発生する可能性がある。 動的優先度順方式:優先度を変更する方式(待ち時間が一定時間以上のタスクの優先度を高くするなど) 別名:エージング方式 優先度を高くして実行の可能性を与えることを「エージング」と呼ぶため。 スタベージョン # タスクにCPU使用権が割り当てられず、なかなか実行されてない状態\nリソーススタベーション # タスクの実行に必要なリソースを与えられない状態\nラウンドロビン方式 # 実行可能待ち行例の先頭のタスクから順番にCPU時間(タイムクウォンタム)を割り当てる方式\n実行タスクがタイムクウォンタム内に終了しない場合は、実行を中断して次のタスクにCPUに割り当てる タイムシェアリングシステムのスケジューリングに適している。 フィードバック待ち行列方式（多段待ち行列方式） # ラウンドロビン方式に優先度を加えて方式\n処理時間順方式（SPT(Shortest Proccessing Time First)方式） # 処理時間の短いタスクから順番に実行する方式\n実際には残り処理時間を予測することは不可能のため、フィードバック待ち行列方式として実現されている。 Hadoop # ペタバイト級の大規模データの蓄積・処理の分散処理を実現するミドルウェア\n主に「HDFS(Hadoop Distributed File System)」という分散ファイルシステムと\n「MapReduce」という分散処理プログラミングモデルを中心に構成されている\nGPL（General Public License） # GNUプロジェクトのためにリチャード・ストールマンにより制作されたフリーソフトウェアライセンス\n「コピーレフト」という概念を採用している コピーレフト # GPLでライセンスされたソフトウェアを改変またはそれを基にした派生著作物を配布する際に、\nそのソフトウェアや派生著作物もGPLのもとで配布しなければならないというルール\nMOSトランジスタ # 金属と半導体の間に酸化物絶縁体を挟んだ構造を持つ半導体素子。金属(M)、酸化膜(O)、半導体(S)の三層構造を持つ。\n使用用途: ゲート電圧を変えることで通過する電流量を細かく制御できるため、スイッチや増幅器として多用される。\nSoC(System on a Chip) # 必要とされる全ての機能(システム)を集積した1個の半導体チップ\nメリット:\n専有面積の削減 高速化 低消費電力化 コスト削減 HDL(Hardware Description Language) # デジタル回路の設計や構成をテキストベースで記述できるハードウェア記述言語の総称\nFPGAなどに実装するデジタル回路を記述し，論理合成するために使用される\n具体例: VHDL、Verilog、SystemCなど\nDSP(Digital Signal Processor) # 主にリアルタイムコンピュータで使用される、デジタル信号処理に特化したプロセッサ\n積和演算などの機能を内蔵しているので，デジタルフィルターを実現するのに適している。\nユーザー調査手法：アンケート # 質問票を配布してユーザーから回答を集める手法。大規模な調査が可能、定量的データの収集\n思考発話法 # 被験者に操作をしながら考えていることを声に出してもらい、思考プロセスを分析する手法。ユーザーの思考過程を直接把握可能\n回顧法 # 操作後に操作内容やその時の判断、感想などを思い出してもらい、ヒアリングする手法。操作完了後に実施\nログデータ分析法 # ユーザーの操作ログを収集・解析し、利用状況や問題点を定量的に評価する手法。客観的データに基づく分析\n認知的ウォークスルー法 # 専門家がユーザーの視点に立ってタスクを実行し、ユーザーが目標を達成できるか、操作で迷わないかなどを評価する手法\nヒューリスティック評価 # 専門家が経験則(ヒューリスティックス)に基づいて、UIなどがガイドラインに沿っているかを評価する手法\nパンくずリスト # Webサイト内でユーザーが現在閲覧しているページの位置を、トップページからの階層構造で示したもの\n名前の由来: 童話「ヘンゼルとグレーテル」で、主人公が森で迷わないようにパンくずを落として道しるべにした逸話から\nパルス符号変調(PCM) # アナログ信号をデジタル信号に変換する手法\n手順\n標本化(サンプリング):アナログ信号を一定の時間間隔で区切り、その瞬間の値を取り出す処理。サンプリング周波数(Hz) = 1秒間にサンプリングする回数 量子化:標本化で得られたアナログ値を、最も近い離散的な値(整数値)に近似する処理。量子化ビット数 = 1つの値を表現するために使うビット数 符号化:量子化で得られた整数値を、0と1の2進符号に変換する処理 レンダリング # 3D空間の物体のデータ(形状、質感、光源など)を基に、2次元の画像を生成する処理\nレイトレーシング法 # 光源から出た光が物体に反射し、視点に届くまでの経路を逆に追跡することで、リアルな画像を生成するレンダリング手法\n光の反射や屈折を精密に計算できる スキャンライン法 # スクリーンの走査線ごとに視点とその走査線を結ぶ走査面を作成し，各走査面と描画の対象となる物体との交差を調べて交差線分を求め，奥行き判定を行うことによって描画する手法\nスキャンライン法・レイトレーシング法との違い # スキャンライン法は画面上の走査線ごとに物体の描画を行う手法で、高速にレンダリングできるが、光の複雑な表現が不可能\nレイトレーシング法は光線を追跡してリアルな反射・屈折・影を表現できるが、計算量が多く処理が重い\nZバッファ法 # 視点からの奥行き情報(Z値)をピクセルごとに保持し、不要な部分(隠れた部分)を描画しないことで、効率的に隠面消去を行うレンダリング手法\nラジオシティ法 # 物体表面での光の相互反射(間接光)を計算することで、柔らかな陰影や、部屋の壁が照らし合う様子などをリアルに表現するレンダリング手法\nアンチエイリアシング # 斜線や曲線の境界に生じる階段状のギザギザ(ジャギー)を、中間色を補うことで滑らかに見せる手法\nディザリング # 色数が限られた環境で、異なる色のピクセルを隣接して配置することで、擬似的に中間色や多くの色を表現する手法\nメタボール # 複数の球体を定義し、それらが融合し合うような滑らかで有機的な曲面を生成するモデリング手法\n液体や粘体などの表現に用いられる\n帯域幅の計算 # 解像度 × 色深度 × フレームレート\n例: 800×600×24×30 = 345.6 Mbps\n音声データ容量計算 # サンプリング周波数 × 量子化ビット数 × 時間\n例: 11,000Hz × 8bit × 60秒 = 5,280,000ビット = 660,000バイト\nリング型配線 # LANの代表的な接続形態(トポロジー)の一つで、全てのノードがリング(輪)のように一方向または双方向に接続される方式\ngraph LR %% リング型トポロジー subgraph リング型トポロジー A --- B --- C --- D --- A end スター型配線 # LANの代表的な接続形態(トポロジー)の一つで、中心となるネットワーク機器(スイッチやハブ)を中心に、各機器が放射状に接続される形態\ngraph LR %% スター型トポロジー subgraph スター型トポロジー S((スイッチ・ハブ)) A -- 接続 --\u003e S B -- 接続 --\u003e S C -- 接続 --\u003e S D -- 接続 --\u003e S end バス形配線 # LANの代表的な接続形態(トポロジー)の一つで、すべてのデバイスが一本の主幹ケーブル(バス)に接続され、データはこのバスを通じて送受信される形式\ngraph LR %% バス型トポロジー subgraph バス型トポロジー direction LR A --- B --- C --- D end コネクション型通信 # 回線を確保したまま通信を行う方式\n具体例: 電話・回線交換方式\nコネクションレス型通信 # 通信前に受信相手を確認せずに一方的にデータを送信する方式。\n送信するパケットに宛先を示す情報を付与する必要がある。\n具体例: パケット交換方式\nTCP(Transmission Control Protocol) # 送信するデータが正確に、かつ送信した順序通りに相手に届くことを保証する、信頼性の高い通信プロトコル\nOSI参照モデルの第4トランスポート層に位置する。 信頼性を確保するための確認応答や制御が多いため、UDPに比べて通信速度が遅くなる傾向がある。 コネクション型通信。3ウェイハンドシェイクで通信経路を確立する。 UDP(User Datagram Protocol) # データの転送速度やリアルタイム性を重視したプロトコル\nOSI参照モデルの第4トランスポート層に位置する。 プロトコルがシンプルなため、高速で遅延が少ない通信が可能 コネクションレス型通信。TCPのような事前のコネクション確立を実施しない。 RDP(Remote Desktop Protocol) # リモートデスクトップ接続で使用される通信プロトコル\n遠隔地からのPC操作、サーバ管理にて使用される。\nポート番号: TCP/3389\\\nSSL-VPN # SSLプロトコルを使用したVPN接続方式\nWebブラウザから接続可能、専用クライアント不要の場合もある リモートワーク環境での安全な社内ネットワークアクセスにて使用される。 MIME(Multipurpose Internet Mail Extension) # メールでにて日本語の\u0026quot;2バイトコード\u0026quot;や画像データを送信するための仕組み\n使用用途: ASCII文字しか使用できないSMTPを利用したメールで利用される。\nIMAPS(IMAP over SSL/TLS) # メール受信プロトコルであるIMAP(Internet Message Access Protocol)にTLSを組み合わせ、\nTLSによって暗号化された通信コネクション上でメール受信を行うプロトコル\n補足: バージョン番号を付けてIMAP4Sと表記されることもある。\nポート番号 # ネットワーク上でデータ通信を行う際に、コンピュータ内で動作している\n特定のプログラムやサービスを識別するための番号\nURLで宛先のポート番号を指定する場合: ホスト名の直後に\u0026quot;:\u0026quot;(コロン)と数字で指定する\nウェルノウンポート # インターネットプロトコルにおいて、特定のサービスやアプリケーション用に予約された標準的なポート番号(0-1023番)\\\nIANA(Internet Assigned Numbers Authority)により管理・割り当て システム権限(root権限)でのみバインド可能 全世界で統一された標準番号 主要なウェルノウンポート一覧 # プロトコル/サービス ポート番号 プロトコル 用途 FTP(データ用) 20 TCP ファイル転送のデータ通信 FTP(制御用) 21 TCP ファイル転送の制御コマンド SSH 22 TCP 安全なリモートログイン・暗号化通信 Telnet 23 TCP リモートログイン(平文通信) SMTP 25 TCP メール送信 DNS 53 TCP・UDP ドメイン名前解決 DHCP(サーバ用) 67 UDP IPアドレス自動割り当て(サーバ側) DHCP(クライアント用) 68 UDP IPアドレス自動割り当て(クライアント側) HTTP 80 TCP Web通信(平文) POP3 110 TCP メール受信 NTP 123 UDP 時刻同期 IMAP4 143 TCP メール受信(サーバ上でメール管理) SNMP 161 UDP ネットワーク機器管理・監視 SNMP Trap 162 UDP ネットワーク機器からの通知・アラート HTTPS 443 TCP 暗号化Web通信(SSL/TLS) DNSレコード # ドメイン名とIPアドレスを紐づけるなど、インターネット上でドメイン名を管理するための重要な情報\nAレコード (Address Record) # ドメイン名(ホスト名)をIPv4アドレスに対応付ける、最も基本的なDNSレコード\\\nユーザーがブラウザにウェブサイトのドメイン名を入力した際に、そのサイトが置かれているサーバーのIPアドレスを特定 AAAAレコード (Quad A Record) # AレコードのIPv6版で、ドメイン名(ホスト名)をIPv6アドレスに対応付ける\nIPv6アドレスでウェブサイトにアクセスするために必要 CNAMEレコード (Canonical Name Record) # あるドメイン名(エイリアス)を別の正規のドメイン名(Canonical Name)に関連付けるために使用\n複数のドメイン名を一つのウェブサイトに向けたり、管理を簡素化する IPアドレスを直接指定するのではなく、別のドメイン名を指し示す MXレコード (Mail Exchange Record) # そのドメイン宛てのメールを配送するメールサーバーを指定するためのレコード\nメールサーバーがどのサーバーにメールを届ければよいかを確認 優先度の数値が小さいサーバーから順に配送が試行される PTRレコード (Pointer Record) # IPアドレスからドメイン名(ホスト名)を特定するために使用される(逆引き)\nメールサーバーが受信したメールの送信元IPアドレスの信頼性を確認 なりすましメール対策として利用される。設定が正しくないとメールがスパムとして扱われる可能性がある OP25B(Outbound Port 25 Blocking) # ISPが用意したスパムメール対策の仕組み\nISPが用意したメールサーバーを経由しないメール(高確率でスパムメール)を弾くようになっている。 OP25Bにおけるサブミッションポートの役割 # OP25Bを回避するための「正規のユーザー専用通用口」 サブミッションポートは、OP25Bでブロックされるポート25の代替となる、メール送信専用のポートです。ポート番号は587番が標準として定められています。 OP25Bの対象外になる対象 # 固定IPからの送信 SMTP-AUTHで認証済ノードからの送信 SPF(Sender Policy Framework) # メールを送信しようとしてきたメールサーバのIPアドレス情報を検証することで身元検証する技術\nSPFの手順 # 送信側は、送信側ドメインのDNSサーバのSPFレコード(またはTXTレコード)に正当なメールサーバのIPアドレスやホスト名を登録し、公開しておく。 送信側から受信側へ、SMTPメールが送信される。 受信側メールサーバは、受信側ドメインのDNSサーバを通じて、MAIL FROMコマンドに記載された送信者メールアドレスのドメインを管理するDNSサーバに問い合わせ、SPF情報を取得する。 SPF情報との照合でSMTP接続してきたメールサーバのIPアドレスの確認に成功すれば、正当なドメインから送信されたと判断する。 プロキシサーバ # クライアントPCの代理としてWebサイトにアクセスする中継サーバ 利用用途として、「URLフィルタリング」による業務上不要なサイトへの接続禁止などを設定する\nURLフィルタリング # 宛先URLをチェックし、許可/禁止リストと照合して通信を検証・フィルタリングする\nIEEE 802.11a/n # 無線LAN(Wi-Fi)の技術規格\n802.11a:5GHz帯、最大54Mbps 802.11n:2.4GHz/5GHz両対応、MIMO技術でより高速化 IEEE 802.1Q # タグVLAN(仮想LAN)の技術規格\n用途: ネットワークセグメント分離、VLAN間通信制御\nIEEE 802.1X # LANに接続する端末の認証規格\n用途:\nMACアドレス認証 認証サーバを用いた端末認証 社内LANへの不正アクセス防止 実装: 認証サーバ(RADIUS等)と連携した認証システム\nnslookup # DNSサーバに名前解決を問い合わせ、結果を確認するコマンド\n基本形: nslookup \u0026lt;名前\u0026gt; [DNSサーバ]\n例: nslookup www.example.com 192.168.11.41\\\n用途:\nDNS名前解決の動作確認 DNSサーバの応答性能測定 ドメイン名とIPアドレスの対応関係確認 類似コマンド: dig(UNIX系)、host(UNIX系)\nping # 宛先への到達可否と遅延(往復時間)を確認するコマンド\n用途: 基本的な疎通確認\ntracert # 宛先までに経由するルータの一覧と遅延を可視化するコマンド\n用途: ネットワーク経路の調査\narp # IPアドレスとMACアドレスの対応表を表示・更新するコマンド\n用途: ARPテーブルの確認・操作\nipconfig # 端末のネットワーク設定の表示・更新するコマンド\n用途: ネットワーク設定の確認・変更\n情報セキュリティの3要素(CIA) # 機密性 (Confidentiality) 完全性 (Integrity) 可用性 (Availability) 情報セキュリティの3要素(CIA)：機密性 (Confidentiality) # 認可された者のみが情報にアクセス可能であること\n脅威: データ窃取、不正アクセス\n対策: アクセス制御、暗号化\n情報セキュリティの3要素(CIA)：完全性 (Integrity) # 情報が破壊・改ざんされていないこと\n脅威: データ改ざん、不正な変更\n対策: 電子署名、ハッシュ値による検証\n情報セキュリティの3要素(CIA)：可用性 (Availability) # 必要な時に情報にアクセス可能であること\n脅威: DoS攻撃、システム障害\n対策: 冗長化、負荷分散\n否認防止の特性 # 情報セキュリティマネジメントの付加的な要素で、行った操作や発生した事象を後になって否認されないように証明できる能力 補足: JIS Q 27000:2019(情報セキュリティマネジメントシステム－用語)において定義されている\nCC（Common Criteria：情報セキュリティ国際評価基準） # IT製品やシステムのセキュリティ機能を評価し認証するための基準を定めた規格\nほぼそのままの形でISO 15408(日本版では JIS X 5070)として国際標準化されている。\n耐タンパ性 # 暗号システムやハードウェアが物理的な不正操作や改ざん(タンパー)に対して耐えられる能力\n境界型防御 # 社内ネットワーク(信頼できる)とインターネット(信頼できない)の境界で通信を制御する防御手法\n実装: ファイアウォール、IDS/IPS\n弱点: 内部犯行、正当な通信を装った攻撃に対応困難\nゼロトラスト # 「何も信頼しない」を前提とし、全てのアクセス要求に対して厳格な認証と認可を行うセキュリティモデル\n原則: いかなる通信も信頼しない\n適用場面: クラウド環境、リモートワーク環境\n多層防御 # 複数の対策を組み合わせ、一つの対策が破られても他の対策で攻撃を防ぐ考え方\n例:\nネットワーク層:ファイアウォール、WAF アプリケーション層:入力検証、プレースホルダ データ層:ハッシュ化、暗号化 運用層:監視、ログ分析 CSIRT # 対象とする範囲でセキュリティ上の問題が起きていないかどうかを監視するとともに、発生したセキュリティインシデントについて対応するチームや組織の総称\nPSIRT # 製品セキュリティインシデント対応チーム\n言い換えると: 自社製品版のCSIRT\nSQLインジェクション # Webアプリケーションの入力フィールドに不正なSQL文を挿入し、データベースを不正操作する攻撃\n影響: データの窃取、改ざん、削除が可能\n対策: プレースホルダ(バインド機構)の使用、入力値検証\n辞書攻撃 # 特定のIDに対して、一般的な単語や頻用されるパスワードをリスト化した「辞書」を用いてログイン試行する攻撃\n特徴: IDを固定し、パスワードを総当たりする\n対策: アカウントロックアウト、複雑なパスワードポリシー\nブルートフォース攻撃 # パスワードを総当たりで試行する攻撃手法\n特徴: すべての可能な組み合わせを試行する\n対策: アカウントロックアウト、複雑なパスワードポリシー\nリバースブルートフォース攻撃 # パスワードを固定し、IDを総当たりする攻撃手法\n特徴: 一般的なパスワードを多数のIDに対して試行する\n対策: レート制限、異常なアクセスパターンの検知\nレインボーテーブル攻撃 # 事前に計算したハッシュ値とパスワードの対応表を使用してパスワードを推測する攻撃\n対象: ハッシュ化されたパスワードの解析\n対策: ソルト、ペッパーの使用\nサプライチェーン攻撃 # 直接の攻撃対象ではなく、関連する業者や取引先を経由して本来の標的にアクセスする攻撃手法\n特徴: 信頼関係を悪用し、防御が手薄な経路から侵入する\n対策: 取引先のセキュリティ監査、ゼロトラスト原則の適用\nMan-in-the-Browser(MITB)攻撃 # PCに侵入したマルウェアが，利用者のインターネットバンキングへのログインを\n検知して、Webブラウザから送信される振込先などのデータを改ざんする攻撃\nクリプトジャッキング # マイニング作業（暗号資産を入手するための計算処理）を他のコンピュータに秘密裏に代行させる行為\nPPAP # パスワード付きZIPファイルをメールで送信し、パスワードを別メールで送る方式\n問題点: 誤送信時に暗号化ファイルとパスワードが両方とも漏えい、同一経路での盗聴リスクがある\n対策: パスワードを電話や携帯メールなど異なる手段で伝達する\nフォールスネガティブ # 本来は検知すべき悪意のある活動を、誤って害のないものとして分類すること。\n自分なりに言い換えると「セキュリティが対象を見逃すこと」 フォールスポジティブ # 本来は通過させるべき害のない活動を、誤って悪意のあるものとして分類すること。\n自分なりに言い換えると「セキュリティの過剰反応」 多要素認証 # 複数の異なる認証要素を組み合わせる認証方式\n認証3要素:\n知識情報:ID・パスワード(知っていること) 所持情報:スマートフォン・ICカード(持っているもの) 生体情報:指紋・顔認証(自分自身の特性) ロックアウトのしきい値 # パスワード認証に規定回数失敗した際にアカウントを一時的にロックするまでの失敗回数\n目的: 辞書攻撃、ブルートフォース攻撃の対策\n限界: リバースブルートフォース攻撃(IDを分散させた攻撃)には効果が限定的\nSAML認証（Security Assertion Markup Language） # 一度のログインで複数のクラウドサービスやアプリケーションにアクセス可能にする「シングルサインオン(SSO)」を実現するための標準規格\nメリット\n利便性の向上:ユーザーは一度ログインするだけで、SAML連携している複数のサービスに追加のログインなしでアクセスできます。 セキュリティの強化:IdP側で多要素認証やアクセス制御ポリシーを一元的に設定・管理できるため、全体のセキュリティレベルが向上します。 管理コストの削減:IT管理者はIdPでアカウント情報を一元管理できるため、サービスごとにIDを発行・管理する手間が省け、運用負荷が軽減されます。 デメリット\n対応サービスの制約:連携したいクラウドサービス側がSAML認証に対応している必要があります。対応していない場合は、別途開発が必要になることがあります。 SAML認証の仕組み：SP起点の認証フロー # SAML認証の登場人物 ユーザー: サービスを利用する本人。 IDプロバイダー (IdP): ユーザーのID情報を管理し、認証を行うサービス(例: Microsoft Entra ID、Oktaなど) サービスプロバイダー (SP): ユーザーが利用したいクラウドサービスやアプリケーション(例: Salesforce, Concur, Adobeなど) SP起点の認証フロー ユーザーがSP(例:クラウドサービスA)にアクセスします。 SPはユーザーが未認証であるため、IdPにリダイレクトさせるための「SAML認証要求」を生成し、ユーザーのブラウザに送り返します。 ユーザーのブラウザは、受け取ったSAML認証要求をIdPに送信します。 IdPのログイン画面が表示され、ユーザーはIDとパスワードを入力して認証を行います。 認証が成功すると、IdPは「SAMLアサーション」と呼ばれるXML形式の認証情報を生成し、ユーザーのブラウザに送ります。 ユーザーのブラウザは、このSAMLアサーションをSPに送信します。 SPは受け取ったSAMLアサーションを検証し、正当なユーザーであればログインを許可します。 SAML認証の仕組み：IdP起点の認証フロー # SAML認証の登場人物\nユーザー: サービスを利用する本人。 IDプロバイダー (IdP): ユーザーのID情報を管理し、認証を行うサービス(例: Microsoft Entra ID、Oktaなど) サービスプロバイダー (SP): ユーザーが利用したいクラウドサービスやアプリケーション(例: Salesforce, Concur, Adobeなど) IdP起点の認証フロー\nユーザーはIdPのポータルサイトなどにアクセスし、ログインします。 ログイン後、IdPの画面に表示されている利用可能なサービス一覧から、利用したいSP(例:クラウドサービスA)を選択します。 IdPはSAMLアサーションを生成し、ユーザーのブラウザに送ります。 ユーザーのブラウザは、SAMLアサーションをSPに送信します。 SPはSAMLアサーションを検証し、ログインを許可します。 SAML認証とOAuthの違い # SAMLとよく比較される規格に「OAuth(オーオース)」があります。両者の主な違いは役割\nSAML:ユーザーが誰であるかを証明する「認証」と、そのユーザーに何をする権限があるかを示す「認可」の両方を扱う。 OAuth:主に「認可」を目的としたプロトコル。例えば、「あるアプリにGoogleアカウントの写真へのアクセスを許可する」といった場面で使われ、ユーザー自身の認証は実施しない。 3Dセキュア # オンライン決済時に本人のみが知る情報(パスワードや属性情報等)を入力させることで、利用者本人が取引を行っていることを確認する仕組み\nどうやって3Dセキュアを実現する？\n事前にカード発行会社に登録したパスワードやワンタイムパスワード、SMS認証、生体認証などで本人確認を行い、不正利用を防ぐ\n名称の由来: なんで3Dセキュアって呼ぶ？\\\n3Dセキュアの「3D」は「3つのドメイン(Domain)」を意味しています。具体的には、 イシュアドメイン(カード発行会社の領域) アクワイアラドメイン(加盟店の領域) 相互運用ドメイン(これら2つをつなぐ国際カードブランドの領域) この3つのドメイン間で認証に関わる情報交換の手続きを規定する仕組みであり、「3Dセキュア」と名付けられています ハッシュ関数 # 任意の長さのデータを固定長の不可逆なデータ(ハッシュ値)に変換する関数\n特性: 一方向性(逆算困難)、雪崩効果(わずかな変更で大きく変化)\n用途: パスワード保存、デジタル署名、データ完全性確認\n公開鍵暗号 # 基本ルール:\n署名:送信者の秘密鍵で署名 → 送信者の公開鍵で検証 暗号化:受信者の公開鍵で暗号化 → 受信者の秘密鍵で復号 特徴: 処理速度が遅い\n用途: 共通鍵の配送、電子署名\\\n共通鍵暗号 # 暗号化と復号に同一の鍵を使用する暗号方式\n特徴: 処理速度が速い\n用途: 大容量データの暗号化\nハイブリッド暗号 # 共通鍵暗号と公開鍵暗号を組み合わせた暗号方式\n仕組み: データは高速な共通鍵暗号で暗号化し、その共通鍵を公開鍵暗号で保護\nメリット: 高速性と安全性の両立\n電子署名 # メッセージの送信者を認証し、内容の改ざんを検知する技術\n仕組み: 送信者の秘密鍵で署名、受信者の公開鍵で検証\n目的: 認証(誰が送ったか)、完全性(改ざんされていないか)の確保\nS/MIME # メールの電子署名と暗号化を行うセキュリティ技術 機能: 認証、完全性、機密性を保証 構成要素: 電子署名、ハイブリッド暗号、電子証明書\nソルト # パスワードハッシュ化時にユーザーごとに異なる値を付加する技術\n目的: レインボーテーブル攻撃の対策\n保存場所: データベースの会員テーブル内\nペッパー # パスワードハッシュ化時に全ユーザー共通の秘密値を付加する技術\n目的: データベース漏えい時の追加保護\n保存場所: 設定ファイルなど、データベースとは別の安全な場所\n利点: データベースを窃取されてもペッパーは入手されない\nRSAと楕円曲線の違い # 両者の違い:\n楕円曲線暗号(ECC)とRSAは、いずれも公開鍵暗号方式ですが、根本的な仕組みと特徴に明確な違いがある。 RSAは「大きな素数の積の素因数分解が困難」という性質を利用 楕円曲線暗号(ECC)は「楕円曲線上の離散対数問題が困難」という性質を利用 特徴 RSA 楕円曲線暗号(ECC) 数学的基盤 素因数分解の困難さ 楕円曲線上の離散対数問題 鍵サイズ 大(2048bit以上推奨) 小(256bit程度で高強度) 計算コスト 高い 低い 通信量 多い 少ない 普及度 歴史長く広く普及 近年の新規プロトコルで主流化 WPA2(Wi-Fi Protected Access 2) # 無線LANのセキュリティを保護するための規格\nAESが暗号アルゴリズムとして利用される RSAやECCではない理由はAESのほうが処理速度で優れているため。 CRL（Certificate Revocation List） # 公開鍵基盤(PKI)において失効した(信用性のない)公開鍵証明書のリスト\nプレースホルダ # SQLクエリの構造と値を完全に分離する仕組み\n効果: SQLインジェクション攻撃を原理的に防ぐ\n実装: 外部入力値が埋め込まれる箇所を専用の記号(?など)に置き換える\nSIEM（Security Information and Event Management） # 様々なIT機器のログを一元的に収集・分析し、セキュリティインシデントの兆候をリアルタイムで検知する仕組み\n目的: セキュリティインシデントの発生を迅速に検知する\\\nEDR(Endpoint Detection and Response) # PC・サーバ(エンドポイント)での不審な挙動を検知し、インシデント発生後の迅速な対応を支援するソリューション\n機能: ネットワーク遮断、不審なプロセス終了\n対象: 未知の攻撃による侵入後の対応\nWAF(Web Application Firewall) # Webアプリケーションへの攻撃を検知・防御する専用ファイアウォール\n対象: SQLインジェクション、XSS等のアプリケーション層攻撃\nデジタルフォレンジックス # 電磁的記録(デジタルデータ)の証拠保全、調査及び分析を行う技術・手続き\n目的: サイバー攻撃の原因究明、被害範囲の特定、法的証拠の確保\n対象: PC・サーバ内のログ、ファイル等の電子データ\n補足: 応用情報技術者試験の情報セキュリティの午後問題にて、たまに記述式の問題で出題されるので覚える\nモジュール結合度 # モジュール同士の関連性の強さを表す度合い\nモジュール結合度の強弱(1が弱。6が強) データ結合:データだけ受け渡す スタンプ結合:処理に必要なデータだけをデータ構造として受け渡す 制御結合:モジュールの動作を制御するための要素を受け渡す 外部結合:大域宣言された単一のデータを複数のモジュールで参照 共通結合:大域宣言されたレコードや構造体などのデータ構造を、複数のモジュールが参照 内容結合:モジュールの内部を直接参照 「データ結合」は頻出\nペトリネット（Petri Net） # プレース、トランジション、トークンの3つの要素を使用した有向グラフでシステムの動作を記述する図法\n使用例: 並行する処理同士の制御の流れや同期のタイミングを分析・設計するために使用される。\nOCSP（Online Certificate Status Protocol） # リアルタイムでデジタル証明書の失効情報を検証し、有効性を確認するプロトコル\\\nOCSPの確認手順 OCSPクライアントは、確認対象となるデジタル証明書のシリアル番号等をOCSPレスポンダに送信し、\n有効性検証の結果を受け取ります。この仕組みを利用することで、クライアント自身がCRL(証明書失効リスト)を取得・検証する手間を省くことができます。\nDNSキャッシュポイズニング攻撃 # DNSサーバーの「キャッシュ」に偽の情報を意図的に注入(ポイズニング＝毒を盛る)することで、\nユーザーを正規のウェブサイトになりすました悪意のある偽サイトへ誘導するサイバー攻撃\nDNSの基本的な仕組み # DNSの通常処理手順\nユーザーがブラウザに www.example.com と入力すると、PCは近くのキャッシュDNSサーバー(プロバイダなどが管理)に「www.example.com のIPアドレスは何ですか?」と問い合わせます。 キャッシュDNSサーバーに答え(キャッシュ)がなければ、目的の情報を管理している権威DNSサーバーに問い合わせに行きます。 権威DNSサーバーから正しいIPアドレス (93.184.216.34) を受け取ります。 キャッシュDNSサーバーは、そのIPアドレスを一定期間キャッシュ(一時保存)し、ユーザーに返します。次回同じ問い合わせが来た際は、権威DNSサーバーまで聞きに行かずにキャッシュから素早く応答できます。 DNSキャッシュポイズニング攻撃の仕組み # DNSキャッシュポイズニング攻撃は、上記のステップの2と3の間に割り込みます。\n攻撃者は、まず標的となるキャッシュDNSサーバーに、まだキャッシュされていないドメイン名(例: www.victim-bank.com)の問い合わせをさせます。 キャッシュDNSサーバーが権威DNSサーバーに問い合わせを行っている、ごくわずかな隙を突いて、攻撃者は権威DNSサーバーになりすまし、偽の応答をキャッシュDNSサーバーに送りつけます。 この偽の応答には、「www.victim-bank.com のIPアドレスは、攻撃者が用意した偽サイトのIPアドレス (10.0.0.99) です」という嘘の情報が含まれています。 攻撃者は、本物の権威DNSサーバーからの応答よりも先に、かつDNSの通信ルール(トランザクションIDなど)に合った偽の応答を送る必要があります。 キャッシュDNSサーバーがこの偽の応答を信じてしまうと、偽のIPアドレスをキャッシュに保存してしまいます。 その後、このキャッシュDNSサーバーを利用している一般のユーザーが www.victim-bank.com にアクセスしようとすると、キャッシュDNSサーバーは汚染されたキャッシュから偽サイトのIPアドレスを返してしまいます。 ユーザーは、本物の銀行サイトにアクセスしているつもりで、攻撃者が用意したそっくりの偽サイトに誘導され、IDやパスワード、個人情報を盗まれてしまいます。 被害例 フィッシング詐欺:偽の銀行サイトやショッピングサイトに誘導し、ログイン情報やクレジットカード情報を盗み取ります。 マルウェア感染:偽サイトにアクセスしたユーザーに、ウイルスやスパイウェアなどのマルウェアをダウンロードさせます。 通信の傍受:偽のサーバーを中継させることで、メールなどの通信内容を盗聴します。 DNSキャッシュポイズニング攻撃への対策 # DNSキャッシュポイズニングへの対策は、DNSサーバー管理者側と利用者側の両方で実施する。\nサーバー管理者側の対策\nDNSソフトウェアの最新化:既知の脆弱性をなくすため、DNSサーバーのソフトウェアを常に最新の状態に保ちます。 ソースポートランダマイゼーション DNSの問い合わせに使う送信元ポート番号をランダム化し、攻撃者が偽の応答を送り込む際の推測を困難にします。 DNSSEC (DNS Security Extensions) の導入 DNSの応答に電子署名を付与し、その応答が正当なサーバーから送られ、改ざんされていないことを検証する仕組みです。 最も効果的な対策の一つとされています。 利用者側の対策\n信頼できるDNSサービスの利用:ISPが提供するDNSサーバーや、セキュリティ対策が施されたパブリックDNS(例: Google Public DNS 8.8.8.8, Cloudflare 1.1.1.1)を利用することが推奨されます。 HTTPSの確認:ウェブサイトを訪れた際、URLが「https://」で始まり、ブラウザのアドレスバーに鍵マークが表示されていることを確認します。DNSキャッシュポイズニングによって偽サイトに誘導されても、攻撃者は正規のSSL/TLS証明書を持つことが困難なため、ブラウザが警告を表示することが多くあります。 セキュリティソフトの導入:不正なサイトへのアクセスをブロックする機能を持つセキュリティソフトを導入し、常に最新の状態に保ちます。 DNSSEC(DNS Security Extensions) # DNSの応答が「正当な管理者から発信され、途中で改ざんされていないこと」を保証するための拡張機能\nDNSに「電子署名」の仕組みを追加することで、DNSの応答に信頼性を与える技術 DNSSECについて電子署名による応答の保証 # ドメインの管理者(権威DNSサーバーの管理者)は、秘密鍵と公開鍵のペアを作成します。 管理者は、自分の管理するDNSレコード(例: www.example.com のIPアドレス情報)に対して、秘密鍵を使って電子署名を作成します。この署名情報はRRSIGレコードとしてDNSに追加されます。 署名の検証に使う公開鍵は、DNSKEYレコードとしてDNSで公開されます。 DNSの応答を受け取った側(キャッシュDNSサーバー)は、このDNSKEYレコード(公開鍵)を使って、RRSIGレコード(署名)が正しいかどうかを検証します。 検証に成功すれば、「このDNSレコードは正当な管理者によって署名され、改ざんされていない」ことが証明されます。 サニタイジング # ユーザーが入力したデータや外部から受け取ったデータに含まれる、システムにとって危険な文字列や記号を、無害なものに変換または除去する処理\nISMAP(政府情報システムのためのセキュリティ評価制度) # 国際標準等を踏まえて政府が策定したセキュリティ基準に基づき、各基準が適切に実施されているかを第三者が監査するプロセスを経て、クラウドサービスを登録する国の制度\nIDS(Intrusion Detection System) # ネットワークやホストをリアルタイムで監視し、異常を検知した場合に管理者に通知するなどの処置を行うシステム\nIDSの種類 NIDS(Network-Based IDS):ネットワークセグメントに接続しネットワークを流れる通信を監視するIDS HIDS(Host-Based IDS):監視対象のサーバ(ホスト)にインストールしてそのサーバで発生するイベントを監視するIDS SBOM(Software Bill Of Materials) # ある製品に含まれるソフトウェアに含まれるすべてのコンポーネントについて、\nそれらの名称、バージョン・ビルド情報、ライセンス情報、依存関係、その他関連情報を含めて、機械処理可能なリストにしたもの\nCVE(Common Vulnerabilities and Exposures：共通脆弱性識別子) # 個別に発見されたコンピューターのソフトウェアやハードウェアの脆弱性(セキュリティ上の欠陥や弱点)に、それぞれ固有の識別番号を割り振るための世界共通の仕組み\\\n簡単に言い換えると: 脆弱性につけられる、ユニークなID番号\nTPM(Trusted Platform Module) # PCなどの機器に搭載され鍵生成・ハッシュ演算及び暗号処理を行うセキュリティチップ\nシステム監査基準 # 監査人が従うべき行動規範\n全般統制 # 組織や集団全体を対象とした統制\n業務処理統制 # 個々の業務が対象の統制\n帯域幅（R6秋午前問26） # 問題\n解像度: 800 × 600 ピクセル 色深度: 24ビットフルカラー フレームレート: 30フレーム/秒 上記の動画像の配信に最低限必要な帯域幅はいくつか。\n計算\n1フレームあたりのデータ量 800 × 600 ピクセル × 24 ビット/ピクセル = 11,520,000 ビット = 11.52 Mビット\n1秒あたりのデータ量（帯域幅） 11.52 Mビット/フレーム × 30 フレーム/秒 = 345.6 Mビット/秒 (Mbps)\n答え 345.6 Mbps\n色数（H17春午前問22） # 問題 あるディスプレイのビデオメモリは、解像度「800 × 600画素」で最大「2^16色」の表示が可能である。このビデオメモリを流用して解像度を「1600 × 1200画素」に変更した場合、表示できる最大の色数はいくつか。\n計算\n必要なビデオメモリ容量の計算\n1画素あたりのデータ量: 2^16色を表現するには16ビット（= 2バイト）必要。 ビデオメモリ容量: 800 × 600 画素 × 2 バイト/画素 = 960,000 バイト 変更後の解像度で1画素あたりに割り当てられるデータ量の計算\n変更後の総画素数: 1600 × 1200 画素 = 1,920,000 画素 1画素あたりのデータ量: 960,000 バイト / 1,920,000 画素 = 0.5 バイト = 4 ビット 最大色数の計算 4ビットで表現できる色数は 2^4 色。\n答え 2^4色\n音声サンプリング（H18春午前問55） # 問題\nサンプリング周波数: 11,000回/秒 量子化ビット数: 8ビット 記録媒体: 32 × 10^6 バイトの容量を持つUSBメモリ この条件で、最大何分間の音声を保存できるか。\n計算\n1秒あたりのデータ量 11,000 回/秒 × 8 ビット/回 = 88,000 ビット/秒\n1分あたりのデータ量（バイト単位）\n88,000 ビット/秒 × 60 秒/分 = 5,280,000 ビット/分 5,280,000 ビット/分 / 8 ビット/バイト = 660,000 バイト/分 記録可能な時間（分） 32,000,000 バイト / 660,000 バイト/分 ≈ 48.48 分\n答え 最大 48分\nアローダイアグラムにおける総余裕日数（H31春午前問53） # 問題 応用情報技術者試験 平成31年春期 午前問53 より引用\n上図のアローダイアグラムにおいて、総余裕日数は何日か。\n計算 総余裕日数は「その作業の開始をどれだけ遅らせても、プロジェクト全体のスケジュールに影響を与えないか」を示す日数。以下の手順で計算する。\n最遅結合点時刻の計算（終点から始点へ）\nB・C・G・H のルート（60日）\nプロジェクトの最短完了日数（クリティカルパス）は 60日\n最早結合点時刻の計算（始点から終点へ）\nH・D・B（30日）\n作業Fの総余裕日数の計算 総余裕日数 = 最遅結合点時刻 - 最早結合点時刻 総余裕日数 = 60 - 30 = 30\n答え\n30日\nACID特性 # データベースのトランザクション（SQLなどの処理における最小単位）処理における必要な4つの特性を指す\nAtomicity（原子性）\nトランザクション内の処理がすべて実行されるか、または全く実行されないことを保証する性質\nConsistency（一貫性）\nデータに矛盾が発生しないことを保証する性質\nIsolation（独立性）\n複数のトランザクションを同時に実行した場合と，順番に実行した場合の処理結果が一致する性質\nDurability（耐久性）\n正常に終了したトランザクションの更新結果は，障害が発生してもデータベースから消失しない性質\nキャッシュメモリの実効アクセス時間 # キャッシュメモリを利用したときのアクセス時間のことを実行アクセス時間を呼ぶ\nCPUが主記憶記憶とデータをやり取りする際にかかる時間が「アクセス時間」 実行アクセス時間の計算\n実効アクセス時間 = (キャッシュメモリへのアクセス時間 * ヒット率) + (主記憶装置へのアクセス時間 * (1 - ヒット率))\n具体例（応用情報技術者試験_午前問題_平成19年春期_問題18）\nキャッシュメモリのアクセス時間が10ナノ秒，主記憶のアクセス時間が70ナノ秒，キャッシュメモリのヒット率が90%のとき，実効アクセス時間は何ナノ秒か。\n答え\n実効アクセス時間は 16ナノ秒\n3層スキーマ # データベースの構造を「外部」「概念」「内部」の3つの視点（層）に分けて定義する考え方。 各層を独立させることで、一方の変更が他方に影響を与えにくくする。\n構成要素\n外部スキーマ（ビュー）: ユーザーやアプリケーションから見たデータベースの構造。 必要なデータだけを特定の形式で見せるためのもので、SQLのビュー（VIEW）がこれにあたる。 概念スキーマ（論理構造）: データベースに格納されるすべてのデータの論理的な構造や関係性を定義したもの。 開発者視点のスキーマであり、テーブル定義などが該当する。 内部スキーマ（物理構造）: データがストレージ（HDDなど）に物理的にどのように格納されるかを定義したもの。 インデックスの設定やデータファイルの配置などが含まれる。 関係データベース # データを「リレーション」と呼ばれる二次元の表（テーブル）の形式で管理するデータベース\n基本概念: リレーション（テーブル）: 行（タプル）と列（属性）で構成される表形式のデータ集合。 タプル（行）: テーブル内の一件分のデータ。レコードとも呼ばれる。 属性（列）: データの項目。フィールドやカラムとも呼ばれる。 主キー: テーブル内の一つの行を一意に識別するための属性（またはその組み合わせ）。 外部キー: 他のテーブルの主キーを参照する属性。テーブル間の関連付けに用いられる。 引用元：【SQL入門】外部キーとは？主キーとの関係や作成方法について解説\n2相コミット # ネットワークで接続された複数のデータベース（分散データベース）にまたがるトランザクションの一貫性を保証する仕組み\nフェーズ: 準備フェーズ（Phase 1）: コーディネータが全参加者（各データベース）にコミット可能か問い合わせる。各参加者は処理を実行し、結果（コミット可能か否か）をログに記録して応答する。 コミットフェーズ（Phase 2）: 全員から「コミット可能」の応答があれば、コーディネータは全員にコミットを指示。一人でも「不可能」の応答があれば、全員にロールバックを指示する。 参加者: コーディネータ: トランザクション全体を調整し、コミットかロールバックかを決定する役割。 パーティシパント: 各データベースサイトで、トランザクションの一部を実行する役割。 利点と課題: 分散環境での原子性を確保できる。一方で、準備フェーズで応答不能な参加者がいると、全参加者がその応答を待ち続けるブロッキング状態になる課題がある。 PKI(Public Key Infrastructure) # 公開鍵暗号を安全かつ信頼性の高い形で運用するための基盤となるシステム\nCVSS(Common Vulnerability Scoring System：共通脆弱性評価システム) # 情報システムの脆弱性に対する標準的な評価方法\n簡単にまとめると？：脆弱性の危険度を点数（スコア）で表す仕組み セキュアOS # セキュリティを最優先に考え、不正アクセスやマルウェアによる被害を根本的に防ぐことを目的として設計・構築されたOS\n強制アクセス制御（MAC：Mandatory Access Control）や最小特権という特徴がある。 SSID(Service Set Identifier) # 最長32オクテットのネットワーク識別子であり，接続するアクセスポイントの選択に用いられる。\nパーセントエンコーディング # 一般にURLエンコードと呼ばれ、URLにおいて使用できない文字をURLに記述するために「%」＋16進2桁を組合わせた文字列に変換すること\nJIS X 25010:2013 # システム及びソフトウェア製品の品質を評価する基準\nJIS X 25010:2013：機能適合性 # 明示された状況下で使用するとき，明示的ニーズ及び\n暗黙のニーズを満足させる機能を実行できる度合い\nJIS X 25010:2013：性能効率性(performance efficiency) # 明記された条件で使用する資源の量に関係する性能の度合い\nJIS X 25010:2013：互換性(compatibility) # 他の製品又はシステムと情報を交換できるか、同じハードウェア環境又はソフトウェア環境を共有できるかという度合い\nJIS X 25010:2013：使用性(usability) # 「ユーザーが目的を達成できる」ことを大前提として、それが「いかに効率的で、満足でき、安全で、様々な状況で使えるか」を総合的に評価する指標\nJIS X 25010:2013：信頼性(reliability) # 明示された時間、明示された条件下で、明示された機能をどの程度実行できるかという度合い\nJIS X 25010:2013：セキュリティ(security) # システムが情報及びデータを保護する度合い\nJIS X 25010:2013：保守性(maintainability) # システムについて修正しやすさ\nJIS X 25010:2013：移植性(portability) # 他の運用環境若しくは利用環境から別環境に構成要素を移すことができる有効性及び効率性の度合い\nJIS X 0161の各保守についてまとめ # 是正保守 → バグ修正（問題が起きてから対応） 予防保守 → 潜在バグの修正（問題が起きる前に先回り） 適応保守 → 環境変化への対応（OS、法律、外部システムなど） 完全化保守 → 改善・機能追加（より良くするための活動）\n2段階エディット法 # 共通バグの発見率から全体の総バグ数を推定する手法\n2段階エディット法（計算問題） # ソフトウェア開発技術者平成17年秋期 午前問46より\nあるプログラムについて，互いに独立したテストa，bを実施したところ，それぞれ30個及び40個のバグが検出された。また，そのうち20個は共通のバグであった。プログラムに含まれる推定総バグ数は幾つか。\n正解は60個\nそれぞれのテストで検出されたバグ数をNA，NB、共通のバグ数をNABとする\n総バグ数は以下の公式より計算 総バグ数＝(NA×NB)／NAB\nアサーションチェック # プログラム実行中の特定の時点で成立する変数間の関係や\n条件を記述した論理式を埋め込んで，そのプログラムの正当性を検証する手法\n言い換えると、「プログラム内に埋め込むセルフチェック機能」\nSysML # システムの設計及び検証を行うために用いられる，\nUML仕様の一部を流用して機能拡張したグラフィカルなモデリング言語\n構造化チャート # 順次、選択、繰返しの基本制御構造のみで構成される処理の流れを図式化する手法\nGOTOを表現する方法をもたず，モジュール内の論理構造を表現するのに適している\n","date":"2025年 10月 1日","externalUrl":null,"permalink":"/scraps/1759322139_ap2025_tech_study_memo/","section":"スクラップ","summary":"","title":"【応用情報技術者試験】テクノロジ系学習メモ","type":"scraps"},{"content":" 10大脅威（組織向け） # 1. ランサム攻撃による被害 # 概要: PCやサーバーを「ランサムウェア」に感染させ、端末のロックやデータの暗号化を行い、その解除と引き換えに金銭（身代金）を要求するサイバー攻撃。3年連続で脅威の1位となっており、攻撃手法は常に巧妙化しています。\n主な攻撃形態:\nRaaS (Ransomware as a Service): 攻撃ツールがサービスとして提供され、高度な技術がなくても攻撃が可能。 ノーウェアランサム: データを暗号化せず、窃取した機密情報を「公開する」と脅迫して金銭を要求する。 二重脅迫・四重脅迫: 「データの暗号化」「データの暴露」「DDoS攻撃」「関係者への連絡」など、複数の脅迫を組み合わせる悪質な手口。 主な攻撃手口:\n脆弱性の悪用: OSやソフトウェアのセキュリティ上の欠陥を悪用しネットワーク経由で侵入する。 不正アクセス: リモートデスクトップなど、外部に公開された設定の不備を突いて侵入する。 メールやWebサイト: 業務連絡を装ったメールの添付ファイルや、改ざんされたWebサイトを閲覧させることで感染させる。 対策:\nインシデント発生を前提とした対応体制の整備。 バックアップの適切な運用（オフライン保管、世代管理の徹底）。 バックアップデータ自体の改ざんを防ぐWORM（Write Once Read Many）機能の導入。 OSやソフトウェアの迅速なアップデート、多要素認証の導入。 キーワード:\nランサムウェア、RaaS、ノーウェアランサム、二重脅迫、WORM機能 2. サプライチェーンや委託先を狙った攻撃 # 概要: 製品の企画から販売に至る一連の商流（サプライチェーン）の中で、セキュリティ対策が手薄な取引先や業務委託先を踏み台にする攻撃。3年連続で2位となっており、自社だけでなく関係各社を含めた対策が不可欠です。\n主な攻撃手口:\nビジネス上の繋がりの悪用: 標的企業よりセキュリティが脆弱な取引先や子会社に侵入し、そこを経由して標的のネットワークへ侵入する。 ソフトウェアサプライチェーンの悪用: 多くの企業が利用するソフトウェアの開発元を攻撃し、正規のアップデートなどを通じてマルウェアを広範囲に拡散させる（例：XZ Utilsへのバックドア混入）。 対策:\n委託先を含めたサプライチェーン全体でのセキュリティレベルの確認と向上。 契約時にセキュリティに関する責任範囲を明確化する。 ソフトウェアの構成要素を管理する「SBOM」の導入を検討する。 客観的な状況把握のため、セキュリティ評価サービス（SRS）を活用する。 キーワード:\nサプライチェーン、踏み台攻撃、ソフトウェアサプライチェーン、SBOM、SRS 3. システムの脆弱性を突いた攻撃 # 概要: OS、ソフトウェア、ネットワーク機器などに存在するセキュリティ上の欠陥（脆弱性）を悪用する攻撃。脆弱性情報が公開されてから攻撃までの時間が短くなっており、迅速な対応が求められます。\n代表的な攻撃:\nゼロデイ攻撃: 脆弱性が発見されてから、修正プログラム（パッチ）が提供されるまでの無防備な期間を狙う攻撃。 Nデイ攻撃: 修正プログラム公開後、利用者がパッチを適用していない「隙」を狙う攻撃。 対策:\n脆弱性に関する情報を迅速に収集し、早期にパッチを適用する体制を構築する。 自組織で利用しているIT資産（サーバー、PC、ソフトウェア等）を正確に把握・管理する。 キーワード:\n脆弱性、ゼロデイ攻撃、Nデイ攻撃、パッチ管理 4. 内部不正による情報漏えい等 # 概要: 従業員や元従業員など、組織の内部関係者が意図的に機密情報や個人情報を持ち出し、漏えいさせる行為。「転職先での優位性確保」や「職場への不満」などが主な動機です。\n主な手口:\nアクセス権限の悪用: 業務上付与された権限を悪用し、顧客情報や技術情報を窃取する。 退職者アカウントの悪用: 削除されずに残っている退職者のアカウントを悪用して侵入する。 情報の不正な持ち出し: USBメモリやクラウドストレージなどを利用して、データを外部へ持ち出す。 対策:\n不正の3要素（動機・機会・正当化）を抑制する就業規則を整備し、周知徹底する。 アクセス権限を必要最小限に設定し（最小権限の原則）、退職者のアカウントは速やかに削除する。 重要情報へのアクセスログを監視し、不審な操作を検知できる体制を整える。 従業員への定期的な情報リテラシー教育を実施する。 キーワード:\n内部不正、不正のトライアングル、最小権限の原則、アクセスログ監視 5. 機密情報等を狙った標的型攻撃 # 概要: 特定の企業や組織を標的とし、機密情報や知的財産の窃取、または業務妨害を目的として執拗に行われるサイバー攻撃です。\n主な攻撃手口:\n標的型攻撃メール: 業務に関連する巧妙な内容でメールを送り、添付ファイル開封やURLクリックによりマルウェアに感染させる。 水飲み場攻撃: 標的組織の従業員が頻繁に訪れるWebサイトを改ざんし、アクセスした従業員のPCをマルウェアに感染させる。 不正アクセス: VPN機器や公開サーバーの脆弱性を悪用してネットワーク内部へ侵入する。 対策:\n従業員への教育（不審なメールやURLを安易に開かない、など）。 侵入を早期に検知し、迅速に対応するための体制整備（EDR/NDR等の導入）。 キーワード:\n標的型攻撃、APT (Advanced Persistent Threat)、標的型攻撃メール、水飲み場攻撃 6. リモートワーク等の環境や仕組みを狙った攻撃 # 概要: リモートワークの普及に伴い、セキュリティ対策が手薄になりがちな自宅のネットワーク環境や、リモートアクセスに利用されるVPN機器、個人の端末などを標的とする攻撃です。\n主な攻撃手口:\nVPN機器の脆弱性を悪用: パッチが適用されていないVPN機器の脆弱性を突き、社内ネットワークへ侵入する。 認証情報の不正利用: ID・パスワードへの総当たり攻撃や、漏えいした情報の使い回しにより不正ログインを試みる。 対策が不十分な端末への攻撃: 私物端末（BYOD）や管理外の端末を狙い、マルウェアに感染させて侵入の足がかりとする。 対策:\nより安全性の高いZTNA（ゼロトラスト・ネットワーク・アクセス）などの導入を検討する。 リモートアクセス時の多要素認証（MFA）を必須とする。 使用する機器のOS・ソフトウェアを常に最新の状態に保つ。 リモートワークに関するセキュリティポリシーを策定し、従業員に周知徹底する。 キーワード:\nVPN、リモートデスクトップ、BYOD、ZTNA、多要素認証 (MFA) 7. 地政学的リスクに起因するサイバー攻撃 # 概要: 国家間の対立などを背景に、国家が支援する攻撃グループや、政治的主張を目的とするハクティビストなどが、敵対国の政府機関や重要インフラ企業を標的として行う攻撃。2025年版で初めてランクインした脅威です。\n主な攻撃手口:\nDDoS攻撃: 標的のWebサイト等を機能停止させ、社会的な混乱を引き起こす。 スピアフィッシング: 巧妙な標的型攻撃メールで、外交・安全保障に関する機密情報を窃取する。 偽情報の流布: SNS等で偽情報を拡散し、世論操作や社会不安を煽る。 LotL戦術 (Living Off The Land): OS標準の正規ツールを悪用するため、検知が困難な攻撃。 対策:\n自社の事業に関する地政学的リスク情報を常に収集し、影響を評価する。 サービス停止を想定した事業継続計画（BCP）を見直し、訓練を実施する。 侵入を前提とし、ネットワーク監視を強化して不審な挙動を早期に検知できる体制を整える。 キーワード:\n国家支援型攻撃、ハクティビスト、重要インフラ、偽情報、LotL 8. 分散型サービス妨害攻撃（DDoS攻撃） # 概要: マルウェアに感染させた多数の機器（ボットネット）から、標的のサーバー等に一斉に大量のアクセスを送りつけ、サービスを停止させる攻撃。IoT機器の増加により、攻撃が大規模化しています。\n主な攻撃手口:\nフラッド攻撃: 大量のパケットでサーバーやネットワーク機器のリソースを枯渇させる。 リフレクション攻撃: 多数のサーバーからの応答が標的に集中するように仕向け、攻撃を増幅させる。 対策:\n攻撃トラフィックを検知・遮断するDDoS対策サービスの導入。 アクセス負荷を分散させるCDN（コンテンツデリバリーネットワーク）の活用。 攻撃検知時の連絡体制や代替サイトへの切り替え手順などを事前に定めておく。 キーワード:\nDDoS、ボットネット、フラッド攻撃、リフレクション攻撃、CDN 9. ビジネスメール詐欺（BEC） # 概要: 経営者や取引先になりすました巧妙な偽メールで担当者を騙し、攻撃者が用意した口座へ送金させる詐欺。近年ではAIによるディープフェイク技術が悪用されるケースもあります。\n主な攻撃手口:\n経営者へのなりすまし: 「極秘の買収案件」などと緊急性を装い、送金を指示する。 取引先へのなりすまし: 「振込先口座が変更になった」と偽の連絡を行い、送金させる。 ディープフェイクの悪用: AIで生成した偽の音声や映像をビデオ会議で使い、担当者を信用させる。 対策:\n送金や振込先変更の依頼があった際は、メール以外の手段（電話など）で必ず事実確認を行うルールを徹底する。 送信ドメイン認証技術（SPF, DKIM, DMARC）を導入し、なりすましメールを低減させる。 具体的な手口や事例を共有し、従業員への継続的な教育を行う。 キーワード:\nBEC、なりすまし、ディープフェイク、送信ドメイン認証 10. 不注意による情報漏えい等 # 概要: 悪意のある攻撃ではなく、従業員の確認ミスや知識不足といったヒューマンエラーが原因で、意図せず機密情報や個人情報が外部に漏えいする事案です。\n主な発生要因:\nメールの誤送信: 宛先（To/Cc/Bcc）の入力ミスや、添付ファイルの取り違え。 設定の不備: クラウドストレージ等のアクセス権限の設定誤り。 媒体の紛失・置き忘れ: 業務用のPC、スマートフォン、USBメモリ等の紛失。 不適切な廃棄: データを完全に消去せずにHDD等を廃棄してしまう。 対策:\nメール送信前の警告機能や、設定ミスを検知するツールを導入する。 DLP（Data Loss Prevention）製品で重要情報の持ち出しを制御する。 情報の取り扱いに関する明確なルールを定め、全従業員に周知徹底する。 定期的な研修を実施し、従業員の情報セキュリティ意識とリテラシーを向上させる。 キーワード:\nヒューマンエラー、誤送信、設定ミス、DLP 脅威への共通対策 # 1. 適切な認証 # パスワードの不適切な設定・管理は、不正アクセスの主要な原因です。\n設定: 初期設定の変更: 機器やサービスの初期パスワードは必ず変更する。 推測されにくいパスワード: 長く、複雑で、使い回さないパスワードを設定する。 管理: パスワードを教えない、メモを貼らない。 複数人利用のPCにパスワードを記憶させない。 高度な認証: 多要素認証 (MFA): 知識情報・所持情報・生体情報を組み合わせた認証を導入する。 パスキー: パスワードレス認証の利用を推奨する。 2. 情報リテラシー・モラルの向上 # 意図しないルール違反や不正行為を防ぐため、全従業員に対する継続的な教育が不可欠です。\n教育内容: SNSの適切な利用、偽情報への対処、フィッシング詐欺の手口、内部不正のリスクなど。 実施方法: 定期的な研修の実施、最新の脅威に関する情報提供、緊急時の報告手順の周知徹底。 3. メールの添付ファイルやURLに安易に接続しない # メールやSMSは、マルウェア感染やフィッシング詐欺の主要な侵入経路です。\n基本動作: 差出人を確認: 知らない相手や不審なメールは開かない。 安易にクリックしない: 本文中のURLや添付ファイルを安易に開かない。 確認方法: リンク先のURLにカーソルを合わせ、正規のドメインか確認する。 公式アプリやブックマークから正規サイトにアクセスし、情報の真偽を確認する。 4. 適切な報告・連絡・相談 # インシデントの兆候を発見した場合、迅速な報告が被害の拡大を防ぎます。\n体制構築: インシデント発生時の報告先（CSIRT、情報システム部門など）と報告フローを明確にし、全従業員に周知する。 報告を躊躇させない、隠蔽を許さない組織風土を醸成する。 5. インシデント対応体制の整備 # インシデントは「必ず起きるもの」として、事前の準備が重要です。\nCSIRT (Computer Security Incident Response Team) の構築: セキュリティ問題を専門に扱うチームを設置する。 事前準備: 責任者の任命 (CISOなど)。 対応フローの策定: 「検知」→「トリアージ」→「封じ込め・復旧」→「報告」といった一連の手順を文書化する。 訓練の実施: 定期的に訓練を行い、手順の実効性を確認・改善する。 6. サーバーやPC・ネットワークに適切なセキュリティ対策を施す # 組織のサーバー、PC、ネットワークは、重要な情報を保持し事業活動を支える生命線です。これらは攻撃者にとって価値の高い標的であり、多層的かつ継続的なセキュリティ対策が不可欠となります。資料では、以下の具体的な対策が推奨されています。\nネットワーク管理の徹底 # 侵入された際の被害を最小限に食い止める（局所化する）ための対策です。\nネットワークの分割とアクセス制御:\n目的: ある区画でマルウェア感染が発生しても、他の重要なサーバーや部署のネットワークに被害が拡大するのを防ぎます。 対策: 事業所や部署、機器の用途（例：開発環境、本番環境、業務用PC）に応じてネットワークを論理的・物理的に分割します。その上で、ファイアウォールを設置し、分割されたネットワーク間の通信を「許可されたもの」だけに制限（アクセス制御）します。 Attack Surface Management (ASM) の実施:\n目的: 組織の管理者が把握していない、あるいは意図せず外部に公開されているIT資産（サーバー、サービスなど）を攻撃者の視点で発見し、リスクを低減します。 対策: ASMツールやサービスを利用して、インターネットからアクセス可能な自組織の資産を継続的に棚卸しし、不要な公開や設定ミス、脆弱性を検出・修正します。 不要なポートやプロトコルの遮断:\n目的: 攻撃の侵入口となりうる不要な「扉」を閉ざし、リスクを低減します。 対策: サーバーやネットワーク機器で、業務上使用していない通信ポートやプロトコル（通信ルール）を無効化、またはファイアウォールで遮断します。 脆弱性対策の徹底 # ソフトウェアのセキュリティ上の欠陥を悪用される攻撃を防ぐための基本的な対策です。\nサポート切れのソフトウェア・ハードウェアを使用しない:\n目的: 新たな脆弱性が発見されても修正プログラム（パッチ）が提供されない「無防備な状態」を回避します。 対策: 自組織で使用している製品のサポート期限を把握し、期限が切れる前に後継製品への移行計画を立て、実行します。 迅速な更新プログラム（パッチ）の適用:\n目的: 脆弱性が公表されてから攻撃を受けるまでの時間をなくし、Nデイ攻撃のリスクを最小化します。 対策: 資産管理台帳を整備し、脆弱性情報を常時収集します。パッチが公開された際は、業務影響を検証した上で、速やかに適用する手順と体制を確立します。特にサーバーへの適用は事前検証や再起動が伴うため、迅速に対応できる計画が必要です。 SBOM (Software Bill of Materials) の活用:\n目的: 利用しているソフトウェアにどのような部品（ライブラリ等）が含まれているかを可視化し、部品に脆弱性が発見された際に迅速な影響範囲の特定と対策を可能にします。 対策: ソフトウェアの調達時や開発時にSBOMを導入し、構成要素を管理する体制を整えます。 多層的なセキュリティ製品の導入 # 単一の対策では防ぎきれない巧妙な攻撃に対し、複数の防御壁を設けます。\nエンドポイント対策 (PC・サーバー): ウイルス対策ソフト: 定期的なスキャンと定義ファイルの自動更新を徹底します。 EDR (Endpoint Detection and Response): PCやサーバー内の不審な挙動を検知し、侵入後の迅速な対応を可能にします。 ネットワーク対策: IDS/IPS (不正侵入検知・防御システム): ネットワーク上の不審な通信を検知・遮断します。 WAF (Web Application Firewall): Webアプリケーションの脆弱性を狙った攻撃を防ぎます。 UTM (統合脅威管理): ファイアウォール、IDS/IPS、ウイルス対策など複数のセキュリティ機能を一台に集約した機器です。 アクセス権限管理の厳格化 # 内部不正や、乗っ取られたアカウントによる被害拡大を防ぎます。\nアクセス権限の最小化: 目的: 各アカウントに業務上必要最小限の権限のみを付与し（最小権限の原則）、万が一アカウントが乗っ取られても被害範囲を限定します。 対策: 不要な管理者権限を与えず、データの重要性に応じてアクセスできるユーザーを厳密に制限します。 定期的なアカウントの棚卸: 目的: 退職者や異動者の不要なアカウント、過剰な権限が付与されたアカウントを発見し、不正利用のリスクを排除します。 対策: 四半期に一度など定期的にすべてのアカウントを確認し、不要なものを削除・無効化します。 多要素認証 (MFA) の有効化: 目的: パスワードが漏えいしても、それだけでは不正ログインさせないようにします。 対策: 重要なシステムやリモートアクセスなど、不正ログインによる影響が大きい箇所から優先的にMFAを導入・必須化します。 7. 適切なバックアップ運用 # データの破損や喪失は、サイバー攻撃だけでなく、操作ミスやハードウェア故障でも発生します。迅速に事業を復旧させるためのバックアップは、最後の砦となる極めて重要な対策です。\nバックアップの「取得」計画 # 何を残し、どうやって取得するかを明確に計画します。\n対象の選定:\n業務データだけでなく、システムの復旧に必要な設定ファイルやプログラムもバックアップの対象とします。データの重要度に応じて、バックアップの優先順位を決定します。 取得方法と頻度の検討:\nサーバーの稼働要件に合わせて、オンライン（稼働中）かオフライン（停止後）かを選定します。 データの更新頻度に応じて、「毎日差分（変更分のみ）＋週末にフル（全体）」など、最適な取得間隔と方法を検討します。 バックアップの「保管」戦略 # 取得したバックアップデータを安全に守るための保管方法です。\n基本原則「3-2-1ルール」の実践:\n3: データを3つ（原本＋コピー2つ）保持する。 2: そのうち2つは、異なる種類の媒体（例: HDDとクラウドストレージ）に保管する。 1: 1つは、必ずオフサイト（物理的に離れた場所やネットワーク的に隔離された場所）に保管する。これは災害対策だけでなく、ランサムウェアがネットワーク経由でバックアップまで暗号化するのを防ぐ上で非常に重要です。 世代管理の重要性:\n目的: 最新のバックアップだけでなく、過去の複数時点のバックアップを保管します。データ破損に気づくのが遅れた場合、最新のバックアップもすでに破損している可能性があるためです。 対策: 毎日、毎週、毎月など、複数世代のバックアップを保管し、必要な時点に遡って復旧できる体制を整えます。 バックアップからの「復旧」準備 # バックアップは取得するだけでは意味がなく、「確実に復旧できること」がゴールです。\n復旧計画（リストア計画）の策定:\n目的: 障害が発生した際に、誰が、どのバックアップを使い、どのような手順で、どのくらいの時間で復旧させるかを事前に明確にします。 対策: 想定される障害シナリオごとに、具体的な復旧手順を文書化し、関係者で共有します。 定期的な復旧テストの実施:\n目的: バックアップデータが破損していないか、策定した復旧計画が本当に機能するかを確認します。 対策: 半年に一度など定期的に、実際にバックアップからデータを復旧させるテストを実施します。テストを通じて判明した問題点（手順の不備、想定以上の時間がかかる等）を基に、復旧計画を見直し、改善を続けます。 ","date":"2025年 9月 15日","externalUrl":null,"permalink":"/scraps/1757938931_top_10_information_security_threats_2025_for_organizations/","section":"スクラップ","summary":"","title":"学習メモ：情報セキュリティ10大脅威 2025（組織編）","type":"scraps"},{"content":"","date":"2025年 9月 11日","externalUrl":null,"permalink":"/tags/blowfish/","section":"Tags","summary":"","title":"Blowfish","type":"tags"},{"content":"","date":"2025年 9月 11日","externalUrl":null,"permalink":"/tags/css/","section":"Tags","summary":"","title":"CSS","type":"tags"},{"content":"","date":"2025年 9月 11日","externalUrl":null,"permalink":"/tags/hugo/","section":"Tags","summary":"","title":"Hugo","type":"tags"},{"content":" はじめに # Hugo + BlowfishテーマでのカスタムCSS適用は、独自のデザインカスタマイズを可能にする重要な機能です。テーマファイルを直接編集することなく、安全にスタイルをオーバーライドできるため、テーマ更新の際も変更が維持されます。\n以下に、Hugo・BlowfishでカスタムCSSを適用する手順と実践的な活用方法を説明します。\n基本的なファイル構成 # カスタムCSS適用に必要なファイル構成：\nプロジェクトルート/ ├── assets/ │ └── css/ │ └── custom.css # カスタムCSSファイル ├── config/ │ └── _default/ │ └── params.toml # 設定ファイル 重要: assets/css/ ディレクトリに配置することで、Hugoのアセット処理機能が利用できます。\nインストール・セットアップ # 1. ディレクトリとファイルの作成 # # assetsディレクトリ内にcssフォルダを作成 mkdir -p assets/css # カスタムCSSファイルを作成 touch assets/css/custom.css 2. params.tomlでの設定 # config/_default/params.toml に以下を追加：\n# カスタムスタイル設定 customCSS = [\u0026#34;css/custom.css\u0026#34;] 複数ファイルの場合:\ncustomCSS = [\u0026#34;css/custom.css\u0026#34;, \u0026#34;css/additional.css\u0026#34;] 基本的な使い方 # カスタムCSSの記述 # assets/css/custom.css にスタイルを記述します：\n目的 実装例 解説 カラーパレット設定 :root { --primary-color: #4f46e5; } CSS変数でテーマカラーを統一 既存要素の調整 .card { border-radius: 12px; } Blowfishのクラスをオーバーライド アニメーション追加 .card:hover { transform: translateY(-2px); } ホバーエフェクトの実装 実用的なカスタマイズ例 # /* カスタムカラーパレット */ :root { --primary-gradient-start: #4f46e5; --primary-gradient-end: #06b6d4; --accent-color: #10b981; } /* カード要素の改善 */ .min-h-full.border { border: none !important; box-shadow: 0 10px 25px -3px rgba(0, 0, 0, 0.1); border-radius: 12px; transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1); } .min-h-full.border:hover { transform: translateY(-2px); box-shadow: 0 20px 40px -12px rgba(0, 0, 0, 0.15); } サイトの再生成 # # 開発サーバー再起動 hugo server --port 1313 # または本番ビルド hugo 実践的な使い方 # 1. レスポンシブデザイン対応 # /* モバイル対応 */ @media (max-width: 768px) { .grid.gap-4.sm\\:grid-cols-2.md\\:grid-cols-3 { grid-template-columns: 1fr; gap: 1.5rem; } } 2. アニメーション効果 # /* ホバーエフェクト */ .thumbnail_card { transition: transform 0.3s ease; } .min-h-full.border:hover .thumbnail_card { transform: scale(1.05); } 3. ダークモード対応 # /* ダークモード対応 */ @media (prefers-color-scheme: dark) { .min-h-full.border { background: linear-gradient(145deg, #1f2937 0%, #111827 100%); } } 問題1: CSSが適用されない # 原因と解決策：\n原因 確認方法 解決策 ファイルパス間違い ls -la assets/css/custom.css assets/css/ ディレクトリに正しく配置 params.toml記述ミス 配列形式で記述されているか customCSS = [\u0026quot;css/custom.css\u0026quot;] キャッシュ問題 ブラウザで強制リロード rm -rf public \u0026amp;\u0026amp; hugo 問題2: 既存スタイルとの競合 # /* 詳細度を上げる */ body .main-content .card-element { color: #333 !important; } 問題3: レスポンシブが効かない # /* メディアクエリの順序を確認 */ @media (max-width: 768px) { /* モバイル用スタイル */ } @media (min-width: 769px) { /* デスクトップ用スタイル */ } 参考リンク # Blowfish公式ドキュメント - カスタマイゼーション Hugo Assets処理公式ガイド CSS詳細度の理解 ","date":"2025年 9月 11日","externalUrl":null,"permalink":"/scraps/1757593500_hugo-blowfish-custom-css-guide/","section":"スクラップ","summary":"","title":"Hugo・BlowfishでカスタムCSS適用","type":"scraps"},{"content":"","date":"2025年 9月 11日","externalUrl":null,"permalink":"/tags/darkmode/","section":"Tags","summary":"","title":"Darkmode","type":"tags"},{"content":" はじめに # Hugo静的サイトジェネレーター + Blowfishテーマを使用したサイトにおいて、表示テーマを常にダークモードに固定する方法について整理しました。\nこの設定により、ユーザーの環境設定に関係なく、サイトを常にダークモードで表示させることができます。\n設定方法 # 1. params.tomlファイルの設定 # config/_default/params.tomlの以下の項目を変更します。\n# テーマ設定 colorScheme = \u0026#34;blowfish\u0026#34; defaultAppearance = \u0026#34;dark\u0026#34; # \u0026#34;light\u0026#34; から \u0026#34;dark\u0026#34; に変更 autoSwitchAppearance = false # true から false に変更 # フッター設定 [footer] showMenu = true showCopyright = true showThemeAttribution = true showAppearanceSwitcher = false # true から false に変更（オプション） showScrollToTop = true 各設定項目の説明 # 設定項目 設定値 説明 defaultAppearance \u0026quot;dark\u0026quot; サイトのデフォルト表示テーマをダークモードに設定 autoSwitchAppearance false ユーザーの環境設定に応じた自動切り替えを無効化 showAppearanceSwitcher false フッターのテーマ切り替えボタンを非表示（推奨） 設定反映手順 # 手順 説明 1. ファイル編集 config/_default/params.tomlを上記のとおり変更 2. サーバー再起動 hugo serverコマンドでローカルサーバーを再起動 3. 確認 サイトが常にダークモードで表示されることを確認 設定反映コマンド # # サーバー再起動 hugo server # 下書き含む場合 hugo server -D 設定の効果 # 設定後の動作は以下のようになります：\n✅ 固定表示: サイトが常にダークモードで表示される ✅ 自動切り替え無効: ユーザーの環境設定（OS設定等）の影響を受けない ✅ UI整合性: テーマ切り替えボタンを非表示にして一貫性を保つ ✅ UX向上: ユーザーが意図しないテーマ変更を防止 トラブルシューティング # よくある問題と解決策 # 問題 原因 解決策 設定が反映されない サーバーが再起動されていない hugo serverコマンドでサーバーを再起動 一部要素がライトモード カスタムCSSの影響 カスタムCSSでダークモード用スタイルを確認 テーマボタンが残っている showAppearanceSwitcherがtrueのまま params.tomlでfalseに設定 応用設定 # ライトモードに戻したい場合 # defaultAppearance = \u0026#34;light\u0026#34; autoSwitchAppearance = false showAppearanceSwitcher = false 自動切り替えを有効にしたい場合 # defaultAppearance = \u0026#34;dark\u0026#34; # デフォルトは維持 autoSwitchAppearance = true # 自動切り替えを有効化 showAppearanceSwitcher = true # 切り替えボタンも表示 カスタムダークテーマの適用 # カスタムCSSでさらに詳細なダークモード設定が可能です：\n/* custom.css */ :root[data-theme=\u0026#34;dark\u0026#34;] { --color-primary: #your-color; --color-secondary: #your-color; /* その他のカスタム設定 */ } 参考リンク # Blowfishテーマ公式ドキュメント - Appearance Hugo Configuration Documentation Blowfishテーマ - GitHub ","date":"2025年 9月 11日","externalUrl":null,"permalink":"/scraps/1757588400_hugo-blowfish-darkmode-fixed/","section":"スクラップ","summary":"","title":"Hugo+Blowfish｜ダークモードに固定する設定方法","type":"scraps"},{"content":" はじめに # Hugo静的サイトジェネレーター + Blowfishテーマを使用したサイトにおいて、トップページの「最近の記事」セクションに特定のコンテンツセクション（この場合はスクラップ）を表示させない方法について整理しました。\nこの設定により、メインの記事とスクラップメモを分離して表示でき、読者により適切なコンテンツ体験を提供できます。\n設定方法 # 1. hugo.tomlファイルの設定 # config/_default/hugo.tomlにmainSections設定を追加します。\nenableEmoji = true # Only include posts section in recent articles mainSections = [\u0026#34;posts\u0026#34;] # googleAnalytics = \u0026#34;G-XXXXXXXXX\u0026#34; 効果:\nmainSections = [\u0026quot;posts\u0026quot;]により「最近の記事」にはpostsセクションの記事のみが表示される scrapsディレクトリの記事は自動的に除外される 設定反映手順 # 手順 説明 1. ファイル編集 上記の設定を該当ファイルに追加 2. サーバー再起動 hugo serverコマンドでローカルサーバーを再起動 3. 確認 トップページで「最近の記事」にpostsのみが表示されることを確認 設定反映コマンド # # サーバー再起動 hugo server # 下書き含む場合 hugo server -D 変更の効果 # 設定後の動作は以下のようになります：\n✅ トップページ: 「最近の記事」にはpostsディレクトリの記事のみ表示 ✅ スクラップページ: /scraps/は通常通りアクセス可能 ✅ 記事分離: メインコンテンツと学習メモの適切な分離 ✅ SEO効果: 読者にとって価値の高いメインコンテンツが優先表示 トラブルシューティング # よくある問題と解決策 # 問題 原因 解決策 設定が反映されない サーバーが再起動されていない hugo serverコマンドでサーバーを再起動 スクラップページが表示されない _index.mdが作成されていない content/scraps/_index.mdを作成 他のセクションも除外したい mainSectionsの設定が不適切 mainSections = [\u0026quot;posts\u0026quot;, \u0026quot;articles\u0026quot;]のように配列に追加 応用設定 # 複数セクションを含める場合 # # 複数のセクションを「最近の記事」に含める mainSections = [\u0026#34;posts\u0026#34;, \u0026#34;articles\u0026#34;, \u0026#34;tutorials\u0026#34;] セクション別の除外設定 # 特定のセクションのみ除外したい場合は、Front Matterでの制御も可能です：\n--- title: \u0026#34;記事タイトル\u0026#34; excludeFromRecent: true # この記事を「最近の記事」から除外 --- 参考リンク # Hugo公式ドキュメント - mainSections Blowfishテーマ公式ドキュメント Hugo Configuration Documentation ","date":"2025年 9月 9日","externalUrl":null,"permalink":"/scraps/1757399400_blowfish-exclude-recent/","section":"スクラップ","summary":"","title":"Hugo+Blowfish｜mainSections設定でコンテンツ分離する方法","type":"scraps"},{"content":" はじめに # Pandasは、Pythonでデータを扱う際によく用いられるライブラリであり、データ操作に特化しています。データ分析や機械学習プロジェクトにおけるデータ整理、加工、分析の基礎を築く上で非常に便利です。\n以下に、Pandasライブラリの主要なデータ操作機能とその実用的な活用方法を説明します。\n1. データの読み込みと確認 # CSVファイルの読み込み: pd.read_csv()メソッドを使用して、CSVファイルをデータフレーム（df）として読み込むことができます。これにより、外部の表形式データをPythonで扱えるようになります。 データフレームの内容確認: df.head(n): データフレームの先頭からn行を表示します。通常、データフレーム全体を見ることはないため、データの概要を素早く把握するのに役立ちます。 df.tail(n): データフレームの末尾からn行を表示します。データが時系列順に並んでいる場合など、最新のデータを確認する際に便利です。 2. データの前処理（整形・クリーニング） # データ分析において、生データはしばしば不要な情報や不備を含んでいます。これらを整形・クリーニングすることで、データの品質を高め、分析に適した形に整えます。\n不要な行・列の削除（必要な部分の抽出）: 特定の列を抽出することで、不要な列を実質的に削除できます。これは、データフレームの df[カラム名のリスト] の形式で実現できます。例えば、単位情報や重複した情報を含むカラムなどを削除する際に用います。 特定の行を抽出することで、不要な行を実質的に削除できます。例えば、先頭行が不要なラベル情報である場合、df[1:] のように指定して2行目以降のデータを抽出します。 カラム名の変更: df.columns = [新しいカラム名のリスト] を使用すると、データフレームの全てのカラム名を一度に変更できます。例えば、カラム名に含まれる単位などの不要な部分を一括で削除し、短く分かりやすい名前に変更する際に有効です。 df.rename(columns={'変更前': '変更後'}) メソッドを使用すると、特定のカラム名のみをピンポイントで変更できます。これは、多くのカラムがある中で一部だけ変更したい場合に便利です。ただし、df自体の中身は変わらないため、変更を永続化するには再度代入 (df = df.rename(...)) が必要です。 欠損値の処理: 欠損値の確認: df.isnull() を使用すると、データフレーム内の各要素が欠損値（NaN）であるかどうかがTrue/Falseで判定されます。さらに、.sum() を組み合わせることで、各カラムにいくつ欠損値があるかを確認できます。これは、データ品質の問題を特定する上で重要です。 欠損値の補完: df.fillna(値) メソッドは、データフレーム内の欠損値を指定した値で埋めます。例えば、欠損値を0で埋めることができます。実際には、データの性質に応じて中央値や平均値といった統計量で補完することが多いです。 欠損値の削除: df.dropna(axis=値) メソッドは、欠損値を含む行または列を削除します。axis=1 を指定すると列方向に、axis=0 を指定すると行方向に削除されます。データ分析において、特にデータ数が少ないカラムや、その列全体が欠損値である場合に、その列を削除することでノイズを減らすことができます。 重複の除去: df.drop_duplicates(subset='カラム名') メソッドを使用すると、指定したカラム（subset）において重複する行を削除し、ユニークな行のみを残すことができます。subsetを指定しない場合、全てのカラムが一致する行が削除されます。 データ型の確認: df.dtypes を使用すると、データフレームの各カラムのデータ型を確認できます。これにより、データが意図した型で格納されているか、前処理が必要か（例: 文字列型の日付を日付型に変換するなど）を判断できます。 ダミー変数への変換: pd.get_dummies(df, columns=['カラム名']) メソッドは、カテゴリカルなデータを機械学習モデルで扱える数値データ（0または1）に変換するダミー変数化を行います。例えば、「国籍」のようなカテゴリカルな列を、「国籍_日本」「国籍_アメリカ」といった0/1の列に変換します。 3. データの抽出と選択 # データフレームから特定の条件を満たすデータや、特定の範囲のデータを柔軟に選択・抽出する機能です。\n任意の要素の取得 (iloc, loc): df.iloc[行インデックス, 列インデックス] は、インデックス番号（0から始まる位置）で指定して要素を抽出します。 df.loc[行ラベル, 列ラベル] は、**行や列のラベル名（カラム名）**で指定して要素を抽出します。 これらは、データフレーム内の特定の部分をピンポイントで取得したい場合に非常に強力なツールです。 条件抽出: 特定の条件を満たす行を抽出するには、データフレームに対して直接条件式（例: df[df['カラム名'] == '値']）を適用する方法が一般的です。複数の条件を組み合わせる場合は \u0026amp; (and) や | (or) で連結し、各条件を括弧で囲みます。 df.query('カラム名 == \u0026quot;値\u0026quot;') メソッドは、文字列形式で条件式を記述することで抽出を行います。 df['カラム名'].isin(['値1', '値2']) メソッドは、指定した値のリストに含まれる要素を持つ行を抽出する際に便利です。 これらは、特定の条件（例: 「アメリカ国籍の20歳以上30歳未満の人物」など）に合致するデータを絞り込みたい場合に活用されます。 4. データの集計と分析 # データから意味のある情報を導き出すための集計や統計分析を行う機能です。\nユニークな値と出現回数の確認: df['カラム名'].unique() メソッドは、指定したカラムに含まれるユニークな（重複しない）値のリストを取得します。 df['カラム名'].value_counts() メソッドは、指定したカラムのユニークな値とその出現回数を一覧で表示します。これは、カテゴリカルデータの分布を理解する上で非常に役立ちます。 グループごとの集計: df.groupby('グループ化したいカラム名').mean() のように groupby() メソッドを使用すると、指定したカラムのカテゴリごとにデータをグループ化し、それぞれのグループで平均値（mean()）などの統計量を算出できます。これにより、カテゴリ間の比較分析が容易になります。 統計量の確認: df.mean(), df.median(), df.std(), df.max(), df.min() などを使用すると、データフレームの各カラムの平均値、中央値、標準偏差、最大値、最小値といった基本的な統計量を個別に算出できます。 df.describe() メソッドは、これらの主要な統計量を一括で表形式で出力します。データの全体的な特性を素早く把握する際に非常に便利です。 データの並び替え: df.sort_values(by='カラム名', ascending=False) メソッドは、指定したカラムの値に基づいてデータフレームの行を並び替えます。ascending=False を設定すると降順（高い順）に、True（デフォルト）だと昇順（低い順）に並び替えることができます。 相関係数の算出: df.corr() メソッドは、データフレーム内の数値型カラム間の相関係数を算出します。相関係数は、二つの値がどれだけ関係性があるかを示す指標で、正の相関（一方が増えれば他方も増える）は1に近く、負の相関（一方が増えれば他方が減る）は-1に近く、無相関は0に近くなります。これにより、変数間の関係性を数値で把握できます。 5. データの可視化と出力 # 分析結果を視覚的に表現し、また加工したデータを再利用可能な形式で保存します。\nグラフ表示（可視化）: Pandasのデータフレームは、matplotlibライブラリと連携して直接グラフを描画する機能を持っています。例えば、df.plot(x='横軸カラム名', y=['縦軸カラム名1', '縦軸カラム名2'], kind='line', legend=False) のように指定することで、折れ線グラフなどを表示できます。データの特徴やトレンドを直感的に理解するために不可欠な機能です。ただし、日本語フォントの設定を行わないと文字化けすることがあります。 データ出力: df.to_csv('ファイル名.csv', index=False) メソッドは、加工済みのデータフレームをCSVファイルとして出力します。index=False を指定すると、データフレームのインデックス（左側の数値）は出力されません。これにより、クリーンアップまたは分析されたデータを他のツールやプロジェクトで再利用できます。 これらの機能を活用することで、データの読み込みから、前処理、分析、可視化、出力までの一連のデータ操作を効率的に行うことができます。\nYouTubeチャンネル「いまにゅのプログラミング塾」の動画「【Pandas徹底講座】この動画1本でデータ操作に特化したPythonライブラリPandasの基礎をマスター！」で出題された20問のハンズオンについて、それぞれの概要と解説を以下にまとめます。この講座は、データ整理、加工、分析の基礎を固める上で非常に実用的な内容となっています。\nPandasハンズオン 20問 解説 # 1. データの読み込み # 概要: weather.csvファイルを読み込み、dfというデータフレームとして定義する。 解説: Pandasライブラリをpdとしてインポートした後、pd.read_csv() メソッドを使用してCSVファイルを読み込みます。ファイル名を作業ディレクトリ内に指定するだけで読み込みが可能です。 import pandas as pd df = pd.read_csv(\u0026#39;weather.csv\u0026#39;) print(df) 2. データの中身確認 # 概要: 読み込んだデータフレームdfの先頭3行と末尾10行を表示する。 解説: データフレーム全体を見ることは稀であるため、データの概要を把握する際に使います。 df.head(n): データフレームの先頭からn行を表示します（n=3）。 df.tail(n): データフレームの末尾からn行を表示します（n=10）。 import pandas as pd df = pd.read_csv(\u0026#39;weather.csv\u0026#39;) print(df.head(3)) print(df.tail(10)) 3. 不要な列・行の削除 # 概要: データフレームから不要な先頭行（ラベル情報など）と、特定の不要な列（例: 平均気温.1、平均気温.2のように「.数字」が付く列）を削除し、dfとして再定義する。 解説: 一般的なdropメソッドではなく、必要な部分のみを抽出するアプローチが推奨されています。 列の抽出: 必要なカラム名のみをリストで指定し、df[カラム名のリスト]の形式で抽出します。 行の抽出: 先頭行が不要な場合、df[1:]のようにスライス表記を用いて2行目以降のデータを抽出します。 # ラベル情報を抽出 import pandas as pd df = pd.read_csv(\u0026#39;weather.csv\u0026#39;) print(df.columns) # 必要なラベルを抽出して表示させる df = df[[ \u0026#39;年月日\u0026#39;, \u0026#39;平均気温(℃)\u0026#39;, \u0026#39;最高気温(℃)\u0026#39;, \u0026#39;最低気温(℃)\u0026#39;, \u0026#39;降水量の合計(mm)\u0026#39;, \u0026#39;最深積雪(cm)\u0026#39;, \u0026#39;平均雲量(10分比)\u0026#39;, \u0026#39;平均蒸気圧(hPa)\u0026#39;, \u0026#39;平均風速(m/s)\u0026#39;, \u0026#39;日照時間(時間)\u0026#39;, ]] print(df) # 1行目から取得する場合 df = df[[ \u0026#39;年月日\u0026#39;, \u0026#39;平均気温(℃)\u0026#39;, \u0026#39;最高気温(℃)\u0026#39;, \u0026#39;最低気温(℃)\u0026#39;, \u0026#39;降水量の合計(mm)\u0026#39;, \u0026#39;最深積雪(cm)\u0026#39;, \u0026#39;平均雲量(10分比)\u0026#39;, \u0026#39;平均蒸気圧(hPa)\u0026#39;, \u0026#39;平均風速(m/s)\u0026#39;, \u0026#39;日照時間(時間)\u0026#39; ]][1:] print(df) 4. データの形・サイズ、列名・行名、データ型の確認 # 概要: 各列のデータ型、データフレームのサイズ（行数・列数）、列名（カラム名）、行名（インデックス）を取得する。 解説: データ型: df.dtypes を使用し、各カラムのデータ型（数値型、オブジェクト型など）を確認します。 サイズ: df.shape を使用し、データフレームの行数と列数を(行数, 列数)のタプル形式で取得します。 列名: df.columns を使用し、データフレームのカラム名リストを取得します。 行名（インデックス）: df.index を使用し、行のインデックス情報を取得します。現在のインデックスが数値であれば、その範囲と刻みが表示されます。 print(df.dtypes) print(df.shape) print(df.columns) print(df.index) 5. 任意の要素の取得 # 概要: dfの5行目から10行目まで、かつ3列目から6列目まで（最高気温から最深積雪まで）の要素を取得する。 解説: 特定の範囲のデータにアクセスするために、主に以下の2つの方法があります。 df.iloc[行インデックス, 列インデックス]: インデックス番号（0から始まる位置）で要素を抽出します。例えば、5行目から10行目（インデックス4から9）は4:10、3列目から6列目（インデックス2から5）は2:6と指定します。 df.loc[行ラベル, 列ラベル]: **行ラベル名や列ラベル名（カラム名）**で要素を抽出します。行は5:10のように指定し、列は'最高気温':'最深積雪'のように範囲で指定します。locの行の範囲指定は終端を含みますが、ilocは含みません。 import pandas as pd df = pd.read_csv(\u0026#39;weather.csv\u0026#39;) print(df.iloc[4:10, 2:6]) print(df.loc[5:10,\u0026#39;最高気温(℃)\u0026#39;:\u0026#39;最深積雪(cm)\u0026#39;]) 6. 条件抽出 # 概要: people.csvをdf_peopleとして読み込み、以下の条件を満たすデータを抽出する。 Nationalityが「America」であるもの。 Ageが20以上30未満であるもの。 解説: 直接的な条件式: df_people[df_people['Nationality'] == 'America'] のように、データフレームに対して直接条件式を適用する方法がよく使われます。複数の条件を組み合わせる場合は、各条件を括弧で囲み、\u0026amp;（AND）や|（OR）で連結します（例: (df['Age'] \u0026gt;= 20) \u0026amp; (df['Age'] \u0026lt; 30)）。 df.query() メソッド: df_people.query('Nationality == \u0026quot;America\u0026quot;') のように、文字列形式で条件式を記述して抽出することもできます。 df['カラム名'].isin([]) メソッド: 指定した値のリストに含まれる要素を持つ行を抽出する際に便利です（例: df_people['Nationality'].isin(['America'])）。 import pandas as pd df_people = pd.read_csv(\u0026#39;people.csv\u0026#39;) # n条件に合致したものがTrueとなり、Trueのみ表示させる print(df_people[df_people[\u0026#39;nationality\u0026#39;] == \u0026#39;America\u0026#39;]) print(df_people[(df_people[\u0026#39;age\u0026#39;] \u0026gt;= 20) \u0026amp; (df_people[\u0026#39;age\u0026#39;] \u0026lt; 30)]) # こちらはクエリを利用した方法 print(df_people.query(\u0026#39;nationality == \u0026#34;America\u0026#34;\u0026#39;)) # isinを利用した方法 print(df_people[df_people[\u0026#39;nationality\u0026#39;].isin([\u0026#39;America\u0026#39;])]) 7. ユニークな値の抽出 # 概要: df_peopleの各カラムについて、ユニークな（固有の）値を抽出する。 解説: df['カラム名'].unique() メソッドを使用します。このメソッドはシリーズ（1次元データ）にしか適用できないため、データフレーム全体に直接適用するとエラーになることに注意が必要です。 import pandas as pd df_people = pd.read_csv(\u0026#39;people.csv\u0026#39;) print(df_people[\u0026#39;nationality\u0026#39;].unique()) print(df_people[\u0026#39;name\u0026#39;].unique()) print(df_people[\u0026#39;age\u0026#39;].unique()) 8. 重複除去 # 概要: df_peopleのNationality列において、重複する値を持つ行を削除し、重複がないデータフレームを取得する。 解説: df.drop_duplicates(subset='カラム名') メソッドを使用します。 subset引数を指定しない場合、すべてのカラムの値が一致する行が重複とみなされます。 subset='Nationality'のように特定のカラム名を指定すると、そのカラムの値が重複する場合に該当する行を削除します。 import pandas as pd df_people = pd.read_csv(\u0026#39;people.csv\u0026#39;) print(df_people.drop_duplicates(subset=\u0026#39;nationality\u0026#39;)) 9. カラム名変更 # 概要: dfの各カラム名から、単位部分（例: (℃)、(mm)）を削除する。 解説: カラム名を変更する方法はいくつかあります。 一括変更: df.columns = [新しいカラム名のリスト] を使用し、すべてのカラム名を新しいリストで上書きします。これはカラム数が少ない場合に手動でリストを作成するのに便利です。 df.rename() メソッド: df.rename(columns={'変更前':'変更後'}) を使用すると、特定のカラム名のみをピンポイントで変更できます。df.rename()はデフォルトではデータフレーム自体を直接変更しないため、変更を永続化するには df = df.rename(...) のように再代入が必要です。 import pandas as pd df = pd.read_csv(\u0026#39;weather.csv\u0026#39;) df.columns = [ \u0026#39;年月日\u0026#39;, \u0026#39;平均気温(℃)\u0026#39;, \u0026#39;最高気温(℃)\u0026#39;, \u0026#39;最低気温(℃)\u0026#39;, \u0026#39;降水量の合計(mm)\u0026#39;, \u0026#39;最深積雪(cm)\u0026#39;, \u0026#39;平均雲量(10分比)\u0026#39;, \u0026#39;平均蒸気圧(hPa)\u0026#39;, \u0026#39;平均風速(m/s)\u0026#39;, \u0026#39;日照時間(時間)\u0026#39; ] df.rename(columns={ \u0026#39;平均気温\u0026#39;:\u0026#39;平均\u0026#39; }) 10. 並び替え # 概要: dfを最高気温が高い順（降順）に並び替える。 解説: df.sort_values(by='カラム名', ascending=False) メソッドを使用します。 by引数で並び替えの基準となるカラムを指定します。 ascending=Falseを指定すると降順（高い順）に並び替えます。True（デフォルト）だと昇順（低い順）になります。 import pandas as pd df = pd.read_csv(\u0026#39;weather.csv\u0026#39;) print(df.sort_values(\u0026#39;最高気温(℃)\u0026#39;)) print(df.sort_values(\u0026#39;最高気温(℃)\u0026#39;,ascending=False)) 11. ダミー変数への処理 # 概要: df_peopleのNationalityカラムをダミー変数に変換する。 解説: カテゴリカルなデータを0または1で表現するダミー変数化には pd.get_dummies() メソッドを使用します。 pd.get_dummies(df, columns=['カラム名']) のように、変換したいデータフレームとカラム名を指定することで、指定したカラムのみをダミー変数化し、元のデータフレームに結合された形で取得できます。 import pandas as pd df_people = pd.read_csv(\u0026#39;people.csv\u0026#39;) df_people_dummy = pd.get_dummies(df_people, columns=[\u0026#39;nationality\u0026#39;]) print(df_people_dummy) 12. 欠損値の確認 # 概要: df内の欠損値（値が入っていない要素）を確認する。 解説: df.isnull() メソッドを使用します。これは、各要素が欠損値であればTrue、そうでなければFalseとなるブール型のデータフレームを返します。さらに、.sum()を組み合わせることで、各カラムの欠損値の合計数を簡単に確認できます（例: df.isnull().sum()）。 import pandas as pd df = pd.read_csv(\u0026#39;weather.csv\u0026#39;) print(df.isnull().sum()) 13. 欠損値の補完 # 概要: dfの欠損値をすべて0で補完（埋める）する。 解説: df.fillna(値) メソッドを使用します。このメソッドの引数に0を指定することで、すべての欠損値が0で埋められます。実用上は、中央値や平均値などの統計量で補完することが多いです。 import pandas as pd df = pd.read_csv(\u0026#39;weather.csv\u0026#39;) df = df.fillna(0) print(df.isnull().sum()) 14. 欠損値の削除 # 概要: dfの欠損値を含む列を削除する。 解説: df.dropna(axis=値) メソッドを使用します。 axis=1: 列方向（カラム全体）に欠損値が存在する場合、その列を削除します。 axis=0（デフォルト）: 行方向（行全体）に欠損値が存在する場合、その行を削除します。 今回のケースでは、一部の列がほとんど（またはすべて）欠損値であったため、行を削除するとほとんどのデータが失われるため、列方向の削除が適切でした。df = df.dropna(...)のように再代入しないと、データフレーム自体は変更されません。 import pandas as pd df = pd.read_csv(\u0026#39;weather.csv\u0026#39;) df = df.dropna(axis=1) print(df) 15. ユニークな値と出現回数 # 概要: iris.csvをdf_irisとして読み込み、Classカラムのユニークな値とそれぞれの出現回数を確認する。 解説: df['カラム名'].value_counts() メソッドを使用します。これはシリーズに適用され、ユニークな値とその出現回数を高い順に表示します。 import pandas as pd df_iris = pd.read_csv(\u0026#39;iris.csv\u0026#39;) print(df_iris[\u0026#39;Class\u0026#39;].value_counts()) 16. グループごとの集計 # 概要: df_irisの各Class（Iris-setosa、Iris-versicolor、Iris-virginica）におけるSepal Length、Sepal Width、Petal Length、Petal Widthの平均値を求める。 解説: df.groupby('グループ化したいカラム名').mean() のように、groupby()メソッドと集計メソッドを組み合わせます。groupby()で指定したカラム（例: Class）のカテゴリごとにデータをグループ化し、そのグループに対して平均値（mean()）などの統計量を算出できます。mean()以外にもstd()（標準偏差）などが適用可能です。 import pandas as pd df_iris = pd.read_csv(\u0026#39;iris.csv\u0026#39;) print(df_iris.groupby(\u0026#39;Class\u0026#39;).mean()) 17. 統計量の確認 # 概要: df_irisの各カラムについて、平均値、中央値、標準偏差、最大値、最小値を算出する。 解説: 個別の統計量: df.mean()、df.median()、df.std()、df.max()、df.min() など、各統計量に対応するメソッドを直接呼び出すことができます。 一括統計量: df.describe() メソッドは、これらの主要な統計量（カウント、平均、標準偏差、最小値、25パーセンタイル、中央値、75パーセンタイル、最大値）をまとめて表形式で出力し、データの全体像を素早く把握するのに非常に便利です。 import pandas as pd df_iris = pd.read_csv(\u0026#39;iris.csv\u0026#39;) # df_irisのClass列は文字列なので、数値計算の対象外にする print(df_iris.drop(columns=[\u0026#39;Class\u0026#39;]).mean()) print(df_iris.drop(columns=[\u0026#39;Class\u0026#39;]).median()) print(df_iris.drop(columns=[\u0026#39;Class\u0026#39;]).std()) print(df_iris.drop(columns=[\u0026#39;Class\u0026#39;]).max()) print(df_iris.drop(columns=[\u0026#39;Class\u0026#39;]).min()) print(df_iris.describe()) 18. 折れ線グラフの表示 # 概要: dfの最初の50日間のデータにおける平均気温、最高気温、最低気温を折れ線グラフで可視化する。横軸は年月とし、判例は表示しない。 解説: Pandasのデータフレームはmatplotlibと連携してグラフを描画できます。 matplotlib.pyplotをpltとしてインポートします。 データの最初の50行を抽出し（例: df[:50]）、そのデータフレームに対して df.plot(x='横軸カラム名', y=['縦軸カラム名1', '縦軸カラム名2'], kind='line', legend=False) メソッドを使用します。 kind='line'で折れ線グラフを指定し、legend=Falseで判例を非表示にします。日本語の文字化けが発生する可能性があるため、その場合はmatplotlibの日本語フォント設定が必要です。 import pandas as pd import matplotlib.pyplot as plt df = pd.read_csv(\u0026#39;weather.csv\u0026#39;) df = df[1:51] # 1行目から50行目まで # 日本語の文字化け対策（環境に合わせてフォントを指定） # plt.rcParams[\u0026#39;font.sans-serif\u0026#39;] = [\u0026#39;Hiragino Maru Gothic Pro\u0026#39;] df.plot(x=\u0026#39;年月日\u0026#39;, y=[\u0026#39;平均気温(℃)\u0026#39;, \u0026#39;最高気温(℃)\u0026#39;, \u0026#39;最低気温(℃)\u0026#39;], kind=\u0026#39;line\u0026#39;, legend=False) plt.show() 19. 相関係数の算出 # 概要: dfの平均気温、降水量の合計、日照時間の3項目における相関係数を算出する。 解説: df.corr() メソッドを使用します。 相関係数は、2つの変数間の関係性の強さを示す指標で、-1から1の間の値を取ります。 1に近いほど強い正の相関（一方が増えれば他方も増える）、-1に近いほど強い負の相関（一方が増えれば他方が減る）、0に近いほど相関がないことを示します。 特定の列の相関を見る場合は、それらの列を抽出したデータフレームに対してcorr()を適用します。データフレーム全体に適用すると、すべての数値型カラム間の相関係数を計算します。 import pandas as pd df = pd.read_csv(\u0026#39;weather.csv\u0026#39;) df = df[1:] # データ型を数値に変換 df[\u0026#39;平均気温(℃)\u0026#39;] = pd.to_numeric(df[\u0026#39;平均気温(℃)\u0026#39;], errors=\u0026#39;coerce\u0026#39;) df[\u0026#39;降水量の合計(mm)\u0026#39;] = pd.to_numeric(df[\u0026#39;降水量の合計(mm)\u0026#39;], errors=\u0026#39;coerce\u0026#39;) df[\u0026#39;日照時間(時間)\u0026#39;] = pd.to_numeric(df[\u0026#39;日照時間(時間)\u0026#39;], errors=\u0026#39;coerce\u0026#39;) print(df[[\u0026#39;平均気温(℃)\u0026#39;, \u0026#39;降水量の合計(mm)\u0026#39;, \u0026#39;日照時間(時間)\u0026#39;]].corr()) 20. データの出力 # 概要: 欠損値を0で補完したdfをexport.csvというファイル名でCSVファイルとして出力する。この際、データフレームのインデックスは出力しない。 解説: df.to_csv('ファイル名.csv', index=False) メソッドを使用します。 第一引数に出力するファイル名を指定します。 index=Falseを指定することで、データフレームのインデックス番号がCSVファイルに出力されないようにします。 import pandas as pd df = pd.read_csv(\u0026#39;weather.csv\u0026#39;) df = df.fillna(0) df.to_csv(\u0026#39;export.csv\u0026#39;, index=False) 参考リンク # 【Pandas徹底講座】この動画1本でデータ操作に特化したPythonライブラリPandasの基礎をマスター！\n","date":"2025年 9月 7日","externalUrl":null,"permalink":"/scraps/1757249281_study-pandas/","section":"スクラップ","summary":"","title":"Pandas入門","type":"scraps"},{"content":"","date":"2025年 9月 7日","externalUrl":null,"permalink":"/tags/python/","section":"Tags","summary":"","title":"Python","type":"tags"},{"content":" はじめに # Pythonの基本文法を習得した後は、より実践的なプログラミング技術を身につけることが重要です。アルゴリズムの理解、複雑な条件分岐、ループの応用など、実際の開発現場で使われる技術を段階的に学習できます。\n以下に、Python基礎レベルの実践的な練習問題をハンズオン形式で説明します。\n練習問題 # 九九の段を出力 # 1×1 ～ 9×9 の九九の段を出力するプログラムを書いてください。\n各行の末尾に「○の段です」と表示しましょう。\n1 2 3 4 5 6 7 8 9 「1」の段です 2 4 6 8 10 12 14 16 18 「2」の段です ... 9 18 27 36 45 54 63 72 81 「9」の段です for ループを2つ使う（二重ループ）ことで、九九のような表を作成できます。内側のループが列、外側のループが行を処理します。\nfor i in range(1, 10): for j in range(1, 10): print(i * j, end=\u0026#34; \u0026#34;) print(\u0026#34;「{}」の段です\u0026#34;.format(i)) 3の倍数ならfoo、そうでなければnoo # ユーザーから1つ数字を入力し、それが「3の倍数」であれば foo、そうでなければ noo と出力してください。\n数字を入力してください: 9 foo % 演算子は、割り算の余りを求めます。num % 3 == 0 のように、3で割った余りが0になるかどうかで、3の倍数を判定できます。\nnum = int(input(\u0026#34;数字を入力してください: \u0026#34;)) if num % 3 == 0: print(\u0026#34;foo\u0026#34;) else: print(\u0026#34;noo\u0026#34;) 2つの数字の和を計算しよう # ユーザーから2つの数字を受け取り、その和を出力してください。\n1つ目の数字: 3 2つ目の数字: 5 合計: 8 input() で受け取った文字列を int() で整数に変換してから、足し算を行います。\nx = int(input(\u0026#34;1つ目の数字: \u0026#34;)) y = int(input(\u0026#34;2つ目の数字: \u0026#34;)) print(\u0026#34;合計:\u0026#34;, x + y) 値を入れ替えてみよう # ユーザーから数字を2つ入力し、入れ替えて表示しましょう。\n出力の書式は print(\u0026quot;i =\u0026quot;, i, \u0026quot;, j =\u0026quot;, j) を必ず使ってください。\ni = 1 , j = 2 i = 2 , j = 1 Pythonでは i, j = j, i のように、1行で複数の変数の値を簡単に入れ替えることができます。\ni = input(\u0026#34;iを入力: \u0026#34;) j = input(\u0026#34;jを入力: \u0026#34;) print(\u0026#34;i =\u0026#34;, i, \u0026#34;, j =\u0026#34;, j) i, j = j, i print(\u0026#34;i =\u0026#34;, i, \u0026#34;, j =\u0026#34;, j) 三角形を描いてみよう # ユーザーから高さを入力し、その高さの直角三角形を「*」で描いてください。\n# 出力例（高さ=5） * ** *** **** ***** 文字列に * 演算子を使うと、その文字列を指定した回数だけ繰り返します。\u0026quot;*\u0026quot; * 5 は ***** となります。\nh = int(input(\u0026#34;高さを入力してください: \u0026#34;)) for i in range(1, h+1): print(\u0026#34;*\u0026#34; * i) 素数の和を求めよう # 20000 以下の素数をすべて足し算してください。\n21171191 素数とは、1とその数自身以外に約数を持たない自然数のことです。ある数 i が素数かどうかは、2から i の平方根までの数で割り切れるかどうかで判定できます。\nsum_num = 0 for i in range(2, 20001): for j in range(2, int(i ** 0.5) + 1): if i % j == 0: break else: sum_num += i print(sum_num) 数字を連続で入力してカウントしよう # ユーザーから10回数を入力し、同じ数が連続で入力された回数をカウントしてください。\n10回連続なら perfect!! と表示しましょう。\n数字を入力してください: 1 連続なし 数字を入力してください: 1 2回連続 数字を入力してください: 1 3回連続 ... 1つ前の入力値を prev のような変数に保存しておくことで、現在の入力値と比較して連続しているかどうかを判定できます。\nprev = None count = 1 for i in range(10): num = int(input(\u0026#34;数字を入力してください: \u0026#34;)) if num == prev: count += 1 print(\u0026#34;{}回連続\u0026#34;.format(count)) if count == 10: print(\u0026#34;perfect!!\u0026#34;) else: count = 1 print(\u0026#34;連続なし\u0026#34;) prev = num 数字の中に「5」があるか探そう # 入力された数字を1桁ずつ調べて「5」が含まれるかを出力してください。\n12345 5じゃないです 5じゃないです 5じゃないです 5じゃないです 5です!! input() で受け取った値は文字列なので、for ループで1文字ずつ取り出して調べることができます。\nx = input(\u0026#34;数字を入力してください: \u0026#34;) for i in x: if i == \u0026#34;5\u0026#34;: print(\u0026#34;5です!!\u0026#34;) else: print(\u0026#34;5じゃないです\u0026#34;) 足し算と引き算をしてみよう # 2つの数字を入力し、足し算と引き算の結果を出力してください。\n1つ目の数字: 4 2つ目の数字: 2 足し算の合計 6 引き算の合計 2 input() で受け取った文字列を int() で整数に変換し、+ と - の演算子を使って計算します。\nx = int(input(\u0026#34;1つ目の数字: \u0026#34;)) y = int(input(\u0026#34;2つ目の数字: \u0026#34;)) print(\u0026#34;足し算の合計\u0026#34;, x + y) print(\u0026#34;引き算の合計\u0026#34;, x - y) 九九の表を作ろう # 九九を「式と答え」をセットで表示してください。\n1 x 1 = 1 1 x 2 = 2 ... 9 x 9 = 81 二重の for ループを使い、print() 関数で式と答えを整形して出力します。\nfor i in range(1, 10): for j in range(1, 10): print(i, \u0026#34;x\u0026#34;, j, \u0026#34;=\u0026#34;, i * j) 正方形を描こう # 入力された大きさの正方形を「*」で描きましょう。\n# 5の場合 ***** * * * * * * ***** for ループの中で if 文を使い、最初の行と最後の行、それ以外の行で処理を分けることで、中が空洞の図形を描くことができます。\nh = int(input(\u0026#34;数字を入力してください: \u0026#34;)) for i in range(h): if i == 0 or i == h - 1: print(\u0026#34;*\u0026#34; * h) else: print(\u0026#34;*\u0026#34; + \u0026#34; \u0026#34; * (h - 2) + \u0026#34;*\u0026#34;) フィボナッチ数列を出力しよう # 10000未満のフィボナッチ数列を出力してください。\n0 1 1 2 3 5 8 ... 6765 フィボナッチ数列は、前の2つの項の和が次の項になる数列です。a, b = b, a + b のように値を更新していくことで、数列を生成できます。\na, b = 0, 1 while a \u0026lt; 10000: print(a, end=\u0026#34; \u0026#34;) a, b = b, a + b print() 2つの素数判定 # ユーザーから入力した2つの数字が両方とも素数なら True、そうでなければ False と出力してください。\n1つ目の数字を入力してください: 7 2つ目の数字を入力してください: 11 True 素数判定のロジックを is_prime という関数にまとめることで、同じ処理を何度も書く必要がなくなり、コードが読みやすくなります。\ndef is_prime(n): if n \u0026lt;= 1: return False for i in range(2, int(n ** 0.5) + 1): if n % i == 0: return False return True num1 = int(input(\u0026#34;1つ目の数字を入力してください: \u0026#34;)) num2 = int(input(\u0026#34;2つ目の数字を入力してください: \u0026#34;)) print(is_prime(num1) and is_prime(num2)) バブルソートに挑戦！ # 整数リストを引数に取り、バブルソートで昇順に並べ替える関数を作りましょう。\n関数にリストを渡して、ソート前とソート後を表示してください。\n[5, 3, 8, 1, 9] =\u0026gt; [1, 3, 5, 8, 9] バブルソートは、隣り合う要素を比較して入れ替えながら、リスト全体を整列させるアルゴリズムです。\ndef bubble_sort(data): for i in range(len(data) - 1): for j in range(len(data) - i - 1): if data[j] \u0026gt; data[j + 1]: data[j], data[j + 1] = data[j + 1], data[j] return data data = [5, 3, 8, 1, 9] print(f\u0026#34;{data} =\u0026gt; {bubble_sort(data.copy())}\u0026#34;) ","date":"2025年 9月 7日","externalUrl":null,"permalink":"/scraps/1757227129_python-practice2/","section":"スクラップ","summary":"","title":"Python基礎ハンズオン","type":"scraps"},{"content":" はじめに # Pythonは、初心者にも学びやすく、かつ実用性の高いプログラミング言語です。データ分析、Web開発、機械学習など幅広い分野で活用されており、プログラミングの基礎を身につける最初の言語として最適です。\n以下に、Python基本文法の実践的な練習問題をハンズオン形式で説明します。\n文字の連結 # + 演算子を使用して、文字列同士を連結することができます。\nname = \u0026#34;Taro\u0026#34; greeting = \u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34; print(greeting) 変数 # 変数に値を代入し、その変数を使って計算を行うことができます。\napples = 3 oranges = 5 total = apples + oranges print(total) print() 関数 # print() 関数は、括弧内の値や文字列を画面に出力します。\nprint(\u0026#34;Pythonを学習中\u0026#34;) input() 関数 # input() 関数は、ユーザーからのキーボード入力を受け取り、その値を返します。\nname = input(\u0026#34;あなたの名前は？: \u0026#34;) print(\u0026#34;こんにちは \u0026#34; + name + \u0026#34; さん\u0026#34;) 論理演算子 # and や or などの論理演算子を使って、複数の条件を組み合わせることができます。\nage = int(input(\u0026#34;年齢を入力してください: \u0026#34;)) if age \u0026gt;= 20 and age \u0026lt; 30: print(\u0026#34;20代です\u0026#34;) else: print(\u0026#34;20代ではありません\u0026#34;) if文 # if 文を使うと、条件が真の場合に特定の処理を実行できます。else を使うと、条件が偽の場合の処理も記述できます。\nscore = int(input(\u0026#34;点数を入力してください: \u0026#34;)) if score \u0026gt;= 60: print(\u0026#34;合格\u0026#34;) else: print(\u0026#34;不合格\u0026#34;) 配列（リスト） # リスト（配列）は、複数の値をまとめて格納できるデータ型です。sum() で合計、len() で要素数を取得できます。\nnumbers = [10, 20, 30, 40] average = sum(numbers) / len(numbers) print(\u0026#34;平均:\u0026#34;, average) 繰り返し（for） # for ループは、指定した回数だけ処理を繰り返します。range() 関数と組み合わせて使うことが多いです。\nfor i in range(1, 6): print(i) 繰り返し（while） # while ループは、指定した条件が真である間、処理を繰り返します。\nnum = int(input(\u0026#34;数を入力してください(0で終了): \u0026#34;)) while num != 0: print(\u0026#34;入力された数:\u0026#34;, num) num = int(input(\u0026#34;数を入力してください(0で終了): \u0026#34;)) ","date":"2025年 9月 7日","externalUrl":null,"permalink":"/scraps/1757222743_python-practice/","section":"スクラップ","summary":"","title":"Python入門ハンズオン","type":"scraps"},{"content":" requirements.txtとは # requirements.txtはPythonプロジェクトで使用しているパッケージ名とバージョンを記述したテキストファイルです。 「requirements」は英語で「要件」や「必要条件」を意味します。\nrequirements.txtの書き方 # # パッケージ名のみ記述すると、その時点での最新版がインストールされます requests numpy pandas # バージョンを指定する場合は「==」で完全一致、「\u0026gt;=」「\u0026lt;」などで範囲を指定します Flask==3.0.3 SQLAlchemy\u0026gt;=2.0.0,\u0026lt;3.0.0 requirements.txtを実行するコマンド # # 既存の環境からrequirements.txtを作成する場合、pipのfreezeコマンドを使用 pip freeze \u0026gt; requirements.txt # requirements.txtからパッケージをインストール pip install -r requirements.txt 参考リンク # エンべーダー：requirements.txtの使い方 ","date":"2025年 9月 7日","externalUrl":null,"permalink":"/scraps/1757214539_study-requirements/","section":"スクラップ","summary":"","title":"requirements.txt入門","type":"scraps"},{"content":" virtualenvとは？ # virtualenvは、Pythonで複数の仮想環境を作成・管理できるツールです。これにより、異なるアプリやプロジェクトごとにパッケージ・バージョンの設定を分離できます\nPythonにおける仮想環境とは？ # 仮想環境とは、一時的・独立したPythonの実行環境です。これを使うことで、システムのPython設定に影響を与えず、個別にパッケージ導入や、Pythonバージョンの切替ができます。\nvenvとvirtualenvの違い # venvはPython3.3以降で標準搭載されている機能ですが、Python本体のバージョン管理はできません。\nvirtualenvは、仮想環境ごとに異なるPythonバージョンを指定して管理可能です。これにより、特定の旧バージョンPythonでの動作検証など柔軟に対応できます。\nvirtualenvのinstall # # virtualenvは標準ではインストールされていないため、pipで導入が必要 sudo pip install virtualenv virtualenvコマンドで新しい環境の作成 # # プロジェクト用ディレクトリを準備 mkdir プロジェクトディレクトリ名 cd プロジェクトディレクトリ名 # 通常の仮想環境作成 python3 -m virtualenv 仮想環境名 # 特定バージョンのPythonを指定する場合（要事前インストール） python3 -m virtualenv -p 利用したいPythonのバージョン(例: python3.6) 環境名 仮想環境の起動(activate)・停止(deactivate) # # 仮想環境を有効化 source 仮想環境名/bin/activate # コマンドライン先頭に(仮想環境名)が表示されたら正常起動 # 仮想環境を終了 deactivate # (仮想環境名)表示が消えたら仮想環境解除 参考リンク # エンべーダー：venvの使い方\n","date":"2025年 9月 7日","externalUrl":null,"permalink":"/scraps/1757212175_study-virtualenv/","section":"スクラップ","summary":"","title":"virtualenv入門","type":"scraps"},{"content":" 書籍情報 # 項目 説明 書籍名 「指示通り」ができない人たち 著者 榎本博明 発行年 2024/03/08 出版社 株式会社日経BP 購入の経緯 # 日々の業務における自身の課題を省みた際、ソフトスキル、特に非認知能力の低さを改善する必要があると感じていました。本書がそのヒントになると考え、購入に至りました。\n本書の要点と構成 # 本書は、「指示通り」に業務を遂行できない人々を以下の3つのタイプに分類し、それぞれのケースと原因、改善策を解説しています。\n認知能力に課題がある人 メタ認知能力に課題がある人 非認知能力に課題がある人 改善策の柱として、「読書」 や 「文章の要約」 を通じて読解力を鍛えることが提言されています。また、関連書籍としてダニエル・ゴールドマンの 『EQ こころの知能指数』 も紹介されており、感情的知性の重要性にも触れられています。\nこのメモでは、本書の中から特に自身が共感した、あるいは興味を引かれたケースを抽出し、その内容と改善策をまとめ、今後の自身の行動計画へと繋げます。\n特に印象に残ったケースと考察 # 1. 認知能力：パニックに弱い人 # 複数のタスクを同時に振られると混乱してしまうケースです。本書では、これはワーキングメモリの容量が少ないことが一因であると解説されています。\n【改善策】 タスクの優先順位を都度明確にし、一つの作業に集中する環境を意識的に作ることが有効です。\n2. メタ認知能力：同じミスを繰り返す人 # 過去の指摘を忘れてしまい、同様の失敗を繰り返すケースです。これは、単なる記憶力の問題だけでなく、自身の行動を客観視できていないことに起因します。\n【改善策】 指摘されたことをその場でメモに取る、一日の終わりに日記などで自身の行動を振り返るなど、内省を習慣化することが重要です。\n3. 非認知能力：能力は高いが、対人関係が苦手な人 # 業務遂行能力や知識は豊富であるにもかかわらず、顧客との交渉など対人関係に強い不安を感じ、キャリアの機会を逃してしまうケースです。\n【改善策】 本書では、この「対人不安」は多くの人が抱える普遍的な感情であると指摘しています。まずはその事実を受け入れ、小さな成功体験を積むことで、徐々に不安を克服していくことが推奨されています。\nまとめと今後の行動 # 本書で紹介されている様々なケースの根底には、「読解力」「内省する力」「他者と関わる力（EQ）」の不足があると感じました。そして、これらの能力は、日々の意識とトレーニングによって改善可能であると述べられています。\n具体的なトレーニング方法として、\n読書と要約: 平易な文章からで良いので、内容を要約する習慣をつけることで読解力を養う。 日々の内省: 日記やメモを活用し、自身の行動や感情を客観的に振り返る。 コミュニケーション: 他者との対話を通じて、感情的知性（EQ）を高める。 といったアプローチが紹介されていました。\nこれらの提言を踏まえ、私自身もまずは 「読書メモの作成」 と 「日記による日々の振り返り」 を継続的に実践し、自身の課題改善に繋げていこうと考えています。\n","date":"2025年 9月 7日","externalUrl":null,"permalink":"/scraps/1757209426_memo-sijidourigadekinai/","section":"スクラップ","summary":"","title":"【書評】指示通りができない人たち","type":"scraps"},{"content":"","date":"2025年 9月 7日","externalUrl":null,"permalink":"/tags/%E8%AA%AD%E6%9B%B8%E3%83%A1%E3%83%A2/","section":"Tags","summary":"","title":"読書メモ","type":"tags"},{"content":" pipとは何か？ # pipはPythonの公式パッケージ管理ツールで、Pythonコミュニティで広く採用されています。 Pythonの標準ライブラリに含まれているか、Python 3.4以降は ensurepip によって容易にインストールできるようになりました。 目的は、Pythonの外部モジュールやライブラリ（パッケージ）を簡単に導入し、依存関係も自動管理することです。 パッケージと依存関係の理解 # パッケージとは：\nPythonのコード・データを1つにまとめ配布できる単位。機能ごとに分かれている。 例：Web開発用のFlask、HTTP通信を助けるrequestsなど。 依存関係とは：\nあるパッケージが動作するために必要な、他のパッケージのこと。 例えばFlaskはWerkzeugやJinja2など使っているため、それらが事前にインストールされている必要がある。 pipは依存関係も自動的に解決し、必要なパッケージを連鎖的にインストールしてくれる。 仮想環境（venv）を使う理由 # システム全体に影響を与えず、プロジェクト単位でパッケージを管理できる。 依存関係の衝突を避け、異なるプロジェクトで別バージョンのパッケージを共存可能にする。 開発・テスト用のクリーンな環境を手軽に作られる。 mkdir my_project # プロジェクトディレクトリ作成 cd my_project python3 -m venv venv # 仮想環境作成 source venv/bin/activate # 仮想環境有効化 (Linux/macOS) # Windowsの場合 # venv\\Scripts\\activate.bat # cmd # または # venv\\Scripts\\Activate.ps1 # PowerShell pipの基本操作 # バージョン確認・インストール確認 # pip -V # pipのバージョンとPython環境を確認 もしpipがない場合や更新したい場合は、以下：\npython3 -m ensurepip --default-pip # pipをインストール pip install --upgrade pip # pipのアップグレード パッケージのインストール # pip install Flask # 最新版をインストール pip install Flask==2.3.3 # バージョン指定してインストール pip install \u0026#34;Flask\u0026gt;=2.2,\u0026lt;3.0\u0026#34; # 範囲指定インストール パッケージのアンインストール # pip uninstall Flask # パッケージ削除 インストール済みパッケージの確認 # ライブラリ一覧を見たい時は以下コマンドを使う。 pip list # パッケージとバージョンの一覧 pip freeze # requirements.txt形式でパッケージ＋バージョンを表示 pip freeze は環境の再現性を確保するのに役立つ。 パッケージの詳細情報 # pip show Flask # 表示される例: # Name: Flask # Version: 2.3.3 # Summary: A simple framework for building complex web applications. # Home-page: https://palletsprojects.com/p/flask/ # Author: Armin Ronacher # Author-email: armin.ronacher@active-4.com # License: BSD-3-Clause # Location: /path/to/venv/lib/python3.12/site-packages # Requires: Werkzeug, Jinja2 # Required-by: requirements.txt の利用 # 複数パッケージをまとめて管理・共有できるテキストファイル。 チーム開発やCI/CD環境での環境再現に必須。 # 現在の環境のパッケージをファイル化 pip freeze \u0026gt; requirements.txt # ファイルから環境を再現 pip install -r requirements.txt ベストプラクティス・注意点 # 仮想環境を必ず使う\nシステム環境に影響を与えず複数プロジェクトを管理できる\nバージョン固定を行い再現性を担保\nrequirements.txtやpip freezeを活用し、同じバージョンセットを共有・再利用する\nC拡張モジュールの依存に注意\nMySQLクライアントや画像処理ライブラリなどは、Python依存に加えシステム側にもライブラリが必要な場合がある。\npip のアップグレードを定期的に\nセキュリティやバグ修正、新機能のために最新版を利用する\nまとめ コマンド一覧（代表例） # コマンド 説明 pip install \u0026lt;pkg\u0026gt; パッケージを最新バージョンでインストール pip install \u0026lt;pkg\u0026gt;==\u0026lt;version\u0026gt; 指定バージョンでインストール pip uninstall \u0026lt;pkg\u0026gt; パッケージをアンインストール pip list インストール済みパッケージの一覧表示 pip freeze 環境再現用のrequirements.txt形式で一覧出力 pip show \u0026lt;pkg\u0026gt; パッケージの詳細情報（依存・場所など） pip install -r requirements.txt requirements.txtファイルに基づいて一括インストール pip install --upgrade pip pip自身のアップデート ","date":"2025年 9月 6日","externalUrl":null,"permalink":"/scraps/1757164345_study-pip/","section":"スクラップ","summary":"","title":"pipコマンド入門","type":"scraps"},{"content":" はじめに # venvは、Python 3.3から標準ライブラリに加わった、仮想環境を管理するためのツールです。\nPythonで開発を行う際、プロジェクトごとに利用するパッケージのバージョンが異なることは珍しくありません。venvを使うと、プロジェクトごとに独立したPython環境を構築できます。これにより、他のプロジェクトやシステム全体に影響を与えることなく、パッケージのインストールやバージョン管理を安全に行うことができます。\nvenvの基本的な使い方 # 仮想環境を利用する基本的な流れは、「作成 → 有効化 → パッケージインストール → 無効化」となります。\n1. 仮想環境の作成 # まず、プロジェクト用のディレクトリを作成し、その中で仮想環境を構築します。\n# プロジェクトディレクトリを作成して移動 mkdir my_project cd my_project # 仮想環境を作成（慣習的に`venv`という名前が使われます） python3 -m venv venv 作成が完了すると、venvという名前のディレクトリができます。このディレクトリは、Gitなどのバージョン管理システムから除外するために、.gitignoreファイルにvenv/と追記しておくのが一般的です。\n2. 仮想環境の有効化（activate） # 作成した仮想環境は、有効化（activate）することで利用可能になります。コマンドはOSによって異なります。\nmacOS/Linux:\nsource venv/bin/activate Windows (コマンドプロンプト):\nvenv\\Scripts\\activate コマンドが成功すると、ターミナルのプロンプトの先頭に(venv)のように仮想環境名が表示されます。\n3. パッケージのインストール # 仮想環境が有効な状態でpipコマンドを使うと、その環境内にのみパッケージがインストールされます。\n# 例としてrequestsパッケージをインストール pip install requests # インストールされたパッケージを確認 pip list プロジェクトで利用するパッケージは、requirements.txtというファイルにまとめておくと便利です。\n# 現在の環境にインストールされているパッケージをファイルに出力 pip freeze \u0026gt; requirements.txt # requirements.txtからパッケージをまとめてインストール pip install -r requirements.txt 4. 仮想環境の無効化（deactivate） # 仮想環境での作業が終わったら、以下のコマンドで無効化（deactivate）します。\ndeactivate プロンプトの(venv)という表示が消え、元のターミナル環境に戻ります。\nvenvとvirtualenvの違い # venvが登場する前は、virtualenvというサードパーティ製のツールが広く使われていました。主な違いは以下の通りです。\nvenv: Python 3.3以降の標準機能。追加インストールは不要。 virtualenv: 別途インストールが必要 (pip install virtualenv)。venvよりも高機能な面もあるが、基本的な用途ではvenvで十分。 特別な理由がなければ、標準ライブラリであるvenvの使用が推奨されます。\n補足：Python自体のバージョンを管理したい場合 # venvはPythonのパッケージ環境を分離しますが、Python自体のバージョン（例: 3.9と3.10）を切り替えることはできません。複数のPythonバージョンを管理したい場合は、pyenvのような専用ツールの利用を検討してください。\n参考資料 # Python公式ドキュメント: venv — 仮想環境の作成 ","date":"2025年 9月 6日","externalUrl":null,"permalink":"/scraps/1757143715_study-venv/","section":"スクラップ","summary":"","title":"仮想環境venv入門","type":"scraps"},{"content":"","date":"2025年 9月 6日","externalUrl":null,"permalink":"/tags/github-pages/","section":"Tags","summary":"","title":"GitHub Pages","type":"tags"},{"content":"","date":"2025年 9月 6日","externalUrl":null,"permalink":"/tags/google-search-console/","section":"Tags","summary":"","title":"Google Search Console","type":"tags"},{"content":" はじめに # Hugo + Blowfishテーマで構築し、GitHub Pagesで公開したサイトをGoogle検索結果に表示させるための実践的な手順を解説します。この記事はSEOの基本から具体的な設定まで、初心者でも簡単に実施できるように構成されています。\n解決する課題 # 作成したサイトがGoogle検索結果に表示されない 検索エンジンがサイトを適切にクロールできていない Googleにサイトの存在を認識させる方法が分からない SEO対策の基本的な設定が不明 この記事で学べること # robots.txtの設定とSEOにおける重要性 Google Search Consoleの基本的な使い方 サイト所有権の確認方法とベストプラクティス インデックス登録の効率的な方法 対象読者 # HugoとBlowfishテーマでサイトを構築した方 GitHub Pagesでサイトをホスティングしている方 SEO対策を初めて行うWebサイト運営者 Google検索での可視性を向上させたいブロガー 前提条件 # サイト: Hugo + Blowfishテーマで構築 ホスティング: GitHub Pagesで公開済み アカウント: Googleアカウントが必要（Google Search Console用） 権限: サイトのソースコードへの編集権限 Google検索で表示させるための手順 # Step 0: 準備 - robots.txtの有効化 # 検索エンジンがサイトを適切にクロールできるよう、Hugo設定でrobots.txtの生成を有効化します：\nconfig/_default/hugo.toml\n# 検索エンジンのクロールを許可するrobots.txtを自動生成 enableRobotsTXT = true この設定により、サイトルートに「すべての検索エンジンがサイト全体をクロール可能」という内容のrobots.txtが自動生成されます。 Step 1: Google Search Consoleへのサイト登録 # Googleにサイトの存在を認識させるため、Google Search Consoleでサイトを登録します。\n1. Google Search Consoleへアクセス\nGoogle Search Consoleにアクセスし、Googleアカウントでログインします。\n2. プロパティの追加\nプロパティタイプ選択画面で「URLプレフィックス」を選択し、サイトURLを入力します：\nhttps://your-username.github.io/ # またはカスタムドメインの場合 https://yourdomain.com/ Step 2: サイト所有権の確認 # サイトの所有者であることをGoogleに証明します。\n1. 確認方法の選択\n複数の確認方法がありますが、Hugo + Blowfish環境では「HTMLタグ」方式が最も簡単です。表示されたメタタグをコピーします。\n2. メタタグのサイトへの追加\nBlowfishテーマでは、以下の手順でメタタグを追加します：\nlayouts/partials/extend-head.html ファイルを作成または編集：\n\u0026lt;!-- Google Search Console所有権確認用メタタグ --\u0026gt; \u0026lt;meta name=\u0026#34;google-site-verification\u0026#34; content=\u0026#34;コピーした確認コード\u0026#34; /\u0026gt; Blowfishテーマのextend-head.html機能を使用することで、サイト全ページの\u0026lt;head\u0026gt;セクションに自動的にタグが挿入されます。 3. サイトのデプロイと確認\nメタタグを追加した後は以下の手順で確認します：\n変更をGitHubにプッシュし、GitHub Pagesでデプロイを完了させる サイトが更新されたことを確認（ブラウザでアクセスしてチェック） Google Search Consoleに戻り「確認」ボタンをクリック 成功すると「所有権を確認しました」と表示されます。\nStep 3: インデックス登録リクエスト # サイトのGoogleインデックスへの登録をリクエストします。\n1. URL検査ツールの使用\nGoogle Search Consoleの左メニューから「URL検査」を選択 サイトのURLを入力して検索実行 検索結果画面で「インデックス登録をリクエスト」ボタンをクリック 2. リクエストの完了確認\n正常に完了すると上記のような確認メッセージが表示されます。\nStep 4: サイトマップの送信（推奨） # より効率的なクロールを実現するため、サイトマップを送信します。\n1. サイトマップのURL確認\nHugoではデフォルトでサイトマップが生成されます：\nhttps://your-site.com/sitemap.xml 2. Google Search Consoleでのサイトマップ送信\n左メニューの「サイトマップ」を選択 「新しいサイトマップの追加」にsitemap.xmlを入力 「送信」ボタンをクリック モニタリングと継続的な最適化 # インデックス状況の確認 # 1. カバレッジレポートの確認\n左メニューの「カバレッジ」からインデックス状況をモニタリングできます。\n2. パフォーマンスのチェック\n「検索パフォーマンス」でクリック数、表示回数、CTRなどを確認できます。\n新記事の継続的なインデックス登録 # 新しい記事を公開した場合の推奨ワークフロー：\n記事を公開し、GitHub Pagesでデプロイ完了 Google Search Consoleの「URL検査」で新記事URLをチェック 「インデックス登録をリクエスト」を実行 数日後にインデックス状況を確認 トラブルシューティング # よくある問題と解決法 # 問題1: 所有権の確認に失敗する\n原因: メタタグが正しく設置されていない 解決法: ブラウザのデベロッパーツールでHTMLソースを確認し、メタタグの存在をチェック 問題2: インデックス登録が進まない\n原因: robots.txtの設定ミス、サイトのアクセシビリティ問題 解決法: https://your-site.com/robots.txtにアクセスして内容を確認 問題3: サイトマップが読み込まれない\n原因: URLの記述ミス、サイトマップのアクセシビリティ問題 解決法: ブラウザでhttps://your-site.com/sitemap.xmlに直接アクセスしてチェック まとめ # Hugo + Blowfishで構築したサイトをGoogle検索に表示させるための手順を体系的に解説しました。\n主要ポイント # robots.txt有効化: 検索エンジンのクロールを許可 Google Search Console登録: サイトの存在をGoogleに通知 所有権確認: HTMLメタタグで簡単に実施 インデックスリクエスト: 能動的な登録申請 参考リンク # Google Search Console公式ヘルプ Blowfishテーマ公式ドキュメント - サイト設定 Hugo公式ドキュメント - SEO Google検索セントラル - SEOスターターガイド ","date":"2025年 9月 6日","externalUrl":null,"permalink":"/posts/1757130872_how-to-get-your-hugo+blowfish-website-indexed-by-google/","section":"投稿記事","summary":"","title":"Hugo+Blowfishで構築したサイトをGoogle検索に表示させる手順","type":"posts"},{"content":"","date":"2025年 9月 6日","externalUrl":null,"permalink":"/tags/seo/","section":"Tags","summary":"","title":"SEO","type":"tags"},{"content":"このセクションには、技術記事やチュートリアル、開発に関する記事などを投稿しています。\n","date":"2025年 9月 6日","externalUrl":null,"permalink":"/posts/","section":"投稿記事","summary":"","title":"投稿記事","type":"posts"},{"content":" はじめに # pyenvは、Pythonの複数のバージョンを簡単に切り替えて管理するためのツールです。プロジェクトごとに異なるPythonバージョンを利用したい場合や、システムのPythonに影響を与えずに開発を進めたい場合に非常に役立ちます。\n以下に、pyenvの主要な機能と実用的な活用方法を説明します。\nインストール手順 (Ubuntu) # 1. 依存関係のインストール # Pythonのビルドに必要なパッケージをあらかじめインストールします。\nsudo apt update sudo apt install build-essential libffi-dev libssl-dev zlib1g-dev liblzma-dev libbz2-dev libreadline-dev libsqlite3-dev tk-dev git ※参考記事：Ubuntuにpyenvをインストール\n2. pyenvのインストール # GitHubからpyenvのリポジトリをクローンします。\ngit clone https://github.com/pyenv/pyenv.git ~/.pyenv 3. 環境変数の設定（パスを通す） # ~/.bashrc（Zshの場合は ~/.zshrc）に以下の3行を追記します。\necho \u0026#39;export PYENV_ROOT=\u0026#34;$HOME/.pyenv\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;command -v pyenv \u0026gt;/dev/null || export PATH=\u0026#34;$PYENV_ROOT/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;eval \u0026#34;$(pyenv init -)\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 設定を反映させるため、ターミナルを再起動するか、source ~/.bashrc を実行します。\n基本的な使い方 # Pythonのインストール # # インストール可能なバージョンの一覧を表示 pyenv install --list # 指定したバージョンをインストール pyenv install 3.10.4 使用するPythonのバージョンを切り替える # pyenvでは、global と local の2つの方法でバージョンを指定できます。\nglobal: システム全体でデフォルトとして使用するバージョンを設定します。 local: 現在のディレクトリ（プロジェクト）でのみ有効なバージョンを設定します。 # インストール済みのバージョン一覧を確認 pyenv versions # 全体で使うバージョンを設定 pyenv global 3.10.4 # 現在のディレクトリで使うバージョンを設定（.python-versionファイルが作成される） pyenv local 3.9.13 Pythonのアンインストール # pyenv uninstall 3.10.4 pyenvのアップデート # 方法1: pyenv-updateプラグインを使う # pyenv-updateというプラグインを導入すると、pyenv updateコマンドで簡単に更新できます。\n# 1. プラグインをインストール（初回のみ） git clone https://github.com/pyenv/pyenv-update.git $(pyenv root)/plugins/pyenv-update # 2. pyenvをアップデート pyenv update 方法2: gitで直接アップデートする # pyenv本体はgitリポジトリなので、git pullで直接更新することも可能です。\ncd $(pyenv root) git pull インストール時のトラブルシューティング # pyenv install 時にエラーが出た場合の対処法です。多くは依存パッケージ不足が原因です。\nconfigure: error: no acceptable C compiler found in $PATH # Cコンパイラが見つからないエラーです。build-essentialをインストールします。\nsudo apt install build-essential zipimport.ZipImportError: can't decompress data; zlib not available # zlibライブラリがないエラーです。zlib1g-devをインストールします。\nsudo apt install zlib1g-dev ","date":"2025年 9月 4日","externalUrl":null,"permalink":"/scraps/1756984928_study-pyenv/","section":"スクラップ","summary":"","title":"pyenvでPythonバージョン管理｜インストールから切り替えまで","type":"scraps"},{"content":" はじめに # python用の勉強メモをスクラップとしてまとめます。\nPythonとは # Pythonは1991年に開発された、シンプルで読みやすい文法が特徴のプログラミング言語です。\nインデント（字下げ）でコードのブロックを表現することが大きな特徴です。 文法が比較的シンプルなため、プログラミング初心者でも学習しやすい言語と言われています。 近年では、AI開発や機械学習、データ分析などの分野で特に広く活用されています。 Pythonのインストール方法（Linux/Debian系） # Linux（DebianやUbuntuなど）環境でPython3をインストールする手順です。\nsudo apt update sudo apt install -y python3 コマンドの解説\nsudo apt update: インストール可能なパッケージのリストを最新の状態に更新します。 sudo apt install -y python3: Python3をインストールします。 -yオプションは、インストール中の確認メッセージに対して自動的に「Yes」と回答するためのものです。 インストール後の確認 # インストールが正常に完了したかを確認するには、ターミナルで以下のコマンドを実行します。\npython3 --version 次のように、インストールされたPythonのバージョンが表示されれば成功です。\nPython 3.x.x ※ x.xの部分には、インストールされたバージョン番号が表示されます。\nPythonの対話モード # Pythonのプログラムを実行するには、主に2つの方法があります。\n対話モード: ターミナルで直接コードを一行ずつ入力して実行する方法。 スクリプト実行: .pyファイルにコードを記述し、そのファイルを一括で実行する方法。 対話モードは、ターミナルでpython3コマンドを実行すると開始できます。コードを試したり、簡単な計算をしたりするのに便利です。\n$ python3 Python 3.x.x (default, ... Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; print(\u0026#34;Hello, Python!\u0026#34;) Hello, Python! \u0026gt;\u0026gt;\u0026gt; 対話モードを終了するには、exit()と入力するか、Ctrl + Dを押します。\n関数 (Functions) # 関数は、特定の処理をひとまとめにしたものです。同じ処理を何度も書きたいときに便利です。\ndef 関数名(引数): # ここに処理を書く return 戻り 引数 (argument): 関数に渡す値。 戻り値 (return value): 関数の処理結果として返される値。 例：あいさつする関数 # def greet(name): \u0026#34;\u0026#34;\u0026#34;名前を受け取って、あいさつのメッセージを返す関数\u0026#34;\u0026#34;\u0026#34; message = f\u0026#34;こんにちは、{name}さん！\u0026#34; return message # 関数を呼び出して、戻り値を変数に受け取る greeting = greet(\u0026#34;山田\u0026#34;) print(greeting) # 出力: こんにちは、山田さん！ 練習問題 # 2つの数値を受け取り、その積（掛け算の結果）を返す multiply という名前の関数を作成してください。 その後、その関数を使って 5 と 8 の積を計算し、結果をコンソールに出力してください。\n# 2つの数値の積を返す関数 def multiply(num1, num2): return num1 * num2 # 関数を呼び出して結果を計算 result = multiply(5, 8) print(f\u0026#34;5と8の積は {result} です。\u0026#34;) # 出力: 5と8の積は 40 です。 クラス (Classes) # クラスは、オブジェクトの「設計図」です。データ（属性）と処理（メソッド）を一つにまとめることができます。\nclass クラス名: # コンストラクタ (初期化メソッド) def __init__(self, 引数): self.インスタンス変数 = 引数 # メソッド def メソッド名(self): # 処理 return self.インスタンス変数 インスタンス: クラス（設計図）から作られた実体のこと。 __init__: インスタンスが作られるときに最初に呼ばれる特別なメソッド。 self: インスタンス自身を指す特別な変数。 例：人物を表すクラス # class Person: def __init__(self, name, age): self.name = name # 属性 (インスタンス変数) self.age = age def introduce(self): # メソッド return f\u0026#34;私の名前は{self.name}、{self.age}歳です。\u0026#34; # Personクラスから「インスタンス」を作成 person1 = Person(\u0026#34;鈴木\u0026#34;, 25) # 属性やメソッドを使う print(person1.name) print(person1.introduce()) # 出力: # 鈴木 # 私の名前は鈴木、25歳です。 練習問題 # Dog というクラスを作成してください。\n__init__ メソッドで犬の名前(name)を受け取り、インスタンス変数に設定してください。 bark というメソッドを定義し、呼び出されると「(名前)はワン！と鳴いた」という文字列を返すようにしてください。 その後、Dog クラスから \u0026ldquo;ポチ\u0026rdquo; という名前のインスタンスを作成し、bark メソッドを呼び出して結果を出力してください。\nclass Dog: def __init__(self, name): self.name = name def bark(self): return f\u0026#34;{self.name}はワン！と鳴いた\u0026#34; # インスタンスを作成 my_dog = Dog(\u0026#34;ポチ\u0026#34;) # メソッドを呼び出し message = my_dog.bark() print(message) # 出力: ポチはワン！と鳴いた モジュールとインポート (Modules \u0026amp; Import) # モジュールは、関数やクラスをまとめたPythonファイル（.pyファイル）のことです。他のファイルから再利用できます。\nモジュールの作成 # 例えば、utils.py という名前で以下のファイルを作成したとします。\nPI = 3.14159 def circle_area(radius): \u0026#34;\u0026#34;\u0026#34;円の面積を計算する\u0026#34;\u0026#34;\u0026#34; return PI * (radius ** 2) モジュールの利用 (インポート) # 同じディレクトリにある別のファイル (main.pyなど) から、utils.py の中身をインポートして使えます。\nimport utils # utilsモジュールの中の変数や関数を使う radius = 5 area = utils.circle_area(radius) print(f\u0026#34;半径{radius}の円の面積は {area} です。\u0026#34;) print(f\u0026#34;円周率は {utils.PI} です。\u0026#34;) 練習問題 # string_utils.py というモジュールがあると仮定します。このモジュールには、文字列を逆にする reverse という関数が定義されています。\ndef reverse(text): return text[::-1] from ... import ... 構文を使って string_utils モジュールから reverse 関数だけをインポートし、\u0026quot;hello\u0026quot; という文字列を逆にして出力してください。\n# string_utils から reverse 関数だけをインポート from string_utils import reverse # インポートした関数を直接使える reversed_text = reverse(\u0026#34;hello\u0026#34;) print(reversed_text) # 出力: olleh 参考リンク # ゼロからのPython入門講座 Python チュートリアル ","date":"2025年 9月 3日","externalUrl":null,"permalink":"/scraps/1756853577_styudy-python/","section":"スクラップ","summary":"","title":"Python概要とインストールなど","type":"scraps"},{"content":" はじめに # NumPyは、Pythonで科学技術計算を効率的に行うためのコアライブラリです。特に、多次元配列（ndarray）を高速に扱うための機能が豊富に用意されており、データ分析や機械学習の分野で必須のツールとなっています。\n以下に、NumPyの基本的な使い方から応用的な内容まで、実用的な活用方法を解説とコード例付きで説明します。\nインストールとインポート # インストール # まず、NumPyライブラリをインストールします。ターミナルで以下のコマンドを実行してください。\npip install numpy インポート # Pythonスクリプト内でNumPyを使うには、import文を記述します。慣例として np という別名を付けてインポートするのが一般的です。\nimport numpy as np 基本的な使い方 # 1. 配列 (ndarray) の作成 # NumPyの基本は ndarray オブジェクトです。様々な方法で配列を作成できます。\n目的 コード例 解説 リストから作成 np.array([1, 2, 3]) Pythonのリストやタプルを元にNumPy配列を作成します。 連番配列の作成 np.arange(0, 10, 2) range関数のように、指定した範囲とステップで要素を生成します (この例では [0, 2, 4, 6, 8])。 ゼロ行列 np.zeros((2, 3)) すべての要素が 0 の配列を生成します。形状をタプルで指定します (この例では2行3列)。 全要素が1の行列 np.ones((3, 2)) すべての要素が 1 の配列を生成します。 単位行列 np.eye(3) 対角成分が 1 で、それ以外が 0 の正方行列（単位行列）を生成します (この例では3x3)。 コード例:\n# Pythonのリストから2次元配列を作成 arr2d = np.array([[1, 2, 3], [4, 5, 6]]) print(arr2d) #=\u0026gt; [[1 2 3] # [4 5 6]] # 0から9までの整数の配列を作成 range_arr = np.arange(10) print(range_arr) #=\u0026gt; [0 1 2 3 4 5 6 7 8 9] 2. 配列の基本情報 # 配列がどのようなものかを確認するための属性です。\narr = np.array([[1, 2, 3], [4, 5, 6]]) を例とします。\n属性 コード 結果 解説 形状 (Shape) arr.shape (2, 3) 配列の各次元の要素数をタプルで返します (行数, 列数)。 次元数 (Dimensions) arr.ndim 2 配列の次元の数を返します。 要素数 (Size) arr.size 6 配列に含まれる全要素の数を返します。 データ型 (Data Type) arr.dtype int64 配列の要素のデータ型を返します。 3. インデックスとスライシング # 配列から特定の要素や部分を取り出す操作です。\na = np.arange(10) B = np.array([[1,2,3],[4,5,6],[7,8,9]]) を例とします。\n目的 コード例 解説 要素へのアクセス a[3]B[1, 2] インデックスを指定して要素を取得します。B[1, 2]は2行目・3列目の要素 6 を返します。 スライシング a[2:5] [start:stop] の形式で、指定した範囲の要素を抽出します (この例ではインデックス2から4まで)。 逆順 a[::-1] 配列の要素を逆順にします。 行・列の抽出 B[0, :]B[:, 1] : はその軸のすべての要素を意味します。B[0, :]は1行目全体、B[:, 1]は2列目全体を抽出します。 部分行列の抽出 B[1:, 1:] 2行目以降、かつ2列目以降の要素を抽出します。 4. 配列の操作 # 目的 コード例 解説 形状変更 arr.reshape(3, 2) 要素数を変えずに配列の形状を変更します。 転置 arr.T 行と列を入れ替えた配列を返します。 垂直結合 np.vstack((arr1, arr2)) 2つの配列を垂直（行）方向に結合します。 水平結合 np.hstack((arr1, arr2)) 2つの配列を水平（列）方向に結合します。 垂直分割 np.vsplit(arr, 2) 配列を垂直方向に指定した数に分割します。 水平分割 np.hsplit(arr, 2) 配列を水平方向に指定した数に分割します。 コード例:\ne = np.arange(12) #=\u0026gt; [0, 1, ..., 11] reshaped_e = e.reshape(3, 4) print(reshaped_e) #=\u0026gt; [[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11]] print(reshaped_e.T) # 転置 #=\u0026gt; [[ 0 4 8] # [ 1 5 9] # [ 2 6 10] # [ 3 7 11]] 5. 配列の演算 # 基本的な演算 # a = np.array([[1, 2], [3, 4]]), b = np.array([[5, 6], [7, 8]]) を例とします。\n目的 演算子 関数 解説 要素ごとの加減乗除 +, -, *, / - 同じ位置にある要素同士で計算が行われます。 行列積 @ np.dot(a, b) 数学的な行列の積を計算します。 スカラー倍 * - a * 3 のように、配列の全要素を定数倍します。 ブロードキャスト # 形状が異なる配列同士の演算でも、NumPyが自動的に形状を拡張して計算する機能です。\narr = np.array([[1, 2, 3], [4, 5, 6]]) scalar = np.array([10, 20, 30]) # arr(2x3)とscalar(1x3)の加算 # scalarがarrの各行に対して加算される result = arr + scalar print(result) #=\u0026gt; [[11 22 33] # [14 25 36]] 実践的な使い方 # 数学・統計関数 # 統計関数 # data = np.array([[2, 4, 6], [-1, 5, -3]]) を例とします。\n目的 コード例 解説 最大値 data.max() 全要素の中での最大値を返します。 最小値 data.min() 全要素の中での最小値を返します。 合計 data.sum() 全要素の合計を返します。 平均 data.mean() 全要素の平均値を返します。 分散 data.var() 全要素の分散を返します。 標準偏差 data.std() 全要素の標準偏差を返します。 軸(axis)の指定: axis引数を指定することで、行ごとや列ごとの計算が可能です。\naxis=0: 列方向の計算（各列での集計） axis=1: 行方向の計算（各行での集計） # 列ごとの合計 print(data.sum(axis=0)) #=\u0026gt; [1 9 3] # 行ごとの最小値 print(data.min(axis=1)) #=\u0026gt; [2 -3] ユニバーサル関数 (UFuncs) # 配列の各要素に対して数学的な関数を適用します。\n目的 コード例 平方根 np.sqrt(arr) 指数関数 np.exp(arr) 三角関数 np.sin(arr), np.cos(arr) 線形代数 # np.linalg モジュールには線形代数関連の関数が含まれています。\n目的 コード例 行列式 np.linalg.det(matrix) 逆行列 np.linalg.inv(matrix) 固有値・固有ベクトル np.linalg.eig(matrix) 参考リンク # 【NumPy徹底講座】この動画1本で数値計算に特化したPythonライブラリNumPyの基礎をマスター！ ","date":"2025年 9月 1日","externalUrl":null,"permalink":"/scraps/1756683405_study-numpy/","section":"スクラップ","summary":"","title":"NumPy入門","type":"scraps"},{"content":" 書籍情報 # 項目 説明 書籍名 TAKE NOTES!――メモで、あなただけのアウトプットが自然にできるようになる 著者 ズンク・アーレンス 翻訳 二木 夢子 発行年 2021/10/14 出版社 日経BP 参考リンク 出版社ページ 購入の経緯 # 質の高い勉強メモを作成するために、いわゆる「メモ術」を学ぼうと思い、この本に出会いました。各チャプターごとに内容をスクラップメモとして整理しながら学習していきます。\nはじめに # 『Take Notes!』では、日常的に「質の高いメモ」を蓄積することで、誰もが効率良く、かつ高品質なアウトプットを継続的に生み出せると説かれています。何もないところから考えを生み出すのは容易ではありませんが、日々積み重ねたメモは新たな発想や深い思考の支えとなります。こうした成果を安定して生み出すためには、偶発的な意志力だけに依存せず、システムやルールとしてメモ術を整えることが効果的です。本書は、知的生産を助ける「賢いメモ」を日常的に書き溜めていくことの価値を提案しています。\n章別要点まとめ # 第1章: 「メモのとり方」を知れば、大作が自然に書ける # 第1章では「メモの有効性」と「ツェッテルカステン（Zettelkasten）」の考え方が紹介されている。\n文章執筆にはいくつかのハードルがある：\n計画通りに筆が進まずモチベーションを失ってしまう 情報収集に力を入れすぎて理想が高くなりすぎる 「自分には能力が足りないのでは」と感じるインポスター症候群に陥る こうした課題を乗り越え、質の高いアウトプットにつなげる解決策として提案されているのが**「日常的にメモを取る」**という習慣である。\nその具体的な実践法として、社会学者ニクラス・ルーマンが実践した「ツェッテルカステン」が紹介される。この方法では、小さな単位のメモを作り、それらを相互にリンクさせていく。そのつながりが新たな文脈や洞察を生み、結果として効率的かつ創造的にアイデアを発展させることができる。\n第2章: メモをとればとるほど、財産になる # 第2章では、「メモを蓄積して運用する方法」が解説されている。 自分の言葉で書き直しながらメモを作成することで、思考を整理でき、知識やアイデアをより深く理解できるようになる。\nツェッテルカステンにおけるメモの処理フロー:\n走り書きメモ・文献メモ: 日常で浮かんだアイデアや考えを一時的に記録する。読書や記事から得た情報を要約して残す。 永久保存メモの作成: これらを基に、自分の言葉で再構成した「永久保存メモ」を作成する。これは一つひとつが独立した知識単位となり、今後も再利用できる。 メモの関連づけ: 永久保存メモを、既存のメモと関連づける。番号やリンクを用いて結びつけ、ネットワークとしての知識体系を育てる。 アウトプットへの展開: メモが十分に育った段階で、アウトプット（文章や研究など）につなげていく。 このようにしてメモを日常的に運用していけば、単なる情報の収集にとどまらず、体系的な知識の基盤を築くことができる。\n第3章・第4章: 必要なのはシンプルに「ペン」と「紙」/「メモ」はあなたオリジナルの「思考」を生む魔法のツール # ツェッテルカステンに必要なのはペンと紙。ツールはシンプルで問題ない メモは貯めるだけでは不十分で活用するためのルールやシステムが必要 第5章: メモをとれば、書くことではなく、思考に集中できる # アウトプット前提のインプットが重要。アウトプット前提でインプットすることを意識すれば、情報に対する姿勢が変わる。\n第6章: メモをとるときは、つながりを意識する # メモは単に貯めただけでは知識として機能しない。全体を振り返って関係性を探り、メモ同士の関連や優先度を整理することで、質の高い洞察へと至る。こうした整理の過程そのものが、理解を促進する重要なステップとなる。\n第7章: メモをとれば、オリジナルのテーマと資料が自然に揃う # メモを書いて、自分のアイデアを貯めていけば、自然と自分の興味を持つテーマが決まる。\n第8章: メモをがあれば、大作も書ける # フィードバックや批評はアイデアをレベルアップさせるために必要 フィードバックなしでは特定の主張に偏る可能性が高くなる 第10章: 読書メモは、自分の言葉で書こう # 文献や書籍を読んだ内容は「自分の言葉」に言い換えて書き留める 自分の言葉で言い換えができなければ、理解不足と判断できる まとめと今後の行動 # 本書のテーマは「ツェッテルカステン」というシステムに基づいてメモを蓄積すれば、質の高いアウトプットが可能になる、というものです。\n内容を一言でまとめるなら、「メモに関する自己啓発書」です。ツェッテルカステンをはじめ、メモ術に関する知識やエピソードが紹介されており、モチベーションを高めたり、考え方の指針を得るには役立ちます。ただし、同じ趣旨の説明が繰り返される印象もあり、体系的にメモ術を学びたい人には少し物足りないかもしれません。\nまた、具体的なハウツーが詳細に整理されているわけではないので、「操作マニュアルとして読む」よりも、「メモの意義や可能性を再確認し、刺激を受けるために読む」ことに向いていると感じました。\n今後の行動:\n日常的なメモ取りの習慣を確立する メモ間のつながりを意識した整理方法を実践する アウトプット前提でのインプットを心がける 自分の言葉での言い換えを徹底する ","date":"2025年 8月 19日","externalUrl":null,"permalink":"/scraps/1755557154_memo-take-notes/","section":"スクラップ","summary":"","title":"【書評】TAKE NOTES! ","type":"scraps"},{"content":" はじめに # Voicemeeterは、Windowsでパソコン内部音声を高品質で録音するための強力なツールです。この記事では、Voicemeeterのインストールから設定、実際の録音までの手順を詳しく解説します。\n解決する課題 # Windowsの標準機能ではPC内部音声の録音が困難 オンラインミーティングやシステム音声をクリアに録音したい 複雑な音声ルーティングをシンプルに管理したい この記事で学べること # Voicemeeterの基本的な設定方法 PC内部音声の録音手順 仮想オーディオデバイスの活用方法 対象読者 # Windows環境でPC内部音声を録音したい方 オンラインミーティングの録音を行いたい方 Voicemeeterを初めて使用する方 オンラインミーティングを録音する場合は必ず参加メンバーの許可を取ってから録音してください。 Voicemeeterについて公式サイトの説明：\nVoicemeeter は、任意のオーディオデバイスやアプリケーションから、またはそれらへのあらゆる音声ソースをミックス・管理するために、仮想入出力（Virtual I/O）として機能する仮想オーディオデバイスを備えたオーディオミキサーアプリケーションです。\nハンズオン # Step 0: 準備 # Voicemeeterを使用するための環境を整備します。\n必要な条件:\nWindows 7以降のOS 管理者権限でのインストール インストール後の再起動 Step 1: Voicemeeterの入手とインストール # VB=AUDIO softwareからVoicemeeterをダウンロード 管理者権限でvoicemeetersetupをインストール PCを再起動 Step 2: Voicemeeterのセットアップ # 1. 出力デバイスの設定\nWindowsの「サウンド」設定で出力デバイスを設定します：\n2. 入力デバイスの設定\nWindowsの「サウンド」設定で入力デバイスを設定します：\n各設定 # Voicemeeter Out B1\t仮想出力 B1（Default VAIO） 一般的な仮想マイク（Google Meet等） Voicemeeter Out B2\t仮想出力 B2（AUX VAIO） Zoomなど別ルート用に使う Voicemeeter Out B3\t仮想出力 B3（VAIO3） さらに追加の音声ルートが欲しい時 Voicemeeter Out A1〜A5\t物理的な出力（スピーカーなど） 録音や再生には使わない 3. Voicemeeterアプリケーションの設定\nVoicemeeterを起動 Voicemeeterの「Stereo Input」にて対象のマイクを設定 Voicemeeterの「Hardware Output」にて対象のスピーカーを設定 Step 3: サウンドレコーダーで録音 # 録音を開始する前に以下を確認してください：\n準備事項:\nVoicemeeterが起動していること Windows音声設定が上記の設定になっていること 録音対象の音声が再生されていること 録音手順:\nWindowsのサウンドレコーダーを起動 録音ボタンをクリックして録音開始 録音終了後、ファイルを保存 まとめ # Voicemeeterを使用することで、Windowsで簡単にPC内部音声を録音できるようになります。\n主要ポイント # 仮想オーディオデバイス: Voicemeeterが提供する仮想音声ルーティング シンプルな設定: Windows標準のサウンド設定との連携 高音質録音: クリアなPC内部音声の取得 実践的な価値 # 会議録音: オンラインミーティングの効率的な記録 音声アーカイブ: 重要なシステム音声の保存 コンテンツ制作: 音声素材の高品質な録音 参考リンク # Youtube：【Windows 11】パソコン内音声を録音する手順 VB=AUDIO software ","date":"2025年 8月 10日","externalUrl":null,"permalink":"/posts/1754826645_how-to-record-pc-internal-audio/","section":"投稿記事","summary":"","title":"【Windows】Voicemeeterを使ってパソコン内音声を録音する手順","type":"posts"},{"content":"","date":"2025年 8月 10日","externalUrl":null,"permalink":"/tags/voicemeeter/","section":"Tags","summary":"","title":"Voicemeeter","type":"tags"},{"content":"","date":"2025年 8月 10日","externalUrl":null,"permalink":"/tags/windows/","section":"Tags","summary":"","title":"Windows","type":"tags"},{"content":"","date":"2025年 8月 10日","externalUrl":null,"permalink":"/tags/%E9%9F%B3%E5%A3%B0%E9%8C%B2%E9%9F%B3/","section":"Tags","summary":"","title":"音声録音","type":"tags"},{"content":"","date":"2025年 8月 7日","externalUrl":null,"permalink":"/tags/git/","section":"Tags","summary":"","title":"Git","type":"tags"},{"content":" はじめに # Git worktreeは、1つのGitリポジトリに対して複数のワーキングツリー（作業ディレクトリ）を同時に作成・管理するための強力な機能です。この記事では、git worktreeの基本的な使い方を実践的なハンズオンで学びます。\n解決する課題 # ブランチ切り替え時の作業内容の退避・復元の手間 複数機能を並行開発する際の効率性の問題 緊急バグ修正と通常開発作業の両立 この記事で学べること # git worktreeの基本概念と仕組み 複数ワーキングツリーの作成・管理方法 実際の開発現場での活用パターン 対象読者 # Gitの基本操作（add, commit, merge）を理解している方 複数ブランチでの並行作業を効率化したい方 git worktreeを初めて使用する開発者 前提条件 # Git: v2.5以降（git worktreeコマンド対応版） OS: Windows, macOS, Linux 必要な知識: Gitの基本操作（clone, checkout, merge等） ハンズオン # Step 0: 準備 # ハンズオン用のリポジトリを準備します：\n# 作業用ディレクトリの作成と初期化 mkdir git-worktree-handson-tutorial cd git-worktree-handson-tutorial # Gitリポジトリの初期化 git init # 初期ファイルの作成とコミット echo \u0026#34;Hello World\u0026#34; \u0026gt; main.txt git add main.txt git commit -m \u0026#34;first commit\u0026#34; このハンズオンではローカルリポジトリを使用しますが、実際の開発ではリモートリポジトリをクローンした環境でも同様に利用できます。 Step 1: 新機能開発用ワークツリーの作成 # mainブランチとは独立した場所で新機能feature-Aの開発を行うため、専用ワークツリーを作成します：\n# feature-A用のワークツリーとブランチを同時作成 git worktree add ./feature-a-worktree -b feature-A パラメータ説明:\n./feature-a-worktree: 新規作成するディレクトリのパス -b feature-A: 新規作成するブランチ名 作成されたワークツリーの確認：\ngit worktree list 実行結果例:\n/path/to/git-worktree-handson-tutorial 7a8b9c1 [main] /path/to/git-worktree-handson-tutorial/feature-a-worktree 7a8b9c1 [feature-A] この出力から、2つのワークツリーが並存していることが確認できます。\nStep 2: feature-Aワークツリーでの開発作業 # 作成したワークツリーで実際の機能開発を行います：\n# feature-Aワークツリーに移動 cd feature-a-worktree # 現在のブランチ確認 git branch # 出力: * feature-A # 新機能のファイルを作成 echo \u0026#34;Feature A implementation\u0026#34; \u0026gt; feature-A.txt git add feature-A.txt git commit -m \u0026#34;feat: Add feature-A implementation\u0026#34; 検証: 同時に元のディレクトリでも作業が可能であることを確認：\n# 別のターミナルまたは後で元のディレクトリに戻って確認 cd .. # 元のディレクトリに戻る git branch # 出力: * main ls # main.txtのみが存在（feature-A.txtは存在しない） Step 3: 開発完了後のマージ作業 # feature-Aの開発が完了したため、mainブランチにマージします：\n# mainブランチ（元のワークツリー）にいることを確認 pwd # /path/to/git-worktree-handson-tutorial git branch # 出力: * main # feature-Aブランチをmainにマージ git merge feature-A マージ結果の確認：\n# マージ履歴をグラフで確認 git log --graph --oneline --all # ファイルが統合されていることを確認 ls # 出力: main.txt feature-A.txt Step 4: ワークツリーのクリーンアップ # 開発完了後は不要になったワークツリーを削除してリポジトリを整理します：\n# 現在のワークツリー一覧を確認 git worktree list # feature-Aワークツリーを削除 git worktree remove feature-a-worktree 注意: ワークツリー内に未コミットの変更がある場合、削除は失敗します。その場合は--forceオプションで強制削除するか、事前に変更をコミットまたは破棄してください。 クリーンアップ完了の確認:\n# ワークツリー一覧を再確認（mainのみ残っていることを確認） git worktree list # 万が一、ディレクトリが残っている場合は手動削除 rm -rf feature-a-worktree 実践的な活用パターン # パターン1: 緊急バグ修正と機能開発の並行作業 # # 通常の機能開発中（feature-loginブランチで作業中） git worktree add ../hotfix-worktree -b hotfix/critical-bug # hotfix作業完了後 cd ../hotfix-worktree # バグ修正作業... git add . \u0026amp;\u0026amp; git commit -m \u0026#34;fix: critical security issue\u0026#34; # mainにマージ cd ../main-worktree git merge hotfix/critical-bug # 元の機能開発に戻る cd ../feature-login-worktree # 作業を継続... パターン2: 複数バージョンの同時保守 # # v1.0系の保守用ワークツリー git worktree add ../v1-maintenance origin/release-1.0 # v2.0系の保守用ワークツリー git worktree add ../v2-maintenance origin/release-2.0 # 各バージョンで独立してバグ修正が可能 トラブルシューティング # よくある問題と解決法 # 問題1: ワークツリーの削除ができない\n# エラー例: \u0026#34;worktree contains modified or untracked files\u0026#34; # 解決法1: 変更を確認して必要に応じてコミット cd problem-worktree git status git add . \u0026amp;\u0026amp; git commit -m \u0026#34;save changes\u0026#34; # 解決法2: 強制削除 git worktree remove --force problem-worktree 問題2: 同じブランチを複数のワークツリーで使用しようとしてエラー\n# エラー例: \u0026#34;branch \u0026#39;feature-x\u0026#39; is already checked out\u0026#34; # git worktreeでは同じブランチを複数箇所で同時にチェックアウトできません # 解決法: 異なるブランチ名を使用するか、既存のワークツリーを削除 問題3: ディレクトリが残っているがgit worktree listに表示されない\n# 管理情報のクリーンアップ git worktree prune # 手動でディレクトリ削除 rm -rf orphaned-worktree コマンドリファレンス # # 基本的なワークツリー操作 git worktree add \u0026lt;path\u0026gt; -b \u0026lt;branch-name\u0026gt; # 新規ブランチ作成と同時にワークツリー作成 git worktree add \u0026lt;path\u0026gt; \u0026lt;existing-branch\u0026gt; # 既存ブランチからワークツリー作成 git worktree list # ワークツリー一覧表示 git worktree remove \u0026lt;path\u0026gt; # ワークツリー削除 git worktree prune # 孤立した管理情報のクリーンアップ # 高度な操作 git worktree add --detach \u0026lt;path\u0026gt; \u0026lt;commit\u0026gt; # 特定のコミットをワークツリーとして作成 git worktree remove --force \u0026lt;path\u0026gt; # 未保存の変更があっても強制削除 git worktree move \u0026lt;path\u0026gt; \u0026lt;new-path\u0026gt; # ワークツリーの移動 git worktree lock \u0026lt;path\u0026gt; # ワークツリーをロック（自動削除を防ぐ） git worktree unlock \u0026lt;path\u0026gt; # ワークツリーのロック解除 まとめ # このハンズオンを通じて、git worktreeの基本的な操作から実践的な活用方法まで学習しました。\n主要ポイント # 複数ワークツリーの同時管理: 1つのリポジトリで複数のブランチを並行作業 効率的な開発フロー: ブランチ切り替えに伴う時間的コストの削減 適切なクリーンアップ: 作業完了後のワークツリー削除でリポジトリを整理 実践的な価値 # 開発効率向上: ビルド時間や依存関係の再インストール時間を短縮 作業の並行性: 緊急対応と通常開発を同時進行 コンテキストスイッチの最小化: 作業内容の退避・復元が不要 次のステップ # 実際のプロジェクトでgit worktreeを試用 チーム開発でのワークフロー改善に活用 CI/CDパイプラインとの統合検討 git worktreeを活用することで、Git操作の効率性が大幅に向上し、より柔軟な開発体験を実現できます。\n参考リンク # Git公式ドキュメント - git-worktree Qiita：徹底解説：git worktree の使い方 ","date":"2025年 8月 7日","externalUrl":null,"permalink":"/posts/1754519137_git-worktree-hands-on/","section":"投稿記事","summary":"","title":"git worktree ハンズオン","type":"posts"},{"content":" はじめに # Blowfishテーマを使用したHugoサイトでは、デフォルトで「フグ」のアイコンがfaviconとして設定されています。この記事では、デフォルトのfaviconから独自のfaviconに変更する手順を詳しく解説します。\n解決する課題 # デフォルトfaviconからオリジナルアイコンへの変更 複数デバイス・プラットフォームでの適切なアイコン表示 ブランディング一貫性の確保 この記事で学べること # Hugoサイトでのfavicon設定の仕組み 複数プラットフォーム対応のfavicon一式の作成方法 各faviconファイルの用途と必要性 対象読者 # Hugo + Blowfishテーマを使用している方 Webサイトのfavicon設定を行いたい方 マルチプラットフォーム対応のアイコン設定を学びたい方 対象システム # Hugo: v0.80以降 テーマ: Blowfish 対応OS: Windows, macOS, Linux 対応ブラウザ: Chrome, Firefox, Safari, Edge favicon設定 # Step 0: 準備 # favicon変更に必要なファイルを事前に準備します。以下の形式とサイズのファイルが必要です：\nfavicon.ico - 従来のブラウザ対応用 favicon-16x16.png - 標準解像度用（16×16px） favicon-32x32.png - 高解像度用（32×32px） apple-touch-icon.png - iOS用（180×180px） android-chrome-192x192.png - Android用（192×192px） android-chrome-512x512.png - Android用（512×512px） site.webmanifest - Webマニフェストファイル Step 1: ファビコンファイルの配置 # 準備したfaviconファイルをプロジェクトの static ディレクトリに配置します：\n. └── static/ ├─ android-chrome-192x192.png ├─ android-chrome-512x512.png ├─ apple-touch-icon.png ├─ favicon-16x16.png ├─ favicon-32x32.png ├─ favicon.ico └─ site.webmanifest staticディレクトリに置かれたファイルは、Hugoビルド時に自動的にサイトルートにコピーされます。設定ファイルでのパス指定は不要です。 Step 2: 設定の確認 # ファイル配置後、サイトでfaviconが正しく反映されているかを確認します：\nhugo server -D ブラウザで http://localhost:1313 にアクセスし、以下を確認：\nブラウザタブにfaviconが表示されている ブックマーク時に正しいアイコンが使用される モバイルデバイスでのホーム画面追加時の表示 本番環境への反映：\nhugo 各ファイルの詳細説明 # ブラウザ用favicon # favicon.ico\n最も伝統的なfavicon形式 PCブラウザのタブやブックマークで使用 古いブラウザとの互換性確保のため必須 favicon-16x16.png\n標準解像度ディスプレイのブラウザタブ用 PNG形式で軽量 favicon-32x32.png\n高解像度ディスプレイ（Retina等）用 タスクバーやブックマークでも使用 モバイル用アイコン # apple-touch-icon.png\niOSデバイスの「ホーム画面に追加」時に使用 推奨サイズ：180×180px android-chrome-192x192.png\nAndroidのホーム画面アイコン用 サイズ：192×192px android-chrome-512x512.png\nAndroid用大サイズアイコン スプラッシュスクリーンで使用される場合がある サイズ：512×512px Webマニフェスト # site.webmanifest PWA（Progressive Web App）用設定ファイル サイト名、テーマカラー、アイコンパスを定義 ブラウザが適切なアイコンを選択するための情報を提供 favicon作成に便利なツール # オンラインツール # favicon.io\n1つの画像から主要プラットフォーム向けfavicon一式を自動生成 多様な入力形式に対応（画像、テキスト、絵文字） ICOON MONO\n豊富なアイコン素材を無料でダウンロード可能 SVGおよびPNG形式で提供 推奨ワークフロー # 元となる高解像度画像（512×512px以上）を用意 favicon.ioで各サイズのファイルを一括生成 生成されたファイルを static ディレクトリに配置 サイトを再起動して動作確認 トラブルシューティング # よくある問題と解決法 # 問題1: ブラウザでfaviconが更新されない\n原因: ブラウザキャッシュが残っている 解決法: ハードリロード（Ctrl+Shift+R または Cmd+Shift+R）を実行 問題2: 一部のサイズのfaviconが表示されない\n原因: ファイル名が正しくない、またはサイズが仕様と異なる 解決法: ファイル名とサイズを再確認し、必要に応じて再生成 問題3: モバイルでアイコンが正しく表示されない\n原因: site.webmanifest の設定が不適切 解決法: マニフェストファイルのパスとサイズ指定を確認 favicon変更後は必ずシークレットモード（プライベートブラウジング）でも確認することをお勧めします。キャッシュの影響を受けずに正確な表示を確認できます。 コマンドリファレンス # # Hugo開発サーバーの起動 hugo server -D # 本番ビルド hugo # ビルド成果物のクリーンアップ hugo --cleanDestinationDir # 特定ポートでの起動 hugo server -D -p 8080 # ブラウザキャッシュクリア（開発者ツールで実行） # Chrome/Firefox: Ctrl+Shift+R (Windows/Linux) または Cmd+Shift+R (macOS) # Safari: Cmd+Option+R まとめ # Blowfishテーマでのfavicon設定は、static ディレクトリへのファイル配置だけで簡単に実現できます。複数のプラットフォームに対応するため、適切なサイズとフォーマットのファイルを用意することが重要です。\n主要ポイント # 7種類のfaviconファイルで全プラットフォームをカバー static ディレクトリへの配置で自動的に適用 ブラウザキャッシュに注意した確認作業 参考リンク # Blowfish公式ドキュメント - ファビコン favicon.io ICOON MONO ","date":"2025年 8月 3日","externalUrl":null,"permalink":"/posts/1754190549_favicon_settings/","section":"投稿記事","summary":"","title":"BlowfishでFaviconを設定する方法","type":"posts"},{"content":"","date":"2025年 8月 3日","externalUrl":null,"permalink":"/tags/github/","section":"Tags","summary":"","title":"GitHub","type":"tags"},{"content":"","date":"2025年 8月 3日","externalUrl":null,"permalink":"/tags/github-cli/","section":"Tags","summary":"","title":"GitHub CLI","type":"tags"},{"content":" はじめに # GitHub CLIを使用してGitHubのIssuesをMarkdownファイルとして効率的にダウンロードする方法を解説します。この記事では、基本的な取得から実用的なフォーマット改善まで、段階的にアプローチする方法を紹介します。\n解決する課題 # GitHubのIssuesを手動でコピー\u0026amp;ペーストする非効率性 プライベートリポジトリの作業メモやアイデアの効果的な活用不足 ローカル環境でのIssues管理と再利用の困難さ この記事で学べること # GitHub CLIを使ったIssuesの効率的な取得方法 jqコマンドによる日時フォーマットの改善手法 複数Issuesの一括処理とワークフロー自動化 対象読者 # GitHub CLIの基本的な使い方を知っている方 プライベートリポジトリでIssuesを活用している方 ドキュメント作成や記事執筆の素材としてIssuesを活用したい方 最適解コマンド（日本語日時フォーマット）:\n# Issueの取得（jqコマンドで日時フォーマットを日本語表記に変換） gh issue view \u0026lt;ISSUE_NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; --comments --json comments | jq -r \u0026#39;.comments[] | \u0026#34;## コメント (\u0026#34; + (.createdAt | strptime(\u0026#34;%Y-%m-%dT%H:%M:%SZ\u0026#34;) | strftime(\u0026#34;%Y年%m月%d日 %H時%M分\u0026#34;)) + \u0026#34;)\\n\\n\u0026#34; + .body + \u0026#34;\\n\\n---\\n\u0026#34;\u0026#39; \u0026gt; \u0026lt;FILENAME\u0026gt;.md Isseusを取得する対象としてはプライベートリポジトリかつ、Githubの無料プランを利用しているユーザーを想定しております。 パブリックリポジトリまたは有料プランユーザーの場合は、Github Wiki機能など互換性のある機能があるため、そちらを利用するほうが手順も簡単で、効率的にドキュメント運用できると考えられます。 前提条件\nOS: Linux（Ubuntu）環境（WSL2含む） 権限: GitHubにて対象リポジトリへのアクセス権限を保有している サンプル: 当記事ではサンプルリポジトリ（mr110825/gemini-cli-test-repo）を例として説明します 環境セットアップ # GitHub CLIのインストール # # インストール状況の確認 gh --version # GitHub CLIのインストール（必要な場合） sudo apt install gh GitHub CLIへのログイン # # ログイン状況の確認 gh auth status # GitHub CLIへログイン実行 gh auth login GitHub CLIへのログイン手順の詳細については、以下の記事をご参照ください。\n【Git のセットアップ】GitHub CLI を使って GitHub に接続する GitHub CLIのクイックスタート ハンズオン # Step 1: 基本的なIssues一覧確認 # まず、対象リポジトリのIssues一覧を確認します：\ngh issue list --repo \u0026lt;OWNER/REPO\u0026gt; 実行例:\n# サンプルリポジトリのIssues確認 gh issue list --repo mr110825/gemini-cli-test-repo 出力例:\nID TITLE LABELS UPDATED #1 サンプル用のIssues about 1 hour ago Step 2: 基本的なIssue取得 # 最もシンプルな方法でIssueを取得します：\ngh issue view \u0026lt;ISSUE_NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; --comments \u0026gt; \u0026lt;FILENAME\u0026gt;.md 実行例:\n# Issues#1を「test1.md」として取得 gh issue view 1 --repo mr110825/gemini-cli-test-repo --comments \u0026gt; test1.md 出力例:\nauthor:\tmr110825 association:\towner edited:\ttrue status:\tnone -- 記事を投稿するので構成をまとめる -- author:\tmr110825 association:\towner edited:\ttrue status:\tnone -- 必要な手順 - [x] 文章企画を構成 - [x] サンプルのリポジトリを作成 - [x] 記事作成 - [x] 記事投稿 -- 課題: この方法は最もシンプルですが、多くのメタデータが含まれており読みにくく、コメントのタイミングが分かりづらい問題があります。 Step 3: メタデータ除去とISO形式での取得 # 不要なプロパティを除外し、コメントのみを整形して取得します：\ngh issue view \u0026lt;ISSUE_NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; --comments --json comments --template \u0026#39;{{range .comments}}## コメント ({{.createdAt}}) {{.body}} --- {{end}}\u0026#39; \u0026gt; \u0026lt;FILENAME\u0026gt;.md 実行例:\n# 整形されたコメントを「test2.md」として取得 gh issue view 1 --repo mr110825/gemini-cli-test-repo --comments --json comments --template \u0026#39;{{range .comments}}## コメント ({{.createdAt}}) {{.body}} --- {{end}}\u0026#39; \u0026gt; test2.md 出力例:\n## コメント (2025-06-28T12:24:28Z) 記事を投稿するので構成をまとめる --- ## コメント (2025-06-28T12:25:50Z) 必要な手順 - [x] 文章企画を構成 - [x] サンプルのリポジトリを作成 - [x] 記事作成 - [x] 記事投稿 --- 改善点: メタデータが除去され、コメントの内容と投稿日時が明確になりました。しかし、ISO形式の日時表記は読みづらいため、さらなる改善が必要です。 Step 4: jqコマンドによる日時フォーマット改善（推奨） # jqコマンドを使用して、日時を日本語表記に変換します：\n# jqコマンドのインストール（必要な場合） sudo apt install jq gh issue view \u0026lt;ISSUE_NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; --comments --json comments | jq -r \u0026#39;.comments[] | \u0026#34;## コメント (\u0026#34; + (.createdAt | strptime(\u0026#34;%Y-%m-%dT%H:%M:%SZ\u0026#34;) | strftime(\u0026#34;%Y年%m月%d日 %H時%M分\u0026#34;)) + \u0026#34;)\\n\\n\u0026#34; + .body + \u0026#34;\\n\\n---\\n\u0026#34;\u0026#39; \u0026gt; \u0026lt;FILENAME\u0026gt;.md 実行例:\n# 日本語日時形式で「test3.md」として取得 gh issue view 1 --repo mr110825/gemini-cli-test-repo --comments --json comments | jq -r \u0026#39;.comments[] | \u0026#34;## コメント (\u0026#34; + (.createdAt | strptime(\u0026#34;%Y-%m-%dT%H:%M:%SZ\u0026#34;) | strftime(\u0026#34;%Y年%m月%d日 %H時%M分\u0026#34;)) + \u0026#34;)\\n\\n\u0026#34; + .body + \u0026#34;\\n\\n---\\n\u0026#34;\u0026#39; \u0026gt; test3.md 出力例:\n## コメント (2025年06月28日 12時24分) 記事を投稿するので構成をまとめる --- ## コメント (2025年06月28日 12時25分) 必要な手順 - [x] 文章企画を構成 - [x] サンプルのリポジトリを作成 - [x] 記事作成 - [x] 記事投稿 --- 最適解: この方法が最も実用的です。日本語表記により日時が直感的に理解でき、ドキュメントとして保存した際も読みやすくなります。 Step 5: Issueタイトル・本文・コメントの完全取得 # Issueの全情報を取得したい場合の完全版コマンド：\n# Issueのタイトル、本文、コメントを完全取得 gh issue view \u0026lt;ISSUE_NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; --comments --json title,body,comments | jq -r \u0026#39;\u0026#34;# \u0026#34; + .title + \u0026#34;\\n\\n\u0026#34; + \u0026#34;## Issue本文\\n\\n\u0026#34; + .body + \u0026#34;\\n\\n---\u0026#34;, (.comments[] | \u0026#34;## コメント (\u0026#34; + (.createdAt | strptime(\u0026#34;%Y-%m-%dT%H:%M:%SZ\u0026#34;) | strftime(\u0026#34;%Y年%m月%d日 %H時%M分\u0026#34;)) + \u0026#34;)\\n\\n\u0026#34; + .body + \u0026#34;\\n\\n---\u0026#34;)\u0026#39; \u0026gt; \u0026lt;FILENAME\u0026gt;.md これにより、Issueのタイトル、本文、整形されたコメントが順番に出力されるMarkdownファイルが生成されます。\n応用パターン # 複数Issues の一括取得 # # 全Issuesを一括でMarkdown化 for issue in $(gh issue list --repo \u0026lt;OWNER/REPO\u0026gt; --json number -q \u0026#39;.[].number\u0026#39;); do gh issue view $issue --repo \u0026lt;OWNER/REPO\u0026gt; --comments --json title,body,comments | jq -r \u0026#39;\u0026#34;# \u0026#34; + .title + \u0026#34;\\n\\n\u0026#34; + \u0026#34;## Issue本文\\n\\n\u0026#34; + .body + \u0026#34;\\n\\n---\u0026#34;, (.comments[] | \u0026#34;## コメント (\u0026#34; + (.createdAt | strptime(\u0026#34;%Y-%m-%dT%H:%M:%SZ\u0026#34;) | strftime(\u0026#34;%Y年%m月%d日 %H時%M分\u0026#34;)) + \u0026#34;)\\n\\n\u0026#34; + .body + \u0026#34;\\n\\n---\u0026#34;)\u0026#39; \u0026gt; \u0026#34;issue-${issue}.md\u0026#34; done 特定ラベルのIssues取得 # # 特定ラベル（例：documentation）のIssuesのみ取得 gh issue list --repo \u0026lt;OWNER/REPO\u0026gt; --label \u0026#34;documentation\u0026#34; --json number -q \u0026#39;.[].number\u0026#39; トラブルシューティング # よくある問題と解決法 # 問題1: GitHub CLI認証エラー\n# エラー例: \u0026#34;authentication required\u0026#34; # 解決法: 再認証の実行 gh auth login 問題2: jqコマンドが見つからない\n# Ubuntu/Debian系 sudo apt install jq # CentOS/RHEL系 sudo yum install jq # macOS brew install jq 問題3: 日時フォーマットエラー\n# strptime/strftimeが動作しない場合は、シンプルな置換を使用 gh issue view 1 --repo \u0026lt;OWNER/REPO\u0026gt; --comments --json comments | jq -r \u0026#39;.comments[] | \u0026#34;## コメント (\u0026#34; + .createdAt + \u0026#34;)\\n\\n\u0026#34; + .body + \u0026#34;\\n\\n---\\n\u0026#34;\u0026#39; 問題4: プライベートリポジトリへのアクセス権限不足\n# 権限スコープの確認 gh auth status # 必要に応じて追加スコープで再認証 gh auth login --scopes \u0026#34;repo\u0026#34; コマンドリファレンス # # 基本操作 gh issue list --repo \u0026lt;OWNER/REPO\u0026gt; # Issues一覧表示 gh issue view \u0026lt;NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; # 基本的なIssue表示 gh auth status # 認証状況確認 gh auth login # GitHub認証 # メタデータ付き取得 gh issue view \u0026lt;NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; --comments \u0026gt; \u0026lt;FILE\u0026gt;.md # JSON形式での取得 gh issue view \u0026lt;NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; --json title,body,comments # テンプレート使用（ISO日時） gh issue view \u0026lt;NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; --comments --json comments --template \u0026#39;{{range .comments}}## コメント ({{.createdAt}})\\n\\n{{.body}}\\n\\n---\\n{{end}}\u0026#39; # jq使用（日本語日時・推奨） gh issue view \u0026lt;NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; --comments --json comments | jq -r \u0026#39;.comments[] | \u0026#34;## コメント (\u0026#34; + (.createdAt | strptime(\u0026#34;%Y-%m-%dT%H:%M:%SZ\u0026#34;) | strftime(\u0026#34;%Y年%m月%d日 %H時%M分\u0026#34;)) + \u0026#34;)\\n\\n\u0026#34; + .body + \u0026#34;\\n\\n---\\n\u0026#34;\u0026#39; # 完全版（タイトル・本文・コメント） gh issue view \u0026lt;NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; --comments --json title,body,comments | jq -r \u0026#39;\u0026#34;# \u0026#34; + .title + \u0026#34;\\n\\n\u0026#34; + \u0026#34;## Issue本文\\n\\n\u0026#34; + .body + \u0026#34;\\n\\n---\u0026#34;, (.comments[] | \u0026#34;## コメント (\u0026#34; + (.createdAt | strptime(\u0026#34;%Y-%m-%dT%H:%M:%SZ\u0026#34;) | strftime(\u0026#34;%Y年%m月%d日 %H時%M分\u0026#34;)) + \u0026#34;)\\n\\n\u0026#34; + .body + \u0026#34;\\n\\n---\u0026#34;)\u0026#39; # 一括処理 for issue in $(gh issue list --repo \u0026lt;OWNER/REPO\u0026gt; --json number -q \u0026#39;.[].number\u0026#39;); do gh issue view $issue --repo \u0026lt;OWNER/REPO\u0026gt; --comments --json title,body,comments | jq -r \u0026#39;\u0026#34;# \u0026#34; + .title + \u0026#34;\\n\\n\u0026#34; + .body + \u0026#34;\\n\\n---\u0026#34;\u0026#39; \u0026gt; \u0026#34;issue-${issue}.md\u0026#34; done # 特定ラベルでフィルタ gh issue list --repo \u0026lt;OWNER/REPO\u0026gt; --label \u0026#34;\u0026lt;LABEL_NAME\u0026gt;\u0026#34; まとめ # GitHub CLIを使用してIssuesをMarkdownファイルとしてダウンロードする方法を段階的改善アプローチで解説しました。\n主要ポイント # 段階的改善: 基本的な取得から最適化まで5段階のアプローチ 実用的な解決策: jqコマンドを使った日本語日時フォーマットが最適解 柔軟な活用: 単発取得から一括処理まで様々なパターンに対応 推奨ワークフロー # 基本取得: まずシンプルな方法でデータを確認 フォーマット改善: jqコマンドで読みやすい形式に変換 自動化: 複数Issuesや定期取得の仕組み構築 統合活用: 既存のドキュメント管理システムとの連携 GitHub CLIとjqコマンドの組み合わせにより、GitHubのデータを効率的にローカル環境で活用する基盤が整います。\n参考リンク # GitHub CLI公式ドキュメント GitHub CLIクイックスタート jq公式ドキュメント GitHub API v4ドキュメント ","date":"2025年 8月 3日","externalUrl":null,"permalink":"/posts/1754153716_how_to_download_github_issues/","section":"投稿記事","summary":"","title":"Github CLIでIssuesをMarkdownファイルとしてダウンロードする方法","type":"posts"}]