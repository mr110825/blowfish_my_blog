
[{"content":" はじめに # この記事では、CloudFrontで配信している技術ブログに独自ドメインを設定します。 Route53でドメインを購入し、ACM（AWS Certificate Manager）でSSL/TLS証明書を発行してHTTPS通信を実現します。\nこの記事で構築するもの # Route53でのドメイン購入 ACM証明書の発行（DNS検証） CloudFrontへのカスタムドメイン設定 Route53 Aliasレコードの設定 想定する読者 # 前回までの記事でS3 + CloudFront + 監視 + ログ分析環境を構築済みの方 CloudFrontのデフォルトドメイン（dxxxxx.cloudfront.net）から独自ドメインに変更したい方 AWS初心者〜中級者 完成イメージ # 【変更前】 https://dxxxxx.cloudfront.net/ 【変更後】 https://example.com/ ← 独自ドメインでアクセス可能に 独自ドメインでHTTPSアクセスできるようになります。\nシリーズ全体像 # 【Hugo×AWS】シリーズ全体で5記事投稿予定です。今回の記事は最終回の5本目です。\n# タイトル 内容 1 Hugo + S3 + CloudFrontで技術ブログを公開する Hugo環境構築〜手動デプロイまで 2 GitHub Actions + OIDCで自動デプロイ CI/CD構築、アクセスキー不要の認証 3 CloudWatch + SNSで監視・アラート通知 ダッシュボード、エラー率アラーム 4 Athenaでアクセスログを分析する CloudFrontログのSQL分析 5 独自ドメインを設定する（Route53 + ACM） カスタムドメイン、HTTPS なぜ独自ドメインが必要なのか # CloudFrontのデフォルトドメイン（dxxxxx.cloudfront.net）でも技術的には問題ありませんが、独自ドメインには以下のメリットがあります。\n観点 デフォルトドメイン 独自ドメイン ブランディング △ AWSのサブドメイン ✅ 自分の名前 覚えやすさ △ ランダムな文字列 ✅ 意味のある名前 信頼性 △ 一時的に見える ✅ 本格的に見える SEO △ ドメインパワーなし ✅ 独自ドメインで蓄積 ポートフォリオ △ 印象が弱い ✅ プロフェッショナル 転職ポートフォリオとして見せる場合、独自ドメインは「本気で運用している」印象を与えます。\n前提条件 # 必要な環境 # 本記事は、これまでの記事で以下が構築済みであることを前提としています。\nCloudFront Distribution Terraformプロジェクト 必要な情報 # cd hugo-s3-demo-infra/prod terraform output cloudfront_distribution_id = \u0026#34;E2XXXXXXXXXX\u0026#34; cloudfront_domain_name = \u0026#34;dxxxxx.cloudfront.net\u0026#34; 【重要】ACM証明書のリージョン制約 # :::message alert CloudFrontでACM証明書を使う場合、必ず us-east-1（バージニア北部）で証明書を作成する必要があります。\n東京リージョン（ap-northeast-1）で作成した証明書は、CloudFrontの設定画面で選択できません。 :::\nなぜus-east-1なのか # CloudFrontはグローバルサービスであり、グローバルサービスは us-east-1 のACM証明書しか参照できない仕様です。\nサービス ACM証明書のリージョン CloudFront us-east-1のみ ALB ALBと同じリージョン API Gateway（Edge） us-east-1のみ AWS公式ドキュメントにも明記されています。\n\u0026ldquo;To use an ACM certificate with Amazon CloudFront, you must request or import the certificate in the US East (N. Virginia) region.\u0026rdquo; — Supported Regions - AWS Certificate Manager\nドメインの購入（Route53） # Route53でドメインを購入する理由 # 購入先 メリット デメリット Route53 AWSサービスとの連携が簡単、DNS検証が1クリック 一部TLDは割高 お名前.com等 安いTLDが多い ネームサーバー移管が必要 Cloudflare .dev等が購入可能 Route53との連携に手間 本記事ではRoute53での購入を前提に解説します。\n:::message Route53では .dev ドメインを購入できません。.dev を使いたい場合は、Cloudflare等で購入後、Route53にネームサーバーを移管する必要があります。 :::\n購入手順 # AWSコンソールで Route53 を開く 左メニューの「登録済みドメイン」→「ドメインの登録」 希望のドメイン名を検索（例: example） 利用可能なTLDと価格を確認し、カートに追加 連絡先情報を入力 以下の設定を確認 プライバシー保護: 有効（WHOIS情報を非公開） 自動更新: 有効（更新忘れ防止） 購入を完了 購入後の確認 # 購入後、以下のメールが届きます。\n# メール件名 対応 1 Amazon Registrar にサインアップ〜 対応不要 2 [Action Required] Verify your email address ⚠️ リンクをクリックして承認 3 Registration of example.com succeeded 対応不要（完了通知） :::message alert 承認メールが迷惑メールフォルダに入っていることがあります。届かない場合は迷惑メールを確認してください。 :::\nホストゾーンの確認 # ドメイン購入時に、Route53のホストゾーンが自動作成されます。\nRoute53 → ホストゾーン 購入したドメイン名のホストゾーンを開く NS（ネームサーバー）とSOAレコードが存在することを確認 :::message ドメイン購入はTerraformで管理できません（一度きりの操作、連絡先入力が必要なため）。 ホストゾーンは data ソースで参照します。 :::\nACM証明書の発行 # ACMとは # ACM（AWS Certificate Manager） は、SSL/TLS証明書を管理するAWSサービスです。\n従来の方法 ACM 証明書を購入（年間数千〜数万円） 無料 手動でサーバーにインストール AWS側で自動設定 有効期限切れを手動管理 自動更新 Terraformでのマルチリージョン設定 # ACM証明書を us-east-1 で作成するため、マルチリージョンのprovider設定が必要です。\nversions.tf の修正 # terraform { required_version = \u0026#34;\u0026gt;= 1.0\u0026#34; required_providers { aws = { source = \u0026#34;hashicorp/aws\u0026#34; version = \u0026#34;~\u0026gt; 5.0\u0026#34; } } } # デフォルトプロバイダー（東京リージョン） provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; default_tags { tags = { Project = var.project_name ManagedBy = \u0026#34;terraform\u0026#34; } } } # us-east-1プロバイダー（ACM証明書用） provider \u0026#34;aws\u0026#34; { alias = \u0026#34;us_east_1\u0026#34; region = \u0026#34;us-east-1\u0026#34; default_tags { tags = { Project = var.project_name ManagedBy = \u0026#34;terraform\u0026#34; } } } alias = \u0026quot;us_east_1\u0026quot; を設定することで、リソースごとにプロバイダーを使い分けられます。\nacm.tf # acm.tf を新規作成します。\n# =========================================== # ACM証明書（us-east-1で作成） # =========================================== resource \u0026#34;aws_acm_certificate\u0026#34; \u0026#34;main\u0026#34; { provider = aws.us_east_1 # us-east-1で作成 domain_name = var.domain_name subject_alternative_names = [\u0026#34;*.${var.domain_name}\u0026#34;] validation_method = \u0026#34;DNS\u0026#34; lifecycle { create_before_destroy = true } tags = { Name = \u0026#34;${var.project_name}-certificate\u0026#34; } } # =========================================== # DNS検証用レコード # =========================================== resource \u0026#34;aws_route53_record\u0026#34; \u0026#34;acm_validation\u0026#34; { for_each = { for dvo in aws_acm_certificate.main.domain_validation_options : dvo.domain_name =\u0026gt; { name = dvo.resource_record_name record = dvo.resource_record_value type = dvo.resource_record_type } } zone_id = data.aws_route53_zone.main.zone_id name = each.value.name type = each.value.type records = [each.value.record] ttl = 60 allow_overwrite = true } # =========================================== # 証明書の検証完了を待機 # =========================================== resource \u0026#34;aws_acm_certificate_validation\u0026#34; \u0026#34;main\u0026#34; { provider = aws.us_east_1 certificate_arn = aws_acm_certificate.main.arn validation_record_fqdns = [for record in aws_route53_record.acm_validation : record.fqdn] } コード解説 # 証明書リソース # resource \u0026#34;aws_acm_certificate\u0026#34; \u0026#34;main\u0026#34; { provider = aws.us_east_1 # 重要: us-east-1で作成 domain_name = var.domain_name # example.com subject_alternative_names = [\u0026#34;*.${var.domain_name}\u0026#34;] # *.example.com（ワイルドカード） validation_method = \u0026#34;DNS\u0026#34; # DNS検証 } 属性 説明 provider us-east-1プロバイダーを指定 domain_name メインドメイン subject_alternative_names サブドメイン（ワイルドカードで全て対応） validation_method DNS検証（Route53なら自動化可能） DNS検証レコード # resource \u0026#34;aws_route53_record\u0026#34; \u0026#34;acm_validation\u0026#34; { for_each = { for dvo in aws_acm_certificate.main.domain_validation_options : dvo.domain_name =\u0026gt; { ... } } # ... } ACMがDNS検証用に要求するCNAMEレコードを、Route53に自動作成します。 for_each でドメインごとにレコードを作成します（メインドメイン + ワイルドカード）。\n検証完了の待機 # resource \u0026#34;aws_acm_certificate_validation\u0026#34; \u0026#34;main\u0026#34; { certificate_arn = aws_acm_certificate.main.arn validation_record_fqdns = [for record in aws_route53_record.acm_validation : record.fqdn] } 証明書の検証が完了するまで待機するリソースです。 これにより、証明書が「発行済み」になるまでTerraformが次のリソース作成を待ちます。\nvariables.tf に追記 # variable \u0026#34;domain_name\u0026#34; { description = \u0026#34;Domain name for the website\u0026#34; type = string } terraform.tfvars に追記 # domain_name = \u0026#34;example.com\u0026#34; # 購入したドメイン名に置き換え Route53の設定 # route53.tf # route53.tf を新規作成します。\n# =========================================== # ホストゾーンの参照（ドメイン購入時に自動作成済み） # =========================================== data \u0026#34;aws_route53_zone\u0026#34; \u0026#34;main\u0026#34; { name = var.domain_name private_zone = false } # =========================================== # Aliasレコード（CloudFrontへのルーティング） # =========================================== resource \u0026#34;aws_route53_record\u0026#34; \u0026#34;main\u0026#34; { zone_id = data.aws_route53_zone.main.zone_id name = var.domain_name type = \u0026#34;A\u0026#34; alias { name = aws_cloudfront_distribution.main.domain_name zone_id = aws_cloudfront_distribution.main.hosted_zone_id evaluate_target_health = false } } # wwwサブドメイン用（任意） resource \u0026#34;aws_route53_record\u0026#34; \u0026#34;www\u0026#34; { zone_id = data.aws_route53_zone.main.zone_id name = \u0026#34;www.${var.domain_name}\u0026#34; type = \u0026#34;A\u0026#34; alias { name = aws_cloudfront_distribution.main.domain_name zone_id = aws_cloudfront_distribution.main.hosted_zone_id evaluate_target_health = false } } # =========================================== # Outputs # =========================================== output \u0026#34;website_url\u0026#34; { value = \u0026#34;https://${var.domain_name}\u0026#34; } コード解説 # ホストゾーンの参照 # data \u0026#34;aws_route53_zone\u0026#34; \u0026#34;main\u0026#34; { name = var.domain_name private_zone = false } ドメイン購入時に自動作成されたホストゾーンを data ソースで参照します。\nAliasレコード # resource \u0026#34;aws_route53_record\u0026#34; \u0026#34;main\u0026#34; { type = \u0026#34;A\u0026#34; alias { name = aws_cloudfront_distribution.main.domain_name zone_id = aws_cloudfront_distribution.main.hosted_zone_id evaluate_target_health = false } } Aliasレコードは、AWSサービス（CloudFront、ALB、S3等）への特殊なルーティングです。\n通常のAレコード Aliasレコード IPアドレスを指定 AWSサービスのドメイン名を指定 TTLを設定 TTL不要（自動） DNSクエリ課金あり 無料 CloudFrontへのルーティングには、Aliasレコードを使用するのがベストプラクティスです。\nCloudFrontの更新 # CloudFront Distributionにカスタムドメインと証明書を設定します。\nmain.tf の修正 # aws_cloudfront_distribution リソースを修正します。\nresource \u0026#34;aws_cloudfront_distribution\u0026#34; \u0026#34;main\u0026#34; { # ...既存の設定... # カスタムドメインを追加 aliases = [var.domain_name, \u0026#34;www.${var.domain_name}\u0026#34;] # viewer_certificate を修正 viewer_certificate { acm_certificate_arn = aws_acm_certificate.main.arn ssl_support_method = \u0026#34;sni-only\u0026#34; minimum_protocol_version = \u0026#34;TLSv1.2_2021\u0026#34; } # 証明書の検証完了を待ってから作成 depends_on = [aws_acm_certificate_validation.main] # ...既存の設定... } コード解説 # aliases # aliases = [var.domain_name, \u0026#34;www.${var.domain_name}\u0026#34;] CloudFrontが受け付けるドメイン名を指定します。 example.com と www.example.com の両方からアクセス可能になります。\nviewer_certificate # viewer_certificate { acm_certificate_arn = aws_acm_certificate.main.arn ssl_support_method = \u0026#34;sni-only\u0026#34; minimum_protocol_version = \u0026#34;TLSv1.2_2021\u0026#34; } 属性 説明 acm_certificate_arn ACM証明書のARN ssl_support_method sni-only（SNI対応クライアントのみ、追加料金なし） minimum_protocol_version 最小TLSバージョン（セキュリティ向上のため1.2以上推奨） :::message ssl_support_method = \u0026quot;vip\u0026quot; を選択すると、専用IPアドレスが割り当てられますが、月額$600の追加料金が発生します。 個人ブログでは sni-only で十分です。 :::\ndepends_on # depends_on = [aws_acm_certificate_validation.main] 証明書の検証が完了してから、CloudFront Distributionを作成/更新するようにします。\nHugoの設定更新 # hugo.toml の baseURL を独自ドメインに更新します。\nbaseURL = \u0026#39;https://example.com/\u0026#39; languageCode = \u0026#39;en-us\u0026#39; title = \u0026#39;My Tech Blog\u0026#39; theme = \u0026#39;ananke\u0026#39; 更新後、pushすればGitHub Actionsが自動デプロイします。\n実行 # terraform plan terraform apply :::message ACM証明書の検証には数分〜数十分かかる場合があります。 terraform apply が長時間待機状態になっても、正常に処理が進んでいます。 :::\n動作確認 # 1. 証明書のステータス確認 # AWSコンソール → ACM（us-east-1リージョン）で、証明書のステータスが「発行済み」になっていることを確認します。\n2. ブラウザでアクセス # 以下のURLにアクセスし、正常に表示されることを確認します。\nhttps://example.com/ https://www.example.com/ 確認ポイント:\nサイトが正常に表示される ブラウザのアドレスバーに鍵マークが表示される（HTTPS） 記事詳細ページにもアクセスできる 3. HTTPリダイレクト確認 # http://example.com/ にアクセスし、https://example.com/ にリダイレクトされることを確認します。 （CloudFrontの viewer_protocol_policy = \u0026quot;redirect-to-https\u0026quot; により自動リダイレクト）\nコストについて # Route53 # 項目 料金 ドメイン（.com） $15/年 ホストゾーン $0.50/月 DNSクエリ（Alias） 無料 ACM # 項目 料金 パブリック証明書 無料 自動更新 無料 独自ドメインの追加コストは、ドメイン代 + ホストゾーン代で月額約200円程度です。\nトラブルシューティング # 証明書がCloudFrontの選択肢に表示されない # 原因: 証明書が us-east-1 以外のリージョンで作成されている\n対処法:\nAWSコンソールで現在の証明書のリージョンを確認 us-east-1 以外の場合は、証明書を削除して us-east-1 で再作成 DNS検証が完了しない # 原因: DNS検証レコードが正しく作成されていない\n確認ポイント:\nRoute53のホストゾーンにCNAMEレコードが作成されているか確認 レコードの値がACMの要求と一致しているか確認 対処法: terraform apply を再実行\nサイトにアクセスできない # 原因: DNSの伝播に時間がかかっている\n対処法:\ndig example.com でDNSレコードを確認 数分〜数時間待ってから再度アクセス ERR_SSL_VERSION_OR_CIPHER_MISMATCH # 原因: 証明書の設定が正しくない\n確認ポイント:\nCloudFrontの aliases に正しいドメイン名が設定されているか ACM証明書のドメイン名が一致しているか まとめ # 本記事では、以下を構築しました。\nRoute53: ドメイン購入、DNSレコード管理 ACM: SSL/TLS証明書の発行（us-east-1） CloudFront: カスタムドメイン設定 Terraform: マルチリージョンprovider設定 作成したリソース # リソース 用途 Route53 Aliasレコード CloudFrontへのルーティング Route53 CNAMEレコード ACM DNS検証 ACM証明書 HTTPS通信の実現 CloudFront aliases カスタムドメインの受け付け 重要ポイント # 項目 ポイント ACM証明書のリージョン us-east-1必須 Aliasレコード CloudFrontへのルーティングは無料 ssl_support_method sni-only で追加料金なし DNS伝播 最大72時間かかる場合がある これで【Hugo×AWS】シリーズは完了です！\n5記事を通じて、以下の技術ブログ基盤を構築しました。\n静的サイトホスティング: S3 + CloudFront 自動デプロイ: GitHub Actions + OIDC 監視・アラート: CloudWatch + SNS + AWS Budgets ログ分析: Athena + Glue 独自ドメイン: Route53 + ACM すべてTerraformでコード化されているため、再現性があり、ポートフォリオとしても活用できます。\n参考資料 # Route53 ドメイン登録 - AWS公式 ACM パブリック証明書 - AWS公式 CloudFront カスタムドメイン - AWS公式 ACM Supported Regions - AWS公式 Terraform aws_acm_certificate Terraform aws_route53_record ","date":"2025年 12月 30日","externalUrl":null,"permalink":"/posts/251230211322_hugoaws%E7%8B%AC%E8%87%AA%E3%83%89%E3%83%A1%E3%82%A4%E3%83%B3%E3%82%92%E8%A8%AD%E5%AE%9A%E3%81%99%E3%82%8Broute53+acm/","section":"Posts","summary":"","title":"【Hugo×AWS】独自ドメインを設定する（Route53+ACM）","type":"posts"},{"content":"","date":"2025年 12月 30日","externalUrl":null,"permalink":"/series/hugo+s3+cloudfront%E3%81%A7%E6%8A%80%E8%A1%93%E3%83%96%E3%83%AD%E3%82%B0%E3%82%92%E5%85%AC%E9%96%8B%E3%81%99%E3%82%8B/","section":"Series","summary":"","title":"Hugo+S3+CloudFrontで技術ブログを公開する","type":"series"},{"content":"","date":"2025年 12月 30日","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"2025年 12月 30日","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","date":"2025年 12月 30日","externalUrl":null,"permalink":"/","section":"毎日.log","summary":"","title":"毎日.log","type":"page"},{"content":" はじめに # この記事では、CloudFrontのアクセスログをAthenaでSQL分析できる環境を構築します。 サーバーレスでインフラ管理不要、S3のログファイルを直接クエリできるため、個人ブログのログ分析に最適です。\nこの記事で構築するもの # CloudFrontログの出力設定（S3バケット） Athenaクエリ環境（Workgroup、Glue Database/Table） サンプルクエリ（人気ページ、キャッシュヒット率、エッジロケーション分析） 想定する読者 # 前回までの記事でS3 + CloudFront + 監視環境を構築済みの方 CloudFrontのアクセスログを分析したい方 SQLでログ分析したい方 完成イメージ # AthenaでSQLクエリを実行するだけで、以下のような分析ができるようになります。\n人気ページランキング キャッシュヒット率 エッジロケーション別アクセス数 エラー発生状況 シリーズ全体像 # 【Hugo×AWS】シリーズ全体で5記事投稿予定です。今回の記事は4本目です。\n# タイトル 内容 1 Hugo + S3 + CloudFrontで技術ブログを公開する Hugo環境構築〜手動デプロイまで 2 GitHub Actions + OIDCで自動デプロイ CI/CD構築、アクセスキー不要の認証 3 CloudWatch + SNSで監視・アラート通知 ダッシュボード、エラー率アラーム 4 Athenaでアクセスログを分析する CloudFrontログのSQL分析 5 独自ドメインを設定する（Route53 + ACM） カスタムドメイン、HTTPS なぜAthenaを選んだのか # ログ分析サービスの比較です。\nサービス 特徴 月額コスト 個人ブログに適切か Athena サーバーレス、S3直接クエリ 数円〜数十円 ✅ 最適 Redshift 大規模データウェアハウス 数万円〜 ❌ 過剰 Elasticsearch 全文検索、リアルタイム分析 数千円〜 ❌ 過剰 CloudWatch Logs Insights CloudWatchログ専用 従量課金 △ 可能だが機能限定 Athenaのメリット # サーバーレス: インフラ管理不要、クエリ実行時のみ起動 S3直接クエリ: データ移動不要、S3のログをそのまま分析可能 コスト効率: スキャンしたデータ量に対して$5/TB（個人ブログなら月数円以下） 標準SQL: 特別な言語を覚える必要がない 前提条件 # 必要な環境 # 本記事は、これまでの記事で以下が構築済みであることを前提としています。\nCloudFront Distribution Terraformプロジェクト 必要な情報 # cd hugo-s3-demo-infra/prod terraform output cloudfront_distribution_id = \u0026#34;E2XXXXXXXXXX\u0026#34; ログ用S3バケットの作成 # CloudFrontのアクセスログを保存するS3バケットを作成します。\nディレクトリ構成 # hugo-s3-demo-infra/ └── prod/ ├── versions.tf ├── backend.tf ├── variables.tf ├── main.tf ├── iam.tf ├── sns.tf ├── cloudwatch.tf ├── budgets.tf ├── outputs.tf └── logs.tf ← 新規作成 logs.tf # # =========================================== # ログ用S3バケット # =========================================== resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;logs\u0026#34; { bucket = \u0026#34;${var.project_name}-logs\u0026#34; tags = { Name = \u0026#34;${var.project_name}-logs\u0026#34; } } # パブリックアクセスブロック resource \u0026#34;aws_s3_bucket_public_access_block\u0026#34; \u0026#34;logs\u0026#34; { bucket = aws_s3_bucket.logs.id block_public_acls = true block_public_policy = true ignore_public_acls = true restrict_public_buckets = true } # CloudFrontからのログ書き込みを許可するバケットポリシー resource \u0026#34;aws_s3_bucket_policy\u0026#34; \u0026#34;logs\u0026#34; { bucket = aws_s3_bucket.logs.id policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34; Statement = [ { Sid = \u0026#34;AllowCloudFrontLogs\u0026#34; Effect = \u0026#34;Allow\u0026#34; Principal = { Service = \u0026#34;cloudfront.amazonaws.com\u0026#34; } Action = \u0026#34;s3:PutObject\u0026#34; Resource = \u0026#34;${aws_s3_bucket.logs.arn}/cloudfront/*\u0026#34; Condition = { StringEquals = { \u0026#34;AWS:SourceArn\u0026#34; = aws_cloudfront_distribution.main.arn } } } ] }) } # ログのライフサイクル設定（90日で削除） resource \u0026#34;aws_s3_bucket_lifecycle_configuration\u0026#34; \u0026#34;logs\u0026#34; { bucket = aws_s3_bucket.logs.id rule { id = \u0026#34;delete-old-logs\u0026#34; status = \u0026#34;Enabled\u0026#34; expiration { days = 90 } filter { prefix = \u0026#34;cloudfront/\u0026#34; } } } # バケット所有者の強制（ACL無効化） resource \u0026#34;aws_s3_bucket_ownership_controls\u0026#34; \u0026#34;logs\u0026#34; { bucket = aws_s3_bucket.logs.id rule { object_ownership = \u0026#34;BucketOwnerEnforced\u0026#34; } } output \u0026#34;logs_bucket_name\u0026#34; { value = aws_s3_bucket.logs.bucket } コード解説 # ライフサイクル設定 # resource \u0026#34;aws_s3_bucket_lifecycle_configuration\u0026#34; \u0026#34;logs\u0026#34; { rule { expiration { days = 90 } } } 90日経過したログファイルを自動削除します。 ログを永続保存するとコストがかかるため、個人ブログでは90日程度が適切です。\nバケット所有者の強制 # resource \u0026#34;aws_s3_bucket_ownership_controls\u0026#34; \u0026#34;logs\u0026#34; { rule { object_ownership = \u0026#34;BucketOwnerEnforced\u0026#34; } } CloudFrontが書き込んだログファイルの所有権を、バケット所有者（自分）に強制します。 これにより、ACL（アクセスコントロールリスト）を使わずにバケットポリシーだけでアクセス制御できます。\nCloudFrontのログ設定 # CloudFront Distributionにログ出力設定を追加します。\nmain.tf の修正 # aws_cloudfront_distribution リソースに logging_config を追加します。\nresource \u0026#34;aws_cloudfront_distribution\u0026#34; \u0026#34;main\u0026#34; { # ...既存の設定... # ログ設定を追加 logging_config { bucket = aws_s3_bucket.logs.bucket_regional_domain_name prefix = \u0026#34;cloudfront/\u0026#34; include_cookies = false } # ...既存の設定... } 属性 説明 bucket ログ出力先のS3バケット（リージョナルドメイン名を指定） prefix ログファイルのプレフィックス include_cookies Cookieをログに含めるか（プライバシーに配慮してfalse） 実行 # terraform apply :::message ログが出力されるまで数分〜数十分かかります。 しばらくアクセスしてから、S3バケットを確認してください。 :::\nログ出力の確認 # aws s3 ls s3://hugo-s3-demo-logs/cloudfront/ --recursive | head -10 以下のようなファイルが出力されていればOKです。\n2025-12-04 09:49:29 673 cloudfront/E2XXXXXXXXXX.2025-12-04-00.29cc3bb9.gz 2025-12-04 13:49:30 580 cloudfront/E2XXXXXXXXXX.2025-12-04-04.74d28fa3.gz Athena環境の構築 # athena.tf # athena.tf を新規作成します。\n:::details athena.tf の全体\n# =========================================== # Athenaクエリ結果用S3バケット # =========================================== resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;athena_results\u0026#34; { bucket = \u0026#34;${var.project_name}-athena-results\u0026#34; tags = { Name = \u0026#34;${var.project_name}-athena-results\u0026#34; } } resource \u0026#34;aws_s3_bucket_public_access_block\u0026#34; \u0026#34;athena_results\u0026#34; { bucket = aws_s3_bucket.athena_results.id block_public_acls = true block_public_policy = true ignore_public_acls = true restrict_public_buckets = true } # クエリ結果は7日で削除 resource \u0026#34;aws_s3_bucket_lifecycle_configuration\u0026#34; \u0026#34;athena_results\u0026#34; { bucket = aws_s3_bucket.athena_results.id rule { id = \u0026#34;delete-query-results\u0026#34; status = \u0026#34;Enabled\u0026#34; expiration { days = 7 } filter { prefix = \u0026#34;query-results/\u0026#34; } } } # =========================================== # Athena Workgroup # =========================================== resource \u0026#34;aws_athena_workgroup\u0026#34; \u0026#34;main\u0026#34; { name = \u0026#34;${var.project_name}-workgroup\u0026#34; configuration { enforce_workgroup_configuration = true publish_cloudwatch_metrics_enabled = true result_configuration { output_location = \u0026#34;s3://${aws_s3_bucket.athena_results.bucket}/query-results/\u0026#34; } } tags = { Name = \u0026#34;${var.project_name}-workgroup\u0026#34; } } # =========================================== # Glue Database # =========================================== resource \u0026#34;aws_glue_catalog_database\u0026#34; \u0026#34;logs\u0026#34; { name = replace(\u0026#34;${var.project_name}_logs\u0026#34;, \u0026#34;-\u0026#34;, \u0026#34;_\u0026#34;) } # =========================================== # Glue Table（CloudFrontログ用） # =========================================== resource \u0026#34;aws_glue_catalog_table\u0026#34; \u0026#34;cloudfront_logs\u0026#34; { name = \u0026#34;cloudfront_logs\u0026#34; database_name = aws_glue_catalog_database.logs.name table_type = \u0026#34;EXTERNAL_TABLE\u0026#34; parameters = { \u0026#34;skip.header.line.count\u0026#34; = \u0026#34;2\u0026#34; \u0026#34;EXTERNAL\u0026#34; = \u0026#34;TRUE\u0026#34; } storage_descriptor { location = \u0026#34;s3://${aws_s3_bucket.logs.bucket}/cloudfront/\u0026#34; input_format = \u0026#34;org.apache.hadoop.mapred.TextInputFormat\u0026#34; output_format = \u0026#34;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\u0026#34; ser_de_info { serialization_library = \u0026#34;org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\u0026#34; parameters = { \u0026#34;field.delim\u0026#34; = \u0026#34;\\t\u0026#34; \u0026#34;serialization.format\u0026#34; = \u0026#34;\\t\u0026#34; } } # CloudFrontログの33カラム定義 columns { name = \u0026#34;date\u0026#34; type = \u0026#34;date\u0026#34; } columns { name = \u0026#34;time\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;x_edge_location\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;sc_bytes\u0026#34; type = \u0026#34;bigint\u0026#34; } columns { name = \u0026#34;c_ip\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;cs_method\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;cs_host\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;cs_uri_stem\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;sc_status\u0026#34; type = \u0026#34;int\u0026#34; } columns { name = \u0026#34;cs_referer\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;cs_user_agent\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;cs_uri_query\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;cs_cookie\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;x_edge_result_type\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;x_edge_request_id\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;x_host_header\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;cs_protocol\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;cs_bytes\u0026#34; type = \u0026#34;bigint\u0026#34; } columns { name = \u0026#34;time_taken\u0026#34; type = \u0026#34;float\u0026#34; } columns { name = \u0026#34;x_forwarded_for\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;ssl_protocol\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;ssl_cipher\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;x_edge_response_result_type\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;cs_protocol_version\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;fle_status\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;fle_encrypted_fields\u0026#34; type = \u0026#34;int\u0026#34; } columns { name = \u0026#34;c_port\u0026#34; type = \u0026#34;int\u0026#34; } columns { name = \u0026#34;time_to_first_byte\u0026#34; type = \u0026#34;float\u0026#34; } columns { name = \u0026#34;x_edge_detailed_result_type\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;sc_content_type\u0026#34; type = \u0026#34;string\u0026#34; } columns { name = \u0026#34;sc_content_len\u0026#34; type = \u0026#34;bigint\u0026#34; } columns { name = \u0026#34;sc_range_start\u0026#34; type = \u0026#34;bigint\u0026#34; } columns { name = \u0026#34;sc_range_end\u0026#34; type = \u0026#34;bigint\u0026#34; } } } # =========================================== # Outputs # =========================================== output \u0026#34;athena_workgroup\u0026#34; { value = aws_athena_workgroup.main.name } output \u0026#34;athena_database\u0026#34; { value = aws_glue_catalog_database.logs.name } output \u0026#34;athena_table\u0026#34; { value = aws_glue_catalog_table.cloudfront_logs.name } output \u0026#34;athena_results_bucket\u0026#34; { value = aws_s3_bucket.athena_results.bucket } :::\nコード解説 # Athena Workgroup # resource \u0026#34;aws_athena_workgroup\u0026#34; \u0026#34;main\u0026#34; { configuration { enforce_workgroup_configuration = true publish_cloudwatch_metrics_enabled = true result_configuration { output_location = \u0026#34;s3://${aws_s3_bucket.athena_results.bucket}/query-results/\u0026#34; } } } 属性 説明 enforce_workgroup_configuration Workgroupの設定を強制（ユーザーが上書きできない） publish_cloudwatch_metrics_enabled クエリメトリクスをCloudWatchに出力 output_location クエリ結果の保存先 Glue Data Catalogとは # resource \u0026#34;aws_glue_catalog_database\u0026#34; \u0026#34;logs\u0026#34; { name = replace(\u0026#34;${var.project_name}_logs\u0026#34;, \u0026#34;-\u0026#34;, \u0026#34;_\u0026#34;) } Glue Data Catalogは、AWSのメタデータカタログサービスです。 Athenaはこれを参照してテーブル定義（スキーマ）を取得します。\nAthena → Glue Data Catalog（テーブル定義）→ S3（実データ） :::message Glueのデータベース名にはハイフン - を使用できません。 replace() 関数でアンダースコア _ に置換しています。 :::\nCloudFrontログのカラム定義 # CloudFrontの標準ログは33カラムのTSV（タブ区切り）形式です。 各カラムの意味はAWS公式ドキュメントを参照してください。\n主要なカラムは以下の通りです。\nカラム名 説明 date, time リクエスト日時 x_edge_location エッジロケーション（NRT=東京など） cs_uri_stem リクエストされたパス sc_status HTTPステータスコード x_edge_result_type キャッシュヒット/ミス 実行 # terraform apply 分析クエリの実行 # AWSコンソールでAthenaを開き、クエリを実行します。\nWorkgroupの選択 # Athenaコンソールを開く 右上の「Workgroup」で作成したWorkgroup（hugo-s3-demo-workgroup）を選択 左側のデータベースで作成したデータベース（hugo_s3_demo_logs）を選択 クエリ1: データ確認 # まずテーブルにデータが入っているか確認します。\nSELECT * FROM hugo_s3_demo_logs.cloudfront_logs LIMIT 10; 33カラムのデータが表示されればOKです。\nクエリ2: 人気ページランキング # SELECT cs_uri_stem AS path, COUNT(*) AS views FROM hugo_s3_demo_logs.cloudfront_logs WHERE sc_status = 200 AND cs_uri_stem NOT LIKE \u0026#39;%.js\u0026#39; AND cs_uri_stem NOT LIKE \u0026#39;%.css\u0026#39; AND cs_uri_stem NOT LIKE \u0026#39;%.png\u0026#39; AND cs_uri_stem NOT LIKE \u0026#39;%.jpg\u0026#39; AND cs_uri_stem NOT LIKE \u0026#39;%.ico\u0026#39; GROUP BY cs_uri_stem ORDER BY views DESC LIMIT 10; 静的アセット（JS/CSS/画像）を除外して、ページのアクセス数をランキング表示します。\nクエリ3: キャッシュヒット率 # SELECT x_edge_result_type AS result_type, COUNT(*) AS count, ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) AS percentage FROM hugo_s3_demo_logs.cloudfront_logs GROUP BY x_edge_result_type ORDER BY count DESC; 結果タイプ 意味 Hit キャッシュヒット（エッジから配信） Miss キャッシュミス（オリジンから取得） Error エラー発生 Redirect リダイレクト キャッシュヒット率が高いほど、CDNが効率的に動作しています。\nクエリ4: エッジロケーション別アクセス # SELECT x_edge_location AS edge, COUNT(*) AS requests FROM hugo_s3_demo_logs.cloudfront_logs GROUP BY x_edge_location ORDER BY requests DESC LIMIT 10; どのエッジロケーションからのアクセスが多いかを確認できます。\nエッジコード 場所 NRT 東京 KIX 大阪 SEA シアトル SIN シンガポール FRA フランクフルト クエリ5: 日別アクセス数 # SELECT date, COUNT(*) AS requests FROM hugo_s3_demo_logs.cloudfront_logs GROUP BY date ORDER BY date DESC LIMIT 30; クエリ6: HTTPステータス別集計 # SELECT sc_status AS status, COUNT(*) AS count FROM hugo_s3_demo_logs.cloudfront_logs GROUP BY sc_status ORDER BY count DESC; 4xx/5xxエラーが多い場合は、サイトに問題がある可能性があります。\nコストについて # Athenaの料金は、スキャンしたデータ量に対して**$5/TB**です。\n個人ブログの場合 # 項目 概算 1日のログサイズ 約100KB〜1MB 1ヶ月のログサイズ 約3MB〜30MB 1クエリあたりのコスト 約$0.00001〜$0.0001 月間クエリコスト 数円程度 個人ブログ規模であれば、月額数円〜数十円で収まります。\nコスト最適化のポイント # 不要なカラムを除外: SELECT * ではなく必要なカラムのみ指定 WHERE句で絞り込み: 日付範囲を指定してスキャン量を削減 パーティション: 大規模データの場合は日付でパーティション分割（本記事では省略） トラブルシューティング # クエリ結果が0件 # 原因: ログがまだ出力されていない、またはテーブル定義が間違っている\n確認ポイント:\nS3バケットにログファイルがあるか確認 ログファイルのパスとGlue Tableのlocationが一致しているか確認 skip.header.line.count が 2 になっているか確認（CloudFrontログは2行のヘッダーがある） HIVE_CURSOR_ERROR # 原因: カラム定義とログ形式の不一致\n対処法: Glue Tableのカラム定義を確認し、CloudFrontログの形式と一致させる\nクエリ結果の保存先が不明 # 原因: Workgroupの設定が適用されていない\n対処法: Athenaコンソールで正しいWorkgroupを選択しているか確認\nまとめ # 本記事では、以下を構築しました。\nログ用S3バケット: CloudFrontログの保存先（90日で自動削除） CloudFrontログ設定: アクセスログの出力 Athena環境: Workgroup、Glue Database/Table 分析クエリ: 人気ページ、キャッシュヒット率、エッジロケーション分析 作成したリソース # リソース 用途 S3バケット（logs） CloudFrontログ保存 S3バケット（athena-results） Athenaクエリ結果保存 Athena Workgroup クエリ実行環境 Glue Database メタデータカタログ Glue Table CloudFrontログのスキーマ定義 分析でわかること # 分析項目 活用例 人気ページ コンテンツ戦略の参考 キャッシュヒット率 CDN設定の最適化 エッジロケーション ユーザーの地理的分布 HTTPステータス エラー発生状況の把握 参考資料 # Amazon Athena - AWS公式 AWS Glue Data Catalog - AWS公式 CloudFrontログの形式 - AWS公式 Terraform aws_athena_workgroup Terraform aws_glue_catalog_table ","date":"2025年 12月 30日","externalUrl":null,"permalink":"/posts/251230211301_hugoawsathena%E3%81%A7%E3%82%A2%E3%82%AF%E3%82%BB%E3%82%B9%E3%83%AD%E3%82%B0%E3%82%92%E5%88%86%E6%9E%90%E3%81%99%E3%82%8B/","section":"Posts","summary":"","title":"【Hugo×AWS】Athenaでアクセスログを分析する","type":"posts"},{"content":" はじめに # この記事では、CloudFrontで配信している技術ブログに監視・アラート通知の仕組みを構築します。 CloudWatchでメトリクスを可視化し、エラー率が閾値を超えた場合にSNS経由でメール通知を送信します。 また、AWS Budgetsでコスト監視も設定します。\nこの記事で構築するもの # CloudWatchダッシュボード（リクエスト数、エラー率、キャッシュヒット率の可視化） CloudWatchアラーム（エラー率が閾値を超えたらメール通知） AWS Budgets（月額コストが閾値を超えたらメール通知） 想定する読者 # 前回までの記事でS3 + CloudFront + GitHub Actionsを構築済みの方 サイトの監視・アラートを設定したい方 AWS初心者〜中級者 完成イメージ # 「何か問題があったらメールで知らせてくれる」仕組みを構築します。\nシリーズ全体像 # 【Hugo×AWS】シリーズ全体で5記事投稿予定です。今回の記事は3本目です。\n# タイトル 内容 1 Hugo + S3 + CloudFrontで技術ブログを公開する Hugo環境構築〜手動デプロイまで 2 GitHub Actions + OIDCで自動デプロイ CI/CD構築、アクセスキー不要の認証 3 CloudWatch + SNSで監視・アラート通知 ダッシュボード、エラー率アラーム 4 Athenaでアクセスログを分析する CloudFrontログのSQL分析 5 独自ドメインを設定する（Route53 + ACM） カスタムドメイン、HTTPS なぜ監視が必要なのか # 個人ブログでも監視は重要です。\n監視しないと\u0026hellip; 監視していれば\u0026hellip; エラーに気づかない 即座にメールで通知される 原因調査に時間がかかる ダッシュボードで状況を把握 予想外のコストが発生 閾値超過で早期に検知 特にCloudFrontは「動いているように見えて実はエラーが出ている」ことがあります。 定期的にダッシュボードを確認し、異常時にはアラートで検知できる仕組みを作りましょう。\n前提条件 # 必要な環境 # 本記事は、これまでの記事で以下が構築済みであることを前提としています。\nS3バケット（コンテンツ用） CloudFront Distribution Terraformプロジェクト 必要な情報 # Terraformの出力値から以下を確認してください。\ncd hugo-s3-demo-infra/prod terraform output cloudfront_distribution_id = \u0026#34;E2XXXXXXXXXX\u0026#34; us-east-1 provider の追加 # CloudFrontのメトリクスは us-east-1 リージョンにのみ存在します。 CloudWatch AlarmとSNS Topicも同じリージョンに作成する必要があるため、main.tf に以下を追記します。\n# CloudFront metrics are only available in us-east-1 provider \u0026#34;aws\u0026#34; { alias = \u0026#34;us_east_1\u0026#34; region = \u0026#34;us-east-1\u0026#34; } :::message alert この設定がないと、CloudWatch Alarmがメトリクスを取得できず、アラームが機能しません。 CloudFrontメトリクスは us-east-1 固定であり、他リージョンのCloudWatch Alarmからは参照できないためです。 :::\nSNSトピックの作成 # まず、アラート通知の送信先となるSNSトピックを作成します。\nSNSとは # Amazon SNS（Simple Notification Service）は、メッセージの配信を行うフルマネージドサービスです。 Pub/Sub（発行/購読）モデルで、1つのトピックに対して複数の購読者（メール、SMS、Lambda等）を設定できます。\nCloudWatch Alarm → SNS Topic → Email → SMS → Lambda → etc... ディレクトリ構成 # 前回までのTerraformプロジェクトに sns.tf を追加します。\nhugo-s3-demo-infra/ └── prod/ ├── versions.tf ├── backend.tf ├── variables.tf ├── main.tf ← us-east-1 provider追記 ├── iam.tf ├── outputs.tf ├── sns.tf ← 新規作成 └── terraform.tfvars ← 新規作成 sns.tf # # =========================================== # SNS Topic（通知の送信先） # us-east-1に作成（CloudFrontメトリクスと同じリージョン） # =========================================== resource \u0026#34;aws_sns_topic\u0026#34; \u0026#34;alerts\u0026#34; { provider = aws.us_east_1 name = \u0026#34;${var.project_name}-alerts\u0026#34; tags = { Name = \u0026#34;${var.project_name}-alerts\u0026#34; } } # =========================================== # メールアドレス変数 # =========================================== variable \u0026#34;alert_email\u0026#34; { description = \u0026#34;Email address for alerts\u0026#34; type = string sensitive = true } # =========================================== # SNS Subscription（メール通知設定） # =========================================== resource \u0026#34;aws_sns_topic_subscription\u0026#34; \u0026#34;email\u0026#34; { provider = aws.us_east_1 topic_arn = aws_sns_topic.alerts.arn protocol = \u0026#34;email\u0026#34; endpoint = var.alert_email } # =========================================== # Output # =========================================== output \u0026#34;sns_topic_arn\u0026#34; { description = \u0026#34;SNS Topic ARN for CloudWatch Alarms\u0026#34; value = aws_sns_topic.alerts.arn } コード解説 # SNS Topic # resource \u0026#34;aws_sns_topic\u0026#34; \u0026#34;alerts\u0026#34; { provider = aws.us_east_1 name = \u0026#34;${var.project_name}-alerts\u0026#34; } SNSトピックは、通知メッセージの送信先を束ねる「トピック」です。 CloudWatchアラームやAWS Budgetsからこのトピックに通知を送信し、購読者（メール等）に配信します。\nprovider = aws.us_east_1 を指定することで、CloudFrontメトリクスと同じリージョンにSNSトピックを作成します。\nsensitive変数 # variable \u0026#34;alert_email\u0026#34; { description = \u0026#34;Email address for alerts\u0026#34; type = string sensitive = true } sensitive = true を設定すると、terraform plan/apply の出力でメールアドレスがマスクされます。 機密情報を扱う変数には必ず設定しましょう。\nSNS Subscription # resource \u0026#34;aws_sns_topic_subscription\u0026#34; \u0026#34;email\u0026#34; { provider = aws.us_east_1 topic_arn = aws_sns_topic.alerts.arn protocol = \u0026#34;email\u0026#34; endpoint = var.alert_email } 属性 説明 provider リソースを作成するリージョン（us-east-1） protocol 通知方式（email, sms, lambda, https等） endpoint 通知先（メールアドレス、電話番号等） terraform.tfvars # 機密情報を含む変数は terraform.tfvars に記載します。\nalert_email = \u0026#34;your-email@example.com\u0026#34; :::message alert terraform.tfvars には機密情報が含まれるため、.gitignore に追加してGit管理対象外にしてください。 :::\n実行と購読確認 # terraform plan terraform apply 実行後、指定したメールアドレスに「AWS Notification - Subscription Confirmation」というメールが届きます。\n:::message メール内の「Confirm subscription」リンクをクリックして購読を確認してください。 「Unsubscribe」リンクをクリックすると購読が解除されてしまうので注意してください。 :::\n動作確認 # AWS CLIでテストメッセージを送信します。\naws sns publish \\ --region us-east-1 \\ --topic-arn \u0026#34;arn:aws:sns:us-east-1:123456789012:hugo-s3-demo-alerts\u0026#34; \\ --subject \u0026#34;テスト通知\u0026#34; \\ --message \u0026#34;SNS動作確認テストです。このメールが届けば成功です。\u0026#34; メールが届けばSNSの設定は完了です。\nCloudWatchダッシュボードの作成 # CloudFrontの主要メトリクスを可視化するダッシュボードを作成します。\ncloudwatch.tf # cloudwatch.tf を新規作成します。\n:::details cloudwatch.tf の全体（ダッシュボード部分）\n# =========================================== # CloudWatch Dashboard # CloudFrontの主要メトリクスを可視化 # =========================================== resource \u0026#34;aws_cloudwatch_dashboard\u0026#34; \u0026#34;main\u0026#34; { dashboard_name = \u0026#34;${var.project_name}-dashboard\u0026#34; dashboard_body = jsonencode({ widgets = [ # リクエスト数（時系列グラフ） { type = \u0026#34;metric\u0026#34; x = 0 y = 0 width = 12 height = 6 properties = { title = \u0026#34;CloudFront リクエスト数\u0026#34; region = \u0026#34;us-east-1\u0026#34; metrics = [ [\u0026#34;AWS/CloudFront\u0026#34;, \u0026#34;Requests\u0026#34;, \u0026#34;DistributionId\u0026#34;, aws_cloudfront_distribution.main.id, \u0026#34;Region\u0026#34;, \u0026#34;Global\u0026#34;] ] period = 300 stat = \u0026#34;Sum\u0026#34; } }, # エラー率（時系列グラフ） { type = \u0026#34;metric\u0026#34; x = 12 y = 0 width = 12 height = 6 properties = { title = \u0026#34;CloudFront エラー率 (%)\u0026#34; region = \u0026#34;us-east-1\u0026#34; metrics = [ [\u0026#34;AWS/CloudFront\u0026#34;, \u0026#34;4xxErrorRate\u0026#34;, \u0026#34;DistributionId\u0026#34;, aws_cloudfront_distribution.main.id, \u0026#34;Region\u0026#34;, \u0026#34;Global\u0026#34;], [\u0026#34;.\u0026#34;, \u0026#34;5xxErrorRate\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;] ] period = 300 stat = \u0026#34;Average\u0026#34; } }, # バイト転送量（時系列グラフ） { type = \u0026#34;metric\u0026#34; x = 0 y = 6 width = 12 height = 6 properties = { title = \u0026#34;CloudFront データ転送量 (Bytes)\u0026#34; region = \u0026#34;us-east-1\u0026#34; metrics = [ [\u0026#34;AWS/CloudFront\u0026#34;, \u0026#34;BytesDownloaded\u0026#34;, \u0026#34;DistributionId\u0026#34;, aws_cloudfront_distribution.main.id, \u0026#34;Region\u0026#34;, \u0026#34;Global\u0026#34;], [\u0026#34;.\u0026#34;, \u0026#34;BytesUploaded\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;.\u0026#34;] ] period = 300 stat = \u0026#34;Sum\u0026#34; } }, # キャッシュヒット率（時系列グラフ） { type = \u0026#34;metric\u0026#34; x = 12 y = 6 width = 12 height = 6 properties = { title = \u0026#34;CloudFront キャッシュヒット率 (%)\u0026#34; region = \u0026#34;us-east-1\u0026#34; metrics = [ [\u0026#34;AWS/CloudFront\u0026#34;, \u0026#34;CacheHitRate\u0026#34;, \u0026#34;DistributionId\u0026#34;, aws_cloudfront_distribution.main.id, \u0026#34;Region\u0026#34;, \u0026#34;Global\u0026#34;] ] period = 300 stat = \u0026#34;Average\u0026#34; } } ] }) } output \u0026#34;cloudwatch_dashboard_url\u0026#34; { description = \u0026#34;CloudWatch Dashboard URL\u0026#34; value = \u0026#34;https://ap-northeast-1.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-1#dashboards:name=${aws_cloudwatch_dashboard.main.dashboard_name}\u0026#34; } :::\nコード解説 # ダッシュボードの構造 # dashboard_body = jsonencode({ widgets = [ { type = \u0026#34;metric\u0026#34; x = 0 # 左端からの位置 y = 0 # 上端からの位置 width = 12 # 幅（最大24） height = 6 # 高さ properties = { # ウィジェットの設定 } } ] }) ダッシュボードはJSON形式で定義します。jsonencode() 関数でHCLからJSONに変換します。\nCloudFrontメトリクスのリージョン # properties = { region = \u0026#34;us-east-1\u0026#34; # ... } CloudFrontはグローバルサービスですが、メトリクスは us-east-1 で取得する必要があります。 これはCloudFrontの仕様です。\nダッシュボードは properties.region で他リージョンのメトリクスを参照できるため、ダッシュボード自体は ap-northeast-1 に作成しても問題ありません。\n4つのウィジェット # ウィジェット メトリクス 用途 リクエスト数 Requests アクセス量の把握 エラー率 4xxErrorRate, 5xxErrorRate エラー発生状況の監視 データ転送量 BytesDownloaded, BytesUploaded 通信量の把握 キャッシュヒット率 CacheHitRate CDNの効率確認 period と stat # 属性 説明 設定値 period メトリクスの集計間隔（秒） 300（5分間隔） stat 集計方法 Sum（合計）、Average（平均） 実行と確認 # terraform apply 出力されたURLでダッシュボードにアクセスし、4つのウィジェットが表示されることを確認します。\n:::message キャッシュヒット率は、アクセスが少ない場合「データがありません」と表示されることがあります。 これは正常です。アクセスが増えると表示されるようになります。 :::\nCloudWatchアラームの作成 # エラー率が閾値を超えた場合にSNS経由でメール通知を送信するアラームを作成します。\ncloudwatch.tf に追記 # :::details cloudwatch.tf に追記（アラーム部分）\n# =========================================== # CloudWatch Alarms # エラー率が閾値を超えたらSNS通知 # us-east-1に作成（CloudFrontメトリクスと同じリージョン） # =========================================== # 5xxエラー率アラーム（サーバーエラー） resource \u0026#34;aws_cloudwatch_metric_alarm\u0026#34; \u0026#34;error_5xx\u0026#34; { provider = aws.us_east_1 alarm_name = \u0026#34;${var.project_name}-5xx-error-rate\u0026#34; alarm_description = \u0026#34;CloudFront 5xxエラー率が1%を超えた場合にアラート\u0026#34; comparison_operator = \u0026#34;GreaterThanThreshold\u0026#34; evaluation_periods = 2 metric_name = \u0026#34;5xxErrorRate\u0026#34; namespace = \u0026#34;AWS/CloudFront\u0026#34; period = 300 statistic = \u0026#34;Average\u0026#34; threshold = 1 treat_missing_data = \u0026#34;notBreaching\u0026#34; dimensions = { DistributionId = aws_cloudfront_distribution.main.id Region = \u0026#34;Global\u0026#34; } alarm_actions = [aws_sns_topic.alerts.arn] ok_actions = [aws_sns_topic.alerts.arn] tags = { Name = \u0026#34;${var.project_name}-5xx-error-rate\u0026#34; } } # 4xxエラー率アラーム（クライアントエラー） resource \u0026#34;aws_cloudwatch_metric_alarm\u0026#34; \u0026#34;error_4xx\u0026#34; { provider = aws.us_east_1 alarm_name = \u0026#34;${var.project_name}-4xx-error-rate\u0026#34; alarm_description = \u0026#34;CloudFront 4xxエラー率が5%を超えた場合にアラート\u0026#34; comparison_operator = \u0026#34;GreaterThanThreshold\u0026#34; evaluation_periods = 2 metric_name = \u0026#34;4xxErrorRate\u0026#34; namespace = \u0026#34;AWS/CloudFront\u0026#34; period = 300 statistic = \u0026#34;Average\u0026#34; threshold = 5 treat_missing_data = \u0026#34;notBreaching\u0026#34; dimensions = { DistributionId = aws_cloudfront_distribution.main.id Region = \u0026#34;Global\u0026#34; } alarm_actions = [aws_sns_topic.alerts.arn] ok_actions = [aws_sns_topic.alerts.arn] tags = { Name = \u0026#34;${var.project_name}-4xx-error-rate\u0026#34; } } :::\nコード解説 # アラームの主要設定 # resource \u0026#34;aws_cloudwatch_metric_alarm\u0026#34; \u0026#34;error_5xx\u0026#34; { provider = aws.us_east_1 # us-east-1に作成 comparison_operator = \u0026#34;GreaterThanThreshold\u0026#34; # 閾値を超えたらアラート evaluation_periods = 2 # 2回連続で閾値超過したらアラート period = 300 # 5分間隔で評価 threshold = 1 # 1%を閾値とする treat_missing_data = \u0026#34;notBreaching\u0026#34; # データなしは正常扱い } 属性 説明 provider リソースを作成するリージョン（us-east-1必須） evaluation_periods 何回連続で閾値超過したらアラートにするか treat_missing_data データがない場合の扱い :::message alert provider = aws.us_east_1 を指定しないと、CloudWatch AlarmがCloudFrontメトリクスを取得できず、アラームが機能しません。 :::\n:::message evaluation_periods = 2 とすることで、一時的なスパイクでアラートが発火するのを防ぎます。 :::\n閾値の設定根拠 # アラーム 閾値 根拠 5xxエラー率 1% サーバーエラーは重大。低い閾値で早期検知 4xxエラー率 5% 404等のクライアントエラーは一定量発生するため緩めに設定 通知アクション # alarm_actions = [aws_sns_topic.alerts.arn] # アラート発火時 ok_actions = [aws_sns_topic.alerts.arn] # アラート解消時 ok_actions を設定することで、アラートが解消した際にも通知を受け取れます。\n実行 # terraform apply AWS Budgetsの設定 # 月額コストが閾値を超えた場合にメール通知を送信します。\nbudgets.tf # budgets.tf を新規作成します。\n# =========================================== # AWS Budgets # 月額コストが閾値を超えたらメール通知 # =========================================== resource \u0026#34;aws_budgets_budget\u0026#34; \u0026#34;monthly\u0026#34; { name = \u0026#34;${var.project_name}-monthly-budget\u0026#34; budget_type = \u0026#34;COST\u0026#34; limit_amount = \u0026#34;5\u0026#34; limit_unit = \u0026#34;USD\u0026#34; time_unit = \u0026#34;MONTHLY\u0026#34; # 80%到達で通知 notification { comparison_operator = \u0026#34;GREATER_THAN\u0026#34; threshold = 80 threshold_type = \u0026#34;PERCENTAGE\u0026#34; notification_type = \u0026#34;ACTUAL\u0026#34; subscriber_email_addresses = [var.alert_email] } # 100%到達で通知 notification { comparison_operator = \u0026#34;GREATER_THAN\u0026#34; threshold = 100 threshold_type = \u0026#34;PERCENTAGE\u0026#34; notification_type = \u0026#34;ACTUAL\u0026#34; subscriber_email_addresses = [var.alert_email] } # 予測で100%超過しそうな場合に通知 notification { comparison_operator = \u0026#34;GREATER_THAN\u0026#34; threshold = 100 threshold_type = \u0026#34;PERCENTAGE\u0026#34; notification_type = \u0026#34;FORECASTED\u0026#34; subscriber_email_addresses = [var.alert_email] } } コード解説 # 予算設定 # limit_amount = \u0026#34;5\u0026#34; # $5/月 limit_unit = \u0026#34;USD\u0026#34; time_unit = \u0026#34;MONTHLY\u0026#34; 月額$5を予算として設定します。個人ブログであれば十分な金額です。\n3種類の通知 # 通知タイプ 閾値 意味 ACTUAL 80% $4 予算の80%に到達したら警告 ACTUAL 100% $5 予算を超過したら通知 FORECASTED 100% $5（予測） 月末に予算超過しそうなら早期警告 FORECASTED を設定することで、月初の段階で「このペースだと予算超過しそう」という警告を受け取れます。\n実行 # terraform apply 動作確認 # 作成したリソースの確認 # terraform output 以下が出力されることを確認します。\nsns_topic_arn = \u0026#34;arn:aws:sns:us-east-1:123456789012:hugo-s3-demo-alerts\u0026#34; cloudwatch_dashboard_url = \u0026#34;https://ap-northeast-1.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-1#dashboards:name=hugo-s3-demo-dashboard\u0026#34; AWSコンソールでの確認 # CloudWatchダッシュボード\n4つのウィジェットが表示されている メトリクスデータが表示されている（アクセスがあれば） CloudWatchアラーム（us-east-1リージョンで確認）\n2つのアラームが「OK」状態になっている AWS Budgets\n予算が作成されている 現在のコストが表示されている トラブルシューティング # SNS購読確認メールが届かない # 確認ポイント:\n迷惑メールフォルダを確認 メールアドレスが正しいか確認（terraform.tfvars） Terraformの実行が成功しているか確認 対処法: 購読を再作成する\nterraform destroy -target=aws_sns_topic_subscription.email terraform apply アラームが「INSUFFICIENT_DATA」のまま（アクセスなし） # 原因: CloudFrontにアクセスがなく、メトリクスデータがない\n対処法: サイトに何度かアクセスしてメトリクスを生成する。treat_missing_data = \u0026quot;notBreaching\u0026quot; を設定していれば、データがなくてもアラートは発火しません。\nアラームが「INSUFFICIENT_DATA」のまま（リージョン問題） # 原因: SNSトピックやCloudWatch Alarmを ap-northeast-1 に作成している\nCloudFrontメトリクスは us-east-1 にのみ存在するため、他リージョンのCloudWatch Alarmからは参照できません。\n確認方法:\n# アラームのリージョンを確認 aws cloudwatch describe-alarms \\ --alarm-names \u0026#34;hugo-s3-demo-5xx-error-rate\u0026#34; \\ --region us-east-1 \\ --query \u0026#39;MetricAlarms[0].StateValue\u0026#39; 対処法:\nmain.tf に us-east-1 provider を追加 SNSとAlarmに provider = aws.us_east_1 を指定 terraform apply でリソースを再作成 State lockエラー # 症状:\nError: Error acquiring the state lock Lock Info: ID: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx 原因: 前回の操作のロックが残っている\n対処法:\nterraform force-unlock {LOCK_ID} :::message alert force-unlock は、他の人が操作中でないことを確認してから実行してください。 :::\nまとめ # 本記事では、以下を構築しました。\nSNS: アラート通知の送信先（us-east-1） CloudWatchダッシュボード: リクエスト数、エラー率、キャッシュヒット率の可視化 CloudWatchアラーム: 5xxエラー率1%、4xxエラー率5%で通知（us-east-1） AWS Budgets: 月額$5の予算、80%/100%/予測100%で通知 作成したリソース # リソース リージョン 用途 SNS Topic us-east-1 通知の送信先 SNS Subscription us-east-1 メール通知設定 CloudWatch Dashboard ap-northeast-1 メトリクス可視化（4ウィジェット） CloudWatch Alarm (5xx) us-east-1 5xxエラー率監視 CloudWatch Alarm (4xx) us-east-1 4xxエラー率監視 AWS Budgets グローバル コスト監視 監視のポイント # 項目 設定値 理由 リージョン us-east-1 CloudFrontメトリクスはus-east-1固定 5xxエラー閾値 1% サーバーエラーは重大なため低めに 4xxエラー閾値 5% 404等は一定量発生するため緩めに evaluation_periods 2 一時的なスパイクを除外 treat_missing_data notBreaching データなしは正常扱い 参考資料 # Amazon SNS - AWS公式 Amazon CloudWatch - AWS公式 AWS Budgets - AWS公式 Terraform aws_sns_topic Terraform aws_cloudwatch_dashboard Terraform aws_cloudwatch_metric_alarm ","date":"2025年 12月 30日","externalUrl":null,"permalink":"/posts/251230211232_hugoawscloudwatch+sns%E3%81%A7%E7%9B%A3%E8%A6%96%E3%82%A2%E3%83%A9%E3%83%BC%E3%83%88%E9%80%9A%E7%9F%A5/","section":"Posts","summary":"","title":"【Hugo×AWS】CloudWatch+SNSで監視・アラート通知","type":"posts"},{"content":" はじめに # この記事では、GitHub Actionsを使ってHugoブログをAWS（S3 + CloudFront）に自動デプロイする方法を解説します。 OIDC（OpenID Connect）認証を使用することで、アクセスキーを保存せずにセキュアなデプロイ環境を構築します。\nこの記事で構築するもの # mainブランチへのpushで自動的にS3へデプロイ CloudFrontのキャッシュ自動無効化 OIDC認証による安全なAWS認証 想定する読者 # 前回の記事でS3 + CloudFront環境を構築済みの方 GitHub Actionsを使ったCI/CDに興味がある方 アクセスキーを使わない安全なデプロイ方法を知りたい方 完成イメージ # mainブランチにpushするだけで、以下が自動実行されます。\nHugoでサイトをビルド S3にコンテンツをアップロード CloudFrontのキャッシュを無効化 デプロイ完了まで約40秒です。\nシリーズ全体像 # 【Hugo×AWS】シリーズ全体で5記事投稿予定です。今回の記事は2本目です。\n# タイトル 内容 1 Hugo + S3 + CloudFrontで技術ブログを公開する Hugo環境構築〜手動デプロイまで 2 GitHub Actions + OIDCで自動デプロイ CI/CD構築、アクセスキー不要の認証 3 CloudWatch + SNSで監視・アラート通知 ダッシュボード、エラー率アラーム 4 Athenaでアクセスログを分析する CloudFrontログのSQL分析 5 独自ドメインを設定する（Route53 + ACM） カスタムドメイン、HTTPS なぜOIDC認証を使うのか # GitHub ActionsからAWSにアクセスする方法は主に2つあります。\n方式 セキュリティ 管理コスト AWS/GitHub推奨 OIDC認証 ◎ 一時認証情報、15分で期限切れ ◎ ローテーション不要 ✅ 推奨 アクセスキー △ 漏洩で永続的アクセスのリスク △ 定期的なローテーション必要 - OIDC認証のメリット # アクセスキー不要: GitHubシークレットにAWSの認証情報を保存しない 自動期限切れ: 一時認証情報は15分で失効、漏洩しても被害が限定的 細かい権限制御: リポジトリ名・ブランチ名で認証を制限可能 AWSとGitHubの公式ドキュメントでもOIDC認証が推奨されています。\n前提条件 # 必要な環境 # 本記事は、前回の記事で以下が構築済みであることを前提としています。\nS3バケット（コンテンツ用） CloudFront Distribution Terraformプロジェクト 必要な情報 # Terraformの出力値から以下を確認してください。\ncd hugo-s3-demo-infra/prod terraform output s3_bucket_name = \u0026#34;hugo-s3-demo-content-xxxxxxxx\u0026#34; cloudfront_distribution_id = \u0026#34;E2XXXXXXXXXX\u0026#34; OIDC認証の仕組み # 実装に入る前に、OIDC認証の仕組みを理解しておきましょう。\n┌─────────────────┐ │ GitHub Actions │ └────────┬────────┘ │ ① OIDCトークンを要求 ▼ ┌─────────────────┐ │ GitHub OIDC │ │ Provider │ └────────┬────────┘ │ ② トークン発行 ▼ ┌─────────────────┐ │ AWS STS │ │ (Security │ │ Token Service)│ └────────┬────────┘ │ ③ トークンを検証 │ ④ IAMロールの信頼ポリシーを確認 │ ⑤ 一時認証情報を発行 ▼ ┌─────────────────┐ │ GitHub Actions │ │ (S3/CloudFront │ │ にアクセス) │ └─────────────────┘ ステップ 処理内容 ① GitHub ActionsがOIDCトークンを要求 ② GitHubがJWTトークンを発行（リポジトリ名、ブランチ名を含む） ③ AWS OIDC ProviderがGitHubの公開鍵でトークンを検証 ④ IAMロールの信頼ポリシーで、リポジトリ名・ブランチ名が一致するか確認 ⑤ 条件を満たせば、15分間有効な一時認証情報を発行 ポイントは、AWSにアクセスキーを渡さず、GitHubが発行するトークンで認証することです。\nIAMリソースの作成 # ディレクトリ構成 # 前回の記事で作成したTerraformプロジェクトに iam.tf を追加します。\nhugo-s3-demo-infra/ └── prod/ ├── versions.tf ├── backend.tf ├── variables.tf ├── main.tf ├── outputs.tf └── iam.tf ← 新規作成 iam.tf # OIDC Provider、IAMロール、IAMポリシーを作成します。\n:::details iam.tf の全体\n# =========================================== # GitHub OIDC Provider # =========================================== resource \u0026#34;aws_iam_openid_connect_provider\u0026#34; \u0026#34;github\u0026#34; { url = \u0026#34;https://token.actions.githubusercontent.com\u0026#34; client_id_list = [\u0026#34;sts.amazonaws.com\u0026#34;] thumbprint_list = [\u0026#34;ffffffffffffffffffffffffffffffffffffffff\u0026#34;] tags = { Name = \u0026#34;${var.project_name}-github-oidc\u0026#34; } } # =========================================== # GitHub Actions用IAMロール # =========================================== resource \u0026#34;aws_iam_role\u0026#34; \u0026#34;github_actions\u0026#34; { name = \u0026#34;${var.project_name}-github-actions-role\u0026#34; assume_role_policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34; Statement = [ { Effect = \u0026#34;Allow\u0026#34; Principal = { Federated = aws_iam_openid_connect_provider.github.arn } Action = \u0026#34;sts:AssumeRoleWithWebIdentity\u0026#34; Condition = { StringEquals = { \u0026#34;token.actions.githubusercontent.com:aud\u0026#34; = \u0026#34;sts.amazonaws.com\u0026#34; } StringLike = { \u0026#34;token.actions.githubusercontent.com:sub\u0026#34; = \u0026#34;repo:YOUR_GITHUB_USERNAME/YOUR_REPO_NAME:ref:refs/heads/main\u0026#34; } } } ] }) } # =========================================== # GitHub Actions用IAMポリシー # =========================================== resource \u0026#34;aws_iam_role_policy\u0026#34; \u0026#34;github_actions\u0026#34; { name = \u0026#34;${var.project_name}-github-actions-policy\u0026#34; role = aws_iam_role.github_actions.id policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34; Statement = [ { Sid = \u0026#34;S3Deploy\u0026#34; Effect = \u0026#34;Allow\u0026#34; Action = [ \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34; ] Resource = [ aws_s3_bucket.content.arn, \u0026#34;${aws_s3_bucket.content.arn}/*\u0026#34; ] }, { Sid = \u0026#34;CloudFrontInvalidation\u0026#34; Effect = \u0026#34;Allow\u0026#34; Action = [ \u0026#34;cloudfront:CreateInvalidation\u0026#34;, \u0026#34;cloudfront:GetInvalidation\u0026#34; ] Resource = aws_cloudfront_distribution.main.arn } ] }) } :::\n:::message alert YOUR_GITHUB_USERNAME/YOUR_REPO_NAME は、ご自身のGitHubユーザー名とリポジトリ名に置き換えてください。 :::\nコード解説 # OIDC Provider # resource \u0026#34;aws_iam_openid_connect_provider\u0026#34; \u0026#34;github\u0026#34; { url = \u0026#34;https://token.actions.githubusercontent.com\u0026#34; client_id_list = [\u0026#34;sts.amazonaws.com\u0026#34;] thumbprint_list = [\u0026#34;ffffffffffffffffffffffffffffffffffffffff\u0026#34;] } 属性 説明 url GitHubのOIDCプロバイダーURL client_id_list 対象のオーディエンス（AWS STSを指定） thumbprint_list 証明書のサムプリント（後述） :::details thumbprintについて\n2023年7月以降、AWSはGitHub OIDCの証明書を自動検証するようになりました。 そのため、thumbprint_list には任意の40文字の16進数を設定しても動作します。 以前は正確なthumbprintの取得が必要でしたが、現在は省略可能です。\n参考: GitHub Actions の OIDC トークンを使用した AWS へのアクセス\n:::\nIAMロールの信頼ポリシー # assume_role_policy = jsonencode({ # ...省略... Condition = { StringEquals = { \u0026#34;token.actions.githubusercontent.com:aud\u0026#34; = \u0026#34;sts.amazonaws.com\u0026#34; } StringLike = { \u0026#34;token.actions.githubusercontent.com:sub\u0026#34; = \u0026#34;repo:YOUR_GITHUB_USERNAME/YOUR_REPO_NAME:ref:refs/heads/main\u0026#34; } } }) Condition 意味 aud = \u0026quot;sts.amazonaws.com\u0026quot; AWS STSに対するトークンであることを確認 sub = \u0026quot;repo:xxx:ref:refs/heads/main\u0026quot; 特定のリポジトリのmainブランチからのリクエストのみ許可 :::message なぜmainブランチに限定するのか？\n* （ワイルドカード）にすると、任意のブランチやPull Requestからデプロイ可能になります。 悪意のあるPRがマージされる前にデプロイされるリスクがあるため、本番環境へのデプロイはmainブランチのみに制限するのがベストプラクティスです。 :::\nIAMポリシー（最小権限設計） # policy = jsonencode({ Statement = [ { Sid = \u0026#34;S3Deploy\u0026#34; Action = [ \u0026#34;s3:PutObject\u0026#34;, # ファイルアップロード \u0026#34;s3:GetObject\u0026#34;, # sync時の比較に必要 \u0026#34;s3:DeleteObject\u0026#34;, # --deleteオプション用 \u0026#34;s3:ListBucket\u0026#34; # バケット内一覧取得 ] Resource = [ aws_s3_bucket.content.arn, # バケット自体 \u0026#34;${aws_s3_bucket.content.arn}/*\u0026#34; # バケット内オブジェクト ] }, { Sid = \u0026#34;CloudFrontInvalidation\u0026#34; Action = [ \u0026#34;cloudfront:CreateInvalidation\u0026#34;, # キャッシュ無効化 \u0026#34;cloudfront:GetInvalidation\u0026#34; # 無効化ステータス確認 ] Resource = aws_cloudfront_distribution.main.arn } ] }) ポイントは以下の2点です。\n最小権限の原則: デプロイに必要な権限のみを付与 リソース制限: 特定のS3バケット・CloudFront Distributionのみに権限を制限 outputs.tf に追記 # GitHub Actionsで使用するIAMロールのARNを出力します。\noutput \u0026#34;github_actions_role_arn\u0026#34; { value = aws_iam_role.github_actions.arn } 実行 # terraform plan terraform apply 出力値をメモしておいてください。\ngithub_actions_role_arn = \u0026#34;arn:aws:iam::123456789012:role/hugo-s3-demo-github-actions-role\u0026#34; GitHub Actionsの設定 # ワークフローファイルの作成 # Hugoプロジェクトに .github/workflows/deploy.yml を作成します。\nhugo-s3-demo/ ├── .github/ │ └── workflows/ │ └── deploy.yml ← 新規作成 ├── content/ ├── themes/ └── hugo.toml deploy.yml # :::details deploy.yml の全体\nname: Deploy to AWS on: push: branches: - main workflow_dispatch: permissions: id-token: write contents: read env: AWS_REGION: ap-northeast-1 S3_BUCKET: hugo-s3-demo-content-xxxxxxxx # terraform outputの値に置き換え CLOUDFRONT_DISTRIBUTION_ID: E2XXXXXXXXXX # terraform outputの値に置き換え jobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v4 with: submodules: true - name: Setup Hugo uses: peaceiris/actions-hugo@v3 with: hugo-version: \u0026#39;latest\u0026#39; extended: true - name: Build run: hugo --minify - name: Configure AWS Credentials uses: aws-actions/configure-aws-credentials@v4 with: role-to-assume: arn:aws:iam::123456789012:role/hugo-s3-demo-github-actions-role # terraform outputの値に置き換え aws-region: ${{ env.AWS_REGION }} - name: Deploy to S3 run: aws s3 sync public/ s3://${{ env.S3_BUCKET }}/ --delete - name: Invalidate CloudFront Cache run: | aws cloudfront create-invalidation \\ --distribution-id ${{ env.CLOUDFRONT_DISTRIBUTION_ID }} \\ --paths \u0026#34;/*\u0026#34; :::\n:::message alert 以下の3箇所を、terraform output で確認した値に置き換えてください。\nS3_BUCKET CLOUDFRONT_DISTRIBUTION_ID role-to-assume ::: コード解説 # トリガー設定 # on: push: branches: - main workflow_dispatch: 設定 意味 push: branches: - main mainブランチへのpush時に実行 workflow_dispatch: GitHub UIからの手動実行も可能にする パーミッション設定 # permissions: id-token: write contents: read 権限 意味 なぜ必要か id-token: write OIDCトークンの発行を許可 AWS認証に必須 contents: read リポジトリの読み取りを許可 コードをcheckoutするため :::message id-token: write がないとOIDC認証が失敗します。 :::\nステップ詳細 # 1. Checkout\n- name: Checkout uses: actions/checkout@v4 with: submodules: true リポジトリのコードを取得 submodules: true でHugoテーマ（gitサブモジュール）も取得 2. Setup Hugo\n- name: Setup Hugo uses: peaceiris/actions-hugo@v3 with: hugo-version: \u0026#39;latest\u0026#39; extended: true Hugo extended版をインストール extended: true でSCSS対応版を使用 3. Build\n- name: Build run: hugo --minify --minify でHTML/CSS/JSを圧縮 public/ ディレクトリに静的ファイルが生成される 4. Configure AWS Credentials\n- name: Configure AWS Credentials uses: aws-actions/configure-aws-credentials@v4 with: role-to-assume: arn:aws:iam::123456789012:role/hugo-s3-demo-github-actions-role aws-region: ${{ env.AWS_REGION }} AWS公式のアクション OIDCトークンを使ってIAMロールを引き受ける アクセスキーは不要 5. Deploy to S3\n- name: Deploy to S3 run: aws s3 sync public/ s3://${{ env.S3_BUCKET }}/ --delete sync で差分のみ転送（効率的） --delete でローカルにないファイルをS3から削除 6. Invalidate CloudFront Cache\n- name: Invalidate CloudFront Cache run: | aws cloudfront create-invalidation \\ --distribution-id ${{ env.CLOUDFRONT_DISTRIBUTION_ID }} \\ --paths \u0026#34;/*\u0026#34; CloudFrontのエッジキャッシュを無効化 /* で全パスを対象 :::message キャッシュ無効化は月1,000パスまで無料です。 /* で全ファイルを無効化すると1パスとしてカウントされます。 :::\n動作確認 # 1. ワークフローをコミット・プッシュ # cd hugo-s3-demo git add .github/workflows/deploy.yml git commit -m \u0026#34;Add GitHub Actions workflow for deployment\u0026#34; git push origin main 2. GitHub Actionsの実行を確認 # GitHubリポジトリの「Actions」タブで、ワークフローの実行状況を確認します。\n確認ポイント：\n全ステップが緑色（成功）になっている 実行時間が1分以内 3. サイトの更新を確認 # 記事を編集してpushし、自動デプロイを確認します。\n# 記事を編集 vim content/posts/first-post.md # コミット・プッシュ git add . git commit -m \u0026#34;Update first post\u0026#34; git push origin main ブラウザでサイトにアクセスし、変更が反映されていることを確認します。\nセキュリティのポイント # 本記事で構築した環境のセキュリティポイントをまとめます。\n1. OIDC認証 # 観点 従来方式（アクセスキー） 本記事の方式（OIDC） 認証情報の保存 GitHubシークレットに保存が必要 保存不要 有効期限 無期限（手動ローテーション） 15分（自動期限切れ） 漏洩リスク 高（永続的なアクセス） 低（短命で再利用不可） 2. ブランチ制限 # \u0026#34;token.actions.githubusercontent.com:sub\u0026#34; = \u0026#34;repo:xxx/xxx:ref:refs/heads/main\u0026#34; mainブランチからのリクエストのみを許可し、不正なデプロイを防止しています。\n3. 最小権限のIAMポリシー # デプロイに必要な最小限の権限のみを付与し、特定のリソースのみに制限しています。\n権限 用途 s3:PutObject, s3:GetObject, s3:DeleteObject, s3:ListBucket S3へのコンテンツデプロイ cloudfront:CreateInvalidation, cloudfront:GetInvalidation キャッシュ無効化 トラブルシューティング # OIDC認証が失敗する # 症状: Error: Could not assume role with OIDC などのエラー\n確認ポイント:\nIAMロールの信頼ポリシー\nリポジトリ名が正確か（repo:username/repo-name の形式） ブランチ名が一致しているか（refs/heads/main） GitHub Actionsのパーミッション\npermissions: id-token: write が設定されているか AWS OIDC Provider\nurl が https://token.actions.githubusercontent.com になっているか デプロイは成功したが反映されない # 症状: GitHub Actionsは成功しているが、サイトに変更が反映されない\n確認ポイント:\nCloudFrontキャッシュ\nAWS ConsoleでInvalidationの状態を確認（Completedになっているか） ブラウザキャッシュ\nシークレットウィンドウで確認、またはキャッシュをクリア S3バケット\nAWS Consoleで、正しくファイルがアップロードされているか確認 S3へのアクセスが拒否される # 症状: Access Denied エラー\n確認ポイント:\nIAMポリシーのリソース\nS3バケット名が正しいか arn:aws:s3:::bucket-name と arn:aws:s3:::bucket-name/* の両方が指定されているか S3バケットの権限\nバケットポリシーでIAMロールからのアクセスがブロックされていないか まとめ # 本記事では、以下を構築しました。\nGitHub Actions: mainブランチへのpushで自動デプロイ OIDC認証: アクセスキー不要の安全な認証 IAMロール/ポリシー: 最小権限の原則に基づいた設計 作成したリソース # リソース 用途 OIDC Provider GitHubとAWSの信頼関係を構築 IAM Role GitHub Actionsが引き受けるロール IAM Policy S3デプロイ、CloudFrontキャッシュ無効化の権限 デプロイフロー # git push (main) ↓ GitHub Actions起動 ↓ Hugo Build (約10秒) ↓ OIDC認証 → IAMロール引き受け ↓ S3 Sync (差分のみ) ↓ CloudFront Cache Invalidation ↓ デプロイ完了 (合計約40秒) 参考資料 # GitHub Actions OIDC + AWS AWS IAM OIDC Provider peaceiris/actions-hugo aws-actions/configure-aws-credentials Terraform aws_iam_openid_connect_provider ","date":"2025年 12月 30日","externalUrl":null,"permalink":"/posts/251230211150_hugoawsgithub_actions+oidc%E3%81%A7%E8%87%AA%E5%8B%95%E3%83%87%E3%83%97%E3%83%AD%E3%82%A4/","section":"Posts","summary":"","title":"【Hugo×AWS】GitHub_Actions+OIDCで自動デプロイ","type":"posts"},{"content":" はじめに # この記事では、Hugoで作成した静的サイトをAWS（S3 + CloudFront）でホスティングする方法を解説します。 Terraformを使ってインフラをコード化し、手動デプロイまでを行います。\n想定する読者 # AWSを使って静的サイトをホスティングしたい方 Terraformでインフラをコード化したい方 AWS初心者〜中級者 Terraformを初めて使う方へ # 本記事ではTerraformの基本的な使い方（terraform init/plan/applyの意味、HCL構文等）は省略しています。初めての方はHashiCorp公式チュートリアルを先に確認することをお勧めします。\n完成イメージ # 本記事の完了後、CloudFrontのデフォルトドメイン（https://dxxxxx.cloudfront.net）でブログにアクセスできるようになります。 CloudFrontからS3へのアクセスにはOAC（Origin Access Control）を使用し、S3バケットへの直接アクセスを禁止します。 シリーズ全体像 # 【Hugo×AWS】シリーズ全体で5記事投稿予定です。今回の記事は1本目です。\n# タイトル 内容 1 Hugo + S3 + CloudFrontで技術ブログを公開する Hugo環境構築〜手動デプロイまで 2 GitHub Actions + OIDCで自動デプロイ CI/CD構築、アクセスキー不要の認証 3 CloudWatch + SNSで監視・アラート通知 ダッシュボード、エラー率アラーム 4 Athenaでアクセスログを分析する CloudFrontログのSQL分析 5 独自ドメインを設定する（Route53 + ACM） カスタムドメイン、HTTPS なぜS3 + CloudFrontで構築するのか # 静的サイトのホスティング方法として、以下を比較検討しました。\n選択肢 コスト（月額） 管理負担 IaC化 S3 + CloudFront 100〜170円 ※1 なし ◎ EC2 + Nginx 1,500円〜 OS管理必要 ○ Lightsail 500円〜 OS管理必要 △ Amplify Hosting 無料枠あり なし × ※1 個人ブログ規模の予想値となります。おおよそのコスト感としてとらえてください。\nS3 + CloudFrontを選んだ理由 # コスト効率：静的サイトに最適、月額100円台 運用負担ゼロ：サーバーレスでOS管理不要 Terraform対応：全リソースをコードで管理可能 高可用性：S3のSLA 99.99% 高速配信：CloudFrontのエッジキャッシュ セキュリティ：OAC（Origin Access Control）でS3への直接アクセスを禁止 EC2/Lightsailは静的サイトにはオーバースペックで、Amplifyは便利だがTerraformで管理できないため見送りました。\n前提条件 # 構築環境 # 本記事は以下の環境で構築しています。\nOS: Ubuntu 24.04（Docker） Hugo: v0.152.2 extended Terraform: v1.14.2 AWS CLI: v2.32.16 必要なツール # 以下のツールがインストールされていることを確認してください。\nツール バージョン 公式ドキュメント AWS CLI v2 インストールガイド Terraform 1.0以上 インストールガイド Git - インストールガイド Hugo - インストールガイド AWSアカウントが必要です。ルートユーザーではなく、IAMユーザーでの操作を推奨します。\n:::details 参考用：自分が実際に実行したコマンド\nAWS CLI # curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install Terraform # sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y gnupg lsb-release wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg echo \u0026#34;deb [arch=amd64 signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\u0026#34; | sudo tee /etc/apt/sources.list.d/hashicorp.list sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y terraform Hugo # # 最新バージョンを確認 curl -s https://api.github.com/repos/gohugoio/hugo/releases/latest | grep \u0026#34;tag_name\u0026#34; # extended版をダウンロード・インストール wget https://github.com/gohugoio/hugo/releases/download/v0.152.2/hugo_extended_0.152.2_linux-amd64.deb sudo dpkg -i hugo_extended_0.152.2_linux-amd64.deb Git # 最初からインストール済みのため対応不要でした。\n:::\nAWS CLIの認証情報を設定していない場合は、以下のコマンドで設定してください。\naws configure プロンプトに従って入力します。\nAWS Access Key ID [None]: {IAMユーザーのアクセスキーを入力} AWS Secret Access Key [None]: {IAMユーザーのシークレットアクセスキーを入力} Default region name [None]: ap-northeast-1 Default output format [None]: json 確認コマンド # aws --version terraform --version git --version hugo version aws sts get-caller-identity # AWS認証情報の確認 Hugoセットアップ # 作業ディレクトリ構成 # 本記事では以下のディレクトリ構成で作業します。\n作業ディレクトリ/ ├── hugo-s3-demo/ # Hugoプロジェクト └── hugo-s3-demo-infra/ # Terraformプロジェクト ├── backend-setup/ └── prod/ サイト作成 # hugo new site hugo-s3-demo cd hugo-s3-demo テーマ追加 # Anankeテーマ（Hugo公式チュートリアルでも採用）を追加します。 git submoduleを使うことで、テーマの更新管理が容易になります。\ngit init git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke hugo.toml編集 # hugo.toml を編集してテーマを有効化します。\nbaseURL = \u0026#39;https://example.org/\u0026#39; languageCode = \u0026#39;en-us\u0026#39; title = \u0026#39;Hugo S3 Demo\u0026#39; theme = \u0026#39;ananke\u0026#39; baseURL は後でCloudFrontのドメインに変更します。\n最初の記事作成 # hugo new content posts/first-post.md 作成されたファイルを編集し、draft = false に変更して公開状態にします。\n+++ date = \u0026#39;2025-12-14T14:59:51Z\u0026#39; draft = false title = \u0026#39;First Post\u0026#39; +++ これは最初の投稿です。 ビルド確認 # # Hugoでビルド実行 hugo # `public/` ディレクトリにHTMLファイルが生成されていればOK ls public/ # 404.html ananke categories images index.html index.xml posts sitemap.xml tags ローカルでプレビューしたい場合 # hugo server http://localhost:1313/ でプレビューできます。Ctrl+C で停止します。\nTerraform state管理の準備 # Terraformとは # TerraformはHashiCorpが開発したInfrastructure as Code（IaC）ツールです。 Go言語で実装されたOSSで、AWS・Azure・GCPなどのクラウドインフラをコードとして記述・管理できます。\n本記事では、TerraformでS3バケットやCloudFrontディストリビューションを定義して、AWS環境を構築します。\nTerraformを使うメリット # 宣言的な記述 - 「こうなってほしい」状態を書くだけで構築できる スピードと安全性 - デプロイの自動化で高速かつ繰り返し実行可能 ドキュメント化 - コード自体がインフラ構成のドキュメントになる バージョン管理 - Gitでインフラの変更履歴を追跡できる 再利用性 - 実績あるコードを再利用できる VSCode拡張機能（推奨） # Terraformのコードを書く際は、VSCode拡張機能「HashiCorp Terraform」のインストールを推奨します。シンタックスハイライト、自動補完、フォーマットなどが利用できます。 マーケットプレイスへのリンク\nなぜ先にstate管理環境を作るのか # Terraformはインフラの状態を「tfstate」というファイルで管理します。 このファイルをS3に保存し、チームで共有・ロック管理します。 tfstateによってTerraformのステータスなどを管理するので、 本体のインフラ環境とは別ディレクトリで先に作成します\ntfstateを保存するS3バケットが必要 そのS3バケットをTerraformで作りたい でもTerraform実行前にbackend（S3）が存在している必要がある →　最初にtfstate管理環境を構築する ディレクトリ構成 # hugo-s3-demo-infra/ └── backend-setup/ └── main.tf backend-setup/ でtfstate管理用のリソースを作成します。\nmkdir -p hugo-s3-demo-infra/backend-setup cd hugo-s3-demo-infra/backend-setup backend-setup/main.tf # :::details 以下がmain.tfの全体となります。\nterraform { required_version = \u0026#34;\u0026gt;= 1.0\u0026#34; required_providers { aws = { source = \u0026#34;hashicorp/aws\u0026#34; version = \u0026#34;~\u0026gt; 5.0\u0026#34; } random = { source = \u0026#34;hashicorp/random\u0026#34; version = \u0026#34;~\u0026gt; 3.0\u0026#34; } } } provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } resource \u0026#34;random_id\u0026#34; \u0026#34;suffix\u0026#34; { byte_length = 4 } resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;tfstate\u0026#34; { bucket = \u0026#34;hugo-s3-demo-tfstate-${random_id.suffix.hex}\u0026#34; } resource \u0026#34;aws_s3_bucket_versioning\u0026#34; \u0026#34;tfstate\u0026#34; { bucket = aws_s3_bucket.tfstate.id versioning_configuration { status = \u0026#34;Enabled\u0026#34; } } resource \u0026#34;aws_s3_bucket_server_side_encryption_configuration\u0026#34; \u0026#34;tfstate\u0026#34; { bucket = aws_s3_bucket.tfstate.id rule { apply_server_side_encryption_by_default { sse_algorithm = \u0026#34;AES256\u0026#34; } } } resource \u0026#34;aws_s3_bucket_public_access_block\u0026#34; \u0026#34;tfstate\u0026#34; { bucket = aws_s3_bucket.tfstate.id block_public_acls = true block_public_policy = true ignore_public_acls = true restrict_public_buckets = true } resource \u0026#34;aws_dynamodb_table\u0026#34; \u0026#34;tfstate_lock\u0026#34; { name = \u0026#34;hugo-s3-demo-tfstate-lock\u0026#34; billing_mode = \u0026#34;PAY_PER_REQUEST\u0026#34; hash_key = \u0026#34;LockID\u0026#34; attribute { name = \u0026#34;LockID\u0026#34; type = \u0026#34;S\u0026#34; } } output \u0026#34;s3_bucket_name\u0026#34; { value = aws_s3_bucket.tfstate.bucket } output \u0026#34;dynamodb_table_name\u0026#34; { value = aws_dynamodb_table.tfstate_lock.name } :::\nコード解説 # terraform / provider ブロック # terraform { required_version = \u0026#34;\u0026gt;= 1.0\u0026#34; required_providers { # AWSリソースを作成するためのプロバイダー aws = { source = \u0026#34;hashicorp/aws\u0026#34; version = \u0026#34;~\u0026gt; 5.0\u0026#34; } # ランダム文字列を生成するためのプロバイダー random = { source = \u0026#34;hashicorp/random\u0026#34; version = \u0026#34;~\u0026gt; 3.0\u0026#34; } } } provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; # 東京リージョン } terraform ブロック：Terraformのバージョンと使用するプロバイダーを指定 provider ブロック：AWSリージョンを東京（ap-northeast-1）に設定 random_id # # S3バケット名の一意性を確保するためのランダム文字列 resource \u0026#34;random_id\u0026#34; \u0026#34;suffix\u0026#34; { byte_length = 4 # 8文字の16進数を生成 } S3バケット名はグローバルで一意である必要があります。 random_id でランダムな文字列を生成し、バケット名の末尾に付与します。\nS3バケット # # tfstate保存用バケット resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;tfstate\u0026#34; { bucket = \u0026#34;hugo-s3-demo-tfstate-${random_id.suffix.hex}\u0026#34; } # バージョニング有効化（誤操作時に復元可能） resource \u0026#34;aws_s3_bucket_versioning\u0026#34; \u0026#34;tfstate\u0026#34; { bucket = aws_s3_bucket.tfstate.id versioning_configuration { status = \u0026#34;Enabled\u0026#34; } } # サーバーサイド暗号化（tfstateには機密情報が含まれる可能性がある） resource \u0026#34;aws_s3_bucket_server_side_encryption_configuration\u0026#34; \u0026#34;tfstate\u0026#34; { bucket = aws_s3_bucket.tfstate.id rule { apply_server_side_encryption_by_default { sse_algorithm = \u0026#34;AES256\u0026#34; } } } # パブリックアクセスを完全ブロック resource \u0026#34;aws_s3_bucket_public_access_block\u0026#34; \u0026#34;tfstate\u0026#34; { bucket = aws_s3_bucket.tfstate.id block_public_acls = true block_public_policy = true ignore_public_acls = true restrict_public_buckets = true } リソース 役割 aws_s3_bucket tfstate保存用バケット aws_s3_bucket_versioning バージョニング有効化（誤操作時に復元可能） aws_s3_bucket_server_side_encryption_configuration 暗号化（tfstateには機密情報が含まれる可能性がある） aws_s3_bucket_public_access_block パブリックアクセスを完全ブロック DynamoDB # # tfstateロック用テーブル（同時実行を防止） resource \u0026#34;aws_dynamodb_table\u0026#34; \u0026#34;tfstate_lock\u0026#34; { name = \u0026#34;hugo-s3-demo-tfstate-lock\u0026#34; billing_mode = \u0026#34;PAY_PER_REQUEST\u0026#34; # 使った分だけ課金 hash_key = \u0026#34;LockID\u0026#34; attribute { name = \u0026#34;LockID\u0026#34; type = \u0026#34;S\u0026#34; # 文字列型 } } tfstateのロック管理用テーブルです。 複数人が同時に terraform apply を実行した際の競合を防ぎます。\noutputs # # 作成されたリソース名を出力（次のセクションで使用） output \u0026#34;s3_bucket_name\u0026#34; { value = aws_s3_bucket.tfstate.bucket } output \u0026#34;dynamodb_table_name\u0026#34; { value = aws_dynamodb_table.tfstate_lock.name } 作成されたリソース名を出力します。次のセクションでbackend設定に使用します。\n実行 # main.tf を作成したら実行します。\nterraform init # terraform init プロバイダー（AWS、random）がダウンロードされます。\nInitializing the backend... Initializing provider plugins... - Installing hashicorp/aws v5.x.x... - Installing hashicorp/random v3.x.x... Terraform has been successfully initialized! terraform plan # terraform plan 実行計画を確認します。実際のリソースは作成されません。\nPlan: 6 to add, 0 to change, 0 to destroy. 6つのリソースが作成される予定であることを確認できます。\nterraform apply # terraform apply Enter a value: と表示されたら yes と入力します。\nApply complete! Resources: 6 added, 0 changed, 0 destroyed. Outputs: dynamodb_table_name = \u0026#34;hugo-s3-demo-tfstate-lock\u0026#34; s3_bucket_name = \u0026#34;hugo-s3-demo-tfstate-xxxxxxxx\u0026#34; :::message 出力値をメモしてください s3_bucket_name と dynamodb_table_name は次のセクションで使用します。 :::\nよく使うTerraformコマンド # 本セクションで使用したコマンドをまとめます。\nコマンド 説明 terraform init 初期化（プロバイダーのダウンロード） terraform fmt コードのフォーマット整形 terraform validate 構文チェック terraform plan 実行計画の確認（実際には変更しない） terraform apply インフラの構築・変更 terraform destroy インフラの削除 基本的な流れは init → plan → apply です。\nfmt、validate、plan は以下のように一気に実行できます。\nterraform fmt \u0026amp;\u0026amp; terraform validate \u0026amp;\u0026amp; terraform plan Terraform基盤構築 # 前のセクションでtfstate管理用のS3とDynamoDBを作成しました。 このセクションでは、実際にブログをホスティングするためのS3バケットとCloudFrontを構築します。\nディレクトリ構成 # hugo-s3-demo-infra/ ├── backend-setup/ │ └── main.tf # tfstate用（作成済み） └── prod/ ├── versions.tf # Terraform + Provider設定 ├── backend.tf # S3 backend設定 ├── variables.tf # 変数定義 ├── main.tf # S3, OAC, CloudFront └── outputs.tf # 出力値 prod/ ディレクトリを作成します。\nmkdir -p ../prod cd ../prod versions.tf # Terraformのバージョンとプロバイダーを設定します。\nterraform { required_version = \u0026#34;\u0026gt;= 1.0\u0026#34; required_providers { aws = { source = \u0026#34;hashicorp/aws\u0026#34; version = \u0026#34;~\u0026gt; 5.0\u0026#34; } random = { source = \u0026#34;hashicorp/random\u0026#34; version = \u0026#34;~\u0026gt; 3.0\u0026#34; } } } provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } backend.tf # tfstateをS3で管理するための設定です。 前のセクションで出力された値を使用してください。\nterraform { backend \u0026#34;s3\u0026#34; { bucket = \u0026#34;hugo-s3-demo-tfstate-xxxxxxxx\u0026#34; # 出力されたs3_bucket_name key = \u0026#34;prod/terraform.tfstate\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;hugo-s3-demo-tfstate-lock\u0026#34; # 出力されたdynamodb_table_name encrypt = true } } :::message alert bucket の値は、前のセクションで出力された s3_bucket_name に置き換えてください。 :::\nvariables.tf # プロジェクト名を変数として定義します。\nvariable \u0026#34;project_name\u0026#34; { description = \u0026#34;Project name for resource naming\u0026#34; type = string default = \u0026#34;hugo-s3-demo\u0026#34; } main.tf # S3バケット、OAC、CloudFront Functionを作成します。\n# バケット名の一意性を確保するためのランダム文字列 resource \u0026#34;random_id\u0026#34; \u0026#34;suffix\u0026#34; { byte_length = 4 } # コンテンツ用S3バケット resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;content\u0026#34; { bucket = \u0026#34;${var.project_name}-content-${random_id.suffix.hex}\u0026#34; } # パブリックアクセスブロック resource \u0026#34;aws_s3_bucket_public_access_block\u0026#34; \u0026#34;content\u0026#34; { bucket = aws_s3_bucket.content.id block_public_acls = true block_public_policy = true ignore_public_acls = true restrict_public_buckets = true } # CloudFront OAC（Origin Access Control） resource \u0026#34;aws_cloudfront_origin_access_control\u0026#34; \u0026#34;main\u0026#34; { name = \u0026#34;${var.project_name}-oac\u0026#34; origin_access_control_origin_type = \u0026#34;s3\u0026#34; signing_behavior = \u0026#34;always\u0026#34; signing_protocol = \u0026#34;sigv4\u0026#34; } # CloudFront Function（URLリライト） resource \u0026#34;aws_cloudfront_function\u0026#34; \u0026#34;url_rewrite\u0026#34; { name = \u0026#34;${var.project_name}-url-rewrite\u0026#34; runtime = \u0026#34;cloudfront-js-2.0\u0026#34; publish = true code = \u0026lt;\u0026lt;-EOF function handler(event) { var request = event.request; var uri = request.uri; if (uri.endsWith(\u0026#39;/\u0026#39;)) { request.uri += \u0026#39;index.html\u0026#39;; } else if (!uri.includes(\u0026#39;.\u0026#39;)) { request.uri += \u0026#39;/index.html\u0026#39;; } return request; } EOF } # CloudFront Distribution resource \u0026#34;aws_cloudfront_distribution\u0026#34; \u0026#34;main\u0026#34; { origin { domain_name = aws_s3_bucket.content.bucket_regional_domain_name origin_id = \u0026#34;S3Origin\u0026#34; origin_access_control_id = aws_cloudfront_origin_access_control.main.id } enabled = true default_root_object = \u0026#34;index.html\u0026#34; default_cache_behavior { allowed_methods = [\u0026#34;GET\u0026#34;, \u0026#34;HEAD\u0026#34;] cached_methods = [\u0026#34;GET\u0026#34;, \u0026#34;HEAD\u0026#34;] target_origin_id = \u0026#34;S3Origin\u0026#34; viewer_protocol_policy = \u0026#34;redirect-to-https\u0026#34; cache_policy_id = \u0026#34;658327ea-f89d-4fab-a63d-7e88639e58f6\u0026#34; # CachingOptimized function_association { event_type = \u0026#34;viewer-request\u0026#34; function_arn = aws_cloudfront_function.url_rewrite.arn } } restrictions { geo_restriction { restriction_type = \u0026#34;none\u0026#34; } } viewer_certificate { cloudfront_default_certificate = true } } # S3バケットポリシー（CloudFrontからのアクセスを許可） resource \u0026#34;aws_s3_bucket_policy\u0026#34; \u0026#34;content\u0026#34; { bucket = aws_s3_bucket.content.id policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34; Statement = [ { Effect = \u0026#34;Allow\u0026#34; Principal = { Service = \u0026#34;cloudfront.amazonaws.com\u0026#34; } Action = \u0026#34;s3:GetObject\u0026#34; Resource = \u0026#34;${aws_s3_bucket.content.arn}/*\u0026#34; Condition = { StringEquals = { \u0026#34;AWS:SourceArn\u0026#34; = aws_cloudfront_distribution.main.arn } } } ] }) } コード解説 # OAC（Origin Access Control） # resource \u0026#34;aws_cloudfront_origin_access_control\u0026#34; \u0026#34;main\u0026#34; { name = \u0026#34;${var.project_name}-oac\u0026#34; origin_access_control_origin_type = \u0026#34;s3\u0026#34; signing_behavior = \u0026#34;always\u0026#34; signing_protocol = \u0026#34;sigv4\u0026#34; } OACはCloudFrontからS3へのアクセスを制御する仕組みです。 S3バケットへの直接アクセスを禁止し、CloudFront経由のみに制限できます。\n旧方式のOAI（Origin Access Identity）より細かい権限制御が可能で、AWSが推奨する新しい方式です。\nCloudFront Function # resource \u0026#34;aws_cloudfront_function\u0026#34; \u0026#34;url_rewrite\u0026#34; { name = \u0026#34;${var.project_name}-url-rewrite\u0026#34; runtime = \u0026#34;cloudfront-js-2.0\u0026#34; publish = true code = \u0026lt;\u0026lt;-EOF function handler(event) { var request = event.request; var uri = request.uri; if (uri.endsWith(\u0026#39;/\u0026#39;)) { request.uri += \u0026#39;index.html\u0026#39;; } else if (!uri.includes(\u0026#39;.\u0026#39;)) { request.uri += \u0026#39;/index.html\u0026#39;; } return request; } EOF } なぜCloudFront Functionが必要なのか？\nOACを使用すると、S3の「静的ウェブサイトホスティング」機能が使えません。 そのため、/posts/first-post/ へのアクセスで index.html が自動補完されず、404エラーになります。\nCloudFront Functionでviewer-requestイベント時にURLリライトを行い、この問題を解決します。\nURLパターン 変換後 /posts/ /posts/index.html /posts/first-post /posts/first-post/index.html CloudFront Distribution # resource \u0026#34;aws_cloudfront_distribution\u0026#34; \u0026#34;main\u0026#34; { # ...省略... default_cache_behavior { # HTTPをHTTPSにリダイレクト viewer_protocol_policy = \u0026#34;redirect-to-https\u0026#34; # AWS管理のキャッシュポリシー（静的サイトに最適） cache_policy_id = \u0026#34;658327ea-f89d-4fab-a63d-7e88639e58f6\u0026#34; # CloudFront Functionを関連付け function_association { event_type = \u0026#34;viewer-request\u0026#34; function_arn = aws_cloudfront_function.url_rewrite.arn } } # デフォルト証明書を使用（カスタムドメインは#5で設定） viewer_certificate { cloudfront_default_certificate = true } } cache_policy_id の 658327ea-f89d-4fab-a63d-7e88639e58f6 は、AWSが提供する「CachingOptimized」ポリシーのIDです。 静的サイトに最適化されたキャッシュ設定が適用されます。\nS3バケットポリシー # resource \u0026#34;aws_s3_bucket_policy\u0026#34; \u0026#34;content\u0026#34; { bucket = aws_s3_bucket.content.id policy = jsonencode({ # ...省略... Condition = { StringEquals = { \u0026#34;AWS:SourceArn\u0026#34; = aws_cloudfront_distribution.main.arn } } }) } CloudFrontからのアクセスのみを許可するバケットポリシーです。 Condition で特定のCloudFront DistributionのARNを指定し、他のCloudFrontからのアクセスも拒否します。\noutputs.tf # 作成されたリソースの情報を出力します。\noutput \u0026#34;s3_bucket_name\u0026#34; { value = aws_s3_bucket.content.bucket } output \u0026#34;cloudfront_distribution_id\u0026#34; { value = aws_cloudfront_distribution.main.id } output \u0026#34;cloudfront_domain_name\u0026#34; { value = aws_cloudfront_distribution.main.domain_name } 実行 # 5つのファイルを作成したら実行します。\n# 初期化（backend設定を読み込み） terraform init # 実行計画の確認 terraform plan # 構築 terraform apply terraform apply の実行後、以下のような出力が表示されます。\nApply complete! Resources: 7 added, 0 changed, 0 destroyed. Outputs: cloudfront_distribution_id = \u0026#34;E2XXXXXXXXXX\u0026#34; cloudfront_domain_name = \u0026#34;dxxxxxxxxxxxxx.cloudfront.net\u0026#34; s3_bucket_name = \u0026#34;hugo-s3-demo-content-xxxxxxxx\u0026#34; :::message 出力値をメモしてください s3_bucket_name と cloudfront_domain_name は次のセクションで使用します。 :::\n手動デプロイ # S3バケットとCloudFrontが作成されたので、Hugoでビルドしたコンテンツをデプロイします。\nbaseURLの更新 # Hugoプロジェクトに戻り、hugo.toml の baseURL をCloudFrontのドメインに更新します。\ncd /path/to/hugo-s3-demo hugo.toml を編集します。\nbaseURL = \u0026#39;https://dxxxxxxxxxxxxx.cloudfront.net/\u0026#39; # 出力されたcloudfront_domain_name languageCode = \u0026#39;en-us\u0026#39; title = \u0026#39;Hugo S3 Demo\u0026#39; theme = \u0026#39;ananke\u0026#39; :::message alert baseURL は、前のセクションで出力された cloudfront_domain_name に置き換えてください。 末尾のスラッシュ / を忘れずに付けてください。 :::\nビルド # hugo public/ ディレクトリにHTMLファイルが生成されます。\nS3にアップロード # aws s3 sync public/ s3://hugo-s3-demo-content-xxxxxxxx/ --delete s3://hugo-s3-demo-content-xxxxxxxx/ は出力された s3_bucket_name に置き換えてください --delete オプションは、S3にあってローカルにないファイルを削除します 動作確認 # ブラウザで https://dxxxxxxxxxxxxx.cloudfront.net/ にアクセスします。\n以下を確認してください。\nトップページが表示される HTTPSで接続できる（ブラウザのアドレスバーに鍵マーク） 記事詳細ページ（/posts/first-post/）が表示される :::message 記事詳細ページが404になる場合は、CloudFront Functionが正しく動作していません。 Terraformコードの aws_cloudfront_function を確認してください。 :::\nトラブルシューティング # 403 Forbidden # 原因: S3バケットポリシーが正しく設定されていない\n対処法:\nterraform apply を再実行 S3バケットポリシーがCloudFrontのARNを許可しているか確認 404 Not Found（サブページのみ） # 原因: CloudFront Functionが動作していない\n対処法:\nAWSコンソールでCloudFront Functionsを開く 関数が「Published」状態になっているか確認 CloudFront Distributionに関連付けられているか確認 更新が反映されない # 原因: CloudFrontのキャッシュが残っている\n対処法: キャッシュを無効化します。\naws cloudfront create-invalidation \\ --distribution-id E2XXXXXXXXXX \\ --paths \u0026#34;/*\u0026#34; --distribution-id は terraform output で確認できます。\n:::message キャッシュ無効化は月1,000パスまで無料です。 /* で全ファイルを無効化すると1パスとしてカウントされます。 :::\nクリーンアップ（リソース削除） # 記事の検証が終わったら、AWSリソースを削除してコストを抑えましょう。\nprod環境の削除 # cd hugo-s3-demo-infra/prod # S3バケット内のファイルを削除（空でないと削除できない） aws s3 rm s3://hugo-s3-demo-content-xxxxxxxx/ --recursive # Terraformリソースを削除 terraform destroy backend-setup環境の削除 # cd ../backend-setup # S3バケット内のファイルを削除 aws s3 rm s3://hugo-s3-demo-tfstate-xxxxxxxx/ --recursive # バージョニング有効のため、DeleteMarkerも削除が必要な場合あり # 削除に失敗した場合は、AWSコンソールからバケットを空にしてください # Terraformリソースを削除 terraform destroy :::message alert terraform destroy を実行すると、すべてのリソースが削除されます。 本番環境では十分注意してください。 :::\nまとめ # 本記事では、以下を構築しました。\nHugo: 静的サイトジェネレーターでブログを作成 S3: コンテンツの保存先 CloudFront: CDNでHTTPS配信 OAC: S3への直接アクセスを禁止 CloudFront Function: URLリライトで404を回避 Terraform: 全リソースをコード化 作成したリソース # リソース 用途 S3バケット（content） Hugoビルド成果物の保存 S3バケット（tfstate） Terraformのstate管理 DynamoDB tfstateのロック管理 CloudFront Distribution CDN、HTTPS終端 CloudFront OAC S3へのアクセス制御 CloudFront Function URLリライト S3バケットポリシー CloudFrontからのアクセス許可 参考資料 # Hugo公式ドキュメント Terraform AWS Provider CloudFront OAC - AWS公式 CloudFront Functions - AWS公式 ","date":"2025年 12月 30日","externalUrl":null,"permalink":"/posts/251230210947_hugoawshugo+s3+cloudfront%E3%81%A7%E6%8A%80%E8%A1%93%E3%83%96%E3%83%AD%E3%82%B0%E3%82%92%E5%85%AC%E9%96%8B%E3%81%99%E3%82%8B/","section":"Posts","summary":"","title":"【Hugo×AWS】Hugo+S3+CloudFrontで技術ブログを公開する","type":"posts"},{"content":"","date":"2025年 12月 30日","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":" ウルトララーニングとは？ # 自己管理的かつ集中的な、スキルや知識を習得するための戦略\n読んだ動機 # 資格勉強や個人勉強について参考になる本を探しているうちに見つけた。\nメタ学習：3つの問い # Why：なぜ学ぶ？（実利 or 興味）→ そのスキルで本当に目的達成できるか確認 What：何を学ぶ？ → 概念（理解）・事実（暗記）・行動（実践）に分解し、ボトルネック特定 How：どう学ぶ？ → ベンチマーク調査 → 効果的なものを強調、低効果なものを除去 9つの原則 # # 原則 実践の核心 1 メタ学習 学習開始前に「Why・What・How」を明確化する 2 集中 5分だけ始める → 環境から誘惑を排除する 3 直接性 実際に使う文脈で学ぶ（プロジェクトベース、没入） 4 基礎練習 ボトルネックを分解し、弱点だけを集中強化する 5 回想 見ずに思い出す（白紙勉強法、自作テスト） 6 フィードバック 結果FB→情報FB→修正FBの順で具体性を上げる 7 保持 間隔反復・手続き化・過剰学習で忘却を防ぐ 8 直感 ファインマンテクニック：他人に教えるように説明を書く 9 実験 複数手法を試し、制約を設け、安全圏を出る チェックリスト # 学習開始時 # Why/What/Howを言語化したか ボトルネックを特定したか 予想学習時間の10%をメタ学習に投じたか 学習中 # 実際に使う文脈で学んでいるか（直接性） 見ずに思い出す練習をしているか（回想） 適切なフィードバックを得ているか 行き詰まり時 # ファインマンテクニックで理解を確認したか 別のアプローチを試したか（実験） メタ学習を再実施してプロジェクトを見直したか 習得の判定基準 # レベル 判定基準 わかる 概念を説明できる、選択式問題に正答できる できる 手順書・検索なしで実行できる、エラーを自力解決できる 見せられる 設計意図や選択理由を説明できる、質問に答えられる 書籍情報 # 項目 内容 書籍名 ULTRA LEARNING 超・自習法 どんなスキルでも最速で習得できる9つのメソッド 著者 スコット・H・ヤング 出版社 ダイヤモンド社 発売日 2020/03/05 ","date":"2025年 12月 30日","externalUrl":null,"permalink":"/posts/251230055935_%E3%82%A6%E3%83%AB%E3%83%88%E3%83%A9%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%A8%E3%81%AF/","section":"Posts","summary":"","title":"ウルトララーニングとは？","type":"posts"},{"content":"","date":"2025年 12月 30日","externalUrl":null,"permalink":"/tags/%E5%AD%A6%E7%BF%92%E6%B3%95/","section":"Tags","summary":"","title":"学習法","type":"tags"},{"content":"","date":"2025年 12月 30日","externalUrl":null,"permalink":"/tags/%E8%AA%AD%E6%9B%B8%E3%83%A1%E3%83%A2/","section":"Tags","summary":"","title":"読書メモ","type":"tags"},{"content":"","date":"2025年 12月 30日","externalUrl":null,"permalink":"/tags/%E5%AD%A6%E7%BF%92%E4%BD%9C%E6%A5%AD%E3%83%AD%E3%82%B0/","section":"Tags","summary":"","title":"学習・作業ログ","type":"tags"},{"content":" 今日学んだこと # 2025年に転職活動したので、その反省より 次の転職活動をどう進めるか整理します。\n具体的な手順は下記の5ステップ。\nストーリーの設定 スキルの整備 前準備 転職活動の実行 内定判断 1. ストーリーの設定 # ストーリーとは何か # ストーリーとは、「なぜ前職を辞めたのか」「なぜこの業界なのか」「なぜこの会社なのか」という問いに、 一貫した軸で答えられることである。\n面接では「なんでこの判断をしたのか？」というWhyを繰り返し問われた。 面接官は「この人のキャリアには方向性があるか」「場当たり的な転職ではないか」を見ている。 一貫したストーリーがあれば「すぐ辞めなさそう」という定着性のアピールにもなる。\nなぜ最初に設定するか # ストーリーが決まっていないと、スキルを何のために磨くか、どの企業に応募するか、内定を受けるかの判断がブレる。 すべての判断の土台になるから、最初に固める必要がある。\n2. スキルの整備 # ストーリーから逆算する # 設定したストーリーに説得力を持たせるスキルを整備する。「クラウドインフラエンジニアになりたい」というストーリーなら、AWS・Terraform・ネットワークなどのスキルが必要になる。 ストーリーだけあってもスキルが伴わなければ「口だけ」になる。スキルはストーリーの実現可能性を証明するものである。\n言語化の方法 # スキルは「持っている」だけでは不十分で、「説明できる」レベルまで落とし込む必要がある。 具体的な方法は下記。\n面談Q\u0026amp;Aを作成し、想定質問への回答を準備する 技術ブログ（Zenn、TILブログ等）で学んだことを言語化する 技術用語を自分の言葉で説明する練習をする 面接の失敗例 # R社の面接で面接官から技術的な質問を受けた。（エンジニア出身の面接官） 「何ができて、何ができないか」を問われたが、自分の回答はボロボロだった。\n資格は持っていたが、その知識を自分の言葉で説明できなかった。 「クラウドエンジニアになりたい」というストーリーに対して、スキル面の説得力が全くないことが露呈した失敗だった。\n3. 前準備 # 書類準備 # 履歴書・職務経歴書を準備する。\n2025年の転職活動時は実務経験の少なさが大きなネック。 転職エージェントからも個人開発や資格では書類選考に限界があるとのアドバイスを受けた。 改めて、実務経験の重要性を理解。 面談Q\u0026amp;Aの設定 # 想定質問と回答（面談Q\u0026amp;A）を事前に準備する。\nカテゴリ例：\n自己紹介・経歴説明 志望動機 転職理由 IT基礎用語 情報収集 # 希望企業について調査する。企業研究、口コミ確認、カジュアル面談での情報収集など。 ただし、口コミと実態は乖離することがある（分野・時期による差）。 口コミだけで判断せず、オファー面談等で直接確認することが重要。\n必要に応じて転職エージェントも活用する。\n4. 転職活動の実行 # 面接で問われる4要素 # 面接官が知りたいのは以下の4つである。\nスキル：この人は何ができるのか？ 志望動機：なぜうちの会社なのか？ 定着性：長く働いてくれるか？ 人柄：一緒に働きやすそうか？ これらの疑問に先回りして答えられる準備をする。\n2025年の自分の面接時は、ほぼ営業・人事部だった。技術面接は少なく、ストーリー（志望動機・定着性）と人柄を重視されている印象だった。\n面談Q\u0026amp;Aの調整 # 面接を重ねる中で、想定外の質問や回答しづらかった質問が出てくる。その都度、面談Q\u0026amp;Aを更新する。\n5. 内定判断 # 事前に判断基準を設定する # 内定をもらってから考えるのではなく、事前に「何を満たせば承諾するか」を決めておく。感情に流されず判断できる。\n面談で検証する # 口コミや想像ではなく、面談で直接確認する。 事前に設定した判断基準に照らして、承諾するかどうかを決める。\nまとめ # 転職活動は5つのステップで進める。\nストーリーの設定：すべての判断の土台。最初に固める スキルの整備：ストーリーに説得力を持たせる。「説明できる」レベルまで言語化する 前準備：書類・面談Q\u0026amp;A・情報収集を整える 転職活動の実行：面接官が知りたい4要素（スキル・志望動機・定着性・人柄）に先回りして答える 内定判断：事前に判断基準を決め、面談で検証する 2025年の転職活動で得た最大の学びは2つ。\nスキルは「持っている」ではなく「説明できる」が重要 口コミと実態は乖離する。面談で直接確認する ","date":"2025年 12月 30日","externalUrl":null,"permalink":"/posts/251230051917_%E6%AC%A1%E3%81%AE%E8%BB%A2%E8%81%B7%E6%B4%BB%E5%8B%95%E3%81%AF%E3%81%A9%E3%81%86%E3%81%99%E3%82%8B%E3%81%8B/","section":"Posts","summary":"","title":"次の転職活動はどうするか","type":"posts"},{"content":"","date":"2025年 12月 30日","externalUrl":null,"permalink":"/tags/%E8%BB%A2%E8%81%B7/","section":"Tags","summary":"","title":"転職","type":"tags"},{"content":"","date":"2025年 12月 27日","externalUrl":null,"permalink":"/tags/%E5%BF%9C%E7%94%A8%E6%83%85%E5%A0%B1%E6%8A%80%E8%A1%93%E8%80%85%E8%A9%A6%E9%A8%93/","section":"Tags","summary":"","title":"応用情報技術者試験","type":"tags"},{"content":" 概要 # 2025年秋の応用情報技術者試験に合格しました。このメモではその振り返りをしていこうと思います。 前提としては、自分は応用情報技術者試験前に基本情報技術者試験とCCNAに合格済みだったので、 資格勉強に多少慣れた状態で臨んでいます。\nメモの構成 # 応用情報技術者試験の概要 実際に自分が実行した勉強方法（午前） 実際に自分が実行した勉強方法（午後） 応用情報技術者試験の結果 もう一度応用情報技術者試験を受験するならどうする 応用情報技術者試験の概要 # 応用情報技術者試験は午前問題と午後問題の2部構成で、両方とも60点以上で合格です。\n区分 問題形式 補足 午前 4択の選択式問題（80問） 3分野から出題：ストラテジ系、マネジメント系、テクノロジ系 午後 記述式 情報セキュリティ（必須）＋ 4分野を選択して解答 詳細はIPA公式：応用情報技術者試験を参照\n午前と午後で求められる力の違い # 区分 求められる力 午前 知識の広さ・暗記。過去問演習を繰り返せば合格ラインに達する 午後 概念の深い理解・応用力。キーワードを理解した上で問題形式に慣れる必要がある。\n過去問より自分なりの解法パターンやコツを見つけられるようにしておく。 実際に自分が実行した勉強方法（午前） # 応用情報技術者試験過去問道場をひたすら繰り返します。 利用した応用情報技術者試験過去問道場はこちら\n演習範囲はR6秋〜H29春まで（約15回分） 演習中に知らないキーワードや理解が曖昧な概念があった場合は、合格教本（技術評論社）で学習 令和07年：応用情報技術者合格教本 通勤時間や空き時間を利用して、少しずつ繰り返し演習していました。 先に過去問に挑戦して、後から合格教本を確認という流れです。 実際に自分が実行した勉強方法（午後） # 応用情報技術者試験過去問道場より過去問を演習 知らないキーワードの深掘りや自分なりの解法パターンを見つけて整理しておく。\n演習範囲はR7春〜R2秋まで（約10回分）\nこちらも知らないキーワードなどがあれば、合格教本（技術評論社）で深堀り\nどうしても解説などがしっくりこないのであれば、NoteBookLMやGeminiなどに問題を読み込ませて、「小学生へ教えるつもりで解説して」などというようにAIに解説または、壁打ち相手になってもらいました。\n解法パターンの例：経営戦略\n出題されている会社の抱えている問題を正確に把握する 頻出フレームワーク（PPM、SWOT等）の概要を覚えておく 問題文の情報をフレームワークに当てはめて解答する 午後問題の分野選択 # 実際に各分野の過去問を2回分解いて、自分にしっくりくる分野を選びました。 ネットワークは一般的にはおすすめされない分野ですが、CCNAなど過去に ネットワーク関連を学習していたため個人的に苦にならなかったです。\n午後問題の選択基準はいろいろあると思いますが、実際に過去問演習をして、 解きやすい分野を選んでよいと思います。 このとき、7～8分野を勉強しておいて、本番では簡単そうな5分野を選べるようにしておきましょう。\n自分が実際に選択した分野 情報セキュリティ（必須） 経営戦略 ネットワーク プロジェクトマネジメント システム監査 自分の実際の結果 + 勉強時間 # 試験結果 # 試験日：2025年10月12日(日) 結果：合格 午前得点：86.25点 午後得点：78.00点 総勉強時間：213時間32分 # 午前と午後の勉強時間の割合は概ね、7:3。 6月から少しずつ勉強開始（6月時点で18時間） 9・10月に追い込みをかけました（9月：83時間 / 10月：61時間） 勉強時間は「Toggl Track」というアプリで管理 もう一度受験するならどう勉強するか # 時間配分を50:50にする 実際は午前:午後 = 7:3 で午前に偏っていました。 午前問題は過去問で効率的に点が取れるため、午後問題にもっと時間を割くべきでした。 午前で7割取れるようになったら午後に移行してもよいと思います。\n午後の分野は7〜8分野を勉強しておく 前述ですが、事前に多めに勉強しておくことで、当日は簡単な問題を選択できる余地ができます。 （本番では5分野を選択）\n通勤時間や休み時間などのスキマ時間を活用する スキマ時間だけでもまとめると結構な勉強時間になるので、馬鹿にできないです。 特に午前問題はスキマ時間で演習しやすいので、この時間で勉強したほうがよいと思います。\n最初から過去問に取り掛かる 参照書などを読み込んでから過去問では、時間効率が悪いと思います。 過去問を繰り返すとわかることですが、「この問題何度も出てくるな」や「このパターンは他の過去問でも応用できるな」など、過去問から得られる情報は多いです。この情報は本番の試験でも使えるので、早いうちに過去問に挑戦して、重要度の高い分野や問題、パターンを学習したほうがおすすめです。\nまとめ # 正直、自分が応用情報技術者試験を受験したときは自信がなかったです。 特に午後問題の勉強時間が不足しており、十分な対策ができているとは言えない状態でした。 応用情報技術者試験は範囲が広く、基本情報技術者試験の内容を踏襲しておりますが、難易度は高くなっています。 範囲が広く、難易度も高い試験となると勉強時間のペース配分が難しくなります。（実際自分もペース配分については失敗していました。） ただ、各分野の基本的な知識をしっかり理解して、過去問を繰り返し取り組めば、本番でも合格点をとれると思います。 やるべきことが多岐にわたる試験でしたが、良い経験だったと振り返って思っています。 このメモがこれから受験する人たちの一助になれば幸いです。\n","date":"2025年 12月 27日","externalUrl":null,"permalink":"/posts/251227153436_%E5%BF%9C%E7%94%A8%E6%83%85%E5%A0%B1%E6%8A%80%E8%A1%93%E8%80%85%E8%A9%A6%E9%A8%93%E3%81%AE%E6%8C%AF%E3%82%8A%E8%BF%94%E3%82%8A%E3%81%A8%E3%82%82%E3%81%86%E4%B8%80%E5%BA%A6%E5%8F%97%E9%A8%93%E3%81%99%E3%82%8B%E3%81%AA%E3%82%89%E3%81%A9%E3%81%86%E3%81%99%E3%82%8B%E3%81%8B/","section":"Posts","summary":"","title":"応用情報技術者試験の振り返りともう一度受験するならどうするか","type":"posts"},{"content":"","date":"2025年 12月 27日","externalUrl":null,"permalink":"/tags/%E8%B3%87%E6%A0%BC%E8%A9%A6%E9%A8%93/","section":"Tags","summary":"","title":"資格試験","type":"tags"},{"content":"","date":"2025年 12月 22日","externalUrl":null,"permalink":"/tags/cli/","section":"Tags","summary":"","title":"CLI","type":"tags"},{"content":"","date":"2025年 12月 22日","externalUrl":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux","type":"tags"},{"content":"","date":"2025年 12月 22日","externalUrl":null,"permalink":"/tags/til/","section":"Tags","summary":"","title":"TIL","type":"tags"},{"content":" 今日学んだこと # treeコマンドを使うと、ディレクトリ構造をツリー形式で表示できます。階層の深さ制限や除外パターンを指定することで、必要な情報だけを確認できます。\n学習内容 # Step1: インストール # Ubuntuではデフォルトでインストールされていないため、aptでインストールします。\nsudo apt update sudo apt install tree Step2: 基本的な使い方 # 引数なしで実行すると、カレントディレクトリ以下のすべてのファイル・ディレクトリが表示されます。\ntree ただし、階層が深かったりファイル数が多いと出力が膨大になります。-Lオプションで表示する階層の深さを制限できます。\n# 2階層まで表示 tree -L 2 Step3: よく使うオプション # オプション 説明 例 -L \u0026lt;n\u0026gt; 表示する階層の深さを指定 tree -L 2 -d ディレクトリのみ表示 tree -d -I \u0026lt;pattern\u0026gt; 指定パターンを除外 tree -I \u0026quot;node_modules\u0026quot; オプションは組み合わせて使えます。\n# 3階層まで、ディレクトリのみ、node_modulesを除外 tree -L 3 -d -I \u0026#34;node_modules\u0026#34; ユースケース：Hugoプロジェクトの構造確認 # Hugoブログのプロジェクトでtree -L 2を実行すると、主要なディレクトリ構成がひと目で把握できます。\n$ tree -L 2 . ├── archetypes │ └── default.md ├── assets │ ├── css │ ├── img │ └── js ├── config │ └── _default ├── content │ └── posts ├── layouts │ ├── partials │ └── series ├── public │ ├── css │ ├── posts │ └── ... ├── static │ └── ... └── themes └── blowfish lsだけでは把握しづらい入れ子構造も、treeなら一発で確認できます。\nまとめ # treeはディレクトリ構造をツリー形式で表示するコマンド -L \u0026lt;n\u0026gt;で階層の深さを制限できる -dでディレクトリのみ、-Iで除外パターンを指定可能 プロジェクト全体の構造把握に便利 参考 # tree(1) - Linux man page ","date":"2025年 12月 22日","externalUrl":null,"permalink":"/posts/251222010445_tree%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%83%87%E3%82%A3%E3%83%AC%E3%82%AF%E3%83%88%E3%83%AA%E6%A7%8B%E9%80%A0%E3%82%92%E5%8F%AF%E8%A6%96%E5%8C%96%E3%81%99%E3%82%8B/","section":"Posts","summary":"","title":"treeコマンド：ディレクトリ構造を可視化する","type":"posts"},{"content":"","date":"2025年 12月 19日","externalUrl":null,"permalink":"/tags/docker/","section":"Tags","summary":"","title":"Docker","type":"tags"},{"content":"","date":"2025年 12月 19日","externalUrl":null,"permalink":"/tags/vscode/","section":"Tags","summary":"","title":"VSCode","type":"tags"},{"content":" 今日学んだこと # VSCode Dev Containersを使うと、Dockerコンテナ内でVSCodeを直接開いて編集できることを学びました。ホスト側とコンテナ側の権限問題を回避でき、コンテナ内の環境でそのまま作業できます。\n学習内容 # Dev Containersとは # Dockerコンテナ内でVSCodeを直接開き、コンテナ内のファイルを編集できるVSCode拡張機能です。\nStep 1: インストール # VSCodeの拡張機能で「Dev Containers」を検索 Microsoft製の拡張機能をインストール 拡張機能ID: ms-vscode-remote.remote-containers\nStep 2: 実行中のコンテナにアタッチ # コンテナを起動しておく（docker compose up -d など） VSCodeで Ctrl + Shift + P（コマンドパレット） Dev Containers: Attach to Running Container... を選択 対象のコンテナを選択 新しいVSCodeウィンドウが開き、コンテナ内で直接編集できます。\nStep 3: フォルダを開く # アタッチ後、以下の手順でコンテナ内のフォルダを開きます。\nファイル \u0026gt; フォルダを開く コンテナ内のパス（例：/workspace/）を指定 Dev Containersのメリット # メリット 説明 権限問題の解消 rootで作成したファイルも編集可能 環境の一致 コンテナ内の環境でそのまま作業 拡張機能の分離 コンテナごとに拡張機能を管理可能 関連拡張機能 # 拡張機能 用途 Dev Containers コンテナ内でVSCodeを開く Docker コンテナの管理・ログ確認 まとめ # Dev ContainersはDockerコンテナ内でVSCodeを直接開ける拡張機能 Attach to Running Containerで実行中のコンテナにアタッチ ホスト側とコンテナ側の権限問題を回避できる コンテナごとに拡張機能を分離して管理可能 参考 # Developing inside a Container - VSCode公式ドキュメント ","date":"2025年 12月 19日","externalUrl":null,"permalink":"/posts/251219202830_vscode-dev-containers-container-development-environment/","section":"Posts","summary":"","title":"VSCode Dev Containersでコンテナ内開発環境を構築する","type":"posts"},{"content":"","date":"2025年 12月 19日","externalUrl":null,"permalink":"/tags/%E3%83%84%E3%83%BC%E3%83%AB/","section":"Tags","summary":"","title":"ツール","type":"tags"},{"content":"","date":"2025年 12月 19日","externalUrl":null,"permalink":"/tags/%E5%AE%9F%E8%B7%B5/","section":"Tags","summary":"","title":"実践","type":"tags"},{"content":" 今日学んだこと # Dockerを使って学習用の使い捨て環境を構築する方法を学びました。docker run -it --rmの基本パターンを押さえておけば、Node.js、Python、MySQL、Linux基礎など様々な学習環境をローカルPCを汚さずに構築できます。\n学習内容 # 基本パターン # # 使い捨てコンテナの基本形 docker run -it --rm \u0026lt;イメージ名\u0026gt; bash # ローカルファイルをマウントする場合 docker run -it --rm -v $(pwd):/work -w /work \u0026lt;イメージ名\u0026gt; bash オプション 意味 -it 対話モード（ターミナルで操作可能） --rm 終了時にコンテナ自動削除 -v $(pwd):/work カレントディレクトリをコンテナ内の/workにマウント -w /work 作業ディレクトリを/workに設定 学習内容別イメージ一覧 # 学習内容 イメージ 用途 Node.js/フロントエンド node:20 npm、Babel、Webpack、React等 Python/データ分析 python:3.12 pip、Pandas、Scikit-learn等 MySQL mysql:8.0 SQL学習 Linux基礎 ubuntu:24.04 コマンド操作練習 Node.js環境 # docker run -it --rm -v $(pwd):/work -w /work node:20 bash # コンテナ内 npm init -y npm install --save-dev @babel/cli @babel/core @babel/preset-env Python環境 # docker run -it --rm -v $(pwd):/work -w /work python:3.12 bash # コンテナ内 pip install pandas matplotlib scikit-learn python script.py MySQL環境 # # 単体でSQL練習（データは消える） docker run -it --rm -e MYSQL_ROOT_PASSWORD=root mysql:8.0 mysql -uroot -proot # バックグラウンドで起動してクライアントから接続 docker run -d --rm --name mysql-study -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 mysql:8.0 # 接続 docker exec -it mysql-study mysql -uroot -proot # 終了時 docker stop mysql-study Linux基礎（Ubuntu）環境 # docker run -it --rm ubuntu:24.04 bash # コンテナ内でパッケージをインストール apt update apt install -y curl vim tree # コマンド練習 ls -la / cat /etc/os-release ファイル操作の練習をする場合：\ndocker run -it --rm -v $(pwd):/work -w /work ubuntu:24.04 bash # コンテナ内 mkdir -p dir1/dir2 touch dir1/file1.txt dir1/dir2/file2.txt tree dir1 find dir1 -name \u0026#34;*.txt\u0026#34; Docker Compose（複数コンテナ連携） # アプリとDBなど複数コンテナを扱う場合に便利です。\n# docker-compose.yml services: app: image: node:20 volumes: - .:/work working_dir: /work command: bash tty: true stdin_open: true db: image: mysql:8.0 environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: study # 起動 docker compose up -d # アプリコンテナに入る docker compose exec app bash # 終了・削除 docker compose down Dockerfileで環境を固定 # 毎回同じ環境を再現したい場合に使用します。\n# Dockerfile FROM node:20 WORKDIR /workspace RUN npm install -g npm@latest CMD [\u0026#34;bash\u0026#34;] docker build -t study-env . docker run -it --rm -v $(pwd):/workspace study-env 学習例：Babelのトランスパイル # 実際にBabelの学習環境を構築してみます。\nmkdir babel-study \u0026amp;\u0026amp; cd babel-study docker run -it --rm -v $(pwd):/work -w /work node:20 bash # コンテナ内 npm init -y npm install --save-dev @babel/cli @babel/core @babel/preset-env echo \u0026#39;{ \u0026#34;presets\u0026#34;: [\u0026#34;@babel/preset-env\u0026#34;] }\u0026#39; \u0026gt; .babelrc mkdir src dist echo \u0026#39;const greet = () =\u0026gt; console.log(\u0026#34;Hello\u0026#34;);\u0026#39; \u0026gt; src/app.js npx babel src/app.js -o dist/app.js cat dist/app.js exit マウントしたファイルは手元に残ります。不要になったらbabel-studyディレクトリごと削除すればクリーンアップ完了です。\nクリーンアップ # 学習が終わったら以下の手順で環境を削除します。\n1. 作業ディレクトリの削除 # マウントしたディレクトリが不要になったら削除します。\nrm -rf babel-study # 作成したディレクトリごと削除 2. Dockerイメージの削除 # ダウンロードしたイメージが不要になったら削除します。\n# イメージ一覧を確認 docker images # 個別に削除 docker rmi node:20 docker rmi python:3.12 docker rmi mysql:8.0 docker rmi ubuntu:24.04 3. まとめて掃除する場合 # # 未使用のイメージ・コンテナ・ネットワークを一括削除 docker system prune # 確認メッセージが表示されるので y を入力 Note: docker system pruneは他のプロジェクトで使用中のリソースには影響しませんが、複数プロジェクトでDockerを使っている場合はdocker rmiで個別削除が安全です。\nまとめ # パターン コマンド 用途 基本形 docker run -it --rm \u0026lt;イメージ\u0026gt; bash 簡単な動作確認 ファイル永続化 docker run -it --rm -v $(pwd):/work -w /work \u0026lt;イメージ\u0026gt; bash 学習成果を残したい場合 複数コンテナ docker compose up -d アプリ+DB連携 環境固定 Dockerfile + docker build チームで同一環境を共有 --rmオプションでコンテナ終了時に自動削除されるため、ローカル環境を汚さない -vでマウントしたディレクトリ内のファイルはコンテナ終了後も残る 学習終了後はディレクトリごと削除すれば完全にクリーンアップできる 参考 # Docker公式ドキュメント Docker Hub ","date":"2025年 12月 14日","externalUrl":null,"permalink":"/posts/251214215249_docker-disposable-study-environment/","section":"Posts","summary":"","title":"Dockerで勉強用の使い捨て環境を構築する","type":"posts"},{"content":"","date":"2025年 12月 14日","externalUrl":null,"permalink":"/tags/%E3%83%8F%E3%83%B3%E3%82%BA%E3%82%AA%E3%83%B3%E3%83%81%E3%83%A5%E3%83%BC%E3%83%88%E3%83%AA%E3%82%A2%E3%83%AB/","section":"Tags","summary":"","title":"ハンズオン・チュートリアル","type":"tags"},{"content":"","date":"2025年 12月 14日","externalUrl":null,"permalink":"/tags/%E5%85%A5%E9%96%80/","section":"Tags","summary":"","title":"入門","type":"tags"},{"content":"","date":"2025年 12月 14日","externalUrl":null,"permalink":"/tags/css/","section":"Tags","summary":"","title":"CSS","type":"tags"},{"content":"","date":"2025年 12月 14日","externalUrl":null,"permalink":"/tags/tailwind-css/","section":"Tags","summary":"","title":"Tailwind CSS","type":"tags"},{"content":" 今日学んだこと # Tailwind CSSはユーティリティファーストのCSSフレームワークです。従来のCSSとは異なり、小さなユーティリティクラスをHTMLに直接記述することで、スタイルの定義と適用箇所を同じ場所に置く（コロケーション）アプローチを取ります。\n学習内容 # Tailwind CSSとは # Tailwind CSSは、bg-blue-500 や text-white などの小さなユーティリティクラスを組み合わせてスタイリングを行うCSSフレームワークです。\n従来のCSSとの違い # 従来のCSSでは、HTMLとCSSを別ファイルに分離して管理していました。\n/* 従来のCSS */ .primary-button { background-color: blue; color: white; padding: 8px 16px; border-radius: 4px; } \u0026lt;button class=\u0026#34;primary-button\u0026#34;\u0026gt;ボタン\u0026lt;/button\u0026gt; しかし、実際の開発ではHTMLとCSSを常にセットで変更することが多く、ファイル間の追跡が困難という課題がありました。\nTailwind CSSでは、ユーティリティクラスをHTMLに直接記述します。\n\u0026lt;!-- Tailwind CSS --\u0026gt; \u0026lt;button class=\u0026#34;bg-blue-500 text-white px-4 py-2 rounded\u0026#34;\u0026gt;ボタン\u0026lt;/button\u0026gt; スタイルの定義と適用箇所が同じ場所にあるため、直感的に理解しやすくなります。\nユーティリティファーストとは # Tailwind CSSの根底にある考え方が「ユーティリティファースト」です。\nユーティリティクラスとは「1つのCSSプロパティだけを持つ小さなクラス」のことです。このユーティリティクラスを最優先に使用することで、CSSの肥大化を防ぐことができます。\n共通スタイルの一括管理が必要な場合は、コンポーネント化や@applyディレクティブで対応可能です。\nまとめ # Tailwind CSSはユーティリティファーストのCSSフレームワーク 小さなユーティリティクラスをHTMLに直接記述する スタイルの定義と適用箇所が同じ場所にある（コロケーション）ため、直感的に理解しやすい 共通スタイルはコンポーネント化や@applyで管理可能 自分の言葉でまとめる # Tailwind CSS とは、ユーティリティファーストのCSSフレームワークである。 従来のCSSでは、HTMLとCSSを別ファイルに分離して管理していた。 しかし、実際の開発ではHTMLとCSSを常にセットで変更することが多く、 ファイル間の追跡が困難という課題があった。\nTailwind CSSではbg-blue-500 や text-white などの 小さなユーティリティクラスをHTMLに直接記述する。これにより、 スタイルの定義と適用箇所が同じ場所にある（コロケーション）ため、直感的に理解しやすい。\nまた、共通スタイルの一括管理はコンポーネント化や@applyで対応可能である。 Tailwind CSSにおいては「ユーティリティファースト」という考えが根底にある。 「1つのCSSプロパティだけを持つ小さなクラス」であるユーティリティクラスを 最優先に使用することで、CSSの肥大化などを防ぐことが可能。\n/* 従来のCSS */ .primary-button { background-color: blue; color: white; padding: 8px 16px; border-radius: 4px; } \u0026lt;!-- Tailwind CSS（HTMLに直接記述） --\u0026gt; \u0026lt;button class=\u0026#34;bg-blue-500 text-white px-4 py-2 rounded\u0026#34;\u0026gt; 参考 # Tailwind CSS公式ドキュメント ","date":"2025年 12月 14日","externalUrl":null,"permalink":"/posts/251214211109_what-is-tailwind-css-and-how-is-it-different-from-traditional-css/","section":"Posts","summary":"","title":"Tailwind CSS とは何か？従来のCSSと何が違うのか？","type":"posts"},{"content":"","date":"2025年 12月 14日","externalUrl":null,"permalink":"/tags/aws/","section":"Tags","summary":"","title":"AWS","type":"tags"},{"content":"","date":"2025年 12月 14日","externalUrl":null,"permalink":"/tags/%E3%82%A4%E3%83%B3%E3%83%95%E3%83%A9/","section":"Tags","summary":"","title":"インフラ","type":"tags"},{"content":" 今日学んだこと # ファインマンテクニックを使ってAWS IAMを整理しました。「12歳にも分かるように説明する」というプロセスを通じて、自分の理解が曖昧だった部分（IAMロールの対象、4概念の関係性）が明確になりました。\n学習内容 # ファインマンテクニックとは # ノーベル物理学賞を受賞したリチャード・ファインマンに由来する学習法です。「専門用語を使わずに説明できなければ、本当に理解していない」という考えに基づいています。\nステップ 内容 Step 1 学びたい概念を選ぶ Step 2 12歳でも分かるように説明を書く Step 3 説明に詰まった箇所（ギャップ）を特定し、学び直す Step 4 説明を改訂し、シンプルにする Step 1 \u0026amp; 2：最初の説明を書く # AWS IAMについて、専門用語を避けて説明を書いてみました。\nIAMというのはAWSリソースへのアクセスを管理する仕組みです。\nAWSというのはAmazonが管理しているクラウドサービスの集まり。パソコンからいろいろ便利なサービスを利用できます。このとき注意しないといけないのは、誰が・どのサービスを・何処まで触ってよいのかということです。AWSではサービスや設定を簡単にいじることができます。そうすると、不必要なお金がかかったり、サービスが正しく運用できなくなります。\nこのトラブルをあらかじめ防ぐためにIAMがあります。 それぞれの作業者や社員にIAMで権限を管理することで、AWSへのリソースやサービスへの接続を管理します。\nStep 3：ギャップの特定 # 書いた説明を見直すと、以下の3つのギャップが見つかりました。\n# ギャップ 具体的に何が足りない？ 1 「誰が」が浅い 人間だけでなく、プログラム（EC2、Lambda）も権限管理の対象という視点が抜けている 2 「どうやって」がない ポリシー・ユーザー・グループ・ロールの使い分けが説明されていない 3 アナロジーがない 12歳でも分かる比喩があると定着する ギャップ1への対応：「誰が」の範囲を広げる # 「作業者や社員」という表現では、人間しかイメージできません。実際にはEC2やLambdaといったAWSサービス自身も、他のAWSリソースにアクセスする際に権限が必要です。\n修正内容\nBefore：「それぞれの作業者や社員に」 After：「ユーザーやサービス（EC2・Lambda）による」 ギャップ2への対応：4概念の追加 # IAMの「どうやって」を説明するため、4つの概念を整理しました。\n最初に書いた定義\nIAMポリシー：IAMにおいて、操作や接続を認可するための仕組み IAMユーザー：IAMによって発行されたユーザーアカウント IAMグループ：IAMユーザーをグループ単位で管理するための仕組み IAMロール：各種AWSリソースに対して他のAWSリソースへの操作や接続を認可する仕組み 見直して気づいた問題\nIAMロールの説明が「リソース間」に限定されていました。実際には人間がIAMロールを引き受ける（AssumeRole）こともあります。例えば、別のAWSアカウントに一時的にアクセスするケースです。\n修正後の定義\nIAMポリシー：「何を許可/拒否するか」を定義したルール IAMユーザー：個人に紐づくアカウント IAMグループ：ユーザーをまとめて同じルールを適用 IAMロール：人間やサービスに一時的に権限を与える仕組み ギャップ3への対応：アナロジーの追加 # 会社のオフィスビルに例えると、各概念がイメージしやすくなりました。\nIAMの概念 オフィスビルで例えると IAMポリシー 「3階の会議室は入れるが、サーバールームは入れない」というルール IAMユーザー 社員証（個人を識別） IAMグループ 「営業部」「開発部」といった部署単位でルールをまとめて適用 IAMロール 清掃業者用の一時入館証（人ではなく役割に紐づく） 追加の修正：IAMを使わないとどうなるか # 最初の説明では「不必要なお金がかかる」という例を挙げていましたが、これはIAMで防げる問題ではありませんでした。IAMは「誰が何をできるか」を制限するもので、「どのスペックを選ぶか」は制限できません。\n修正内容\nBefore：「要件以上スペック（オーバースペック）などを設定すると…」 After：「退職者など想定していないユーザーがサービスなどへ接続したり、リソースを削除する…」 Step 4：完成版 # 反復改善を経て、以下の説明が完成しました。\nAWS IAMとは、ユーザーやサービス（EC2・Lambda）による「AWSのリソースやサービス」へのアクセスを管理する仕組みです。AWSとはAmazonが提供しているクラウドサービスの総称であり、コンピュータから便利なサービスを利用することが可能です。 AWSを利用する際の注意点として、「誰が・どのサービスを・何処まで」アクセスしてよいか制限する必要があります。 IAMによる管理を実施しない場合、退職者など想定していないユーザーがサービスなどへ接続したり、リソースを削除するような危険性があります。 このとき、IAMの用語として、「IAMポリシー」・「IAMユーザー」・「IAMグループ」・「IAMロール」があります。 AWSの環境を会社のビルに例えると、それぞれは下記に例えられます。\nIAMポリシー：「何を許可/拒否するか」を定義したルール IAMユーザー：個人に紐づくアカウント（社員証） IAMグループ：ユーザーをまとめて同じルールを適用（部署単位） IAMロール：人間やサービスに一時的に権限を与える仕組み（一時入館証） IAMユーザー・グループ・ロールにIAMポリシーを付与することで、権限を管理します。 上記のようなトラブルをAWS IAMによって適切な権限を設定することで防ぐことが可能になり、適切なAWSの運用が可能になります。\nBefore / After 比較 # # ギャップ Before After 1 「誰が」が浅い 人間（作業者・社員）のみ ユーザーやサービス（EC2・Lambda） 2 「どうやって」がない 説明なし 4概念（ポリシー・ユーザー・グループ・ロール）を正確に説明 3 アナロジーがない なし 会社のビル（社員証・部署・一時入館証）で例示 まとめ # ファインマンテクニックは「説明できない箇所 = 理解が曖昧な箇所」を特定するのに有効 IAMの権限管理対象は人間だけでなく、EC2・Lambdaなどのサービスも含む IAMロールは「リソース間の権限付与」だけでなく「人間への一時的な権限付与」にも使う アナロジー（オフィスビルの例）を使うと、抽象的な概念が具体的になる 「IAMで防げる問題は何か」を正確に理解することが重要 参考 # 『AWS運用入門 改訂第2版 押さえておきたいAWSの基本と運用ノウハウ』山﨑翔平・小倉大・峯侑資 著/SBクリエイティブ（2025年） IAM チュートリアル - AWS公式 ","date":"2025年 12月 14日","externalUrl":null,"permalink":"/posts/251214123005_feynman-technique-aws-iam-organization/","section":"Posts","summary":"","title":"ファインマンテクニックでAWS IAMを整理してみた","type":"posts"},{"content":"","date":"2025年 12月 14日","externalUrl":null,"permalink":"/tags/%E3%83%A1%E3%83%A2/","section":"Tags","summary":"","title":"メモ","type":"tags"},{"content":" 今日学んだこと # AWS IAMは「誰が・どのサービスを・どこまで」アクセスできるかを管理する仕組みです。IAMポリシー・IAMユーザー・IAMグループ・IAMロールの4つの概念を、オフィスビルのアナロジーで整理しました。\n学習内容 # IAMとは # AWS IAM（Identity and Access Management）は、ユーザーやサービス（EC2・Lambda）による「AWSのリソースやサービス」へのアクセスを管理する仕組みです。\nなぜIAMが必要か # AWSを利用する際は、「誰が・どのサービスを・どこまで」アクセスしてよいか制限する必要があります。\nIAMによる管理を実施しない場合、以下のようなリスクがあります。\n退職者など想定していないユーザーがサービスへ接続する 権限のないユーザーがリソースを削除する 4つの概念 # IAMには4つの主要な概念があります。\n概念 役割 IAMポリシー 「何を許可/拒否するか」を定義したルール IAMユーザー 個人に紐づくアカウント IAMグループ ユーザーをまとめて同じルールを適用 IAMロール 人間やサービスに一時的に権限を与える仕組み IAMユーザー・グループ・ロールにIAMポリシーを付与することで、権限を管理します。\nオフィスビルで例える # AWSの環境をオフィスビルに例えると、4つの概念は以下のように対応します。\nIAMの概念 オフィスビルで例えると IAMポリシー 「3階の会議室は入れるが、サーバールームは入れない」というルール IAMユーザー 社員証（個人を識別） IAMグループ 「営業部」「開発部」といった部署単位でルールをまとめて適用 IAMロール 清掃業者用の一時入館証（人ではなく役割に紐づく） 権限管理の仕組み # IAMポリシー（ルール） ↓ 付与 IAMユーザー / IAMグループ / IAMロール ↓ AWSリソースへのアクセス制御 ポリシーを直接ユーザーに付与することも可能ですが、グループにまとめて付与することで効率的に管理できます。\nベストプラクティス # IAMを運用する際は、以下の原則を意識しましょう。\n原則 内容 ルートユーザーは使わない AWSアカウント作成時のルートユーザーは強力すぎるため、日常業務ではIAMユーザーを使用する 最小権限の原則 必要最低限の権限のみを付与し、不要な権限は与えない グループで権限を管理 個人に直接ポリシーを付与せず、グループ経由で管理すると運用が楽になる まとめ # 概念 一言で言うと アナロジー IAMポリシー 許可/拒否のルール 入室ルール IAMユーザー 個人アカウント 社員証 IAMグループ ユーザーのまとまり 部署 IAMロール 一時的な権限付与 一時入館証 IAMは「誰が・どのサービスを・どこまで」を管理する仕組み 管理対象は人間だけでなく、EC2やLambdaなどのサービスも含まれる ポリシーをユーザー・グループ・ロールに付与して権限を制御する 参考 # 『AWS運用入門 改訂第2版 押さえておきたいAWSの基本と運用ノウハウ』山﨑翔平・小倉大・峯侑資 著/SBクリエイティブ（2025年） IAM チュートリアル - AWS公式 ","date":"2025年 12月 13日","externalUrl":null,"permalink":"/posts/251213122533_aws-iam-basics-explained-through-office-building-analogy/","section":"Posts","summary":"","title":"AWS IAMの基礎：4つの概念をオフィスビルで例える","type":"posts"},{"content":"","date":"2025年 12月 13日","externalUrl":null,"permalink":"/tags/%E3%81%BE%E3%81%A8%E3%82%81/","section":"Tags","summary":"","title":"まとめ","type":"tags"},{"content":"","date":"2025年 12月 12日","externalUrl":null,"permalink":"/tags/raycast/","section":"Tags","summary":"","title":"Raycast","type":"tags"},{"content":" 今日学んだこと # Raycast for WindowsにToggl Track拡張を導入し、ホットキー一発で時間計測の開始・停止ができるようになりました。ブラウザを開く手間がなくなり、計測開始のハードルが下がりました。\n学習内容 # 背景 # Toggl Trackで学習時間を記録していたが、毎回ブラウザを開いて操作するのが面倒だった。ショートカットキーで計測を開始・停止できる環境を作りたいと考えた。\nセットアップ手順 # Step 1: Toggl Track拡張のインストール # Raycastを開き「Store」と入力 「Toggl Track」を検索してインストール Step 2: APIトークンの設定 # https://track.toggl.com/profile にアクセス ページ下部の「API Token」をコピー Raycast → 拡張機能の設定 → Toggl Track → APIトークンを貼り付け 「Configure Extension」を選択するとAPIトークンの設定画面に進めます\nStep 3: ホットキーの設定 # Raycast Settings → Extensions → Toggl Track → Commands で設定。\nコマンド 設定例 Start/Stop Time Entry Ctrl+Shift+T 使い方 # 計測開始:\nCtrl+Shift+T を押す 過去のエントリー一覧が表示される 再開したいエントリーを選択、または「Create a new time entry」で新規作成 計測停止:\nCtrl+Shift+T を押す 一番上に表示される実行中エントリーを選択してEnter まとめ # Raycast for WindowsはToggl Track拡張に対応している APIトークンを設定するだけで連携可能 ホットキー設定で、任意のキーから計測開始・停止ができる 参考 # Raycast Store: Toggl Track ","date":"2025年 12月 12日","externalUrl":null,"permalink":"/posts/251212231019_raycast-windows-toggl-track-extension-hotkey-time-tracking/","section":"Posts","summary":"","title":"Raycast for Windows + Toggl Track拡張でホットキーから時間計測","type":"posts"},{"content":"","date":"2025年 12月 10日","externalUrl":null,"permalink":"/tags/terraform/","section":"Tags","summary":"","title":"Terraform","type":"tags"},{"content":" 今日学んだこと # Terraformを使う上で頻繁に参照するコマンド、ブロック構文、関数、パターンを1つの記事にまとめました。作業中に「あれ、どう書くんだっけ？」となったときにすぐ参照できるチートシートです。\n学習内容 # 基本コマンド # 初期化・実行コマンド コマンド 説明 よく使うオプション terraform init 初期化（Provider取得） -upgrade（Provider更新） terraform plan 差分確認（ドライラン） -out=plan.tfplan（計画を保存） terraform apply 変更を適用 -auto-approve（確認スキップ） terraform destroy 全リソース削除 -target=xxx（特定リソースのみ） 確認・検証コマンド コマンド 説明 terraform validate 構文チェック terraform fmt コード整形（インデント等） terraform fmt -check 整形が必要か確認のみ terraform show 現在のStateを表示 terraform output Output値を表示 State操作コマンド コマンド 説明 terraform state list 管理中リソース一覧 terraform state show \u0026lt;リソース\u0026gt; 特定リソースの詳細 terraform state rm \u0026lt;リソース\u0026gt; Stateから削除（実リソースは残る） terraform state mv \u0026lt;旧\u0026gt; \u0026lt;新\u0026gt; リソース名変更 terraform force-unlock \u0026lt;LOCK_ID\u0026gt; ロック強制解除 その他のコマンド コマンド 説明 terraform graph 依存関係をDOT形式で出力 terraform console 対話モード（式の評価テスト） terraform import \u0026lt;リソース\u0026gt; \u0026lt;ID\u0026gt; 既存リソースをStateに取り込み terraform apply -replace=\u0026lt;リソース\u0026gt; 指定リソースを再作成 Note: terraform taintは非推奨。-replaceオプションを使用する。\nブロック構文 # terraform ブロック（設定） ```hcl terraform { required_version = \"\u003e= 1.0.0\" required_providers { aws = { source = \u0026ldquo;hashicorp/aws\u0026rdquo; version = \u0026ldquo;~\u0026gt; 5.0\u0026rdquo; } }\nbackend \u0026ldquo;s3\u0026rdquo; { bucket = \u0026ldquo;my-tfstate-bucket\u0026rdquo; key = \u0026ldquo;terraform.tfstate\u0026rdquo; region = \u0026ldquo;ap-northeast-1\u0026rdquo; dynamodb_table = \u0026ldquo;my-tfstate-lock\u0026rdquo; encrypt = true } }\n\u0026lt;/details\u0026gt; \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;provider ブロック\u0026lt;/summary\u0026gt; ```hcl provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; default_tags { tags = { Project = \u0026#34;my-project\u0026#34; ManagedBy = \u0026#34;terraform\u0026#34; } } } # 複数リージョン対応（alias） provider \u0026#34;aws\u0026#34; { alias = \u0026#34;us_east_1\u0026#34; region = \u0026#34;us-east-1\u0026#34; } resource ブロック ```hcl resource \"aws_instance\" \"web\" { ami = \"ami-12345678\" instance_type = \"t3.micro\" subnet_id = aws_subnet.public.id tags = { Name = \u0026ldquo;web-server\u0026rdquo; }\ndepends_on = [aws_internet_gateway.main]\nlifecycle { create_before_destroy = true prevent_destroy = false ignore_changes = [tags] } }\n\u0026lt;/details\u0026gt; \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;data ブロック（既存リソース参照）\u0026lt;/summary\u0026gt; ```hcl data \u0026#34;aws_ami\u0026#34; \u0026#34;amazon_linux\u0026#34; { most_recent = true owners = [\u0026#34;amazon\u0026#34;] filter { name = \u0026#34;name\u0026#34; values = [\u0026#34;al2023-ami-*-x86_64\u0026#34;] } } resource \u0026#34;aws_instance\u0026#34; \u0026#34;web\u0026#34; { ami = data.aws_ami.amazon_linux.id } variable ブロック（入力変数） ```hcl variable \"instance_type\" { type = string default = \"t3.micro\" description = \"EC2 instance type\" } variable \u0026ldquo;environment\u0026rdquo; { type = string validation { condition = contains([\u0026ldquo;dev\u0026rdquo;, \u0026ldquo;stg\u0026rdquo;, \u0026ldquo;prod\u0026rdquo;], var.environment) error_message = \u0026ldquo;environment must be dev, stg, or prod\u0026rdquo; } }\nvariable \u0026ldquo;password\u0026rdquo; { type = string sensitive = true }\n\u0026lt;/details\u0026gt; \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;output / locals ブロック\u0026lt;/summary\u0026gt; ```hcl output \u0026#34;instance_id\u0026#34; { value = aws_instance.web.id description = \u0026#34;EC2 instance ID\u0026#34; } output \u0026#34;db_password\u0026#34; { value = aws_db_instance.main.password sensitive = true } locals { common_tags = { Project = var.project_name Environment = var.environment ManagedBy = \u0026#34;terraform\u0026#34; } name_prefix = \u0026#34;${var.project_name}-${var.environment}\u0026#34; } module ブロック ```hcl module \"vpc\" { source = \"./modules/vpc\" vpc_cidr = \u0026ldquo;10.0.0.0/16\u0026rdquo; environment = var.environment }\nmodule \u0026ldquo;s3\u0026rdquo; { source = \u0026ldquo;terraform-aws-modules/s3-bucket/aws\u0026rdquo; version = \u0026ldquo;3.0.0\u0026rdquo;\nbucket = \u0026ldquo;my-bucket\u0026rdquo; }\nマルチリージョンプロバイダーを渡す # module \u0026ldquo;acm\u0026rdquo; { source = \u0026ldquo;./modules/acm\u0026rdquo;\nproviders = { aws = aws.us_east_1 } }\n\u0026lt;/details\u0026gt; \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;moved ブロック（リファクタリング）\u0026lt;/summary\u0026gt; ```hcl moved { from = aws_s3_bucket.content to = module.s3_content.aws_s3_bucket.this } moved { from = aws_instance.web to = aws_instance.web_server } よく使う型 # 型 例 string \u0026quot;hello\u0026quot; number 123 bool true, false list(string) [\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;] set(string) toset([\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;]) map(string) { key1 = \u0026quot;value1\u0026quot;, key2 = \u0026quot;value2\u0026quot; } object({...}) { name = string, port = number } any 任意の型 よく使う関数 # 文字列関数 関数 説明 例 format() 書式化 format(\u0026quot;Hello, %s!\u0026quot;, var.name) join() 結合 join(\u0026quot;, \u0026quot;, [\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;]) → \u0026quot;a, b, c\u0026quot; split() 分割 split(\u0026quot;,\u0026quot;, \u0026quot;a,b,c\u0026quot;) → [\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;] lower() 小文字化 lower(\u0026quot;HELLO\u0026quot;) → \u0026quot;hello\u0026quot; upper() 大文字化 upper(\u0026quot;hello\u0026quot;) → \u0026quot;HELLO\u0026quot; replace() 置換 replace(\u0026quot;hello\u0026quot;, \u0026quot;l\u0026quot;, \u0026quot;L\u0026quot;) trimspace() 空白除去 trimspace(\u0026quot; hello \u0026quot;) → \u0026quot;hello\u0026quot; コレクション関数 関数 説明 例 length() 要素数 length([\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;]) → 2 element() インデックス参照 element([\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;], 0) → \u0026quot;a\u0026quot; concat() リスト結合 concat([\u0026quot;a\u0026quot;], [\u0026quot;b\u0026quot;]) → [\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;] flatten() ネスト解除 flatten([[\u0026quot;a\u0026quot;], [\u0026quot;b\u0026quot;]]) → [\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;] merge() マップ結合 merge({a=1}, {b=2}) → {a=1, b=2} lookup() マップ検索 lookup({a=1}, \u0026quot;a\u0026quot;, 0) → 1 keys() キー一覧 keys({a=1, b=2}) → [\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;] values() 値一覧 values({a=1, b=2}) → [1, 2] contains() 要素存在確認 contains([\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;], \u0026quot;a\u0026quot;) → true distinct() 重複除去 distinct([\u0026quot;a\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;]) → [\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;] ファイル関数 関数 説明 例 file() ファイル読み込み file(\u0026quot;./scripts/init.sh\u0026quot;) pathexpand() ~をホームパスに展開 pathexpand(\u0026quot;~/.ssh/id_rsa.pub\u0026quot;) filebase64() Base64で読み込み filebase64(\u0026quot;image.png\u0026quot;) templatefile() テンプレート適用 templatefile(\u0026quot;user_data.sh\u0026quot;, {name = \u0026quot;web\u0026quot;}) 条件・型変換関数 関数 説明 例 coalesce() 最初の非null値 coalesce(null, \u0026quot;default\u0026quot;) → \u0026quot;default\u0026quot; try() エラー時のフォールバック try(var.optional, \u0026quot;default\u0026quot;) tostring() 文字列変換 tostring(123) → \u0026quot;123\u0026quot; tonumber() 数値変換 tonumber(\u0026quot;123\u0026quot;) → 123 tobool() 真偽値変換 tobool(\u0026quot;true\u0026quot;) → true tolist() リスト変換 tolist(toset([\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;])) toset() セット変換 toset([\u0026quot;a\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;]) 条件分岐・ループ # 三項演算子・count ```hcl # 三項演算子 instance_type = var.environment == \"prod\" ? \"t3.large\" : \"t3.micro\" count（インデックスベース） # resource \u0026ldquo;aws_instance\u0026rdquo; \u0026ldquo;web\u0026rdquo; { count = 3 tags = { Name = \u0026ldquo;web-${count.index}\u0026rdquo; } }\n条件付き作成 # resource \u0026ldquo;aws_eip\u0026rdquo; \u0026ldquo;nat\u0026rdquo; { count = var.create_nat ? 1 : 0 }\n\u0026lt;/details\u0026gt; \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;for_each\u0026lt;/summary\u0026gt; ```hcl # マップ resource \u0026#34;aws_subnet\u0026#34; \u0026#34;private\u0026#34; { for_each = { \u0026#34;a\u0026#34; = \u0026#34;10.0.1.0/24\u0026#34; \u0026#34;c\u0026#34; = \u0026#34;10.0.2.0/24\u0026#34; } availability_zone = \u0026#34;ap-northeast-1${each.key}\u0026#34; cidr_block = each.value } # セット resource \u0026#34;aws_security_group_rule\u0026#34; \u0026#34;ports\u0026#34; { for_each = toset([\u0026#34;80\u0026#34;, \u0026#34;443\u0026#34;, \u0026#34;22\u0026#34;]) from_port = tonumber(each.value) to_port = tonumber(each.value) } for式・dynamic ブロック ```hcl # for式 locals { upper_names = [for name in var.names : upper(name)] instance_ids = {for inst in aws_instance.web : inst.tags.Name =\u003e inst.id} prod_instances = [for inst in var.instances : inst if inst.env == \"prod\"] } dynamic ブロック # resource \u0026ldquo;aws_security_group\u0026rdquo; \u0026ldquo;main\u0026rdquo; { name = \u0026ldquo;main\u0026rdquo;\ndynamic \u0026ldquo;ingress\u0026rdquo; { for_each = var.ingress_rules content { from_port = ingress.value.from_port to_port = ingress.value.to_port protocol = ingress.value.protocol cidr_blocks = ingress.value.cidr_blocks } } }\n\u0026lt;/details\u0026gt; --- ### ディレクトリ構成例 \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;シンプル構成\u0026lt;/summary\u0026gt; project/ ├── main.tf ├── variables.tf ├── outputs.tf ├── versions.tf └── terraform.tfvars\n\u0026lt;/details\u0026gt; \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;モジュール構成\u0026lt;/summary\u0026gt; project/ ├── modules/ │ ├── vpc/ │ │ ├── main.tf │ │ ├── variables.tf │ │ └── outputs.tf │ └── ec2/ ├── environments/ │ ├── dev/ │ │ ├── main.tf │ │ ├── backend.tf │ │ └── terraform.tfvars │ └── prod/ └── backend-setup/ └── main.tf\n\u0026lt;/details\u0026gt; --- ### よく使うパターン \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;タグの共通化\u0026lt;/summary\u0026gt; ```hcl locals { common_tags = { Project = \u0026#34;my-project\u0026#34; Environment = var.environment ManagedBy = \u0026#34;terraform\u0026#34; } } resource \u0026#34;aws_instance\u0026#34; \u0026#34;web\u0026#34; { tags = merge(local.common_tags, { Name = \u0026#34;web-server\u0026#34; Role = \u0026#34;web\u0026#34; }) } 条件付きリソース作成 ```hcl resource \"aws_nat_gateway\" \"main\" { count = var.enable_nat_gateway ? 1 : 0 allocation_id = aws_eip.nat[0].id subnet_id = aws_subnet.public.id }\noutput \u0026ldquo;nat_gateway_id\u0026rdquo; { value = var.enable_nat_gateway ? aws_nat_gateway.main[0].id : null }\n\u0026lt;/details\u0026gt; \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;user_data / セキュリティグループ参照\u0026lt;/summary\u0026gt; ```hcl # user_data resource \u0026#34;aws_instance\u0026#34; \u0026#34;web\u0026#34; { user_data = \u0026lt;\u0026lt;-EOF #!/bin/bash dnf update -y dnf install -y httpd systemctl start httpd EOF } # SGをソースに指定 resource \u0026#34;aws_vpc_security_group_ingress_rule\u0026#34; \u0026#34;rds\u0026#34; { security_group_id = aws_security_group.rds.id referenced_security_group_id = aws_security_group.web.id from_port = 3306 to_port = 3306 ip_protocol = \u0026#34;tcp\u0026#34; } 注意点・ベストプラクティス # やるべきこと # terraform fmt でコード整形 terraform validate で構文チェック .terraform.lock.hcl をGit管理（Providerバージョン固定） terraform.tfvars はGit管理外（機密情報含む場合） sensitive = true でパスワード等をマスク リモートバックエンド（S3 + DynamoDB）で状態管理 避けるべきこと # 本番環境で -auto-approve を使わない ハードコードされたAMI ID（data sourceで取得） ハードコードされたパスワード（variables or Secrets Manager） terraform state rm の安易な使用 force-unlock は他の操作がないことを確認してから まとめ # 用途 参照セクション コマンドを調べたい 基本コマンド 書き方を確認したい ブロック構文 関数の使い方を調べたい よく使う関数 ループの書き方を確認したい 条件分岐・ループ 実装パターンを参考にしたい よく使うパターン terraform init → plan → apply が基本フロー countはインデックス、for_eachはキーでリソースを識別 localsで共通値を定義、merge()でタグを結合 参考 # Terraform公式ドキュメント AWS Provider Terraform関数一覧 Terraform Best Practices ","date":"2025年 12月 10日","externalUrl":null,"permalink":"/posts/251210221100_terraform-cheatsheet-commands-syntax-quick-reference/","section":"Posts","summary":"","title":"Terraformチートシート：コマンド・構文・関数クイックリファレンス","type":"posts"},{"content":" 今日学んだこと # TerraformでRDS（MySQL）を構築しました。DBサブネットグループにはシングルAZ構成でも2つの異なるAZのサブネットが必須であること、パスワード管理の本番向け手法を学びました。\n学習内容 # 背景 # 「Amazon Web Services 基礎からのネットワーク\u0026amp;サーバー構築」ではEC2上にMariaDBを構築していましたが、実務ではマネージドサービスのRDSを使うことが多いため、Terraformで構築しました。\n構築するリソース # リソース 名前 説明 DB Subnet Group practice-db-subnet-group RDS配置用（2AZ必須） RDS Instance practice-db-instance MySQL 8.0 DBサブネットグループの作成 # resource \u0026#34;aws_db_subnet_group\u0026#34; \u0026#34;main\u0026#34; { name = \u0026#34;practice-db-subnet-group\u0026#34; subnet_ids = [aws_subnet.private_1.id, aws_subnet.private_2.id] tags = { Name = \u0026#34;practice-db-subnet-group\u0026#34; } } RDSはDBサブネットグループに最低2つの異なるAZのサブネットを要求します。これはマルチAZ配置でなくても必須です。\n設定 サブネット要件 理由 シングルAZ 2AZ必須 将来のマルチAZ化に備えた設計 マルチAZ 2AZ必須 スタンバイを別AZに配置 RDSインスタンスの作成 # resource \u0026#34;aws_db_instance\u0026#34; \u0026#34;main\u0026#34; { identifier = \u0026#34;practice-db-instance\u0026#34; engine = \u0026#34;mysql\u0026#34; engine_version = \u0026#34;8.0\u0026#34; instance_class = \u0026#34;db.t3.micro\u0026#34; allocated_storage = 20 storage_type = \u0026#34;gp2\u0026#34; db_name = \u0026#34;wordpress\u0026#34; username = \u0026#34;admin\u0026#34; password = \u0026#34;YourPassword123!\u0026#34; # 学習用 db_subnet_group_name = aws_db_subnet_group.main.name vpc_security_group_ids = [aws_security_group.rds.id] publicly_accessible = false skip_final_snapshot = true # 学習用 tags = { Name = \u0026#34;practice-db-instance\u0026#34; } } 設定項目の解説 # 基本設定 # 項目 値 説明 identifier practice-db-instance RDSの識別子（エンドポイント名に使用） engine mysql DBエンジン（mysql, postgres, mariadb等） engine_version 8.0 メジャーバージョン指定（マイナーは自動） インスタンス設定 # 項目 値 説明 instance_class db.t3.micro インスタンスタイプ（無料枠対象） allocated_storage 20 ストレージ容量（GB） storage_type gp2 汎用SSD（gp3も選択可） セキュリティ設定 # 項目 値 説明 publicly_accessible false インターネットから直接アクセス不可 vpc_security_group_ids [rds-sg] SGでアクセス制御 publicly_accessible = false を設定するとパブリックIPが付与されず、VPC内からのみ接続可能になります。本番環境では基本的にfalseを設定します。\n学習用と本番用の設定の違い # 項目 学習用 本番推奨 password 直書き Secrets Manager or 変数 skip_final_snapshot true false（削除時にスナップショット作成） deletion_protection なし true（誤削除防止） multi_az false true（高可用性） backup_retention_period 0 7以上（自動バックアップ） パスワード管理（本番向け） # 方法1: 変数で外部化 # variable \u0026#34;db_password\u0026#34; { type = string sensitive = true } resource \u0026#34;aws_db_instance\u0026#34; \u0026#34;main\u0026#34; { # ... password = var.db_password } # 実行時に指定 terraform apply -var=\u0026#34;db_password=SecurePassword123!\u0026#34; 方法2: Secrets Manager（推奨） # data \u0026#34;aws_secretsmanager_secret_version\u0026#34; \u0026#34;db\u0026#34; { secret_id = \u0026#34;prod/db/password\u0026#34; } resource \u0026#34;aws_db_instance\u0026#34; \u0026#34;main\u0026#34; { # ... password = jsondecode(data.aws_secretsmanager_secret_version.db.secret_string)[\u0026#34;password\u0026#34;] } Security Group設計（復習） # resource \u0026#34;aws_vpc_security_group_ingress_rule\u0026#34; \u0026#34;rds_mysql\u0026#34; { security_group_id = aws_security_group.rds.id description = \u0026#34;MySQL from web server\u0026#34; from_port = 3306 to_port = 3306 ip_protocol = \u0026#34;tcp\u0026#34; referenced_security_group_id = aws_security_group.web.id } WebサーバーのSGをソースに指定することで、Webサーバーからのみ接続を許可します。\n作成にかかる時間 # RDSは作成に5〜10分かかります。terraform apply 実行後、気長に待ちます。\naws_db_instance.main: Still creating... [5m0s elapsed] aws_db_instance.main: Still creating... [5m10s elapsed] aws_db_instance.main: Creation complete after 5m15s 接続確認 # WebサーバーからRDSに接続します。\n# WebサーバーにSSH接続後 mysql -h practice-db-instance.xxxxx.ap-northeast-1.rds.amazonaws.com \\ -u admin -p # パスワード入力後 mysql\u0026gt; use wordpress; エンドポイントは terraform output またはAWSコンソールで確認できます。\noutput \u0026#34;rds_endpoint\u0026#34; { value = aws_db_instance.main.endpoint } EC2上のDB vs RDS # 観点 EC2上のDB RDS 管理負担 高（パッチ、バックアップ自前） 低（マネージド） 可用性 自前で構築 マルチAZオプションあり コスト 低め 高め 柔軟性 高（何でもできる） 制限あり 基本はRDS推奨です。特殊な要件がある場合のみEC2を検討します。\nまとめ # トピック 内容 DBサブネットグループ 2AZ必須（シングルAZ構成でも） publicly_accessible false でVPC内からのみ接続 skip_final_snapshot 学習用はtrue、本番はfalse パスワード管理 直書きは学習のみ。本番はSecrets Manager 作成時間 5〜10分かかる 参考 # Amazon Web Services 基礎からのネットワーク＆サーバー構築 改訂4版 Terraform AWS Provider - RDS Instance Terraform AWS Provider - DB Subnet Group AWS RDS ドキュメント ","date":"2025年 12月 10日","externalUrl":null,"permalink":"/posts/251210215023_rds-mysql-with-terraform/","section":"Posts","summary":"","title":"RDS（MySQL）をTerraformで構築","type":"posts"},{"content":" 今日学んだこと # プライベートサブネットのEC2からインターネットにアクセスするためのNAT GatewayをTerraformで構築しました。NAT Gatewayはパブリックサブネットに配置する必要があること、depends_on で暗黙的な依存関係を明示する必要があることを学びました。\n学習内容 # NAT Gatewayの役割 # プライベートサブネットのEC2 ↓ (送信) NAT Gateway（パブリックサブネット） ↓ Internet Gateway ↓ インターネット アウトバウンド: プライベート → インターネット（許可） インバウンド: インターネット → プライベート（拒否） プライベートサブネットのEC2からyum/dnf update等を実行したいが、インターネットからの直接アクセスは許可したくない場合に使用します。\n構築するリソース # リソース 名前 説明 Elastic IP practice-nat-eip NAT Gateway用の固定IP NAT Gateway practice-nat パブリックサブネットに配置 Route - プライベートRT → NAT Gateway Elastic IPの作成 # resource \u0026#34;aws_eip\u0026#34; \u0026#34;nat\u0026#34; { domain = \u0026#34;vpc\u0026#34; tags = { Name = \u0026#34;practice-nat-eip\u0026#34; } depends_on = [aws_internet_gateway.main] } domain = \u0026quot;vpc\u0026quot; でVPC用のElastic IPを作成します。旧構文の vpc = true は非推奨です。\nNAT Gatewayの作成 # resource \u0026#34;aws_nat_gateway\u0026#34; \u0026#34;main\u0026#34; { allocation_id = aws_eip.nat.id subnet_id = aws_subnet.public.id tags = { Name = \u0026#34;practice-nat\u0026#34; } depends_on = [aws_internet_gateway.main] } NAT GatewayはInternet Gateway（IGW）経由でインターネットに接続するため、IGWがアタッチされたVPC内のパブリックサブネットに配置する必要があります。\nプライベートルートテーブルにルート追加 # resource \u0026#34;aws_route\u0026#34; \u0026#34;private_nat\u0026#34; { route_table_id = aws_route_table.private.id destination_cidr_block = \u0026#34;0.0.0.0/0\u0026#34; nat_gateway_id = aws_nat_gateway.main.id } ルートテーブル 0.0.0.0/0 の宛先 結果 パブリック Internet Gateway 直接インターネット通信 プライベート NAT Gateway NAT経由でインターネット通信 depends_onの意味 # depends_on = [aws_internet_gateway.main] Terraformは通常、リソース間の依存関係を自動検出します。しかし、NAT Gateway → IGWの依存関係は暗黙的（コード上の参照がない）なため、明示的に指定する必要があります。\n状況 depends_onの要否 subnet_id = aws_subnet.public.id 不要（参照あり） IGWが存在しないとNATが動作しない 必要（参照なし） コストに注意 # 項目 料金（東京リージョン、2024年12月時点） NAT Gateway時間料金 約$0.062/時（約$45/月） データ処理料金 $0.062/GB 学習環境では使わない時間帯は terraform destroy で削除することを推奨します。\n代替手段との比較 # 方法 コスト 管理負担 可用性 NAT Gateway 高 低（マネージド） 高 NATインスタンス 低 高（自前EC2） 中 VPCエンドポイント 低 低 高（AWSサービスのみ） 本番環境ではNAT Gateway推奨、学習/開発でコスト重視ならNATインスタンスも選択肢になります。S3/DynamoDB等のAWSサービスのみならVPCエンドポイントで十分です。\n動作確認 # プライベートサブネットのEC2にSSH接続（踏み台経由）して確認します。\n# インターネット接続確認 ping -c 3 google.com # NAT Gateway経由で通信していることを確認 curl ifconfig.me # → Elastic IPが表示されればNAT Gateway経由 # パッケージ更新が可能か確認 sudo dnf check-update まとめ # トピック 内容 NAT Gatewayの配置 パブリックサブネット（IGWへのルートが必要） depends_on 暗黙的な依存関係を明示的に指定 Elastic IP domain = \u0026quot;vpc\u0026quot; で作成 コスト 約$45/月。学習時は削除推奨 代替手段 NATインスタンス、VPCエンドポイント 参考 # Amazon Web Services 基礎からのネットワーク＆サーバー構築 改訂4版 Terraform AWS Provider - NAT Gateway AWS NAT Gateway ドキュメント NAT Gateway 料金 ","date":"2025年 12月 10日","externalUrl":null,"permalink":"/posts/251210214738_nat-gateway-with-terraform/","section":"Posts","summary":"","title":"NAT GatewayをTerraformで構築","type":"posts"},{"content":" 今日学んだこと # Terraformの user_data を使って、EC2起動時にApacheを自動インストールする方法を学びました。手動でSSH接続してセットアップする手間を省き、インフラ構築を完全に自動化できます。\n学習内容 # user_dataとは # EC2インスタンスの初回起動時に実行されるスクリプトです。OSの初期設定やソフトウェアのインストールを自動化できます。\nTerraformコード # resource \u0026#34;aws_instance\u0026#34; \u0026#34;web\u0026#34; { ami = data.aws_ami.amazon_linux_2023.id instance_type = \u0026#34;t3.micro\u0026#34; subnet_id = aws_subnet.public.id vpc_security_group_ids = [aws_security_group.web.id] key_name = aws_key_pair.main.key_name user_data = \u0026lt;\u0026lt;-EOF #!/bin/bash dnf update -y dnf install -y httpd systemctl start httpd systemctl enable httpd EOF tags = { Name = \u0026#34;practice-web\u0026#34; } } ヒアドキュメント構文 # user_data = \u0026lt;\u0026lt;-EOF #!/bin/bash コマンド1 コマンド2 EOF 要素 説明 \u0026lt;\u0026lt;-EOF ヒアドキュメント開始。- があると先頭のタブを除去 #!/bin/bash シェバン。Bashで実行することを指定 EOF ヒアドキュメント終了（任意の文字列でOK） \u0026lt;\u0026lt;EOF と \u0026lt;\u0026lt;-EOF の違い # # \u0026lt;\u0026lt;EOF（ハイフンなし）: インデントがそのまま含まれる user_data = \u0026lt;\u0026lt;EOF #!/bin/bash echo \u0026#34;hello\u0026#34; EOF # \u0026lt;\u0026lt;-EOF（ハイフンあり）: 先頭のタブを除去 user_data = \u0026lt;\u0026lt;-EOF #!/bin/bash echo \u0026#34;hello\u0026#34; EOF Terraformコードのインデントを揃えたい場合は \u0026lt;\u0026lt;-EOF を使います。\n💡 補足：標準のシェルでは - はタブのみ除去しますが、Terraform/HCLでは独自処理でインデントを適切に処理します。\nスクリプトの内容 # #!/bin/bash dnf update -y # パッケージを最新化 dnf install -y httpd # Apacheをインストール systemctl start httpd # Apacheを起動 systemctl enable httpd # OS再起動時に自動起動 Amazon Linux 2023ではパッケージマネージャーが dnf になっています（旧Amazon Linux 2は yum）。\n動作確認 # EC2作成後、パブリックIPにHTTPアクセスします。\nhttp://\u0026lt;パブリックIP\u0026gt; 「It works!」が表示されれば成功です。\nトラブルシューティング # 接続できない場合の確認ポイント：\nセキュリティグループ: ポート80（HTTP）が許可されているか user_dataログ: SSH接続して以下で確認 sudo cat /var/log/cloud-init-output.log Apache状態: systemctl status httpd で起動状態を確認 user_dataの注意点 # 注意点 詳細 初回起動時のみ 再起動しても再実行されない 変更時は再作成 user_dataを変更すると、EC2はdestroy→createになる ログ確認 /var/log/cloud-init-output.log で実行結果を確認可能 実行完了を待たない EC2が「running」でもスクリプト実行中の場合がある 応用：変数を埋め込む # variable \u0026#34;app_name\u0026#34; { default = \u0026#34;myapp\u0026#34; } resource \u0026#34;aws_instance\u0026#34; \u0026#34;web\u0026#34; { # ... user_data = \u0026lt;\u0026lt;-EOF #!/bin/bash echo \u0026#34;Deploying ${var.app_name}\u0026#34; \u0026gt; /var/www/html/index.html EOF } ヒアドキュメント内でも ${var.xxx} で変数展開が可能です。\nまとめ # トピック 内容 user_data EC2初回起動時に実行されるスクリプト ヒアドキュメント \u0026lt;\u0026lt;-EOF ... EOF で複数行文字列を記述 - の意味 先頭のタブを除去（Terraformではスペースも処理される） 初回のみ 再起動では再実行されない。変更時はEC2再作成 参考 # Amazon Web Services 基礎からのネットワーク＆サーバー構築 改訂4版 Terraform AWS Provider - EC2 Instance user_data AWS EC2 User Data ドキュメント ","date":"2025年 12月 10日","externalUrl":null,"permalink":"/posts/251210213639_ec2-startup-apache-auto-install-with-user-data/","section":"Posts","summary":"","title":"user_dataでEC2起動時にApacheを自動インストール","type":"posts"},{"content":" 今日学んだこと # 「Amazon Web Services 基礎からのネットワーク\u0026amp;サーバー構築」のハンズオンをTerraformで再構築しました。Security Groupでは「SGをソースに指定する」設計パターン、EC2ではdata sourceを使った最新AMIの動的取得を学びました。\n学習内容 # 構築するリソース # リソース 名前 用途 Security Group practice-web-sg Webサーバー用（SSH, HTTP） Security Group practice-db-sg 踏み台経由DB接続用（SSH, ICMP, MySQL） Security Group practice-rds-sg RDS用（MySQLをWebサーバーからのみ許可） EC2 practice-web パブリックサブネットに配置 EC2 practice-db プライベートサブネットに配置（踏み台） Security Groupの作成 # 基本構造 # resource \u0026#34;aws_security_group\u0026#34; \u0026#34;web\u0026#34; { name = \u0026#34;practice-web-sg\u0026#34; description = \u0026#34;Security group for practice web server\u0026#34; vpc_id = aws_vpc.main.id tags = { Name = \u0026#34;practice-web-sg\u0026#34; } } resource \u0026#34;aws_vpc_security_group_ingress_rule\u0026#34; \u0026#34;web_ssh\u0026#34; { security_group_id = aws_security_group.web.id description = \u0026#34;SSH access\u0026#34; from_port = 22 to_port = 22 ip_protocol = \u0026#34;tcp\u0026#34; cidr_ipv4 = \u0026#34;0.0.0.0/0\u0026#34; } resource \u0026#34;aws_vpc_security_group_ingress_rule\u0026#34; \u0026#34;web_http\u0026#34; { security_group_id = aws_security_group.web.id description = \u0026#34;HTTP access\u0026#34; from_port = 80 to_port = 80 ip_protocol = \u0026#34;tcp\u0026#34; cidr_ipv4 = \u0026#34;0.0.0.0/0\u0026#34; } resource \u0026#34;aws_vpc_security_group_egress_rule\u0026#34; \u0026#34;web_all\u0026#34; { security_group_id = aws_security_group.web.id ip_protocol = \u0026#34;-1\u0026#34; cidr_ipv4 = \u0026#34;0.0.0.0/0\u0026#34; } aws_vpc_security_group_ingress_rule はAWS Provider 5.xで推奨される新しいリソースタイプです。ルールごとに個別リソースになるため、変更時に他ルールへ影響しません。ip_protocol = \u0026quot;-1\u0026quot; は全プロトコル許可を意味します。\n注意: 上記の cidr_ipv4 = \u0026quot;0.0.0.0/0\u0026quot; は学習用の設定です。本番環境ではSSHアクセスを自分のIPアドレスに制限してください。\nSGをソースに指定する # RDSへの接続元をIPではなくSGで指定することで、柔軟なアクセス制御を実現します。\nresource \u0026#34;aws_security_group\u0026#34; \u0026#34;rds\u0026#34; { name = \u0026#34;practice-rds-sg\u0026#34; description = \u0026#34;Security group for practice RDS\u0026#34; vpc_id = aws_vpc.main.id tags = { Name = \u0026#34;practice-rds-sg\u0026#34; } } resource \u0026#34;aws_vpc_security_group_ingress_rule\u0026#34; \u0026#34;rds_mysql\u0026#34; { security_group_id = aws_security_group.rds.id description = \u0026#34;MySQL from web server\u0026#34; from_port = 3306 to_port = 3306 ip_protocol = \u0026#34;tcp\u0026#34; referenced_security_group_id = aws_security_group.web.id } referenced_security_group_id でIPアドレスではなくSGをソースに指定しています。\n方法 メリット デメリット IPアドレス指定 シンプル EC2のIP変更時にSG更新が必要 SG指定 IP変更に強い、スケーリングに対応 設計の理解が必要 Auto ScalingでEC2が増減しても、同じSGが付与されていれば自動的にアクセス許可されます。\nICMPルール（ping用） # resource \u0026#34;aws_vpc_security_group_ingress_rule\u0026#34; \u0026#34;db_icmp\u0026#34; { security_group_id = aws_security_group.db.id description = \u0026#34;Ping\u0026#34; from_port = -1 to_port = -1 ip_protocol = \u0026#34;icmp\u0026#34; cidr_ipv4 = \u0026#34;0.0.0.0/0\u0026#34; } ICMPは from_port = -1, to_port = -1 で全ICMPタイプを許可します。\nEC2の作成 # 最新AMIを動的取得 # data \u0026#34;aws_ami\u0026#34; \u0026#34;amazon_linux_2023\u0026#34; { most_recent = true owners = [\u0026#34;amazon\u0026#34;] filter { name = \u0026#34;name\u0026#34; values = [\u0026#34;al2023-ami-*-x86_64\u0026#34;] } filter { name = \u0026#34;virtualization-type\u0026#34; values = [\u0026#34;hvm\u0026#34;] } } AMI IDをハードコードしない理由は以下のとおりです。\nAMI IDはリージョンごとに異なる 新しいAMIがリリースされると古いIDは非推奨になる data sourceで常に最新を取得すればメンテナンス不要 EC2インスタンス # resource \u0026#34;aws_instance\u0026#34; \u0026#34;web\u0026#34; { ami = data.aws_ami.amazon_linux_2023.id instance_type = \u0026#34;t3.micro\u0026#34; subnet_id = aws_subnet.public.id vpc_security_group_ids = [aws_security_group.web.id] key_name = aws_key_pair.main.key_name tags = { Name = \u0026#34;practice-web\u0026#34; } } resource \u0026#34;aws_instance\u0026#34; \u0026#34;db\u0026#34; { ami = data.aws_ami.amazon_linux_2023.id instance_type = \u0026#34;t3.micro\u0026#34; subnet_id = aws_subnet.private_1.id vpc_security_group_ids = [aws_security_group.db.id] key_name = aws_key_pair.main.key_name tags = { Name = \u0026#34;practice-db\u0026#34; } } vpc_security_group_ids はリスト形式で、複数SGを付与できます。パブリックサブネットのEC2は自動でパブリックIPを取得し、プライベートサブネットのEC2はパブリックIPなしとなります。\nキーペア # resource \u0026#34;aws_key_pair\u0026#34; \u0026#34;main\u0026#34; { key_name = \u0026#34;practice-keypair\u0026#34; public_key = file(\u0026#34;~/.ssh/practice-keypair.pub\u0026#34;) tags = { Name = \u0026#34;practice-keypair\u0026#34; } } 事前にローカルでSSH鍵を生成しておきます。\nssh-keygen -t rsa -b 4096 -f ~/.ssh/practice-keypair -N \u0026#34;\u0026#34; Terraformには公開鍵のみ登録し、秘密鍵はローカルで管理します。\nまとめ # トピック 内容 新しいSGリソース aws_vpc_security_group_ingress_rule が推奨（ルール個別管理） SGをソースに指定 referenced_security_group_id でIP変更・スケーリングに強い設計 data source data \u0026quot;aws_ami\u0026quot; で最新AMIを動的取得 ICMPルール from_port = -1, to_port = -1 で全ICMP許可 キーペア 公開鍵のみAWSに登録、秘密鍵はローカル管理 参考 # Amazon Web Services 基礎からのネットワーク＆サーバー構築 改訂4版 Terraform AWS Provider - Security Group Terraform AWS Provider - EC2 Instance AWS Security Group ドキュメント ","date":"2025年 12月 10日","externalUrl":null,"permalink":"/posts/251210212221_ec2-security-group-terraform-setup/","section":"Posts","summary":"","title":"EC2 + Security GroupをTerraformで構築","type":"posts"},{"content":" 今日学んだこと # 「Amazon Web Services 基礎からのネットワーク\u0026amp;サーバー構築」のハンズオンをTerraformで再構築しました。VPCとサブネットの設計から、パブリック/プライベートの違いがルートテーブルの設定で決まることを実践を通じて理解しました。\n学習内容 # 構築するリソース # リソース 名前 CIDR / AZ VPC practice-vpc 10.0.0.0/16 パブリックサブネット practice-public-subnet 10.0.1.0/24 (ap-northeast-1a) パブリックサブネット2 practice-public-subnet-2 10.0.4.0/24 (ap-northeast-1c) プライベートサブネット practice-private-subnet 10.0.2.0/24 (ap-northeast-1a) プライベートサブネット2 practice-private-subnet-2 10.0.3.0/24 (ap-northeast-1c) Internet Gateway practice-igw - ルートテーブル（パブリック） practice-public-rt 0.0.0.0/0 → IGW ルートテーブル（プライベート） practice-private-rt ローカルのみ VPCの作成 # resource \u0026#34;aws_vpc\u0026#34; \u0026#34;main\u0026#34; { cidr_block = \u0026#34;10.0.0.0/16\u0026#34; enable_dns_hostnames = true enable_dns_support = true tags = { Name = \u0026#34;practice-vpc\u0026#34; } } enable_dns_hostnames = true を設定することで、EC2にパブリックDNS名が割り当てられます。AWSコンソールでは「VPCの設定を編集」から有効化する操作が必要ですが、Terraformでは属性1つで完結します。\nサブネットの作成 # resource \u0026#34;aws_subnet\u0026#34; \u0026#34;public\u0026#34; { vpc_id = aws_vpc.main.id cidr_block = \u0026#34;10.0.1.0/24\u0026#34; availability_zone = \u0026#34;ap-northeast-1a\u0026#34; map_public_ip_on_launch = true tags = { Name = \u0026#34;practice-public-subnet\u0026#34; } } resource \u0026#34;aws_subnet\u0026#34; \u0026#34;private_1\u0026#34; { vpc_id = aws_vpc.main.id cidr_block = \u0026#34;10.0.2.0/24\u0026#34; availability_zone = \u0026#34;ap-northeast-1a\u0026#34; tags = { Name = \u0026#34;practice-private-subnet\u0026#34; } } map_public_ip_on_launch = true はパブリックサブネットのみに設定します。プライベートサブネットにはパブリックIPが不要なため設定しません。\nInternet Gatewayの作成 # resource \u0026#34;aws_internet_gateway\u0026#34; \u0026#34;main\u0026#34; { vpc_id = aws_vpc.main.id tags = { Name = \u0026#34;practice-igw\u0026#34; } } Terraformでは vpc_id を指定するだけでIGW作成とVPCへのアタッチが同時に実行されます。AWSコンソールでは「作成」→「VPCにアタッチ」の2ステップが必要な操作です。\nルートテーブルの作成 # # パブリック用 resource \u0026#34;aws_route_table\u0026#34; \u0026#34;public\u0026#34; { vpc_id = aws_vpc.main.id route { cidr_block = \u0026#34;0.0.0.0/0\u0026#34; gateway_id = aws_internet_gateway.main.id } tags = { Name = \u0026#34;practice-public-rt\u0026#34; } } resource \u0026#34;aws_route_table_association\u0026#34; \u0026#34;public\u0026#34; { subnet_id = aws_subnet.public.id route_table_id = aws_route_table.public.id } # プライベート用 resource \u0026#34;aws_route_table\u0026#34; \u0026#34;private\u0026#34; { vpc_id = aws_vpc.main.id tags = { Name = \u0026#34;practice-private-rt\u0026#34; } } resource \u0026#34;aws_route_table_association\u0026#34; \u0026#34;private_1\u0026#34; { subnet_id = aws_subnet.private_1.id route_table_id = aws_route_table.private.id } パブリックルートテーブルには 0.0.0.0/0 → IGW のルートを設定し、プライベートルートテーブルにはローカルルート（10.0.0.0/16）のみを設定します。このIGWへのルートがあるかどうかがパブリック/プライベートの違いになります。\nなぜ2AZ構成にしたか # ALBは最低2つのAZが必要であり、RDSのDBサブネットグループも2AZ必須です。本番環境を意識した設計として、最初から2AZ構成にしました。\nまとめ # トピック 内容 パブリック/プライベートの違い サブネット作成時点では同じ。ルートテーブルにIGWへのルートがあるかで決まる DNS設定 enable_dns_hostnames = true でパブリックDNS名が割り当てられる IGWアタッチ Terraformでは vpc_id 指定でアタッチまで完了 明示的な関連付け ルートテーブルにサブネットを関連付けないと、メインルートテーブルが適用される 参考 # Amazon Web Services 基礎からのネットワーク＆サーバー構築 改訂4版 Terraform AWS Provider - VPC AWS VPC ドキュメント ","date":"2025年 12月 10日","externalUrl":null,"permalink":"/posts/251210211505_vpc-and-subnet-design-with-terraform/","section":"Posts","summary":"","title":"VPCとサブネット設計をTerraformで構築する","type":"posts"},{"content":" 今日学んだこと # Raycast Windows版を導入しました。キーボード操作で様々な作業を高速に行えるランチャーアプリで、App Launcher、Clipboard History、Snippets、Quicklinks、Calculatorの5つの基本機能を覚えることで、日常業務の効率化が期待できます。\n学習内容 # Raycastとは # キーボード操作で様々な作業を高速に行えるランチャーアプリです。Macで人気だったツールがWindows版としてリリースされました。\n項目 内容 対応OS Windows 10（21H2以降）、Windows 11 料金 基本機能は無料（Pro/Teamsプランは有料） 現状 ベータ版（v0.39.1.0） 導入方法 # 以下のいずれかの方法でインストールします。\n方法1：Microsoft Store\nhttps://www.raycast.com/windows から「Download on Microsoft Store」をクリック\n方法2：Winget\nwinget install raycast 主な機能一覧 # 機能 内容 App Launcher アプリ名を数文字入力するだけで即起動 File Search ローカルファイルを高速検索 Clipboard History コピー履歴を保存・検索・再利用 Snippets 定型文をキーワードで即挿入 Quicklinks よく使うURLに即アクセス Calculator 自然言語で計算 Emoji Picker 絵文字を素早く検索・入力 Quick AI ブラウザを開かずにAIに質問 まず覚える5つの機能 # 1. App Launcher（アプリ起動） # Alt + SpaceでRaycastを起動 アプリ名の一部を入力（例：chr → Chrome） Enterで起動 完全一致は不要で、teでTeams、ouでOutlookなど、あいまい検索に対応しています。使用頻度が高いアプリは自動で上位に表示されます。\n「スタートメニューを開きそうになったらRaycast」と意識すると定着しやすいです。\n2. Clipboard History（クリップボード履歴） # Alt + Space → clipと入力 → Enter 過去にコピーした履歴一覧が表示 使いたい項目を選んでEnterでペースト Settings → Extensions → Clipboard Historyにホットキーを設定すると、直接履歴画面を開けます（例：Ctrl + Shift + V）。\n「さっきコピーしたIPどこだっけ」という場面で活躍します。\n3. Snippets（定型文登録） # Alt + Space → create snippetと入力 → Enter 登録画面で以下を入力 Name: 用途がわかる名前（例：「対応完了メール」） Snippet: 本文 Keyword: 呼び出すトリガー（例：!done） 保存後、どのアプリでも!doneと打つと自動展開 登録例：\nKeyword 内容 !done 対応完了いたしました。ご確認をお願いいたします。 !ack お問い合わせありがとうございます。確認次第ご連絡いたします。 !sig 自分の署名 4. Quicklinks（よく使うURLの登録） # Alt + Space → create quicklinkと入力 → Enter 登録画面で以下を入力 Name: わかりやすい名前（例：「監視ダッシュボード」） Link: URL 以降はAlt + Space → 登録した名前の一部を入力 → Enterで即アクセス 登録例：\nName Link AWS Console https://console.aws.amazon.com/ GitHub https://github.com/ ブラウザを開いてブックマークを探す手間を省略できます。\n5. Calculator（計算機） # Alt + SpaceでRaycastを起動 そのまま計算式を入力（例：1024 * 8） 結果が即表示され、Enterでクリップボードにコピー 対応している計算：\n入力例 用途 100 + 200 * 3 四則演算 100 USD to JPY 単位変換 0xFF to decimal 進数変換 0b11111111 2進数→10進数（サブネットマスク確認） 1024 * 1024 * 1024 GB→バイト変換 電卓アプリを起動せずにその場で計算できます。\n拡張機能 # ストアから追加可能な拡張機能も用意されています。\nGitHub - PR・Issue・通知確認 Slack - ステータス変更・未読確認 Notion - ページ検索・作成 Todoist - タスク管理 まとめ # Raycastはキーボード操作で作業を高速化するランチャーアプリ Windows版はベータ版だが、基本機能はすべて無料で使える まず覚える5つの機能：App Launcher、Clipboard History、Snippets、Quicklinks、Calculator 普段の作業の中で「これってRaycastで効率化できないかな？」と考えながら少しずつ活用範囲を広げていく 参考 # Raycast Windows版 公式サイト Raycast 公式マニュアル Raycastの使い方（Zenn） ","date":"2025年 12月 10日","externalUrl":null,"permalink":"/posts/251210142726_raycast-windows-installation-and-5-core-features/","section":"Posts","summary":"","title":"Raycast Windows版の導入と基本機能5つ","type":"posts"},{"content":"","date":"2025年 12月 10日","externalUrl":null,"permalink":"/tags/windows/","section":"Tags","summary":"","title":"Windows","type":"tags"},{"content":" 今日学んだこと # 個人プロジェクト（技術ブログのAWS移行）のアーキテクチャ図をdraw.ioで作成しました。\nメンターレビューを通じて、「操作主体を明確にする」「分かりにくいフローは凡例で補足する」といった構成図作成のポイントを学びました。\n学習内容 # なぜdraw.ioを選んだか # 最初はMermaidで構成図を書いていましたが、面接での説明を考えてdraw.ioに変更しました。\n選択肢 メリット デメリット Mermaid コードで管理できる、GitHubで直接表示 AWSアイコンが使えない、見た目が簡素 draw.io AWS公式アイコン、視覚的に分かりやすい 画像ファイルとして管理 構成図を使った説明を求められる確率は高いため、AWS公式アイコンを使える\ndraw.io を選択しました。自分で配置を考えて書いた図なら、細部まで説明できます。\nAWS公式アイコンの導入手順 # draw.ioでは「AWS 2025」のアイコンセットが使えます。\ndraw.ioを開く（https://app.diagrams.net/） 左側パネルの「+ More Shapes」をクリック 「AWS」カテゴリから「AWS 2025」を選択 「Apply」で追加完了 これでS3、CloudFront、Route53などのAWSサービスアイコンが使えるようになります。\n作成時に意識したポイント # 1. 対象者を意識する # この構成図を見る人は誰か（面接官、自分）を考え、過度に詳細にせず、主要なコンポーネントと流れが分かるレベルに留めました。\n2. 矢印を交差させない # 矢印が交差すると、どこからどこへの通信か分かりにくくなります。配置を工夫して交差を避けました。\n3. 一貫した命名 # 構成図内のラベルとTerraformのリソース名を一致させると、コードとの対応が取りやすくなります。\n4. 凡例を追加する # 矢印の意味が自明でない場合は凡例で補足します。\n今回は「データの流れ（実線）」「メトリクス/ログ（破線）」を左上に配置しました。\nメンターからのフィードバック # 所属しているスクール（RareTECH）でメンターにレビューを依頼しました。\n全体評価 # 「とても綺麗」「このまま出しても違和感ない」\n指摘された点 # CI/CDフローの矢印が分かりにくい\n修正前は「IAM → S3」「IAM → CloudFront」という矢印を引いていました。これだと「IAMがS3を操作する」ように見えてしまいます。\n実際の流れは以下の通りです。\nGitHub ActionsがIAMロールを引き受ける（OIDC認証） GitHub ActionsがS3にコンテンツを同期する GitHub ActionsがCloudFrontのキャッシュを無効化する コンポーネント 役割 GitHub Actions 操作の実行主体（APIコールを行う） IAM ロール 認証・認可（権限付与） S3 / CloudFront 操作対象 IAMは「鍵」であって「操作者」ではないため、矢印の起点を修正する必要がありました。\n修正内容 # 修正項目 内容 矢印削除 IAM → S3 / IAM → CloudFront 矢印追加 GitHub Actions → S3（コンテンツ同期） 矢印追加 GitHub Actions → CloudFront（キャッシュ無効化） 凡例追加 「GitHub ActionsはIAMによるOIDC認証後、S3・CloudFrontを操作」 説明順序 # 構成図を使って説明するときの順序は下記。\nメインフロー: ユーザー → Route53 → CloudFront → S3（コンテンツ配信の基本経路） CI/CD: GitHub Actions → IAM（OIDC）→ S3/CloudFront（デプロイの流れ） 監視: CloudWatch → SNS → メール通知（運用視点） 上から下、左から右に流れるように配置すると説明しやすくなります。\nまとめ # 学んだこと 詳細 操作主体を明確にする 「IAMがS3を操作」ではなく「GitHub ActionsがS3を操作」 凡例で補足する 分かりにくいフロー（CI/CD、認証）は説明文を追加 レビューを依頼する 自分では気づかない指摘をもらえる 自分で書いた図は説明しやすい 「なぜこの配置にしたか」を説明できる 参考 # draw.io公式 AWS Architecture Icons ","date":"2025年 12月 9日","externalUrl":null,"permalink":"/posts/251209231724_create-aws-architecture-diagram-with-drawio/","section":"Posts","summary":"","title":"draw.ioでAWSアーキテクチャ図を作成する","type":"posts"},{"content":" 今日学んだこと # Terraform movedブロックを使って、既存のTerraformリソースをダウンタイムなしでmodule化しました。movedブロックはStateの参照先だけを変更し、実リソースには触れずにリファクタリングできる機能です。\n学習内容 # 背景と課題 # 個人プロジェクトで構築したAWSインフラ（S3、CloudFront、IAM等）をTerraform module化したいと考えました。最初はenvironments/prod/に全リソースをベタ書きしていましたが、再利用性と可読性のためにmodule構成に移行することにしました。\nしかし、単純にmoduleに移動すると、Terraformは「旧リソースを削除 → 新規作成」と判断します。本番稼働中のサイトでダウンタイムが発生してしまう問題がありました。\nmovedブロックとは # Terraform 1.1で導入された機能です。Stateの参照先だけを変更し、実リソースには触らずにリファクタリングできます。\nmoved { from = aws_s3_bucket.content # 旧パス to = module.s3_content.aws_s3_bucket.this # 新パス } 実践：S3バケットのmodule化 # Step 1: moduleと呼び出し元の構成 # ├── environments/prod/ │ └── main.tf ← movedブロックを記述 └── modules/s3-content/ ├── main.tf ├── outputs.tf └── variables.tf Step 2: module呼び出しとmovedブロックを記述 # # environments/prod/main.tf module \u0026#34;s3_content\u0026#34; { source = \u0026#34;../../modules/s3-content\u0026#34; bucket_name = \u0026#34;example-content\u0026#34; } # State移行 moved { from = aws_s3_bucket.content to = module.s3_content.aws_s3_bucket.this } moved { from = aws_s3_bucket_public_access_block.content to = module.s3_content.aws_s3_bucket_public_access_block.this } Step 3: terraform planで確認 # $ terraform plan # Terraform will perform the following actions: # # aws_s3_bucket.content has moved to module.s3_content.aws_s3_bucket.this # Plan: 0 to add, 0 to change, 0 to destroy. 0 to add, 0 to change, 0 to destroyと表示されれば成功です。Stateの参照が変わるだけで、S3バケット自体は変更されません。\nStep 4: terraform apply # $ terraform apply Apply complete! Resources: 0 added, 0 changed, 0 destroyed. ハマったポイント # 動的な名前生成による再作成 # module内でリソース名を動的生成すると、既存リソースと名前が変わって再作成が発生することがあります。\n# ❌ これだと再作成が発生する可能性 resource \u0026#34;aws_cloudfront_function\u0026#34; \u0026#34;this\u0026#34; { name = \u0026#34;${var.name_prefix}-url-rewrite\u0026#34; } 解決策として、変数で既存の名前を明示的に渡します。\n# ✅ 既存名を変数で渡す variable \u0026#34;function_name\u0026#34; { type = string } resource \u0026#34;aws_cloudfront_function\u0026#34; \u0026#34;this\u0026#34; { name = var.function_name } movedブロックはapply後に削除可能 # movedブロックはapply後、Stateに反映済みであれば削除して問題ありません。残しておくとコードが煩雑になるため、適宜整理します。\ndata sourceはmovedブロック不要 # 既存リソースを参照するだけのdata sourceはState移行が不要です。そのままmodule化できます。\n# 参照のみなのでmovedブロック不要 data \u0026#34;aws_acm_certificate\u0026#34; \u0026#34;this\u0026#34; { domain = var.domain_name statuses = [\u0026#34;ISSUED\u0026#34;] most_recent = true } まとめ # ポイント 内容 movedブロックの用途 既存リソースを壊さずにmodule化・リネーム 成功の確認方法 Plan: 0 to add, 0 to change, 0 to destroy apply後の扱い movedブロックは削除可能 data sourceの扱い 参照のみなのでState移行不要 名前変更に注意 動的生成で名前が変わると再作成される 補足：個人開発でmodule化は必要だったか？ # 正直、現段階のプロジェクトでは不要だったと思います。\n今回はブログ環境をAWSへ移行するプロジェクトでmovedブロックを使用しました。\nただ、以下の理由でmodule化を選択しました。\n観点 理由 将来の拡張性 テスト実装やセキュリティスキャン導入時、module単位で検証できる 実務経験の代替 実務ではmodule化が一般的。設計パターンを経験しておきたかった 学習効果 movedブロック、マルチリージョンprovider、依存関係設計を一度に学べた 「今必要か」だけでなく「将来拡張しやすいか」「学習として価値があるか」も判断軸に入れました。\n参考 # Refactoring - Terraform Terraform のつまずきポイントと回避策 ","date":"2025年 12月 8日","externalUrl":null,"permalink":"/posts/251208082023_terraform-moved-block-module-without-breaking-production-resources/","section":"Posts","summary":"","title":"Terraform movedブロックでリソースを壊さずにmodule化する","type":"posts"},{"content":"","date":"2025年 12月 8日","externalUrl":null,"permalink":"/tags/github/","section":"Tags","summary":"","title":"GitHub","type":"tags"},{"content":" 今日学んだこと # GitHub Actions + OIDC認証を使うことで、アクセスキーを一切保存せずにAWSへ安全にアクセスできることを学びました。一時的な認証情報（15分で期限切れ）を使用するため、従来のアクセスキー方式と比べてセキュリティリスクを大幅に軽減できます。\n学習内容 # なぜOIDC認証を選ぶのか # 最初は「アクセスキーをGitHubのシークレットに保存すれば簡単」と考えましたが、調べていくうちにOIDC認証の方がセキュリティ面で優れていることがわかりました。\n観点 アクセスキー OIDC 認証情報の保存 GitHubシークレットに保存が必要 保存不要 有効期限 無期限（手動でローテーション） 15分で自動期限切れ 漏洩リスク シークレット漏洩で永続的なアクセス トークンは短命で再利用不可 権限の粒度 IAMユーザー単位 リポジトリ・ブランチ単位で制限可能 アクセスキーは「漏洩したら終わり」ですが、OIDCは最初から漏洩リスクがありません。AWS/GitHub公式もOIDCを推奨しています。\nOIDCの認証フロー # 1. GitHub Actions が GitHub OIDC Provider にトークンを要求 ↓ 2. GitHub OIDC Provider がトークンを発行（リポジトリ名、ブランチ名を含む） ↓ 3. AWS STS がトークンを検証し、信頼ポリシーの条件を確認 ↓ 4. 条件を満たせば、一時認証情報を発行（15分有効） ↓ 5. GitHub Actions が一時認証情報でAWSリソースにアクセス GitHub側でOIDCトークンが発行され、トークンには「どのリポジトリの、どのブランチから」という情報が含まれます。AWS側でその情報を検証し、条件を満たせば一時認証情報を発行します。\n実装手順 # OIDC認証の設定は「共通部分」と「デプロイ先に応じた権限設定」の2つに分かれます。\nStep 1: 共通設定（OIDC Provider + IAMロール） # どのAWSサービスにアクセスする場合でも、この設定は共通です。\n# 1. OIDC Provider（GitHubとAWSを繋ぐ設定） resource \u0026#34;aws_iam_openid_connect_provider\u0026#34; \u0026#34;github\u0026#34; { url = \u0026#34;https://token.actions.githubusercontent.com\u0026#34; client_id_list = [\u0026#34;sts.amazonaws.com\u0026#34;] thumbprint_list = [\u0026#34;ffffffffffffffffffffffffffffffffffffffff\u0026#34;] } # 2. IAMロール（GitHub Actionsが引き受けるロール） resource \u0026#34;aws_iam_role\u0026#34; \u0026#34;github_actions\u0026#34; { name = \u0026#34;github-actions-deploy-role\u0026#34; assume_role_policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34; Statement = [ { Effect = \u0026#34;Allow\u0026#34; Principal = { Federated = aws_iam_openid_connect_provider.github.arn } Action = \u0026#34;sts:AssumeRoleWithWebIdentity\u0026#34; Condition = { StringEquals = { \u0026#34;token.actions.githubusercontent.com:aud\u0026#34; = \u0026#34;sts.amazonaws.com\u0026#34; } StringLike = { # リポジトリ・ブランチを制限 \u0026#34;token.actions.githubusercontent.com:sub\u0026#34; = \u0026#34;repo:\u0026lt;OWNER\u0026gt;/\u0026lt;REPO\u0026gt;:ref:refs/heads/main\u0026#34; } } } ] }) } thumbprintについて：2023年7月以降、AWSはGitHub OIDCの証明書を自動検証するようになりました。そのため、任意の値でも動作します。\nStep 2: デプロイ先に応じた権限設定（IAMポリシー） # IAMポリシーはデプロイ先によって変わります。今回はS3 + CloudFrontへの静的サイト配信を例に説明します。\nresource \u0026#34;aws_iam_role_policy\u0026#34; \u0026#34;github_actions\u0026#34; { name = \u0026#34;github-actions-deploy-policy\u0026#34; role = aws_iam_role.github_actions.id policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34; Statement = [ { Effect = \u0026#34;Allow\u0026#34; Action = [ \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34; ] Resource = [ \u0026#34;arn:aws:s3:::\u0026lt;BUCKET_NAME\u0026gt;\u0026#34;, \u0026#34;arn:aws:s3:::\u0026lt;BUCKET_NAME\u0026gt;/*\u0026#34; ] }, { Effect = \u0026#34;Allow\u0026#34; Action = [ \u0026#34;cloudfront:CreateInvalidation\u0026#34; ] Resource = \u0026#34;arn:aws:cloudfront::\u0026lt;ACCOUNT_ID\u0026gt;:distribution/\u0026lt;DISTRIBUTION_ID\u0026gt;\u0026#34; } ] }) } 権限 用途 s3:PutObject ファイルアップロード s3:GetObject sync時の差分比較 s3:DeleteObject --deleteオプション s3:ListBucket バケット内一覧取得 cloudfront:CreateInvalidation キャッシュ無効化 Step 3: GitHub Actions側の設定 # name: Deploy to AWS on: push: branches: - main permissions: id-token: write # OIDCトークン取得に必須 contents: read jobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v4 - name: Configure AWS Credentials uses: aws-actions/configure-aws-credentials@v4 with: role-to-assume: arn:aws:iam::\u0026lt;ACCOUNT_ID\u0026gt;:role/github-actions-deploy-role aws-region: ap-northeast-1 # 以降、AWS CLIでデプロイ操作を実行 - name: Deploy to S3 run: aws s3 sync public/ s3://\u0026lt;BUCKET_NAME\u0026gt;/ --delete permissions: id-token: write を付けないと、GitHub Actionsがトークンを取得できずにエラーになります。\n設計のポイント # mainブランチのみに制限する理由 # \u0026#34;token.actions.githubusercontent.com:sub\u0026#34; = \u0026#34;repo:\u0026lt;OWNER\u0026gt;/\u0026lt;REPO\u0026gt;:ref:refs/heads/main\u0026#34; もし *（ワイルドカード）にすると、任意のブランチやPRからデプロイ可能になります。悪意のあるPRがマージされる前にデプロイされるリスクを防ぐため、mainブランチのみに制限しました。\n最小権限の原則 # IAMポリシーでは、必要なAWSサービス・リソースのみに権限を限定します。今回の例では特定のS3バケット・CloudFront Distributionのみを指定しています。\n他のユースケースへの応用 # OIDC Provider + IAMロールの信頼ポリシー（Step 1）は共通で、IAMポリシー（Step 2）を変えるだけで他のAWSサービスにも応用できます。\n例えば、EC2へのデプロイであれば以下のような権限が必要になります。\nAction = [ \u0026#34;ec2:DescribeInstances\u0026#34;, \u0026#34;ssm:SendCommand\u0026#34;, \u0026#34;ssm:GetCommandInvocation\u0026#34; ] まとめ # OIDC認証はアクセスキー不要で、15分で自動期限切れのため安全 設定は「共通部分（OIDC Provider + IAMロール）」と「デプロイ先に応じた権限（IAMポリシー）」に分かれる GitHub Actions側では permissions: id-token: write の設定が必須 mainブランチのみに制限して本番環境を保護する IAMポリシーを変えれば、S3以外のAWSサービス（EC2等）にも応用可能 参考 # AWS Security Blog: Use IAM roles to connect GitHub Actions to actions in AWS GitHub Docs: About security hardening with OpenID Connect GitHub Docs: Configuring OpenID Connect in Amazon Web Services aws-actions/configure-aws-credentials ","date":"2025年 12月 8日","externalUrl":null,"permalink":"/posts/251208075901_github-actions-oidc-aws-authentication/","section":"Posts","summary":"","title":"GitHub Actions + OIDC認証でアクセスキー不要のAWS認証を実現する","type":"posts"},{"content":" 今日学んだこと # GitHubプロフィールREADMEの作成方法を学びました。自分のユーザー名と同じ名前のリポジトリを作成してREADME.mdを配置すると、プロフィールページのトップに自己紹介を表示できます。\n学習内容 # GitHubプロフィールREADMEとは # GitHubには「プロフィールREADME」という機能があります。自分のユーザー名と同じ名前のリポジトリ（例：username/username）を作成し、README.mdを配置すると、GitHubプロフィールページのトップに表示されます。\n通常のプロフィールページでは、アイコン・名前・Bio程度しか表示されませんが、この機能を使うと自己紹介やスキル、プロジェクト紹介などを自由に記載できます。\n作成手順 # Step 1: リポジトリを作成 # GitHubにログイン 右上の「+」→「New repository」をクリック Repository nameに自分のユーザー名と同じ名前を入力 「Public」を選択（Privateだとプロフィールに表示されない） 「Add a README file」にチェックを入れる 「Create repository」をクリック ユーザー名と同じ名前を入力すると、以下のようなメッセージが表示されます。\nusername/username is a special repository. Its README.md will appear on your public profile.\nこのメッセージが表示されれば、設定は正しいです。\nStep 2: README.mdを編集 # 作成されたリポジトリのREADME.mdを編集します。Markdown形式で自由に書けます。\n最初は以下のようなテンプレートが入っています。\n### Hi there 👋 \u0026lt;!-- **username/username** is a ✨ _special_ ✨ repository because its `README.md` (this file) appears on your GitHub profile. Here are some ideas to get you started: - 🔭 I\u0026#39;m currently working on ... - 🌱 I\u0026#39;m currently learning ... - ... --\u0026gt; コメントアウトを外して編集するか、自分で一から書き直します。\nStep 3: プロフィールページで確認 # 編集後、自分のGitHubプロフィールページ（https://github.com/username）にアクセスすると、README.mdの内容が表示されています。\n何を書けばいいか # 最初は何を書けばいいか迷いました。参考までに、自分が書いた項目を紹介します。\nセクション 内容 自己紹介 何をしている人か、何に興味があるか プロジェクト実績 取り組んだプロジェクトの概要と使用技術 技術アウトプット ブログやZennなどの発信活動 スキルセット 使える技術をカテゴリ別に整理 保有資格 取得した資格を年度順に 連絡先 SNSやメールアドレス 実際に書いてみた例 # 参考として、自分のプロフィールREADMEを載せておきます。\nGitHub: https://github.com/mr110825\n正直、最初はもっとシンプルでした。プロジェクトが完成したり、資格を取得したりするたびに少しずつ更新しています。\n書いてみて気づいたこと # 実際にプロフィールREADMEを書いてみて、いくつか気づいたことがあります。\n完成したものを上に置く\n作成中のプロジェクトより、完成したプロジェクトを先に書いた方が見栄えが良いと感じました。見る人は最初の数秒で判断するので、アピールできるものを上に持ってくるのが良さそうです。\n「学習中」より具体的な内容を書く\n「Terraform学習中」より「Terraformで○○を構築」のように、何をしたか具体的に書いた方が伝わりやすいと思いました。\nテーブル形式は見やすい\n資格やスキルセットなど、項目が多いものはテーブル形式にすると一覧性が高くなりました。\nまとめ # プロフィールREADMEはusername/usernameリポジトリのREADME.mdに書く リポジトリはPublicにする必要がある Markdown形式で自由に自己紹介を書ける 完成したプロジェクトや具体的な実績を上位に置くと効果的 参考 # Managing your profile README - GitHub Docs 自分のプロフィール ","date":"2025年 12月 7日","externalUrl":null,"permalink":"/posts/251207233715_github-profile-readme-creation/","section":"Posts","summary":"","title":"GitHubプロフィールREADMEを作成してみた","type":"posts"},{"content":"","date":"2025年 12月 7日","externalUrl":null,"permalink":"/tags/google/","section":"Tags","summary":"","title":"Google","type":"tags"},{"content":" 今日学んだこと # Google Search Consoleのドメイン所有権検証をTerraformで管理する方法を学びました。DNS検証（TXTレコード）を選択することで、IaCの一貫性を保ちながらSearch Consoleの設定を行えます。\n前提条件 # AWSアカウントを持っている Route53でホストゾーンが作成済み Terraformの基本操作（init, plan, apply）を理解している 学習内容 # 検証方式の選択 # Google Search Consoleには複数の所有権検証方式があります。\n検証方式 概要 Terraform管理 DNS検証（TXTレコード） ドメインのDNSにTXTレコードを追加 ✅ 可能 HTMLファイル 指定されたHTMLファイルをサイトに配置 △ ビルドに含める必要あり metaタグ HTMLのheadにmetaタグを追加 △ テンプレート修正が必要 Google Analytics 既存のGA設定を利用 ❌ 不可 IaCの一貫性を保つため、DNS検証を採用しました。\n実装手順 # Step 1: Google Search ConsoleでTXTレコード値を取得 # Google Search Consoleにアクセス 「プロパティを追加」→「ドメイン」を選択 ドメイン名を入力 表示されたTXTレコード値をコピー 取得できる値の形式：\ngoogle-site-verification=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Step 2: Terraformコードの作成 # 以下は、Route53にGoogle Search Console検証用のTXTレコードを作成するコード例です。\n注意: このコードは個人プロジェクトで使用したものです。実際に利用する際は、ご自身の環境に合わせて調整してください。\nvariables.tf\nvariable \u0026#34;domain_name\u0026#34; { description = \u0026#34;ドメイン名\u0026#34; type = string } variable \u0026#34;google_site_verification\u0026#34; { description = \u0026#34;Google Search Console検証用のTXTレコード値\u0026#34; type = string } main.tf\ndata \u0026#34;aws_route53_zone\u0026#34; \u0026#34;this\u0026#34; { name = var.domain_name } resource \u0026#34;aws_route53_record\u0026#34; \u0026#34;google_site_verification\u0026#34; { zone_id = data.aws_route53_zone.this.zone_id name = var.domain_name type = \u0026#34;TXT\u0026#34; ttl = 300 records = [var.google_site_verification] } terraform.tfvars\ndomain_name = \u0026#34;example.com\u0026#34; google_site_verification = \u0026#34;google-site-verification=XXXXXXXXXXXX\u0026#34; Step 3: Terraform適用 # terraform plan terraform apply Step 4: Search Consoleで検証完了 # Google Search Consoleに戻り、「確認」ボタンをクリックします。DNSの反映には数分かかる場合があります。\nまとめ # Google Search ConsoleのDNS検証はTerraformで管理可能 TXTレコードをRoute53に追加することで所有権を証明 DNS検証は一度設定すれば永続的に有効 参考 # Search Console ヘルプ - ドメイン プロパティを追加する Terraform AWS Provider - aws_route53_record fumi-til-infrastructure - GitHub ","date":"2025年 12月 7日","externalUrl":null,"permalink":"/posts/251207230407_terraform-google-search-console-dns-verification/","section":"Posts","summary":"","title":"TerraformでGoogle Search ConsoleのDNS検証を管理する","type":"posts"},{"content":" 今日学んだこと # GitHub PagesからAWS（S3 + CloudFront）へブログを移行した際、トップページは表示されるが個別記事ページで404エラーが発生しました。原因はOAC（Origin Access Control）使用時にS3の静的ウェブサイトホスティング機能が使えず、/posts/article/ → /posts/article/index.html の自動補完が効かないことでした。CloudFront Functionでviewer-request時にURLリライトを実装して解決しました。\n学習内容 # 問題の発生状況 # GitHub Pagesで正常に動作していたHugoブログをAWSに移行したところ、以下の症状が発生しました。\nページ URL 結果 トップ https://example.com/ ✅ 正常表示 記事一覧 https://example.com/posts/ ❌ 404エラー 個別記事 https://example.com/posts/article-name/ ❌ 404エラー 原因の特定 # S3へのアクセス方式の違いが原因でした。\n方式 index.html自動補完 セキュリティ 静的ウェブサイトホスティング ✅ あり ❌ パブリック公開が必要 OAC経由（今回の構成） ❌ なし ✅ S3は非公開のまま OACを使用する場合、S3はREST APIエンドポイントとしてアクセスされます。この場合、/posts/ というリクエストは「posts/というオブジェクト」を探しに行くため、posts/index.html は見つかりません。\n解決策の比較 # 解決策 実行場所 レイテンシ コスト 採用 CloudFront Function エッジ 極小 無料枠大 ✅ Lambda@Edge リージョン 小 従量課金 - S3静的ホスティング - - - ❌ OAC不可 CloudFront Functionを採用した理由は、単純なURLリライトには十分な機能があり、無料枠が大きく（月200万リクエスト）、エッジで実行されるためレイテンシへの影響が最小限だからです。\n解決策：CloudFront FunctionによるURLリライト # viewer-requestイベントでURLを書き換え、末尾に index.html を付与します。\nfunction handler(event) { var request = event.request; var uri = request.uri; // 末尾が `/` の場合 → `/index.html` を付与 if (uri.endsWith(\u0026#39;/\u0026#39;)) { request.uri += \u0026#39;index.html\u0026#39;; } // 拡張子がない場合 → `/index.html` を付与 else if (!uri.includes(\u0026#39;.\u0026#39;)) { request.uri += \u0026#39;/index.html\u0026#39;; } return request; } 処理フローの図解 # リクエスト: /posts/article/ ↓ CloudFront Function（viewer-request） ↓ URI書き換え: /posts/article/index.html ↓ S3からオブジェクト取得 ↓ レスポンス: 200 OK Terraformでの実装 # resource \u0026#34;aws_cloudfront_function\u0026#34; \u0026#34;rewrite\u0026#34; { name = \u0026#34;url-rewrite\u0026#34; runtime = \u0026#34;cloudfront-js-2.0\u0026#34; publish = true code = \u0026lt;\u0026lt;-EOF function handler(event) { var request = event.request; var uri = request.uri; if (uri.endsWith(\u0026#39;/\u0026#39;)) { request.uri += \u0026#39;index.html\u0026#39;; } else if (!uri.includes(\u0026#39;.\u0026#39;)) { request.uri += \u0026#39;/index.html\u0026#39;; } return request; } EOF } CloudFront Distributionの default_cache_behavior 内で、このFunctionを viewer-request イベントに関連付けます。\nresource \u0026#34;aws_cloudfront_distribution\u0026#34; \u0026#34;blog\u0026#34; { # ... 他の設定 ... default_cache_behavior { # ... 他の設定 ... function_association { event_type = \u0026#34;viewer-request\u0026#34; function_arn = aws_cloudfront_function.rewrite.arn } } } デプロイと動作確認 # 1. Terraformでデプロイ # terraform plan # 変更内容を確認 terraform apply # 適用 2. CloudFrontキャッシュの無効化 # 設定変更後、キャッシュが残っていると古い挙動が続く場合があります。\naws cloudfront create-invalidation \\ --distribution-id \u0026lt;DISTRIBUTION_ID\u0026gt; \\ --paths \u0026#34;/*\u0026#34; 3. 動作確認 # # 末尾スラッシュありのURL curl -I https://example.com/posts/ # 末尾スラッシュなしのURL curl -I https://example.com/posts/article-name いずれも HTTP/2 200 が返れば成功です。\nCloudFront Function vs Lambda@Edge # 項目 CloudFront Function Lambda@Edge 実行場所 全エッジロケーション リージョンエッジキャッシュ 最大実行時間 1ms 5秒（viewer）/ 30秒（origin） メモリ 2MB 128MB〜10GB ネットワークアクセス ❌ 不可 ✅ 可能 対応イベント viewer-request/response 4種類すべて 料金 月200万リクエスト無料 リクエスト+実行時間課金 単純なURLリライトであればCloudFront Functionで十分です。外部APIへのアクセスや複雑な処理が必要な場合はLambda@Edgeを検討してください。\nまとめ # OAC使用時はS3の「index.html自動補完」が効かない CloudFront Functionでviewer-request時にURLリライトを実装して解決 単純なURL書き換えにはCloudFront Functionが最適（低コスト・低レイテンシ） 設定変更後はキャッシュ無効化を忘れずに実行 参考 # CloudFront Functions を使用して URL の末尾から index.html ファイルを表示する｜AWS re:Post CloudFront Functions の作成 - Amazon CloudFront ","date":"2025年 12月 7日","externalUrl":null,"permalink":"/posts/251207182151_cloudfront-oac-404-page-issue-resolution/","section":"Posts","summary":"","title":"CloudFront + OACで個別ページが404になる問題の解決","type":"posts"},{"content":"","date":"2025年 12月 7日","externalUrl":null,"permalink":"/tags/%E3%83%88%E3%83%A9%E3%83%96%E3%83%AB%E3%82%B7%E3%83%A5%E3%83%BC%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0/","section":"Tags","summary":"","title":"トラブルシューティング","type":"tags"},{"content":" 今日学んだこと # AWS Budgetsでアラートを受信した際の対応フローを整理しました。実際にFORECASTEDアラートを受信して対応した経験から、今後も使えるベストプラクティスとしてまとめました。\n学習内容 # この記事を書いた経緯 # AWS Budgetsから予算超過のアラートメールを受信しました。調査の結果、過去のハンズオン環境のコストと一括費用（ドメイン購入）が原因と判明し、対応不要と判断できました。この対応フローは今後も役立つと考え、ベストプラクティスとして整理しました。\nAWS Budgetsとは # AWS Budgetsは、AWSの利用コストを監視し、設定した予算を超えそうな場合にアラートを通知するサービスです。月額の予算を設定しておくと、実績や予測がしきい値を超えた際にメールで通知を受け取れます。\nAWS Budgetsのアラート種別 # AWS Budgetsには2種類のアラートがあります。\n種別 意味 ACTUAL 実際にその金額を使った FORECASTED 月末にその金額になりそう（予測） 出典: AWS公式ドキュメント - Best practices for AWS Budgets\nFORECASTED予測の限界 # FORECASTEDは「現在のペースが月末まで続く」と仮定した線形予測です。この予測方法には限界があります。\n状況 予測の問題点 リソースを月の途中で削除した 削除後もコストが継続する前提で計算される ドメイン購入など一括費用が発生した 毎日同額が発生する前提で計算される ハンズオン環境を短期間だけ使用した 月末まで使い続ける前提で計算される このため、FORECASTEDアラートは「参考程度」に捉え、ACTUALアラートを重視することをおすすめします。\nアラート対応フロー # Step 1: アラート種別の確認 # 受信したメールでACTUAL/FORECASTEDを確認。\nStep 2: Cost Explorerで原因特定 # Cost Explorerにアクセス 期間を「今月（Month-to-date）」に設定 Group byで「Service」を選択 異常に高いサービスを特定 Step 3: 原因の分類と対応 # 原因 対応 一時的な費用（ドメイン購入等） 対応不要、予測は無視 削除済みリソースの残存コスト 対応不要、来月から減る 起動中のリソース 不要なら即削除 想定内の増加 予算設定を見直し Step 4: リソース確認（必要な場合のみ） # 原因が「起動中のリソース」の場合、以下のサービスを優先的に確認します。\n優先度 サービス 確認場所 高 NAT Gateway VPCコンソール 高 EC2（全リージョン） AWS Global View 高 RDS RDSコンソール 高 ALB/ELB EC2 → ロードバランサー 中 Elastic IP（未使用） EC2 → Elastic IP これらのサービスは起動しているだけで課金が発生するため、不要であれば削除します。\nAWS Global Viewを使った全リージョン確認 # EC2インスタンスは通常、リージョンごとにしか確認できません。しかし、AWS Global Viewを使えば、全リージョンのリソースを一画面で確認できます。今回の対応で実際に使用し、非常に便利だと感じました。\nAWS Global Viewとは # AWS Global Viewは、複数のAWSリージョンにまたがるEC2およびVPC関連リソースを単一のコンソールで表示できる機能です。\n確認できるリソース # EC2インスタンス VPC サブネット セキュリティグループ EBSボリューム NAT Gateway Elastic IP アクセス方法 # AWSコンソールで「AWS Global View」を検索 または直接アクセス: https://console.aws.amazon.com/ec2globalview/home 使い方 # 「リージョンエクスプローラー」タブを開く 「リソースの概要」で全リージョンのインスタンス数を確認 インスタンス数のリンクをクリックすると、全リージョンのインスタンス一覧が表示される 不要なインスタンスがあれば、リソースIDをクリックして該当リージョンのコンソールに移動し、削除 リージョンを切り替えながら確認する手間が省けるため、コスト調査の際に非常に便利です。\n運用上のポイント # ポイント 内容 ハンズオン後の確認 リソース削除を忘れないこと 古い設定の整理 不要なBudgetは削除する アラートの使い分け ACTUALを重視、FORECASTEDは参考程度 まとめ # AWS Budgetsのアラートは ACTUAL（実績）と FORECASTED（予測）の2種類がある FORECASTED は線形予測のため、リソース削除や一括費用を考慮しない アラート受信時は Cost Explorer でサービス別に原因を特定する AWS Global View を使えば全リージョンのリソースを一画面で確認できる ハンズオン環境は使用後に必ずリソースを削除する 参考 # AWS Budgets Best practices for AWS Budgets Budgets API Reference - Notification AWS Cost Explorer AWS Global View ","date":"2025年 12月 7日","externalUrl":null,"permalink":"/posts/251207175353_aws-budgets-alert-response-flow/","section":"Posts","summary":"","title":"AWS Budgetsアラートを受信したときの対応フロー","type":"posts"},{"content":"","date":"2025年 12月 4日","externalUrl":null,"permalink":"/tags/it%E5%9F%BA%E7%A4%8E/","section":"Tags","summary":"","title":"IT基礎","type":"tags"},{"content":" 今日学んだこと # CPUが命令を実行する際、処理対象データの位置を指定する「アドレス指定方法」について学びました。即値・直接・間接・指標・基底・相対・レジスタ・レジスタ間接の8種類があり、それぞれ速度・柔軟性・用途が異なります。\n学習内容 # アドレス指定方法とは # コンピュータの命令は「命令部」と「アドレス部（オペランド）」から構成されています。アドレス指定方法とは、オペランドからデータの実際の格納場所（有効アドレス）を求める方式のことです。\n8種類のアドレス指定方法 # 1. 即値アドレス指定 # アドレス部の値がメモリアドレスではなく、演算対象のデータそのものである方式です。\n命令 +------+------+ | 命令 | データ | ← このデータ（オペランド）を直接使う +------+------+ メモリアクセスが不要なため高速ですが、命令内にデータを埋め込むため表現できる値の範囲が制限されます。\n2. 直接アドレス指定 # 命令のアドレス部に、有効アドレスが直接書き込まれている方式です。\n命令 主記憶 +------+---------+ +-------------+ | 命令 | アドレスA | ------------\u0026gt; | データ | ← 目的のデータ +------+---------+ +-------------+ アドレスA 構造がシンプルですが、指定できるメモリアドレスの範囲がアドレス部のビット数に依存します。\n3. 間接アドレス指定 # 命令のアドレス部が指すメモリ番地に、有効アドレスが格納されている方式です。\n命令 主記憶 +------+---------+ +-------------+ +-------------+ | 命令 | アドレスA | ------------\u0026gt; | アドレスB | ------------\u0026gt; | データ | +------+---------+ +-------------+ +-------------+ アドレスA アドレスB 広いメモリ空間にアクセスできますが、メモリアクセスが2回発生するため処理速度が遅くなります。\n4. 指標アドレス指定（インデックスアドレス指定） # 命令のアドレス部の値とインデックスレジスタの値を加算して有効アドレスを求めます。\n命令 インデックスレジスタ +------+---------+ +-------------+ | 命令 | アドレスA | | 値X | +------+---------+ +-------------+ | | +--------\u0026gt; 加算 \u0026lt;---------+ | ↓ 有効アドレス (A+X) 配列など連続したデータ領域へのアクセスに便利です。インデックスレジスタの値を変更するだけでアクセス先をずらせます。\n5. 基底アドレス指定（ベースアドレス指定） # 命令のアドレス部の値とベースレジスタの値を加算して有効アドレスを求めます。\n命令 ベースレジスタ +------+---------+ +-------------+ | 命令 | 変位A | | 基準値B | +------+---------+ +-------------+ | | +--------\u0026gt; 加算 \u0026lt;-----------+ | ↓ 有効アドレス (B+A) プログラムの再配置を容易にします。ベースレジスタにプログラムの先頭アドレスを入れておくことで、プログラムをメモリ上のどこに移動しても命令を書き換える必要がありません。\n6. 相対アドレス指定 # 命令のアドレス部の値とプログラムカウンタの値を加算して有効アドレスを求めます。\n命令 プログラムカウンタ +------+---------+ +-------------+ | 命令 | 変位A | | 現在位置P | +------+---------+ +-------------+ | | +--------\u0026gt; 加算 \u0026lt;---------+ | ↓ 有効アドレス (P+A) 主に分岐命令で使われ、現在の命令位置からの相対的なジャンプ先を指定します。\n7. レジスタアドレス指定 # オペランド部で指定したレジスタの値を直接データとして使う方式です。\n命令 CPU内部レジスタ群 +------+----------+ | 命令 | レジスタA | ------------\u0026gt; +-------------+ +------+----------+ | データ | ← 目的のデータ +-------------+ CPU内部で完結するため極めて高速ですが、レジスタの数は限られています。\n8. レジスタ間接アドレス指定 # オペランド部で指定したレジスタに、有効アドレスが格納されている方式です。\n命令 CPU内部レジスタ群 主記憶 +------+----------+ | 命令 | レジスタA | ------------\u0026gt; +-------------+ +-------------+ +------+----------+ | アドレスB | ------------\u0026gt; | データ | +-------------+ +-------------+ アドレスB 間接アドレス指定ではメモリアクセスが2回必要でしたが、レジスタ間接ではメモリアクセスは1回で済みます。ポインタを利用した処理で高い柔軟性を発揮します。\nまとめ # アドレス指定方法 有効アドレスの求め方 メモリアクセス 特徴・用途 即値 データそのもの 0回 高速、定数の指定 直接 アドレス部の値 1回 シンプル 間接 アドレス部が指す番地の値 2回 広いアドレス空間 指標 アドレス部 + インデックスレジスタ 1回 配列アクセス 基底 アドレス部 + ベースレジスタ 1回 プログラム再配置 相対 アドレス部 + プログラムカウンタ 1回 分岐命令 レジスタ レジスタの値がデータ 0回 最高速 レジスタ間接 レジスタの値がアドレス 1回 ポインタ操作 速度重視なら即値・レジスタアドレス指定（メモリアクセス0回） 柔軟性重視なら間接・レジスタ間接アドレス指定 指標と基底は加算する対象が異なる（配列操作 vs プログラム再配置） ","date":"2025年 12月 4日","externalUrl":null,"permalink":"/posts/251204202004_why-address-specification-is-necessary/","section":"Posts","summary":"","title":"アドレス指定方法はなぜ必要？","type":"posts"},{"content":"","date":"2025年 12月 3日","externalUrl":null,"permalink":"/tags/cloudfront/","section":"Tags","summary":"","title":"CloudFront","type":"tags"},{"content":" 今日学んだこと # CloudFrontでACM証明書を使う場合、証明書は必ずus-east-1（バージニア北部）で作成する必要があることを学びました。東京リージョンで作成すると、CloudFrontの設定画面で選択肢に表示されません。\n学習内容 # なぜus-east-1なのか # CloudFrontはグローバルサービスです。グローバルサービスはus-east-1のACM証明書しか参照できない仕様になっています。 公式ドキュメントにも明記されています\n「Amazon CloudFrontでACM証明書を使用するには、米国東部（バージニア北部）リージョンで証明書をリクエストまたはインポートする必要があります。」 — Supported Regions - AWS Certificate Manager\n「なぜus-east-1なのか」の背景 # 1. CloudFrontのコントロールプレーンがus-east-1にある # CloudFrontはグローバルサービスですが、APIエンドポイントはus-east-1に存在します。\nエンドポイント リージョン cloudfront.amazonaws.com 米国東部（バージニア北部） cloudfront-fips.amazonaws.com 米国東部（バージニア北部） cloudfront.global.api.aws 米国東部（バージニア北部） — Amazon CloudFront endpoints and quotas\n2. グローバルサービスのAPIリクエストはus-east-1にルーティングされる # AWSの公式ドキュメントでは、グローバルエンドポイントについて以下のように説明されています：\n「汎用エンドポイントを使用すると、AWSはAPIリクエストを米国東部（バージニア北部）（us-east-1）にルーティングします。これはAPI呼び出しのデフォルトリージョンです。」 — AWS service endpoints\nCloudFront、IAM、Route 53などのグローバルサービスはus-east-1を管理基盤としています。\n3. ACM証明書はリージョナルリソース # ACM証明書は作成したリージョン内でのみ参照可能です：\nus-east-1で作成した証明書 → us-east-1のリソースからのみ参照可能 ap-northeast-1で作成した証明書 → ap-northeast-1のリソースからのみ参照可能 CloudFrontのコントロールプレーン（API）がus-east-1にあるため、同じus-east-1にあるACM証明書しか「見えない」 のです。\n4. 証明書配布の仕組み # 1. us-east-1でACM証明書を作成 2. CloudFrontディストリビューションに証明書を関連付け 3. CloudFrontが証明書を全エッジロケーションに内部配布 4. 世界中のユーザーがHTTPSでアクセス可能に CloudFrontは世界中に 400以上のエッジロケーション（PoP） を持ち、us-east-1で設定された証明書を各エッジに配布します。\n— Amazon CloudFront features\nサービス別のACM証明書リージョン # サービス ACM証明書のリージョン 理由 CloudFront us-east-1のみ グローバルサービスのため ALB ALBと同じリージョン リージョナルサービスのため API Gateway（Edge最適化） us-east-1のみ CloudFront経由のため API Gateway（リージョナル） API Gatewayと同じリージョン リージョナルサービスのため まとめ # CloudFrontでACM証明書を使う場合はus-east-1で作成必須 ALBは同じリージョンのACM証明書を使用 API Gateway（Edge最適化）もus-east-1が必要 参考 # Supported Regions - AWS Certificate Manager AWS Certificate Manager Overview Amazon CloudFront endpoints and quotas AWS service endpoints Amazon CloudFront features ","date":"2025年 12月 3日","externalUrl":null,"permalink":"/posts/251203194906_cloudfront-acm-certificate-us-east-1-constraint/","section":"Posts","summary":"","title":"CloudFront + ACM証明書でハマるus-east-1制約","type":"posts"},{"content":"","date":"2025年 12月 3日","externalUrl":null,"permalink":"/tags/route53/","section":"Tags","summary":"","title":"Route53","type":"tags"},{"content":" 今日学んだこと # Route53でドメインを購入する手順と、購入時に注意すべきポイントを学びました。\n学習内容 # Step 1: ドメイン名の検討 # Route53で購入可能なTLDと価格を確認します。 （Route53の「ドメインを登録」画面にて料金表を確認できます。：2025年12月時点）\nTLD Route53価格 検討結果 .com $15/年 ✅ 認知度最高、直接購入可能 .tech $40/年 ❌ 高め .io $71/年 ❌ 高め 注意：.devはRoute53で取り扱いがありません。 Cloudflare等で購入してRoute53にDNS移管が必要になり、手間が増えます。\nStep 2: ドメイン購入 # AWSコンソール → Route53 → 登録済みドメイン → ドメインの登録 希望のドメイン名を検索 カートに追加 → チェックアウト 以下の項目を設定： 項目 推奨設定 理由 プライバシー保護 有効 WHOIS情報を非公開にする 自動更新 有効 更新忘れによるドメイン失効を防止 期間 1年 - 購入手続きを実行 Step 3: メール承認 # 購入後、以下のメールが届きます。内容を確認して承認してください。\n[Action Required] Verify your email address for xxx.com\n注意：承認メールが迷惑メールフォルダに入っていることがあります。（自分もそうでした。）\nStep 4: 確認 # Route53 → ホストゾーン で、購入したドメインのホストゾーンが作成されていることを確認します。\n初期状態ではNSレコードとSOAレコードの2件が登録されています。これは正常です。\nTerraform管理範囲について # ドメイン購入はTerraformで管理できません。\n対象 Terraform管理 理由 ドメイン購入 ❌ 不可 一度きりの操作、連絡先入力が必要 ホストゾーン △ 参照のみ 購入時に自動作成される DNSレコード ✅ 管理可能 A, CNAME, ACM検証レコード まとめ # Route53でドメイン購入は数クリックで完了 .devなど一部のTLDはRoute53で購入不可 プライバシー保護と自動更新は有効にしておく 承認メールが迷惑メールに入ることがあるので注意 ドメイン購入はTerraform管理外、DNSレコードはTerraformで管理可能 参考 # Route 53でドメインを購入してみた | DevelopersIO Route53 ドメイン価格表（2025年9月更新） ","date":"2025年 12月 3日","externalUrl":null,"permalink":"/posts/251203194756_route53-domain-purchase-procedure-and-notes/","section":"Posts","summary":"","title":"Route53でドメインを購入する手順と注意点","type":"posts"},{"content":" 今日学んだこと # Terraformでリモートバックエンド（S3 + DynamoDB）を使う場合、 「tfstate用のS3/DynamoDBだけは先に別で作る」必要があることを学びました。 これは「鶏と卵問題」と呼ばれます。\n学習内容 # 鶏と卵問題とは # Terraformで S3, CloudFront, Route53... を作りたい ↓ tfstateをS3に保存したい ↓ でも、そのS3自体をTerraformで作ると... ↓ 「tfstate用S3のtfstate」はどこに保存する？ ← 無限ループ この循環参照を断ち切るため、tfstate用のS3/DynamoDBだけは最初に別で作成します。\n各リソースの役割 # サービス 役割 S3 tfstateファイルの保存場所 DynamoDB ロック機構（同時編集防止） 解決策：backend-setupディレクトリ # fumi-til-infrastructure/ ├── backend-setup/ ← 最初にこれだけ実行 │ ├── main.tf │ └── terraform.tfstate ← ローカルに残る └── environments/ └── prod/ ← backend-setup完了後に実行 └── main.tf 注意点 # backend-setup自体のtfstateはローカルに残る .gitignoreで除外しつつ、ローカルで大切に保管 補足：この方法は唯一の正解ではない # 本記事で紹介した「backend-setupディレクトリでtfstate用インフラを作成する」方法は、よく使われる方法の一つですが、唯一の正解ではありません。\nTerragruntの開発元であるGruntworkの公式ディスカッションでは、以下の方法が並列で紹介されています。\n方法 概要 メリット デメリット 手動作成（コンソール/CLI） AWSコンソールやCLIで直接作成 シンプル、鶏と卵問題なし IaC原則に反する、手順が残らない Terraformで作成（本記事の方式） 別ディレクトリでTerraform管理 IaCで管理可能 ローカルtfstateの管理が課題 CloudFormation/CDK AWSネイティブツールで作成 AWS内で完結 ツール混在 Terragrunt 自動でバックエンド作成 DRY、環境管理が楽 学習コスト Terraform Cloud/Enterprise マネージドサービス 運用が楽 有料 Gruntworkの見解 # Gruntworkのディスカッションでは、手動作成について以下のように述べられています。\n「これは始めるための簡単な方法です。管理するバックエンドが少数（例：会社全体で1〜3個のS3バケットのみ）であれば、このアプローチで十分うまくいきます。」\n一方で、手動作成のデメリットとして「手動プロセスである」「すべてのインフラをコードで管理できていない」「バックエンドのセットアップ方法がドキュメント化されない」も指摘されています。\nディスカッションの内容を自分なり解釈すると「規模が小さい場合はS3/DynamoDBなどを使用する。開発規模が大きくなり、自動化などが必要の場合はTerragruntによる自動作成がおすすめ」という印象でした。\n状況別の推奨 # 状況 推奨方法 個人開発・学習 手動作成 or Terraform（本記事の方式） 小規模チーム Terraform + tfstateをS3に手動コピー 中規模以上 Terragrunt or Terraform Cloud エンタープライズ Terraform Cloud/Enterprise 重要なのは、チームの規模やスキルセットに合った方法を選ぶことです。\nまとめ # tfstate用のS3/DynamoDBは「先に別で作る」必要がある（鶏と卵問題） backend-setup自体のtfstateはローカル管理となる S3は保存、DynamoDBはロックの役割 本記事の方法は「よく使われる方法の一つ」であり、状況に応じて他の方法も検討すべき 参考 # Terraformステート管理 Part1 - S3リモートバックエンドとワークスペース Backend Configuration - Terraform How should I create the backend for storing Terraform state? - Gruntwork Discussion Initial setup of terraform backend using terraform - Stack Overflow ","date":"2025年 12月 3日","externalUrl":null,"permalink":"/posts/251203194515_terraform-tfstate-management-chicken-egg-problem/","section":"Posts","summary":"","title":"Terraform tfstate管理の鶏と卵問題","type":"posts"},{"content":"","date":"2025年 12月 3日","externalUrl":null,"permalink":"/tags/acm/","section":"Tags","summary":"","title":"ACM","type":"tags"},{"content":" 今日学んだこと # ACM（AWS Certificate Manager）はSSL/TLS証明書を無料で発行・自動更新できるAWSサービス。 CloudFrontと組み合わせることで、カスタムドメインでのHTTPS通信を実現できます。\n学習内容 # ACMとは # ACM = AWS Certificate Manager\nSSL/TLS証明書を管理するAWSサービスです。\nSSL/TLS証明書の役割 # SSL/TLS証明書には2つの役割があります\n役割 説明 通信の暗号化 HTTPS通信を実現（HTTP = 暗号化なし、HTTPS = 暗号化あり） サイトの証明 「このサイトは本物です」を保証 ACMのメリット # 従来の方法と比較すると、ACMのメリットが明確です\n無料 AWS側で自動設定 有効期限切れに対して自動更新 CloudFrontでの構成 # ユーザー ↓ HTTPS（暗号化通信） CloudFront ← ACM証明書で「example.com」を証明 ↓ S3（コンテンツ） ACM証明書がないと https://example.com でアクセスできず、ブラウザに警告が出ます。\n重要な制約 # CloudFrontでACM証明書を使用する場合、証明書は必ずus-east-1（バージニア北部）で作成する必要があります。\nCloudFrontでの利用：Amazon CloudFrontでACM証明書を使用する場合、証明書は必ずUS East (N. Virginia) リージョンでリクエストまたはインポートする必要があります。 — AWS Certificate Manager Overview\nまとめ # ACMはSSL/TLS証明書を無料で発行・自動更新できるサービス 従来の証明書管理と比べて、コスト・手間が大幅に削減される CloudFrontと組み合わせてHTTPS通信を実現 CloudFrontで使用する場合はus-east-1で発行が必要 参考 # AWS Certificate Manager Overview Supported Regions - AWS Certificate Manager ","date":"2025年 12月 3日","externalUrl":null,"permalink":"/posts/251203194354_acm-certificate-ssl-tls-basics-cloudfront-integration/","section":"Posts","summary":"","title":"ACM証明書とは？SSL/TLS証明書の基礎からCloudFront連携まで","type":"posts"},{"content":" 今日学んだこと # Terraform を使う上でのつまずきポイントと回避策について学びました。count/for_each の制限事項、plan が成功しても apply が失敗するケース、そしてリファクタリング時の注意点を理解しました。\n学習内容 # count と for_each の制限事項 # リソース出力を参照できない # Terraform は plan フェーズ中に count と for_each を計算できる必要があります。リソースが作成・変更される前に値が決まっていなければなりません。\n値の種類 例 count/for_each で使用 ハードコード 3, [\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;] ✅ 可能 変数 var.user_names ✅ 可能 データソース（静的） data.aws_ami.example.id ✅ 可能（場合による） リソース出力 aws_instance.example.id ❌ 不可 リソース出力が使えない理由は、以下の処理順序にあります。\nplan フェーズ ↓ count/for_each を計算（この時点で値が必要） ↓ apply フェーズ ↓ リソースが作成される（出力値が決まる）← 遅すぎる！ 有効なプランも失敗することがある # terraform validate や terraform plan で問題なしと判定されても、terraform apply でエラーになることがあります。\n具体例：IAM ユーザーの重複 # resource \u0026#34;aws_iam_user\u0026#34; \u0026#34;example\u0026#34; { name = \u0026#34;user1\u0026#34; } コマンド 結果 terraform validate ✅ Success terraform plan ✅ 1 to add terraform apply ❌ エラー 実際のエラーメッセージ：\n│ Error: creating IAM User (user1): EntityAlreadyExists: User with name user1 already exists. なぜ起こるのか # Terraform は自身が管理しているリソース（ステートファイル）しか把握していない AWS コンソールや別の Terraform プロジェクトで作成されたリソースは検知できない plan 時点では AWS に問い合わせないため、重複を検出できない 対策 # 対策 説明 Terraform だけを使う インフラの管理方法を Terraform に統一し、手動作成を禁止 import コマンドを使用 既存のインフラを Terraform のステートに取り込む terraform import aws_iam_user.example user1 リファクタリングは難しい # リファクタリングとは、外部的なふるまいは変更せず、既存コードの内部構造を整理することです。\nTerraform での問題 # Terraform はリソースを識別子（リソースタイプ + リソース名）で管理しています。\n# 変更前 resource \u0026#34;aws_instance\u0026#34; \u0026#34;example\u0026#34; { } # 変更後（リソース名を変更） resource \u0026#34;aws_instance\u0026#34; \u0026#34;web_server\u0026#34; { } 変更 人間の意図 Terraform の解釈 example → web_server 名前を整理しただけ example を削除して web_server を新規作成 本番環境で実行すると、EC2 インスタンスが削除されてしまいます。\nリファクタリングの4つの教訓 # 教訓1：いつも plan コマンドを利用する # 変更や作成される内容を事前に確認します。予期しない削除・作成がないかチェックしましょう。\n教訓2：削除する前に作成 # リソースの置き換え時は、先に置き換え先を作成してから、古いリソースを削除します。\nlifecycle { create_before_destroy = true } 教訓3：リファクタリングにはステートの変更が必要な場合がある # ダウンタイムを起こさずにリファクタリングしたいなら、Terraform ステートも更新します。\n方法 説明 terraform state mv コマンドでステートを移動 moved ブロック コード内でステートの移行を自動実行 terraform state mv の例：\nterraform state mv aws_instance.example aws_instance.web_server moved ブロックの例：\nmoved { from = aws_instance.example to = aws_instance.web_server } moved ブロックの応用例：\n# モジュール名の変更 moved { from = module.webserver_cluster to = module.web } # モジュール内のリソースをモジュール外に移動 moved { from = module.webserver_cluster.aws_security_group.instance to = aws_security_group.instance } moved ブロックのメリットは、コードとして残るためチームメンバーが変更履歴を追跡できること、そして terraform plan で移動が正しく検出されることを確認できる点です。\n教訓4：イミュータブルなパラメータもある # 一部のパラメータは変更するとリソースの再作成が必要になります（インプレース更新ができない）。例えば EC2 の ami や RDS の engine などがこれに該当します。\nまとめ # つまずきポイント 回避策 count/for_each でリソース出力を参照 ハードコードや変数を使う plan 成功でも apply 失敗 Terraform に統一、または import を使用 リソース名変更で削除される moved ブロックや terraform state mv を使う イミュータブルなパラメータの変更 create_before_destroy で対応 count/for_each は plan フェーズで計算されるため、リソース出力を参照できない Terraform は自身が管理しているリソースしか把握していない リファクタリング時は moved ブロックを活用してステートを更新する いつも plan コマンドで変更内容を事前確認する 参考 # 詳解 Terraform 第3版 - Yevgeniy Brikman著、松浦隼人訳、オライリージャパン、2023年 Refactoring (moved blocks) State: terraform state mv Import The lifecycle Meta-Argument ","date":"2025年 12月 2日","externalUrl":null,"permalink":"/posts/251202083121_terraform-stumbling-points-and-solutions/","section":"Posts","summary":"","title":"Terraform のつまずきポイントと回避策","type":"posts"},{"content":"","date":"2025年 12月 2日","externalUrl":null,"permalink":"/tags/devops/","section":"Tags","summary":"","title":"DevOps","type":"tags"},{"content":" 今日学んだこと # Terraform で ASG（Auto Scaling Group）を使ったゼロダウンタイムデプロイを実現する方法を学びました。create_before_destroy ライフサイクルと min_elb_capacity を組み合わせることで、サービスを停止せずにインフラを更新できます。\n学習内容 # 背景と問題 # webserver-cluster モジュールで user-data.sh の内容（server_text など）を変更した場合、以下のような動作になります。\n新しい Launch Configuration が作成される ASG が新しい Launch Configuration を参照するようになる しかし、既存の EC2 インスタンスはそのまま！ Launch Configuration は新しいインスタンスを起動する際のテンプレートであり、既存のインスタンスには影響しません。\n解決策の比較 # 方法 手順 問題点 ASG を削除して再作成 古い ASG 削除 → 新しい ASG 作成 ダウンタイムが発生 create_before_destroy 新しい ASG 作成 → 古い ASG 削除 ダウンタイムなし ✅ ゼロダウンタイムデプロイに必要な3つの設定 # # 設定 目的 1 name を起動設定の名前に依存させる 起動設定が変わると ASG 名も変わり、置き換えが発生 2 create_before_destroy = true 新しい ASG を先に作成してから古いものを削除 3 min_elb_capacity = min_size 新しいインスタンスが ELB のヘルスチェックに合格するまで待機 コード例：ゼロダウンタイムデプロイ対応の ASG # resource \u0026#34;aws_autoscaling_group\u0026#34; \u0026#34;example\u0026#34; { # 1. ASG名が起動設定の名前を参照（起動設定が変わるとASGも置き換え） name = \u0026#34;${var.cluster_name}-${aws_launch_configuration.example.name}\u0026#34; launch_configuration = aws_launch_configuration.example.name vpc_zone_identifier = data.aws_subnets.default.ids target_group_arns = [aws_lb_target_group.asg.arn] health_check_type = \u0026#34;ELB\u0026#34; min_size = var.min_size max_size = var.max_size # 3. ヘルスチェックに合格するまで待機 min_elb_capacity = var.min_size # 2. 新しいASGを先に作成してから古いASGを削除 lifecycle { create_before_destroy = true } tag { key = \u0026#34;Name\u0026#34; value = var.cluster_name propagate_at_launch = true } dynamic \u0026#34;tag\u0026#34; { for_each = { for key, value in var.custom_tags: key =\u0026gt; upper(value) if key != \u0026#34;Name\u0026#34; } content { key = tag.key value = tag.value propagate_at_launch = true } } } デプロイの流れ # server_text 変更 ↓ user-data.sh の内容が変更 ↓ 新しい Launch Configuration 作成（名前が変わる） ↓ ASG の name が変わる → ASG の置き換えが必要と判断 ↓ 新しい ASG を作成（create_before_destroy） ↓ min_elb_capacity 台がヘルスチェック合格を待つ ↓ 古い ASG を削除 ↓ ゼロダウンタイムで完了！ 動作確認方法 # while true; do curl http://\u0026lt;load_balancer_url\u0026gt;; sleep 1; done 1秒ごとにリクエストを送り、デプロイ中もレスポンスが途切れないことを確認します。\n状態 レスポンス デプロイ前 古いメッセージのみ デプロイ中 古い/新しいが混在（両方の ASG が稼働） デプロイ後 新しいメッセージのみ デプロイ中もレスポンスが途切れなければ、ゼロダウンタイム達成です。\nゼロダウンタイムデプロイの制限事項 # 制限1：Auto Scaling ポリシーとは組み合わせて使えない # デプロイのたびに ASG のサイズが min_size にリセットされてしまいます。\n通常運用中：Auto Scaling により 10 台で稼働 ↓ デプロイ実行（create_before_destroy） ↓ 新しい ASG 作成時に min_size（例：2台）でスタート ↓ トラフィックに対してインスタンス数が不足！ 回避策としては、recurrence パラメータの調整や desired_capacity パラメータの明示的な設定があります。\n制限2：ネイティブなデプロイ方法がない（なかった） # 以前の Terraform にはゼロダウンタイムデプロイのようなネイティブなデプロイ方法がありませんでした。最近の Terraform ではネイティブなデプロイ方法がサポートされてきているため、適宜公式ドキュメントの確認が必要です。\nまとめ # ゼロダウンタイムデプロイには3つの設定が必要：ASG名の依存、create_before_destroy、min_elb_capacity create_before_destroy で新しい ASG を先に作成してから古い ASG を削除する min_elb_capacity でヘルスチェック合格まで待機することで、サービス断を防ぐ Auto Scaling ポリシーとの併用には注意が必要 参考 # 詳解 Terraform 第3版 - Yevgeniy Brikman著、松浦隼人訳、オライリージャパン、2023年 The lifecycle Meta-Argument AWS Provider: aws_autoscaling_group ","date":"2025年 12月 2日","externalUrl":null,"permalink":"/posts/251202082958_terraform-zero-downtime-deployment-methods/","section":"Posts","summary":"","title":"Terraformゼロダウンタイムデプロイの実現方法","type":"posts"},{"content":" 今日学んだこと # Terraform で条件分岐を実現する3つの手法（count + 三項演算子、for_each + for の if、if 文字列ディレクティブ）について学びました。特に count を使った「作る/作らない」の制御パターンは実践で頻繁に使われます。\n学習内容 # 条件分岐に使う手法 # 手法 用途 count パラメータ 条件付きリソースの作成（作る/作らない） for_each 式 / for 式 条件付きリソース、インラインブロックの条件生成 if 文字列ディレクティブ 文字列内での条件分岐 count パラメータを使った条件分岐 # count を使った if 文 # 三項演算子と組み合わせて、リソースを「作成する/しない」を制御します。\ncount = var.enable_autoscaling ? 1 : 0 var.enable_autoscaling count 結果 true 1 リソースを作成する false 0 リソースを作成しない コード例：オートスケーリングスケジュール # resource \u0026#34;aws_autoscaling_schedule\u0026#34; \u0026#34;scale_out_during_business_hours\u0026#34; { count = var.enable_autoscaling ? 1 : 0 scheduled_action_name = \u0026#34;${var.cluster_name}-scale-out-during-business-hours\u0026#34; min_size = 2 max_size = 10 desired_capacity = 10 recurrence = \u0026#34;0 9 * * *\u0026#34; autoscaling_group_name = aws_autoscaling_group.example.name } 本番環境では enable_autoscaling = true、ステージング環境では enable_autoscaling = false のように環境ごとに設定を切り替えられます。\ncount を使った if-else 文 # count の値を反転させることで if-else を実現します。\n# if 文（true のとき作成） resource \u0026#34;aws_iam_user_policy_attachment\u0026#34; \u0026#34;user1_cloudwatch_full_access\u0026#34; { count = var.give_user1_cloudwatch_full_access ? 1 : 0 # ... } # else 文（false のとき作成）→ 三項演算子の値を反転 resource \u0026#34;aws_iam_user_policy_attachment\u0026#34; \u0026#34;user1_cloudwatch_read_only\u0026#34; { count = var.give_user1_cloudwatch_full_access ? 0 : 1 # ... } var.give_user1_cloudwatch_full_access full_access の count read_only の count true 1 0 false 0 1 条件付きリソースの出力値を取得 # count で作成したリソースは、条件によって存在したりしなかったりします。concat と one 関数を組み合わせて出力値を取得します。\noutput \u0026#34;user1_cloudwatch_policy_arn\u0026#34; { value = one(concat( aws_iam_user_policy_attachment.user1_cloudwatch_full_access[*].policy_arn, aws_iam_user_policy_attachment.user1_cloudwatch_read_only[*].policy_arn )) } one() 関数は単一要素のリストから値を取り出します。空のリストの場合は null を返します。\nfor_each と for を使った条件分岐 # 基本的な考え方 # for_each に渡す集合 結果 空の集合 {} / [] リソースは作成されない 空ではない集合 リソースが作成される for 式の if でフィルタリングすることで、条件に合う要素のみを処理できます。\ndynamic \u0026#34;tag\u0026#34; { for_each = { for key, value in var.custom_tags: key =\u0026gt; upper(value) if key != \u0026#34;Name\u0026#34; # ← 条件分岐（フィルタリング） } content { key = tag.key value = tag.value propagate_at_launch = true } } この例では key != \u0026quot;Name\u0026quot; の条件により、\u0026ldquo;Name\u0026rdquo; キーを除外しています。\ncount vs for_each の使い分け（条件分岐） # ユースケース 推奨 理由 条件付きでリソース/モジュールを作成（作る or 作らない） count ? 1 : 0 がシンプル リソース/モジュールを複数作成 for_each 途中要素削除の問題がない それ以外のループや条件分岐 for_each 柔軟性が高い if 文字列ディレクティブを使った条件分岐 # 文字列内で条件分岐を行うための構文です。\n基本構文 # %{ if \u0026lt;CONDITION\u0026gt; }\u0026lt;TRUE_VAL\u0026gt;%{ endif } コード例：最後の要素だけカンマを付けない # output \u0026#34;for_directive_index_if\u0026#34; { value = \u0026lt;\u0026lt;EOF %{~ for i, name in var.names ~} ${name}%{ if i \u0026lt; length(var.names) - 1 }, %{ endif } %{~ endfor ~} EOF } ループ i name i \u0026lt; length - 1 出力 1回目 0 user1 true user1, 2回目 1 user2 true user2, 3回目 2 user3 false user3 if-else 構文 # %{ if \u0026lt;CONDITION\u0026gt; }\u0026lt;TRUE_VAL\u0026gt;%{ else }\u0026lt;FALSE_VAL\u0026gt;%{ endif } output \u0026#34;for_directive_index_if_else_strip\u0026#34; { value = \u0026lt;\u0026lt;EOF %{~ for i, name in var.names ~} ${name}%{ if i \u0026lt; length(var.names) - 1 }, %{ else }.%{ endif } %{~ endfor ~} EOF } 出力結果は user1, user2, user3. となり、最後の要素にピリオドが付きます。\nまとめ # 手法 用途 構文例 count + 三項演算子 リソースを作る/作らない count = var.enable ? 1 : 0 count（if-else） 排他的なリソース作成 ? 1 : 0 と ? 0 : 1 を反転 for_each + for の if 条件付きフィルタリング for k, v in map : k =\u0026gt; v if condition if 文字列ディレクティブ 文字列内の条件分岐 %{ if condition }...%{ endif } 「作る or 作らない」の2択なら count がシンプル 複数作成や複雑な条件なら for_each を使う one() と concat() で条件付きリソースの出力値を安全に取得できる 参考 # 詳解 Terraform 第3版 - Yevgeniy Brikman著、松浦隼人訳、オライリージャパン、2023年 The count Meta-Argument The for_each Meta-Argument String Templates Built-in Functions - one ","date":"2025年 12月 2日","externalUrl":null,"permalink":"/posts/251202082829_terraform-conditional-branching-patterns/","section":"Posts","summary":"","title":"Terraform条件分岐パターン集","type":"posts"},{"content":" 今日学んだこと # Terraform の for 式と for 文字列ディレクティブについて学びました。これらは count や for_each とは異なり、リソースを作成するのではなく、リストやマップを変換・加工するための機能です。\n学習内容 # for 式の基本 # for 式は count や for_each とは異なり、リストやマップを変換・加工するための式です。\nリストを出力する構文 # [for \u0026lt;ITEM\u0026gt; in \u0026lt;LIST\u0026gt; : \u0026lt;OUTPUT\u0026gt;] 例として、名前のリストを大文字に変換してみます。\nvariable \u0026#34;names\u0026#34; { type = list(string) default = [\u0026#34;user1\u0026#34;, \u0026#34;user2\u0026#34;, \u0026#34;user3\u0026#34;] } output \u0026#34;upper_names\u0026#34; { value = [for name in var.names : upper(name)] } 出力結果は [\u0026quot;USER1\u0026quot;, \u0026quot;USER2\u0026quot;, \u0026quot;USER3\u0026quot;] となります。\nマップに対するループ # マップをループする場合は、キーと値の両方を取得できます。\n[for \u0026lt;KEY\u0026gt;, \u0026lt;VALUE\u0026gt; in \u0026lt;MAP\u0026gt; : \u0026lt;OUTPUT\u0026gt;] variable \u0026#34;user_roles\u0026#34; { type = map(string) default = { user1 = \u0026#34;admin\u0026#34; user2 = \u0026#34;developer\u0026#34; user3 = \u0026#34;viewer\u0026#34; } } output \u0026#34;user_descriptions\u0026#34; { value = [for name, role in var.user_roles : \u0026#34;${name} is the ${role}\u0026#34;] } 出力結果は [\u0026quot;user1 is the admin\u0026quot;, \u0026quot;user2 is the developer\u0026quot;, \u0026quot;user3 is the viewer\u0026quot;] のようなリストになります。\n注意: マップの要素順序は保証されないため、出力順序は異なる場合があります。\nマップを出力する構文 # [] と {} で出力形式が変わります。\n括弧 出力形式 構文 [] リスト [for ... : \u0026lt;OUTPUT\u0026gt;] {} マップ {for ... : \u0026lt;KEY\u0026gt; =\u0026gt; \u0026lt;VALUE\u0026gt;} output \u0026#34;upper_roles\u0026#34; { value = {for name, role in var.user_roles : upper(name) =\u0026gt; upper(role)} } 出力結果は以下のようなマップになります。\n{ \u0026#34;USER1\u0026#34; = \u0026#34;ADMIN\u0026#34; \u0026#34;USER2\u0026#34; = \u0026#34;DEVELOPER\u0026#34; \u0026#34;USER3\u0026#34; = \u0026#34;VIEWER\u0026#34; } for 式の出力パターンまとめ # 入力 出力 構文例 リスト → リスト [] [for x in list : upper(x)] マップ → リスト [] [for k, v in map : \u0026quot;${k}=${v}\u0026quot;] リスト → マップ {} {for x in list : x =\u0026gt; upper(x)} マップ → マップ {} {for k, v in map : upper(k) =\u0026gt; upper(v)} for 文字列ディレクティブによるループ # 文字列ディレクティブを使用すると、文字列内でループを展開できます。%{...} を使用します。\n基本構文 # %{for \u0026lt;ITEM\u0026gt; in \u0026lt;COLLECTION\u0026gt;} \u0026lt;BODY\u0026gt; %{endfor} 例：名前のリストをカンマ区切りで出力 # output \u0026#34;for_directive\u0026#34; { value = \u0026#34;%{ for name in var.names }${name}, %{ endfor }\u0026#34; } 出力結果は \u0026quot;user1, user2, user3, \u0026quot; となります。\nインデックス付きの構文 # %{for \u0026lt;INDEX\u0026gt;, \u0026lt;ITEM\u0026gt; in \u0026lt;COLLECTION\u0026gt;} \u0026lt;BODY\u0026gt; %{endfor} output \u0026#34;for_directive_with_index\u0026#34; { value = \u0026#34;%{ for index, name in var.names }${index}: ${name}, %{ endfor }\u0026#34; } 出力結果は \u0026quot;0: user1, 1: user2, 2: user3, \u0026quot; となります。\nヒアドキュメント構文 # 文字列ディレクティブでは、複数行の文字列を扱うためにヒアドキュメント構文を使用することが多いです。\n\u0026lt;\u0026lt;EOF 複数行の 文字列を ここに記述 EOF \u0026lt;\u0026lt;-EOF を使うとインデントを自動除去できます。\nstrip marker（~）による空白除去 # 文字列ディレクティブを使うと不要なスペースや改行が追加されることがあります。strip marker（~）で解決できます。\noutput \u0026#34;for_directive_strip\u0026#34; { value = \u0026lt;\u0026lt;EOF %{~ for i, name in var.names ~} ${name}%{ if i \u0026lt; length(var.names) - 1 }, %{ endif } %{~ endfor ~} EOF } 出力結果は user1, user2, user3 ときれいに整形されます。\n記法 効果 %{~ ... } 左側の空白・改行を除去 %{ ... ~} 右側の空白・改行を除去 %{~ ... ~} 両側の空白・改行を除去 for 式と文字列ディレクティブの比較 # 手法 構文 結果 for 式 [for i, name in var.names : \u0026quot;${i}: ${name}\u0026quot;] リスト 文字列ディレクティブ \u0026quot;%{for i, name in var.names}${i}: ${name}%{endfor}\u0026quot; 文字列 まとめ # 手法 用途 結果 for 式 リスト/マップの変換・加工 新しいリスト or マップ for 文字列ディレクティブ 文字列内でのループ展開 文字列 for 式は [] でリスト、{} でマップを出力する 文字列ディレクティブは %{for ...}...%{endfor} で文字列内にループを展開する strip marker（~）を使うと不要な空白・改行を除去できる 参考 # 詳解 Terraform 第3版 - Yevgeniy Brikman著、松浦隼人訳、オライリージャパン、2023年 for Expressions String Templates Built-in Functions ","date":"2025年 12月 2日","externalUrl":null,"permalink":"/posts/251202082701_terraform-for-expression-list-and-map-conversion-techniques/","section":"Posts","summary":"","title":"Terraform for式入門：リストとマップの変換テクニック","type":"posts"},{"content":" 今日学んだこと # Terraform で同じようなリソースを複数作成する際に使う count と for_each について学びました。両者の違いと、途中の要素を削除する際に発生する問題、そして for_each がその問題をどう解決するかを理解しました。\n学習内容 # count と for_each の違い # 項目 count for_each 識別方法 インデックス（番号） キー（名前） 対応データ型 数値のみ 集合（set）・マップ（map） 途中要素の削除 インデックスずれ問題あり 他の要素に影響なし インラインブロック 使用不可 使用可能（dynamic ブロック） count パラメータによるループ # count は Terraform の初期から存在する基本的な機能です。count.index を使ってリソースに一意の名前を付けます。\nresource \u0026#34;aws_iam_user\u0026#34; \u0026#34;example\u0026#34; { count = 3 name = \u0026#34;user.${count.index}\u0026#34; } 作成されるユーザー名は user.0, user.1, user.2 となります。count.index は 0 から始まる点に注意が必要です。\nより実践的なパターンとして、リストと length() 関数を組み合わせる方法があります。\nvariable \u0026#34;user_names\u0026#34; { type = list(string) default = [\u0026#34;user1\u0026#34;, \u0026#34;user2\u0026#34;, \u0026#34;user3\u0026#34;] } resource \u0026#34;aws_iam_user\u0026#34; \u0026#34;example\u0026#34; { count = length(var.user_names) name = var.user_names[count.index] } この方法のメリットは、変数を変更するだけでユーザー数を増減でき、main.tf を編集する必要がない点です。\ncount 使用時のリソース参照 # count を使うとリソースは配列として扱われるため、インデックスを指定して参照します。\n# 特定のユーザーを参照 aws_iam_user.example[0].arn # → user1 の ARN # 全ユーザーの ARN を出力（スプラット式） output \u0026#34;user_arns\u0026#34; { value = aws_iam_user.example[*].arn } count の制限事項 # count には大きな制限事項が2つあります。\n制限1：インラインブロックには利用不可\ningress や egress などのインラインブロック内で count は使えません。インラインブロックを動的に生成したい場合は dynamic ブロックを使用します。\n制限2：途中の要素削除で問題が発生\nこれが count の最大の問題点です。[\u0026quot;user1\u0026quot;, \u0026quot;user2\u0026quot;, \u0026quot;user3\u0026quot;] から user2 を削除しようとすると、以下のような意図しない動作が発生します。\nインデックス 期待 実際の動作 [0] user1（維持） user1（維持） [1] user3（維持） user2 → user3 に変更 [2] - user3 を削除 count はインデックスでリソースを識別するため、途中の要素を抜くとインデックスがずれてしまいます。結果として、user2 ではなく user3 が削除されてしまいます。\nfor_each 式によるループ # for_each はキー（名前）でリソースを識別するため、途中の要素を削除しても他のリソースに影響しません。\nresource \u0026#34;aws_iam_user\u0026#34; \u0026#34;example\u0026#34; { for_each = toset(var.user_names) name = each.value } リストを使う場合は toset() で集合に変換する必要があります。\n注意: toset() は重複する値を自動的に除去します。リストに重複値がある場合、意図しない結果になる可能性があるため、入力データの一意性を確認してください。\neach.key と each.value の動作 # データ型 each.key each.value 集合（set） 値そのもの 値そのもの（key と同じ） マップ（map） キー 値 for_each による途中要素の削除 # [\u0026quot;user1\u0026quot;, \u0026quot;user2\u0026quot;, \u0026quot;user3\u0026quot;] から user2 を削除した場合の動作を比較します。\nfor_each の場合（正しく動作）：\nキー 変更前 変更後 動作 \u0026ldquo;user1\u0026rdquo; user1 user1 維持 \u0026ldquo;user2\u0026rdquo; user2 - 削除（意図通り） \u0026ldquo;user3\u0026rdquo; user3 user3 維持 for_each はキーで識別するため、user2 のみが正しく削除されます。\nfor_each で作成したリソースの参照 # for_each で作成するとリソースはマップ形式になります。ARN を取り出すには values() 関数を使います。\noutput \u0026#34;all_arns\u0026#34; { value = values(aws_iam_user.example)[*].arn } dynamic ブロックによるインラインブロックの動的生成 # for_each を使用するとリソース内のインラインブロックを複数作成できます。\ndynamic \u0026#34;tag\u0026#34; { for_each = var.custom_tags content { key = tag.key value = tag.value propagate_at_launch = true } } まとめ # 状況 推奨 単純な数による繰り返し count 途中の要素を削除する可能性がある for_each インラインブロックを動的生成 for_each（dynamic ブロック） キー/名前でリソースを管理したい for_each count はインデックスで管理、for_each はキーで管理 途中の要素削除が想定される場合は for_each を使う インラインブロックの動的生成には dynamic ブロックと for_each を組み合わせる 参考 # 詳解 Terraform 第3版 - Yevgeniy Brikman著、松浦隼人訳、オライリージャパン、2023年 The count Meta-Argument The for_each Meta-Argument Dynamic Blocks ","date":"2025年 12月 2日","externalUrl":null,"permalink":"/posts/251202082522_terraform-loops-count-and-for-each-usage/","section":"Posts","summary":"","title":"Terraformループの基礎：countとfor_eachの使い分け","type":"posts"},{"content":"","date":"2025年 12月 2日","externalUrl":null,"permalink":"/tags/git/","section":"Tags","summary":"","title":"Git","type":"tags"},{"content":" 今日学んだこと # 以前、Zennに投稿した記事を修正してTILとして投稿します。\nGitHub CLIの gh issue view コマンドを使うと、IssuesをMarkdownファイルとしてダウンロードできます。さらに jq コマンドと組み合わせることで、日時フォーマットを日本語表記に変換し、読みやすい形式で出力できることを学びました。\n学習内容 # 背景と対象読者 # GitHubのプライベートリポジトリでIssuesを作業メモとして活用していましたが、書き溜めた内容をコピー\u0026amp;ペーストで取り出す方法しかなく、効率的に活用できていませんでした。この問題を解決するため、IssuesをMarkdownファイルとしてダウンロードする方法を調べました。\n対象読者：\nGitHub CLIの基本的な使い方を知っている方 ドキュメント作成や記事執筆の素材としてIssuesを活用したい方 前提条件：\nLinux（Ubuntu）環境（WSL2含む） 対象リポジトリへのアクセス権限を保有している パブリックリポジトリまたは有料プランユーザーの場合は、GitHub Wiki機能など互換性のある機能があるため、そちらを利用するほうが手順も簡単で効率的です。\nStep 1: 環境セットアップ # GitHub CLIのインストール # # インストール状況の確認 gh --version # GitHub CLIのインストール（必要な場合） sudo apt install gh GitHub CLIへのログイン # # ログイン状況の確認 gh auth status # GitHub CLIへログイン実行 gh auth login Step 2: Issues一覧の確認 # gh issue list --repo \u0026lt;OWNER/REPO\u0026gt; 実行例：\ngh issue list --repo mr110825/github-issues-to-markdown 出力例：\nID TITLE LABELS UPDATED #1 サンプル用のIssues about 1 hour ago Step 3: Issueの取得（4つの方法） # 方法2・3は --json comments を指定しているため、コメントのみが出力されます。Issue本文も含めたい場合は方法4を使用してください。\n方法1: シンプルな取得 # gh issue view \u0026lt;ISSUE_NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; --comments \u0026gt; \u0026lt;FILENAME\u0026gt;.md 出力例：\nauthor:\tmr110825 association:\towner edited:\ttrue status:\tnone -- 記事を投稿するので構成をまとめる -- この方法は最もシンプルですが、メタデータが多く含まれ、内容が読みにくくなります。\n方法2: コメントのみ取得（ISO形式） # gh issue view \u0026lt;ISSUE_NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; --comments --json comments --template \u0026#39;{{range .comments}}## コメント ({{.createdAt}}) {{.body}} --- {{end}}\u0026#39; \u0026gt; \u0026lt;FILENAME\u0026gt;.md 出力例：\n## コメント (2025-06-28T12:24:28Z) 記事を投稿するので構成をまとめる --- メタデータが除去され、コメントの内容と投稿日時が明確に表示されます。ただし、ISO形式の日時表記は読みづらいです。\n方法3: 日本語表記で取得（推奨） # gh issue view \u0026lt;ISSUE_NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; --comments --json comments | jq -r \u0026#39;.comments[] | \u0026#34;## コメント (\u0026#34; + (.createdAt | strptime(\u0026#34;%Y-%m-%dT%H:%M:%SZ\u0026#34;) | strftime(\u0026#34;%Y年%m月%d日 %H時%M分\u0026#34;)) + \u0026#34;)\\n\\n\u0026#34; + .body + \u0026#34;\\n\\n---\\n\u0026#34;\u0026#39; \u0026gt; \u0026lt;FILENAME\u0026gt;.md jq コマンドが必要です：\nsudo apt install jq 出力例：\n## コメント (2025年06月28日 12時24分) 記事を投稿するので構成をまとめる --- 日本語表記により日時が直感的に理解でき、最も実用的な方法です。\n注意: 出力される日時はUTC（協定世界時）です。日本時間（JST）に変換したい場合は、dateコマンドとの組み合わせや、jq内で9時間加算する処理が必要です。\n方法4: Issue本文とコメントを取得（推奨） # gh issue view \u0026lt;ISSUE_NUMBER\u0026gt; --repo \u0026lt;OWNER/REPO\u0026gt; --json title,body,comments | jq -r \u0026#39; \u0026#34;# \u0026#34; + .title + \u0026#34;\\n\\n\u0026#34; + .body + \u0026#34;\\n\\n---\\n\\n\u0026#34; + ([.comments[] | \u0026#34;## コメント (\u0026#34; + (.createdAt | strptime(\u0026#34;%Y-%m-%dT%H:%M:%SZ\u0026#34;) | strftime(\u0026#34;%Y年%m月%d日 %H時%M分\u0026#34;)) + \u0026#34;)\\n\\n\u0026#34; + .body] | join(\u0026#34;\\n\\n---\\n\\n\u0026#34;)) \u0026#39; \u0026gt; \u0026lt;FILENAME\u0026gt;.md 出力例：\n# サンプル用のIssues これはサンプルのIssueです。 --- ## コメント (2025年06月28日 12時24分) 記事を投稿するので構成をまとめる --- ## コメント (2025年06月28日 12時25分) 必要な手順 - [x] 文章企画を構成 - [x] サンプルのリポジトリを作成 - [x] 記事作成 - [x] 記事投稿 Issue本文（タイトル・概要）とコメントの両方を取得できるため、Issueの全体像を把握したい場合に最適です。\nまとめ # 方法 特徴 推奨度 方法1（シンプル） メタデータが多く読みにくい △ 方法2（ISO形式） コメントのみ抽出、日時が読みにくい ○ 方法3（日本語表記） コメントのみ、読みやすく実用的 ○ 方法4（本文+コメント） Issue全体を取得、最も実用的 ◎ gh issue view コマンドでIssuesをMarkdownとして取得できる --json オプションで comments のみ、または title,body,comments を指定して出力内容を制御可能 jq コマンドを使えば日時フォーマットを日本語表記に変換できる オフライン環境でもIssuesの内容を参照でき、ドキュメント作成の素材として活用できる 参考 # GitHub CLI クイックスタート 【Git のセットアップ】GitHub CLI を使って GitHub に接続する ","date":"2025年 12月 2日","externalUrl":null,"permalink":"/posts/251202080329_download-github-issues-as-markdown-files/","section":"Posts","summary":"","title":"Github-CLIでIssuesをMarkdownファイルとしてダウンロードする方法","type":"posts"},{"content":" 今日学んだこと # NAND型RSフリップフロップの仕組みと動作原理を学びました。2つのNANDゲートをたすきがけに接続することで、1ビットの情報を記憶・保持できる基本的な順序回路です。\n学習内容 # NAND型RSフリップフロップとは # NANDゲートを2つたすきがけすることで構成される論理回路です。\nデジタル回路における基本的な記憶素子の一つ 1ビットの情報（0か1）を記憶し、保持することが可能 RSフリップフロップの「RS」は、それぞれ**セット（Set）とリセット（Reset）**の頭文字に由来 ┌───────┐ S ──────┤ │ │ NAND ├──┬─────── Q ┌───┤ │ │ │ └───────┘ │ │ │ │ ┌───────┐ │ └───┤ ├──┘ │ NAND │ ┌───┤ ├──────── Q̄ │ └───────┘ │ R ──┘ なぜ記憶できるのか # NAND型RSフリップフロップが記憶できる理由は、フィードバック構造にあります。\n各NANDゲートの出力が、もう一方のNANDゲートの入力に接続されている この相互接続により、一度セットまたはリセットされた状態が自己保持される 入力S、Rがともに「1」になっても、出力は直前の状態を維持し続ける つまり、2つのNANDゲートが互いに「支え合う」ことで、電源が供給されている限り状態を保持できます。\nNAND型RSフリップフロップの特徴 # 2つの出力（QとQ̄）は互いに逆の値になる\nS=R=0の禁止状態を除き、QとQ̄は必ず互いに逆の値になります。 S＝0，R＝1でセット（Q＝1）\n入力Sに「0」、Rに「1」が入力されると、出力Qは「1」にセットされます。 Sが入力されるNANDゲートは、入力に「0」があるため出力（Q）が必ず「1」になります。 その結果、もう一方のNANDゲートの入力は両方とも「1」となり、出力（Q̄）は「0」になります。 S＝1，R＝0でリセット（Q＝0）\n入力Sに「1」、Rに「0」が入力されると、出力Qは「0」にリセットされます。 Rが入力されるNANDゲートの出力（Q̄）が「1」になり、その結果、もう一方のNANDゲートの出力（Q）が「0」になります。 S＝R＝1で状態保持\n入力SとRがともに「1」の場合、フリップフロップは直前の出力状態を保持します。 例えば、Qが「1」であれば「1」のまま、Qが「0」であれば「0」のままとなります。 これは、NANDゲートの出力がもう一方の入力に影響を与え合い、安定した状態を維持するためです。 真理値表 # S R Qn+1 Q̄n+1 状態 0 0 1 1 禁止 0 1 1 0 セット 1 0 0 1 リセット 1 1 Qn Q̄n 保持 （Qnは現在の状態、Qn+1は次の状態を示します）\nまとめ # NAND型RSフリップフロップは、2つのNANDゲートをたすきがけに接続した記憶素子 S=0, R=1 で出力Qを「1」にセット S=1, R=0 で出力Qを「0」にリセット S=R=1 で直前の状態を保持 S=R=0 は禁止状態（両出力が「1」になり、QとQ̄が逆にならない。さらに次に両入力が同時に「1」に戻ると出力が不定になる） 参考 # Wikipedia：フリップフロップ 応用情報技術者過去問道場：平成27年秋期 問22 ","date":"2025年 12月 1日","externalUrl":null,"permalink":"/posts/251201221916_nand-type-rs-flip-flop/","section":"Posts","summary":"","title":"1ビットを記憶する仕組み：NAND型RSフリップフロップ","type":"posts"},{"content":"","date":"2025年 12月 1日","externalUrl":null,"permalink":"/tags/%E3%83%87%E3%82%B8%E3%82%BF%E3%83%AB%E5%9B%9E%E8%B7%AF/","section":"Tags","summary":"","title":"デジタル回路","type":"tags"},{"content":" 今日学んだこと # 「指示通りにできない」原因は、認知能力・メタ認知能力・非認知能力の3つに分類でき、それぞれ読書・内省・対話といったトレーニングで改善可能であることを学びました。\n学習内容 # 書籍について # 榎本博明著『「指示通り」ができない人たち』（2024年、日経BP）を読みました。自身のソフトスキル、特に非認知能力の改善ヒントを得たいと考えたのが購入のきっかけです。\n本書の構成 # 本書は「指示通り」に業務を遂行できない人々を以下の3タイプに分類し、それぞれのケースと原因、改善策を解説しています。\n認知能力に課題がある人 メタ認知能力に課題がある人 非認知能力に課題がある人 改善策の柱として「読書」や「文章の要約」による読解力の強化が提言されています。また、関連書籍としてダニエル・ゴールドマンの『EQ こころの知能指数』も紹介されており、感情的知性の重要性にも触れられています。\n印象に残ったケース # 認知能力：パニックに弱い人 # 複数のタスクを同時に振られると混乱してしまうケース。ワーキングメモリの容量が少ないことが一因とされています。\n改善策: タスクの優先順位を都度明確にし、一つの作業に集中する環境を意識的に作る。\nメタ認知能力：同じミスを繰り返す人 # 過去の指摘を忘れ、同様の失敗を繰り返すケース。単なる記憶力の問題ではなく、自身の行動を客観視できていないことに起因します。\n改善策: 指摘をその場でメモに取る、日記で自身の行動を振り返るなど、内省を習慣化する。\n非認知能力：能力は高いが対人関係が苦手な人 # 業務遂行能力や知識は豊富だが、顧客との交渉など対人関係に強い不安を感じ、キャリアの機会を逃してしまうケース。\n改善策: 「対人不安」は多くの人が抱える普遍的な感情であると受け入れ、小さな成功体験を積むことで徐々に克服していく。\n今後の行動 # 本書の提言を踏まえ、以下を継続的に実践していきます。\n読書メモの作成: 内容を要約する習慣で読解力を養う 日記による振り返り: 自身の行動や感情を客観的に内省する まとめ # 課題のタイプ 例 改善アプローチ 認知能力 パニックに弱い 優先順位の明確化、集中環境の構築 メタ認知能力 同じミスを繰り返す メモ・日記による内省の習慣化 非認知能力 対人関係が苦手 不安の受容と小さな成功体験の積み重ね 共通する改善策は「読書と要約」「日々の内省」「他者との対話」の3つです。\n参考 # 榎本博明『「指示通り」ができない人たち』日経BP、2024年 ","date":"2025年 12月 1日","externalUrl":null,"permalink":"/posts/251201082613_reading-memo-people-who-cant-follow-instructions/","section":"Posts","summary":"","title":"読書メモ：指示通りができない人たち","type":"posts"},{"content":" 書籍情報 # タイトル：科学的根拠に基づく最高の勉強法 著者：安川 康介 出版社：KADOKAWA 発売日：2024/2/15 本書のCh.1とCh.2を中心にまとめた読書メモ。\n結論：最高の勉強法は「連続的再学習」 # 本書が提唱する最高の勉強法は 連続的再学習 である。\n連続的再学習 ＝ アクティブリコール ＋ 分散学習\nこの結論は、ダンロスキー教授による勉強法の報告書やブルームタキソノミーなどの研究に基づいている。\n効果が低い勉強法 # 以下の勉強法は効果が低いとされている。\n再読 ノートへの要約 ハイライト なぜ効果の低い方法がメジャーなのか？ # 原因は 「流暢性の誤謬」 にある。\n実感としては効果があるように感じる しかし実際のテスト結果は向上していない または個人差が大きい 一方、アクティブリコールや分散学習は実感が薄いものの、テスト等で実際に結果が出ている。\n実感に惑わされず、本当に効果のある方法を選ぶべき。\nキーコンセプト：望ましい困難 # 脳に負荷をかけて「望ましい困難」を作り出すことがポイント。インプットだけでなくアウトプットの重要性を認識することが大切。\n自分の実践プラン # NotebookLMでフラッシュカード作成 - TILとして書いている技術ブログを読み込ませてフラッシュカードを生成する 白紙から書き出す - ヒントが少ない状態から回答を再現する ゴール提示型ハンズオン - ゴールだけ示して、可能な限りヒントなしで実践する ","date":"2025年 11月 30日","externalUrl":null,"permalink":"/posts/251130211705_best-learning-method-continuous-relearning/","section":"Posts","summary":"","title":"最高の勉強法：連続的再学習のすすめ","type":"posts"},{"content":"","date":"2025年 11月 30日","externalUrl":null,"permalink":"/series/docker%E7%92%B0%E5%A2%83%E3%81%A7node.js%E3%82%92%E5%AD%A6%E3%81%BC%E3%81%86/","section":"Series","summary":"","title":"Docker環境でNode.jsを学ぼう","type":"series"},{"content":" はじめに # 🎯 このメモで理解すべき3つの要点 # yarn：npmの代替パッケージマネージャー\nnpmより高速で厳密なバージョン管理 yarn.lockによる依存関係の固定 Sass：CSSの拡張言語\nネスト構文、変数、ミックスインでCSS開発を効率化 SCSSファイルからCSSファイルへコンパイル nvm/nodenv：Node.jsバージョン管理\nプロジェクトごとに異なるNode.jsバージョンを使用 チーム内でバージョンを統一 ⚠️ よくある初心者の間違い # ❌ npmとyarnを同じプロジェクトで混用してしまう ❌ SassとSCSS、node-sassとDart Sassの違いを理解していない ❌ nvm useの設定が新しいターミナルで引き継がれない 前提条件 # Part 1 を完了していること（Docker基礎、Node.js/npm基礎） Docker Desktopがインストールされていること Section 1: yarn（パッケージマネージャー） # 1.1 yarnとは？ # yarnは、Meta（旧Facebook）が開発したパッケージマネージャーです。\nnpmとyarnの比較 # 項目 npm yarn 開発元 npm, Inc. Meta（旧Facebook） 登場年 2010年 2016年 速度 標準的 高速（並列インストール） ロックファイル package-lock.json yarn.lock オフラインキャッシュ あり より強力 yarn登場の背景 # npmの問題点（特に2016年当時）を解決するために開発されました：\nインストール速度の遅さ 依存関係の不安定さ セキュリティの懸念 現在のnpmは大幅に改善されており、どちらを使うかはチームの方針次第です。\n1.2 ハンズオン：yarn環境構築 # 学習用ディレクトリの作成 # # ローカルで作業ディレクトリを作成 mkdir yarn-study \u0026amp;\u0026amp; cd yarn-study # Dockerコンテナを起動 docker run -it --rm -v $(pwd):/work -w /work node:20 bash yarnのバージョン確認 # # Node.js 20にはyarnが含まれている（Corepack経由） corepack enable yarn --version Corepack：Node.js 16.10以降に含まれるパッケージマネージャー管理ツール\n1.3 yarnでプロジェクト初期化 # # プロジェクト初期化 yarn init -y # package.jsonを確認 cat package.json 生成されるpackage.json # { \u0026#34;name\u0026#34;: \u0026#34;work\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;MIT\u0026#34; } 1.4 パッケージのインストール # # パッケージを追加 yarn add lodash # 開発用パッケージを追加 yarn add --dev jest # パッケージを確認 cat package.json yarnとnpmのコマンド対比 # npm yarn 説明 npm init -y yarn init -y 初期化 npm install yarn または yarn install 依存関係インストール npm install \u0026lt;pkg\u0026gt; yarn add \u0026lt;pkg\u0026gt; パッケージ追加 npm install -D \u0026lt;pkg\u0026gt; yarn add --dev \u0026lt;pkg\u0026gt; 開発用パッケージ追加 npm uninstall \u0026lt;pkg\u0026gt; yarn remove \u0026lt;pkg\u0026gt; パッケージ削除 npm run \u0026lt;script\u0026gt; yarn \u0026lt;script\u0026gt; スクリプト実行 npm update yarn upgrade パッケージ更新 1.5 yarn.lockの役割 # # yarn.lockを確認 cat yarn.lock yarn.lockの特徴 # インストールされた正確なバージョンを記録 チームメンバー全員が同じバージョンを使用 必ずGitにコミットする 1.6 スクリプトの実行 # # package.jsonを更新 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; package.json { \u0026#34;name\u0026#34;: \u0026#34;yarn-study\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;hello\u0026#34;: \u0026#34;echo \u0026#39;Hello from yarn!\u0026#39;\u0026#34;, \u0026#34;test\u0026#34;: \u0026#34;jest\u0026#34; }, \u0026#34;dependencies\u0026#34;: { \u0026#34;lodash\u0026#34;: \u0026#34;^4.17.21\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;jest\u0026#34;: \u0026#34;^29.0.0\u0026#34; } } EOF # スクリプト実行（runを省略可能） yarn hello 1.7 便利なyarnコマンド # # インストール済みパッケージの一覧 yarn list --depth=0 # 特定パッケージの情報 yarn info lodash # キャッシュのクリア yarn cache clean # アップグレード可能なパッケージを確認 yarn outdated 1.8 npmとyarnの混用に注意 # 重要：同じプロジェクトでnpmとyarnを混用しないでください。\n状況 問題 package-lock.jsonとyarn.lockが両方ある 依存関係の不整合 npm install後にyarn add ロックファイルの競合 対策：チームで統一して、どちらか一方のみを使用する\n1.9 コンテナ終了 # exit ✅ このセクションで学んだこと # yarnはnpmの代替パッケージマネージャー（高速、厳密なバージョン管理） yarn addでパッケージ追加、yarnで依存関係インストール yarn.lockでバージョンを固定し、チームで統一 重要：npmとyarnを同じプロジェクトで混用しない Section 2: Sass（CSSプリプロセッサ） # 2.1 Sassとは？ # **Sass（Syntactically Awesome Style Sheets）**は、CSSを拡張したメタ言語です。\nSassの主な機能 # 機能 説明 メリット ネスト セレクタを入れ子で記述 構造が明確に 変数 値を変数に格納 一括変更が容易 ミックスイン スタイルの再利用 DRY原則 継承 スタイルの継承 コード削減 演算 計算式が使用可能 動的な値設定 SCSS vs Sass記法 # 記法 拡張子 特徴 SCSS .scss CSSと互換性あり（中括弧使用） Sass .sass インデントベース（中括弧なし） 現在はSCSS記法が主流です。\n2.2 CSSとSCSSの比較 # CSS（従来） # /* 従来のCSS：セレクタが長くなりがち */ .navbar { background-color: #333; } .navbar ul { list-style: none; } .navbar ul li { display: inline-block; } .navbar ul li a { color: white; padding: 10px; } .navbar ul li a:hover { color: #007bff; } SCSS（Sass） # /* SCSS：ネストで構造が明確 */ $primary-color: #007bff; $dark-bg: #333; .navbar { background-color: $dark-bg; ul { list-style: none; li { display: inline-block; a { color: white; padding: 10px; \u0026amp;:hover { color: $primary-color; } } } } } 2.3 ハンズオン：Sass環境構築 # 学習用ディレクトリの作成 # # ローカルで作業ディレクトリを作成 mkdir sass-study \u0026amp;\u0026amp; cd sass-study # Dockerコンテナを起動 docker run -it --rm -v $(pwd):/work -w /work node:20 bash プロジェクト初期化とSassインストール # # コンテナ内で実行 npm init -y # Sassをインストール（Dart Sass） npm install --save-dev sass 注意：node-sassは非推奨です。公式のsass（Dart Sass）を使用してください。\n2.4 ディレクトリ構造の作成 # # ディレクトリを作成 mkdir -p src/scss dist/css 2.5 SCSSファイルの作成 # 変数とベーススタイル # # 変数ファイル cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; src/scss/_variables.scss // カラーパレット $primary-color: #007bff; $secondary-color: #6c757d; $success-color: #28a745; $danger-color: #dc3545; $dark-color: #343a40; $light-color: #f8f9fa; // フォント $font-family-base: \u0026#39;Helvetica Neue\u0026#39;, Arial, sans-serif; $font-size-base: 16px; // スペーシング $spacing-unit: 8px; EOF ミックスイン # # ミックスインファイル cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; src/scss/_mixins.scss // フレックスボックスセンタリング @mixin flex-center { display: flex; justify-content: center; align-items: center; } // ボタンスタイル @mixin button-style($bg-color, $text-color: white) { background-color: $bg-color; color: $text-color; padding: $spacing-unit * 1.5 $spacing-unit * 3; border: none; border-radius: 4px; cursor: pointer; transition: opacity 0.2s; \u0026amp;:hover { opacity: 0.9; } } // レスポンシブブレークポイント @mixin respond-to($breakpoint) { @if $breakpoint == \u0026#39;sm\u0026#39; { @media (max-width: 576px) { @content; } } @else if $breakpoint == \u0026#39;md\u0026#39; { @media (max-width: 768px) { @content; } } @else if $breakpoint == \u0026#39;lg\u0026#39; { @media (max-width: 992px) { @content; } } } EOF メインスタイル # # メインSCSSファイル cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; src/scss/style.scss // パーシャルファイルをインポート @use \u0026#39;variables\u0026#39; as *; @use \u0026#39;mixins\u0026#39; as *; // リセット * { margin: 0; padding: 0; box-sizing: border-box; } // ベーススタイル body { font-family: $font-family-base; font-size: $font-size-base; line-height: 1.6; color: $dark-color; background-color: $light-color; } // ヘッダー .header { background-color: $dark-color; padding: $spacing-unit * 2; \u0026amp;__title { color: white; font-size: $font-size-base * 1.5; } \u0026amp;__nav { margin-top: $spacing-unit; ul { list-style: none; @include flex-center; gap: $spacing-unit * 2; li a { color: $light-color; text-decoration: none; \u0026amp;:hover { color: $primary-color; } } } } } // メインコンテンツ .main { padding: $spacing-unit * 4; max-width: 1200px; margin: 0 auto; @include respond-to(\u0026#39;md\u0026#39;) { padding: $spacing-unit * 2; } } // カード .card { background-color: white; border-radius: 8px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1); padding: $spacing-unit * 3; margin-bottom: $spacing-unit * 3; \u0026amp;__title { color: $primary-color; margin-bottom: $spacing-unit * 2; } \u0026amp;__content { color: $secondary-color; } } // ボタン .btn { \u0026amp;--primary { @include button-style($primary-color); } \u0026amp;--secondary { @include button-style($secondary-color); } \u0026amp;--success { @include button-style($success-color); } \u0026amp;--danger { @include button-style($danger-color); } } EOF 2.6 Sassのコンパイル # # SCSSをCSSにコンパイル npx sass src/scss/style.scss dist/css/style.css # 生成されたCSSを確認 cat dist/css/style.css 2.7 ウォッチモード（変更監視） # # package.jsonを更新 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; package.json { \u0026#34;name\u0026#34;: \u0026#34;sass-study\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;sass\u0026#34;: \u0026#34;sass src/scss/style.scss dist/css/style.css\u0026#34;, \u0026#34;sass:watch\u0026#34;: \u0026#34;sass --watch src/scss/style.scss:dist/css/style.css\u0026#34;, \u0026#34;sass:compressed\u0026#34;: \u0026#34;sass src/scss/style.scss dist/css/style.min.css --style=compressed\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;sass\u0026#34;: \u0026#34;^1.69.0\u0026#34; } } EOF # ウォッチモードで起動（変更を自動検知） npm run sass:watch Ctrl + C で停止\n2.8 圧縮版CSSの生成 # # 圧縮版を生成（本番用） npm run sass:compressed # 圧縮版を確認 cat dist/css/style.min.css 2.9 HTMLファイルで確認 # # HTMLファイルを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; dist/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ja\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Sass Study\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/style.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;header class=\u0026#34;header\u0026#34;\u0026gt; \u0026lt;h1 class=\u0026#34;header__title\u0026#34;\u0026gt;Sass Study\u0026lt;/h1\u0026gt; \u0026lt;nav class=\u0026#34;header__nav\u0026#34;\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;About\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Contact\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;main class=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;card\u0026#34;\u0026gt; \u0026lt;h2 class=\u0026#34;card__title\u0026#34;\u0026gt;Sassの特徴\u0026lt;/h2\u0026gt; \u0026lt;p class=\u0026#34;card__content\u0026#34;\u0026gt; ネスト、変数、ミックスインなどの機能でCSSの開発効率が向上します。 \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;card\u0026#34;\u0026gt; \u0026lt;h2 class=\u0026#34;card__title\u0026#34;\u0026gt;ボタンサンプル\u0026lt;/h2\u0026gt; \u0026lt;div class=\u0026#34;card__content\u0026#34;\u0026gt; \u0026lt;button class=\u0026#34;btn btn--primary\u0026#34;\u0026gt;Primary\u0026lt;/button\u0026gt; \u0026lt;button class=\u0026#34;btn btn--secondary\u0026#34;\u0026gt;Secondary\u0026lt;/button\u0026gt; \u0026lt;button class=\u0026#34;btn btn--success\u0026#34;\u0026gt;Success\u0026lt;/button\u0026gt; \u0026lt;button class=\u0026#34;btn btn--danger\u0026#34;\u0026gt;Danger\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; EOF 2.10 コンテナ終了 # exit ✅ このセクションで学んだこと # SassはCSSを拡張したメタ言語（ネスト、変数、ミックスインなど） SCSS記法（.scss）が現在の主流 npx sass \u0026lt;input\u0026gt; \u0026lt;output\u0026gt;でコンパイル、--watchで変更監視 --style=compressedで本番用の圧縮版CSSを生成 Section 3: nvm / nodenv（Node.jsバージョン管理） # 💡 Docker環境では不要：このシリーズで学んでいるDocker環境では、node:18、node:20などイメージを変えるだけでバージョンを切り替えられるため、nvm/nodenvのインストールは不要です。このセクションはローカル環境を構築する場合の参考情報として記載しています。\n3.1 なぜバージョン管理が必要？ # 状況 問題 プロジェクトAはNode.js 18が必要 グローバルのNode.jsは1つだけ プロジェクトBはNode.js 20が必要 切り替えが手動で面倒 古いプロジェクトのメンテナンス 古いバージョンが必要 解決策：バージョン管理ツール # ツール 特徴 nvm 最も普及、シェルスクリプトベース nodenv rbenv系、.node-versionファイル volta Rustベース、高速 fnm Rustベース、クロスプラットフォーム 3.2 Docker環境でのバージョン管理 # Dockerではイメージを変えるだけでNode.jsバージョンを切り替えられます。\n# Node.js 18 docker run -it --rm node:18 node -v # 出力: v18.x.x # Node.js 20 docker run -it --rm node:20 node -v # 出力: v20.x.x # Node.js 22 docker run -it --rm node:22 node -v # 出力: v22.x.x メリット：nvm/nodenvをインストールする必要がない\n3.3 ハンズオン：nvm（ローカル環境向け） # 注意：以下はローカルマシン（Mac/Linux）での手順です。Docker内では通常不要です。\nnvmのインストール # 注意：以下のバージョン（v0.40.1）は執筆時点のものです。最新バージョンはnvm公式リポジトリで確認してください。\n# nvmをインストール（最新バージョンは公式リポジトリを確認） curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.1/install.sh | bash # シェル設定を再読み込み source ~/.bashrc # または ~/.zshrc # インストール確認 nvm --version Node.jsバージョンの管理 # # インストール可能なバージョン一覧 nvm ls-remote # LTS版をインストール nvm install --lts # 特定バージョンをインストール nvm install 18.19.0 nvm install 20.10.0 # インストール済みバージョン一覧 nvm ls # バージョンを切り替え（現在のターミナルのみ） nvm use 18.19.0 # デフォルトバージョンを設定（永続化） nvm alias default 20.10.0 .nvmrcファイル # # プロジェクトにバージョンを固定 echo \u0026#34;20.10.0\u0026#34; \u0026gt; .nvmrc # .nvmrcのバージョンを使用 nvm use 3.4 ハンズオン：nodenv（ローカル環境向け） # nodenvのインストール # # nodenvをクローン git clone https://github.com/nodenv/nodenv.git ~/.nodenv # node-buildプラグインをインストール git clone https://github.com/nodenv/node-build.git ~/.nodenv/plugins/node-build # パスを通す（~/.bashrcまたは~/.zshrcに追加） echo \u0026#39;export PATH=\u0026#34;$HOME/.nodenv/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;eval \u0026#34;$(nodenv init -)\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bashrc # 再読み込み source ~/.bashrc # 確認 nodenv --version Node.jsバージョンの管理 # # インストール可能なバージョン一覧 nodenv install -l # 特定バージョンをインストール nodenv install 20.10.0 # グローバルバージョンを設定 nodenv global 20.10.0 # プロジェクトごとのバージョン設定（.node-versionファイル作成） nodenv local 18.19.0 # インストール済みバージョン一覧 nodenv versions # 現在のバージョン確認 nodenv version node -v 3.5 nvmとnodenvの比較 # 項目 nvm nodenv 設定ファイル .nvmrc .node-version 切り替え方法 nvm use 自動（ディレクトリ移動時） シェル統合 手動でnvm useが必要 自動切り替え プラットフォーム Mac/Linux（Windowsはnvm-windows） Mac/Linux 3.6 Docker環境での実践例 # # プロジェクトごとに異なるNode.jsバージョンを使用 # プロジェクトA（Node.js 18） cd project-a docker run -it --rm -v $(pwd):/work -w /work node:18 bash # プロジェクトB（Node.js 20） cd project-b docker run -it --rm -v $(pwd):/work -w /work node:20 bash # プロジェクトC（Node.js 22） cd project-c docker run -it --rm -v $(pwd):/work -w /work node:22 bash 3.7 docker-compose.ymlでのバージョン指定 # # プロジェクトルートにdocker-compose.ymlを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; docker-compose.yml services: app: image: node:20 # ここでバージョンを指定 volumes: - .:/work working_dir: /work command: bash tty: true stdin_open: true ports: - \u0026#34;3000:3000\u0026#34; EOF # 起動 docker compose up -d # コンテナに入る docker compose exec app bash # 終了 docker compose down ✅ このセクションで学んだこと # nvm/nodenvはローカル環境でNode.jsバージョンを管理するツール Docker環境ではイメージ指定（node:18、node:20など）で代替可能 .nvmrcや.node-versionでプロジェクトごとにバージョンを固定 docker-compose.ymlでチーム全体のNode.jsバージョンを統一できる まとめ # 🎯 学んだこと # yarn # コマンド 用途 yarn init -y プロジェクト初期化 yarn add \u0026lt;pkg\u0026gt; パッケージ追加 yarn add --dev \u0026lt;pkg\u0026gt; 開発用パッケージ追加 yarn remove \u0026lt;pkg\u0026gt; パッケージ削除 yarn 依存関係インストール yarn \u0026lt;script\u0026gt; スクリプト実行 Sass # コマンド 用途 npx sass \u0026lt;input\u0026gt; \u0026lt;output\u0026gt; コンパイル npx sass --watch \u0026lt;input\u0026gt;:\u0026lt;output\u0026gt; 監視モード npx sass \u0026lt;input\u0026gt; \u0026lt;output\u0026gt; --style=compressed 圧縮版生成 nvm/nodenv（ローカル環境） # コマンド (nvm) コマンド (nodenv) 用途 nvm install \u0026lt;ver\u0026gt; nodenv install \u0026lt;ver\u0026gt; バージョンインストール nvm use \u0026lt;ver\u0026gt; nodenv local \u0026lt;ver\u0026gt; バージョン切り替え nvm alias default \u0026lt;ver\u0026gt; nodenv global \u0026lt;ver\u0026gt; デフォルト設定 nvm ls nodenv versions 一覧表示 Docker（推奨） # 方法 用途 docker run node:18 Node.js 18を使用 docker run node:20 Node.js 20を使用 docker-compose.ymlでimage指定 プロジェクト設定として管理 📚 シリーズ全体の振り返り # Part 内容 Part 1 Docker環境構築、Node.js/npm基礎 Part 2 Babel、Webpack、Vite（ビルドツール） Part 3 ESLint、Prettier（コード品質） Part 4 yarn、Sass、nvm/nodenv（その他ツール） 🗑️ クリーンアップ # # すべての学習ディレクトリを削除 rm -rf yarn-study sass-study 参考資料 # yarn公式ドキュメント Sass公式ドキュメント nvm公式リポジトリ nodenv公式リポジトリ ","date":"2025年 11月 30日","externalUrl":null,"permalink":"/posts/251130070710_docker-environment-nodejs-miscellaneous-tools/","section":"Posts","summary":"","title":"Docker環境でNode.jsを学ぼう_Part4_その他ツール編","type":"posts"},{"content":"","date":"2025年 11月 30日","externalUrl":null,"permalink":"/tags/sass/","section":"Tags","summary":"","title":"Sass","type":"tags"},{"content":"","date":"2025年 11月 30日","externalUrl":null,"permalink":"/tags/yarn/","section":"Tags","summary":"","title":"Yarn","type":"tags"},{"content":" はじめに # 🎯 このメモで理解すべき3つの要点 # ESLint：静的コード解析ツール\nコードの問題点（バグの可能性、非推奨の書き方）を検出 プロジェクト全体でコーディングルールを統一 Prettier：コードフォーマッター\nコードの見た目（インデント、改行、引用符など）を自動整形 チーム内でコードスタイルを統一 ESLintとPrettierの違いと併用\nESLint = 品質・バグ検出 Prettier = 見た目の整形 両者は競合する部分があるため、設定で調整が必要 ⚠️ よくある初心者の間違い # ❌ ESLintとPrettierの役割を混同している ❌ 両方を入れたら設定が競合してエラーになる ❌ ルールが厳しすぎて開発効率が落ちる 🔄 ESLintとPrettierの関係 # 【コード品質の2つの側面】 ESLint（静的解析） ├── バグの可能性を検出 ├── 未使用変数の警告 ├── 危険なパターンの検出 └── コーディング規約の強制 Prettier（フォーマット） ├── インデントの統一 ├── 引用符の統一（シングル/ダブル） ├── 改行位置の調整 └── 行末のセミコロン 前提条件 # Part 1 を完了していること（Docker基礎、Node.js/npm基礎） Docker Desktopがインストールされていること Section 1: ESLint（静的コード解析） # 1.1 ESLintとは？ # ESLintは、JavaScriptの静的コード解析ツールです。\nESLintができること # 機能 説明 例 エラー検出 バグになりそうなコードを検出 未定義変数の使用 警告表示 非推奨の書き方を指摘 varの使用 スタイル統一 コーディングルールの強制 セミコロンの有無 自動修正 一部の問題を自動で修正 --fixオプション 検出できる問題の例 # // ❌ 未使用の変数 const unusedVar = \u0026#39;not used\u0026#39;; // ❌ 未定義の変数を使用 console.log(undefinedVar); // ❌ 比較演算子の間違い if (value = 10) { } // 代入になっている // ❌ 到達不能コード function test() { return; console.log(\u0026#39;never executed\u0026#39;); } 1.2 ハンズオン：ESLint環境構築 # 学習用ディレクトリの作成 # # ローカルで作業ディレクトリを作成 mkdir eslint-study \u0026amp;\u0026amp; cd eslint-study # Dockerコンテナを起動 docker run -it --rm -v $(pwd):/work -w /work node:20 bash プロジェクト初期化とESLintインストール # # コンテナ内で実行 npm init -y # ESLintをインストール npm install --save-dev eslint 1.3 ESLintの初期設定 # # 対話形式で設定ファイルを作成 npm init @eslint/config 注意：ESLint v9からは「Flat Config」がデフォルトになり、設定ファイル形式がeslint.config.mjsに変わりました。バージョンによって対話形式の選択肢や生成される設定ファイルが異なる場合があります。以下はESLint v9での例です。\n対話形式での選択（推奨設定） # ? How would you like to use ESLint? → To check syntax and find problems ? What type of modules does your project use? → JavaScript modules (import/export) ? Which framework does your project use? → None of these ? Does your project use TypeScript? → No ? Where does your code run? → Node（スペースキーで選択、Enterで確定） ? What format do you want your config file to be in? → JavaScript 生成される設定ファイル（eslint.config.mjs） # import globals from \u0026#34;globals\u0026#34;; import pluginJs from \u0026#34;@eslint/js\u0026#34;; export default [ { languageOptions: { globals: globals.node } }, pluginJs.configs.recommended, ]; 1.4 ESLintを試してみる # 問題のあるコードを作成 # # 問題のあるコードを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; sample.js // 問題のあるコード例 // 1. 未使用の変数 const unusedVariable = \u0026#39;I am not used\u0026#39;; // 2. varの使用（letやconstが推奨） var oldStyle = \u0026#39;using var\u0026#39;; // 3. セミコロンなし（設定によってはエラー） const noSemicolon = \u0026#39;no semicolon\u0026#39; // 4. console.logの使用（本番では非推奨の場合も） console.log(\u0026#39;Hello, ESLint!\u0026#39;); // 5. 未定義変数の使用 console.log(undefinedVar); // 6. 関数 function greet(name) { return \u0026#39;Hello, \u0026#39; + name; } // 7. 関数を呼び出し const result = greet(\u0026#39;World\u0026#39;); console.log(result); EOF ESLintを実行 # # ESLintでチェック npx eslint sample.js 期待される出力（エラー・警告） # /work/sample.js 5:7 error \u0026#39;unusedVariable\u0026#39; is assigned a value but never used no-unused-vars 8:1 error Unexpected var, use let or const instead no-var 17:13 error \u0026#39;undefinedVar\u0026#39; is not defined no-undef ✖ 3 problems (3 errors, 0 warnings) 1 error and 0 warnings potentially fixable with the `--fix` option. 1.5 自動修正を試す # # 自動修正可能な問題を修正 npx eslint sample.js --fix # 修正後のコードを確認 cat sample.js 注意：すべての問題が自動修正されるわけではありません。\n1.6 ESLintルールのカスタマイズ # # 設定ファイルを更新 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; eslint.config.mjs import globals from \u0026#34;globals\u0026#34;; import pluginJs from \u0026#34;@eslint/js\u0026#34;; export default [ { languageOptions: { globals: globals.node } }, pluginJs.configs.recommended, { rules: { // 未使用変数を警告に変更（エラー→警告） \u0026#34;no-unused-vars\u0026#34;: \u0026#34;warn\u0026#34;, // console.logを許可 \u0026#34;no-console\u0026#34;: \u0026#34;off\u0026#34;, // varを禁止してlet/constを強制 \u0026#34;no-var\u0026#34;: \u0026#34;error\u0026#34;, // セミコロンを必須に \u0026#34;semi\u0026#34;: [\u0026#34;error\u0026#34;, \u0026#34;always\u0026#34;], // シングルクォートを強制 \u0026#34;quotes\u0026#34;: [\u0026#34;error\u0026#34;, \u0026#34;single\u0026#34;] } } ]; EOF # 再度チェック npx eslint sample.js ルールの設定値 # 値 意味 \u0026quot;off\u0026quot; または 0 ルールを無効化 \u0026quot;warn\u0026quot; または 1 警告として表示 \u0026quot;error\u0026quot; または 2 エラーとして表示 1.7 package.jsonにスクリプトを追加 # # package.jsonを更新 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; package.json { \u0026#34;name\u0026#34;: \u0026#34;eslint-study\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;module\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;lint\u0026#34;: \u0026#34;eslint .\u0026#34;, \u0026#34;lint:fix\u0026#34;: \u0026#34;eslint . --fix\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@eslint/js\u0026#34;: \u0026#34;^9.0.0\u0026#34;, \u0026#34;eslint\u0026#34;: \u0026#34;^9.0.0\u0026#34;, \u0026#34;globals\u0026#34;: \u0026#34;^15.0.0\u0026#34; } } EOF # スクリプトで実行 npm run lint 1.8 特定ファイルを除外 # # .eslintignoreファイルを作成（または設定ファイルで指定） cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; .eslintignore node_modules/ dist/ build/ *.min.js EOF 1.9 コンテナ終了 # exit ✅ このセクションで学んだこと # ESLintはコードの問題点（バグの可能性、非推奨の書き方）を検出する静的解析ツール ルールは\u0026quot;off\u0026quot;/\u0026quot;warn\u0026quot;/\u0026quot;error\u0026quot;で制御可能 --fixオプションで自動修正可能な問題を修正できる .eslintignoreで除外ファイルを指定 Section 2: Prettier（コードフォーマッター） # 2.1 Prettierとは？ # Prettierは、コードを自動整形するフォーマッターです。\nESLintとPrettierの違い # 観点 ESLint Prettier 主な目的 コード品質・バグ検出 コードスタイル統一 対象 主にJavaScript/TypeScript JS, CSS, HTML, JSON, Markdownなど 設定 細かいルール設定が可能 設定項目は少ない（意見付きツール） 哲学 柔軟性重視 議論を減らす（opinionated） Prettierが整形する内容 # // 整形前（バラバラなスタイル） const foo={a:1,b:2,c:3}; function bar( x,y ){return x+y} const arr = [1,2,3,4,5] // 整形後（統一されたスタイル） const foo = { a: 1, b: 2, c: 3 }; function bar(x, y) { return x + y; } const arr = [1, 2, 3, 4, 5]; 2.2 ハンズオン：Prettier環境構築 # 学習用ディレクトリの作成 # # ローカルで作業ディレクトリを作成 mkdir prettier-study \u0026amp;\u0026amp; cd prettier-study # Dockerコンテナを起動 docker run -it --rm -v $(pwd):/work -w /work node:20 bash プロジェクト初期化とPrettierインストール # # コンテナ内で実行 npm init -y # Prettierをインストール（バージョン固定推奨） npm install --save-dev --save-exact prettier --save-exactの理由：Prettierのバージョンが変わると整形結果が変わる可能性があるため、チーム内でバージョンを固定します。\n2.3 Prettierを試してみる # 整形前のコードを作成 # # 整形前のコードを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; sample.js // 整形前のコード（わざと汚く書く） const user={name:\u0026#34;Alice\u0026#34;,age:25,email:\u0026#34;alice@example.com\u0026#34;}; function greet(name){console.log(\u0026#34;Hello, \u0026#34;+name+\u0026#34;!\u0026#34;);} const numbers=[1,2,3,4,5]; const doubled=numbers.map(n=\u0026gt;n*2); if(user.age\u0026gt;=18){console.log(\u0026#34;Adult\u0026#34;)}else{console.log(\u0026#34;Minor\u0026#34;)} EOF # 内容確認 cat sample.js Prettierでチェック（整形せずに確認） # # 整形が必要かチェック npx prettier --check sample.js 期待される出力 # Checking formatting... [warn] sample.js [warn] Code style issues found in the above file. Run Prettier with --write to fix. Prettierで整形 # # 整形を実行 npx prettier --write sample.js # 整形後のコードを確認 cat sample.js 期待される出力（整形後） # // 整形前のコード（わざと汚く書く） const user = { name: \u0026#34;Alice\u0026#34;, age: 25, email: \u0026#34;alice@example.com\u0026#34; }; function greet(name) { console.log(\u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34;); } const numbers = [1, 2, 3, 4, 5]; const doubled = numbers.map((n) =\u0026gt; n * 2); if (user.age \u0026gt;= 18) { console.log(\u0026#34;Adult\u0026#34;); } else { console.log(\u0026#34;Minor\u0026#34;); } 2.4 Prettier設定ファイルの作成 # # .prettierrcファイルを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; .prettierrc { \u0026#34;semi\u0026#34;: true, \u0026#34;singleQuote\u0026#34;: true, \u0026#34;tabWidth\u0026#34;: 2, \u0026#34;trailingComma\u0026#34;: \u0026#34;es5\u0026#34;, \u0026#34;printWidth\u0026#34;: 80, \u0026#34;bracketSpacing\u0026#34;: true, \u0026#34;arrowParens\u0026#34;: \u0026#34;always\u0026#34; } EOF 設定項目の説明 # 項目 説明 デフォルト 設定例 semi セミコロンを付けるか true true singleQuote シングルクォートを使うか false true tabWidth タブの幅 2 2 trailingComma 末尾カンマ \u0026quot;all\u0026quot; \u0026quot;es5\u0026quot; printWidth 1行の最大文字数 80 80 bracketSpacing オブジェクトの括弧内スペース true true arrowParens アロー関数の括弧 \u0026quot;always\u0026quot; \u0026quot;always\u0026quot; 2.5 設定を反映して再整形 # # 設定を反映して再整形 npx prettier --write sample.js # 結果を確認（シングルクォートに変わる） cat sample.js 期待される出力 # // 整形前のコード（わざと汚く書く） const user = { name: \u0026#39;Alice\u0026#39;, age: 25, email: \u0026#39;alice@example.com\u0026#39; }; function greet(name) { console.log(\u0026#39;Hello, \u0026#39; + name + \u0026#39;!\u0026#39;); } const numbers = [1, 2, 3, 4, 5]; const doubled = numbers.map((n) =\u0026gt; n * 2); if (user.age \u0026gt;= 18) { console.log(\u0026#39;Adult\u0026#39;); } else { console.log(\u0026#39;Minor\u0026#39;); } 2.6 複数ファイルの整形 # # 複数のファイルを作成 mkdir src cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; src/utils.js const add=(a,b)=\u0026gt;a+b; const subtract=(a,b)=\u0026gt;a-b; module.exports={add,subtract}; EOF cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; src/index.js const {add,subtract}=require(\u0026#39;./utils\u0026#39;); console.log(add(5,3)); console.log(subtract(10,4)); EOF # srcディレクトリ内のすべてのJSファイルを整形 npx prettier --write \u0026#34;src/**/*.js\u0026#34; 2.7 除外ファイルの設定 # # .prettierignoreファイルを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; .prettierignore node_modules/ dist/ build/ *.min.js package-lock.json EOF 2.8 package.jsonにスクリプトを追加 # # package.jsonを更新 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; package.json { \u0026#34;name\u0026#34;: \u0026#34;prettier-study\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;format\u0026#34;: \u0026#34;prettier --write .\u0026#34;, \u0026#34;format:check\u0026#34;: \u0026#34;prettier --check .\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;prettier\u0026#34;: \u0026#34;3.3.0\u0026#34; } } EOF # スクリプトで実行 npm run format:check npm run format 2.9 コンテナ終了 # exit ✅ このセクションで学んだこと # Prettierはコードの見た目（インデント、引用符、改行など）を自動整形するフォーマッター .prettierrcで整形ルールを設定（singleQuote、semiなど） --checkでチェックのみ、--writeで整形を実行 --save-exactでバージョンを固定してチーム内で整形結果を統一 Section 3: ESLintとPrettierの併用 # 3.1 なぜ併用するのか？ # ツール 役割 ESLint コードの品質チェック（バグ検出） Prettier コードの見た目を整形 両方使うことで：品質の高い、見た目も統一されたコードになります。\n3.2 競合の問題 # ESLintとPrettierにはスタイルに関するルールが重複しています。\n【競合の例】 ESLint: \u0026#34;セミコロンは必須！\u0026#34; Prettier: \u0026#34;セミコロンなしで整形しました\u0026#34; → 矛盾が発生 3.3 ハンズオン：ESLint + Prettier # 学習用ディレクトリの作成 # # ローカルで作業ディレクトリを作成 mkdir eslint-prettier-study \u0026amp;\u0026amp; cd eslint-prettier-study # Dockerコンテナを起動 docker run -it --rm -v $(pwd):/work -w /work node:20 bash 必要なパッケージをインストール # # コンテナ内で実行 npm init -y # ESLintとPrettierをインストール npm install --save-dev eslint prettier # 競合を解決するパッケージ npm install --save-dev eslint-config-prettier パッケージの説明 # パッケージ 役割 eslint 静的コード解析 prettier コードフォーマッター eslint-config-prettier ESLintのスタイルルールを無効化（Prettierと競合しないように） 3.4 設定ファイルの作成 # ESLint設定 # # eslint.config.mjsを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; eslint.config.mjs import globals from \u0026#34;globals\u0026#34;; import pluginJs from \u0026#34;@eslint/js\u0026#34;; import eslintConfigPrettier from \u0026#34;eslint-config-prettier\u0026#34;; export default [ { languageOptions: { globals: globals.node } }, pluginJs.configs.recommended, // Prettierと競合するルールを無効化（最後に配置） eslintConfigPrettier, { rules: { \u0026#34;no-unused-vars\u0026#34;: \u0026#34;warn\u0026#34;, \u0026#34;no-console\u0026#34;: \u0026#34;off\u0026#34; } } ]; EOF 重要：eslintConfigPrettierは最後に配置して、競合するルールを上書きします。\nPrettier設定 # # .prettierrcを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; .prettierrc { \u0026#34;semi\u0026#34;: true, \u0026#34;singleQuote\u0026#34;: true, \u0026#34;tabWidth\u0026#34;: 2, \u0026#34;trailingComma\u0026#34;: \u0026#34;es5\u0026#34; } EOF 3.5 テストコードの作成と実行 # # 問題のあるコードを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; sample.js // 問題のあるコード const unusedVar=\u0026#34;not used\u0026#34;; const user={name:\u0026#34;Alice\u0026#34;,age:25}; function greet(name){console.log(\u0026#34;Hello, \u0026#34;+name)} console.log(undefinedVar); EOF # ESLintでチェック（品質の問題を検出） npx eslint sample.js 期待される出力 # /work/sample.js 2:7 warning \u0026#39;unusedVar\u0026#39; is assigned a value but never used no-unused-vars 5:13 error \u0026#39;undefinedVar\u0026#39; is not defined no-undef ✖ 2 problems (1 error, 1 warning) # Prettierで整形（見た目を統一） npx prettier --write sample.js # 整形後のコードを確認 cat sample.js 整形後のコード # // 問題のあるコード const unusedVar = \u0026#39;not used\u0026#39;; const user = { name: \u0026#39;Alice\u0026#39;, age: 25 }; function greet(name) { console.log(\u0026#39;Hello, \u0026#39; + name); } console.log(undefinedVar); 3.6 package.jsonにスクリプトを追加 # # package.jsonを更新 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; package.json { \u0026#34;name\u0026#34;: \u0026#34;eslint-prettier-study\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;module\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;lint\u0026#34;: \u0026#34;eslint .\u0026#34;, \u0026#34;lint:fix\u0026#34;: \u0026#34;eslint . --fix\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;prettier --write .\u0026#34;, \u0026#34;format:check\u0026#34;: \u0026#34;prettier --check .\u0026#34;, \u0026#34;check\u0026#34;: \u0026#34;npm run lint \u0026amp;\u0026amp; npm run format:check\u0026#34;, \u0026#34;fix\u0026#34;: \u0026#34;npm run lint:fix \u0026amp;\u0026amp; npm run format\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@eslint/js\u0026#34;: \u0026#34;^9.0.0\u0026#34;, \u0026#34;eslint\u0026#34;: \u0026#34;^9.0.0\u0026#34;, \u0026#34;eslint-config-prettier\u0026#34;: \u0026#34;^9.0.0\u0026#34;, \u0026#34;globals\u0026#34;: \u0026#34;^15.0.0\u0026#34;, \u0026#34;prettier\u0026#34;: \u0026#34;^3.0.0\u0026#34; } } EOF スクリプトの使い分け # スクリプト 用途 npm run lint ESLintでチェック npm run format:check Prettierでチェック npm run check 両方でチェック npm run fix 両方で自動修正 3.7 推奨ワークフロー # # 1. コードを書く # 2. 保存時に自動整形（エディタ設定推奨） # 3. コミット前にチェック npm run check # 4. 問題があれば修正 npm run fix 3.8 コンテナ終了 # exit ✅ このセクションで学んだこと # ESLint（品質チェック）とPrettier（整形）は役割が異なるため併用が効果的 eslint-config-prettierでESLintのスタイルルールを無効化し競合を防止 設定ファイルでeslintConfigPrettierは最後に配置する npm run checkでチェック、npm run fixで自動修正のワークフローを構築 Section 4: VSCode連携（補足） # 4.1 推奨拡張機能 # 拡張機能 機能 ESLint ESLintの結果をエディタに表示 Prettier 保存時に自動整形 4.2 settings.jsonの設定例 # { \u0026#34;editor.formatOnSave\u0026#34;: true, \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;esbenp.prettier-vscode\u0026#34;, \u0026#34;editor.codeActionsOnSave\u0026#34;: { \u0026#34;source.fixAll.eslint\u0026#34;: true }, \u0026#34;[javascript]\u0026#34;: { \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;esbenp.prettier-vscode\u0026#34; } } 4.3 Dev Containers（VSCode + Docker） # VSCodeのDev Containers拡張機能を使えば、Docker環境でもVSCodeの機能をフル活用できます。\nまとめ # 🎯 学んだこと # ESLint # コマンド 用途 npx eslint \u0026lt;file\u0026gt; ファイルをチェック npx eslint . 全ファイルをチェック npx eslint . --fix 自動修正 Prettier # コマンド 用途 npx prettier --check \u0026lt;file\u0026gt; 整形が必要かチェック npx prettier --write \u0026lt;file\u0026gt; 整形を実行 npx prettier --write . 全ファイルを整形 併用時の設定 # ファイル 役割 eslint.config.mjs ESLint設定 + eslint-config-prettier .prettierrc Prettier設定 .eslintignore ESLint除外ファイル .prettierignore Prettier除外ファイル 📚 次のステップ # Part 4: その他ツール編（yarn、Sass、nvm/nodenv） 🗑️ クリーンアップ # # 学習ディレクトリを削除 rm -rf eslint-study prettier-study eslint-prettier-study 参考資料 # ESLint公式ドキュメント Prettier公式ドキュメント eslint-config-prettier ","date":"2025年 11月 30日","externalUrl":null,"permalink":"/posts/251130070546_docker-environment-nodejs-code-quality-tools/","section":"Posts","summary":"","title":"Docker環境でNode.jsを学ぼう_Part3_コード品質ツール編","type":"posts"},{"content":"","date":"2025年 11月 30日","externalUrl":null,"permalink":"/tags/eslint/","section":"Tags","summary":"","title":"ESLint","type":"tags"},{"content":"","date":"2025年 11月 30日","externalUrl":null,"permalink":"/tags/prettier/","section":"Tags","summary":"","title":"Prettier","type":"tags"},{"content":"","date":"2025年 11月 30日","externalUrl":null,"permalink":"/tags/babel/","section":"Tags","summary":"","title":"Babel","type":"tags"},{"content":" はじめに # 🎯 このメモで理解すべき3つの要点 # Babel：JavaScriptトランスパイラ\n最新のJavaScript（ES2015+）を古いブラウザでも動くコードに変換 プリセットで変換ルールを管理 Webpack：モジュールバンドラー\n複数のファイル（JS、CSS、画像）を1つにまとめる ローダーで様々なファイル形式に対応 Vite：次世代ビルドツール\nWebpackより高速な開発サーバー ESModulesを活用したモダンな設計 ⚠️ よくある初心者の間違い # ❌ Babelの設定ファイル（.babelrc）を作り忘れてトランスパイルが動かない ❌ Webpackのローダーの処理順序（右から左）を理解していない ❌ 開発用（dev）と本番用（build）の違いを意識していない 🔄 ツールの関係性 # 【開発時の流れ】 ES2015+ JavaScript ↓ [Babel] トランスパイル（変換） ↓ ES5 JavaScript（古いブラウザ対応） ↓ [Webpack/Vite] バンドル（まとめる） ↓ bundle.js（本番用ファイル） 前提条件 # Part 1 を完了していること（Docker基礎、Node.js/npm基礎） Docker Desktopがインストールされていること Section 1: Babel（トランスパイラ） # 1.1 Babelとは？ # Babelは、JavaScriptのトランスパイラ（変換ツール）です。\nなぜBabelが必要？ # // ES2015+（モダンな書き方） const greet = (name) =\u0026gt; `Hello, ${name}!`; const numbers = [1, 2, 3]; const doubled = numbers.map(n =\u0026gt; n * 2); // ES5（古いブラウザ対応）に変換後 var greet = function(name) { return \u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34;; }; var numbers = [1, 2, 3]; var doubled = numbers.map(function(n) { return n * 2; }); 主な用途 # 用途 説明 ブラウザ互換性 古いブラウザでも最新構文を使用可能に React JSX JSX構文を通常のJavaScriptに変換 TypeScript TypeScriptからJavaScriptへの変換（※） ※TypeScript変換の注意点：Babelでの変換はトランスパイル（構文変換）のみで、型チェックは行われません。型チェックが必要な場合はtsc（TypeScriptコンパイラ）と併用するか、tsc単体での変換を検討してください。\n1.2 ハンズオン：Babel環境構築 # 学習用ディレクトリの作成 # # ローカルで作業ディレクトリを作成 mkdir babel-study \u0026amp;\u0026amp; cd babel-study # Dockerコンテナを起動 docker run -it --rm -v $(pwd):/work -w /work node:20 bash プロジェクト初期化とBabelインストール # # コンテナ内で実行 npm init -y # Babel関連パッケージをインストール npm install --save-dev @babel/cli @babel/core @babel/preset-env パッケージの説明 # パッケージ 役割 @babel/core Babel本体（変換エンジン） @babel/cli コマンドラインツール @babel/preset-env 環境に応じた変換ルールセット 1.3 Babel設定ファイルの作成 # # .babelrcファイルを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; .babelrc { \u0026#34;presets\u0026#34;: [\u0026#34;@babel/preset-env\u0026#34;] } EOF プリセット（preset）とは？ # 変換に必要なプラグインの集合体です。\nプリセット 用途 @babel/preset-env 最新JS→ターゲット環境対応JS @babel/preset-react JSX→JavaScript変換 @babel/preset-typescript TypeScript→JavaScript変換 1.4 トランスパイルの実行 # ソースファイルの作成 # # ディレクトリ構造を作成 mkdir src dist # ES2015+のコードを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; src/app.js // アロー関数 const greet = (name) =\u0026gt; { console.log(`Hello, ${name}!`); }; // テンプレートリテラル const message = `Current time: ${new Date().toLocaleString()}`; // 分割代入 const user = { name: \u0026#39;Alice\u0026#39;, age: 25 }; const { name, age } = user; // スプレッド構文 const numbers = [1, 2, 3]; const moreNumbers = [...numbers, 4, 5]; // クラス構文 class Animal { constructor(name) { this.name = name; } speak() { console.log(`${this.name} makes a sound.`); } } // 実行 greet(\u0026#39;World\u0026#39;); console.log(message); console.log(`User: ${name}, Age: ${age}`); console.log(\u0026#39;Numbers:\u0026#39;, moreNumbers); const dog = new Animal(\u0026#39;Dog\u0026#39;); dog.speak(); EOF トランスパイル実行 # # Babelでトランスパイル npx babel src/app.js -o dist/app.js # 結果を確認 cat dist/app.js 期待される出力（ES5に変換済み） # \u0026#34;use strict\u0026#34;; function _typeof(o) { /* ... */ } function _classCallCheck(a, n) { /* ... */ } function _defineProperties(e, r) { /* ... */ } function _createClass(e, r, t) { /* ... */ } function _toConsumableArray(r) { /* ... */ } var greet = function greet(name) { console.log(\u0026#34;Hello, \u0026#34;.concat(name, \u0026#34;!\u0026#34;)); }; var message = \u0026#34;Current time: \u0026#34;.concat(new Date().toLocaleString()); // ... 以下略 1.5 package.jsonにスクリプトを追加 # # package.jsonを更新 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; package.json { \u0026#34;name\u0026#34;: \u0026#34;babel-study\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;build\u0026#34;: \u0026#34;babel src -d dist\u0026#34;, \u0026#34;watch\u0026#34;: \u0026#34;babel src -d dist --watch\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@babel/cli\u0026#34;: \u0026#34;^7.23.0\u0026#34;, \u0026#34;@babel/core\u0026#34;: \u0026#34;^7.23.0\u0026#34;, \u0026#34;@babel/preset-env\u0026#34;: \u0026#34;^7.23.0\u0026#34; } } EOF # ビルド実行 npm run build # 変換後のコードを実行 node dist/app.js 期待される出力 # Hello, World! Current time: 11/30/2025, 10:00:00 AM User: Alice, Age: 25 Numbers: [ 1, 2, 3, 4, 5 ] Dog makes a sound. 1.6 コンテナ終了と確認 # # コンテナを終了 exit # ローカルでファイル確認 ls babel-study/ # 出力: dist node_modules package-lock.json package.json src ✅ このセクションで学んだこと # Babelは最新のJavaScriptを古いブラウザ対応のコードに変換するトランスパイラ @babel/preset-envで環境に応じた変換ルールを適用 npx babel src -d distでトランスパイル、--watchで変更監視 Section 2: Webpack（モジュールバンドラー） # 2.1 Webpackとは？ # Webpackは、複数のファイルを1つにまとめるモジュールバンドラーです。\nWebpackの役割 # 【バンドル前】 src/ ├── index.js （エントリーポイント） ├── utils.js （ユーティリティ） ├── api.js （API処理） └── style.css （スタイル） 【バンドル後】 dist/ └── bundle.js （すべてまとまった1ファイル） なぜバンドルが必要？ # 理由 説明 HTTPリクエスト削減 複数ファイル→1ファイルでリクエスト数減少 依存関係解決 モジュール間の依存を自動解決 最適化 コード圧縮、不要コード削除 変換処理 ローダーでCSS、画像なども処理可能 2.2 ハンズオン：Webpack環境構築 # 学習用ディレクトリの作成 # # ローカルで作業ディレクトリを作成 mkdir webpack-study \u0026amp;\u0026amp; cd webpack-study # Dockerコンテナを起動 docker run -it --rm -v $(pwd):/work -w /work node:20 bash プロジェクト初期化とWebpackインストール # # コンテナ内で実行 npm init -y # Webpack関連パッケージをインストール npm install --save-dev webpack webpack-cli 2.3 ディレクトリ構造の作成 # # ディレクトリとファイルを作成 mkdir -p src/modules dist # モジュールファイルを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; src/modules/math.js // 数学関連の関数 export const add = (a, b) =\u0026gt; a + b; export const subtract = (a, b) =\u0026gt; a - b; export const multiply = (a, b) =\u0026gt; a * b; export const divide = (a, b) =\u0026gt; a / b; EOF cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; src/modules/greeting.js // 挨拶関連の関数 export const hello = (name) =\u0026gt; `Hello, ${name}!`; export const goodbye = (name) =\u0026gt; `Goodbye, ${name}!`; EOF # エントリーポイントを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; src/index.js // モジュールをインポート import { add, multiply } from \u0026#39;./modules/math.js\u0026#39;; import { hello, goodbye } from \u0026#39;./modules/greeting.js\u0026#39;; // 使用例 console.log(\u0026#39;=== Math Operations ===\u0026#39;); console.log(`5 + 3 = ${add(5, 3)}`); console.log(`5 * 3 = ${multiply(5, 3)}`); console.log(\u0026#39;\\n=== Greetings ===\u0026#39;); console.log(hello(\u0026#39;Webpack\u0026#39;)); console.log(goodbye(\u0026#39;Webpack\u0026#39;)); EOF # HTMLファイルを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; dist/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ja\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Webpack Study\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Webpack バンドルテスト\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;ブラウザのコンソールを確認してください\u0026lt;/p\u0026gt; \u0026lt;script src=\u0026#34;bundle.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; EOF 2.4 Webpack設定ファイルの作成 # # webpack.config.jsを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; webpack.config.js const path = require(\u0026#39;path\u0026#39;); module.exports = { // モード: development（開発）または production（本番） mode: \u0026#39;development\u0026#39;, // エントリーポイント: バンドルの開始地点 entry: \u0026#39;./src/index.js\u0026#39;, // 出力設定 output: { filename: \u0026#39;bundle.js\u0026#39;, path: path.resolve(__dirname, \u0026#39;dist\u0026#39;) } }; EOF 設定項目の解説 # 項目 説明 値 mode ビルドモード development / production entry エントリーポイント ./src/index.js output.filename 出力ファイル名 bundle.js output.path 出力ディレクトリ dist/ 2.5 バンドル実行 # # package.jsonにスクリプトを追加 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; package.json { \u0026#34;name\u0026#34;: \u0026#34;webpack-study\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;build\u0026#34;: \u0026#34;webpack\u0026#34;, \u0026#34;dev\u0026#34;: \u0026#34;webpack --mode development --watch\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;webpack\u0026#34;: \u0026#34;^5.89.0\u0026#34;, \u0026#34;webpack-cli\u0026#34;: \u0026#34;^5.1.4\u0026#34; } } EOF # ビルド実行 npm run build 期待される出力 # asset bundle.js 4.5 KiB [emitted] (name: main) runtime modules 670 bytes 3 modules cacheable modules 524 bytes ./src/index.js 389 bytes [built] [code generated] ./src/modules/math.js 178 bytes [built] [code generated] ./src/modules/greeting.js 135 bytes [built] [code generated] webpack 5.89.0 compiled successfully in 150 ms # バンドル結果をNode.jsで実行 node dist/bundle.js 期待される出力 # === Math Operations === 5 + 3 = 8 5 * 3 = 15 === Greetings === Hello, Webpack! Goodbye, Webpack! 2.6 CSSのバンドル # ローダーのインストール # # CSSローダーをインストール npm install --save-dev css-loader style-loader CSSファイルの作成 # # CSSファイルを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; src/style.css body { font-family: Arial, sans-serif; background-color: #f0f0f0; margin: 0; padding: 20px; } h1 { color: #333; border-bottom: 2px solid #007bff; padding-bottom: 10px; } p { color: #666; } EOF エントリーポイントでCSSをインポート # # index.jsを更新 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; src/index.js // CSSをインポート（Webpackが処理） import \u0026#39;./style.css\u0026#39;; // モジュールをインポート import { add, multiply } from \u0026#39;./modules/math.js\u0026#39;; import { hello, goodbye } from \u0026#39;./modules/greeting.js\u0026#39;; // 使用例 console.log(\u0026#39;=== Math Operations ===\u0026#39;); console.log(`5 + 3 = ${add(5, 3)}`); console.log(`5 * 3 = ${multiply(5, 3)}`); console.log(\u0026#39;\\n=== Greetings ===\u0026#39;); console.log(hello(\u0026#39;Webpack\u0026#39;)); console.log(goodbye(\u0026#39;Webpack\u0026#39;)); // DOM操作 document.addEventListener(\u0026#39;DOMContentLoaded\u0026#39;, () =\u0026gt; { const result = document.createElement(\u0026#39;div\u0026#39;); result.innerHTML = ` \u0026lt;h2\u0026gt;計算結果\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;5 + 3 = ${add(5, 3)}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;5 × 3 = ${multiply(5, 3)}\u0026lt;/p\u0026gt; `; document.body.appendChild(result); }); EOF Webpack設定にローダーを追加 # # webpack.config.jsを更新 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; webpack.config.js const path = require(\u0026#39;path\u0026#39;); module.exports = { mode: \u0026#39;development\u0026#39;, entry: \u0026#39;./src/index.js\u0026#39;, output: { filename: \u0026#39;bundle.js\u0026#39;, path: path.resolve(__dirname, \u0026#39;dist\u0026#39;) }, // モジュール設定（ローダー） module: { rules: [ { test: /\\.css$/, // .cssファイルを対象 use: [\u0026#39;style-loader\u0026#39;, \u0026#39;css-loader\u0026#39;] // 右から左の順で処理 } ] } }; EOF # 再ビルド npm run build ローダーの処理順序 # 【処理の流れ】 style.css ↓ css-loader（CSSをJSで扱える形式に変換） ↓ style-loader（\u0026lt;style\u0026gt;タグとしてHTMLに挿入） ↓ bundle.js に含まれる 重要：use配列は右から左の順で処理されます。\n2.7 ブラウザで確認（オプション） # # コンテナを一度終了 exit # ポート公開で再起動（簡易サーバー用） docker run -it --rm -v $(pwd):/work -w /work -p 8080:8080 node:20 bash # 簡易サーバーをインストール・起動 npm install --save-dev http-server npx http-server dist -p 8080 ブラウザで http://localhost:8080 にアクセスして確認。\n2.8 コンテナ終了 # # Ctrl + C でサーバー停止 exit ✅ このセクションで学んだこと # Webpackは複数のファイルを1つにまとめるモジュールバンドラー entryでエントリーポイント、outputで出力先を設定 ローダー（css-loader、style-loaderなど）で様々なファイル形式に対応 ローダーの処理順序はuse配列の右から左 Section 3: Vite（次世代ビルドツール） # 3.1 Viteとは？ # Vite（ヴィート：フランス語で「速い」）は、Webpackより高速なフロントエンドビルドツールです。\nViteとWebpackの違い # 項目 Webpack Vite 起動速度 遅い（全体を事前バンドル） 速い（必要な部分だけ処理） HMR やや遅い 非常に高速 設定 複雑になりがち シンプル 本番ビルド 独自バンドラー Rollup使用 Viteが高速な理由 # 【Webpack】 起動時: 全ファイルを解析 → バンドル → サーバー起動 【Vite】 起動時: サーバー起動 → リクエストに応じて必要なファイルだけ処理 3.2 ハンズオン：Viteプロジェクト作成 # 学習用ディレクトリの作成 # # ローカルで作業ディレクトリを作成 mkdir vite-study \u0026amp;\u0026amp; cd vite-study # Dockerコンテナを起動（ポート公開） docker run -it --rm -v $(pwd):/work -w /work -p 5173:5173 node:20 bash Viteプロジェクトの作成 # # コンテナ内で実行 npm create vite@latest my-vite-app 対話形式での選択 # ? Select a framework: › Vanilla ? Select a variant: › JavaScript フレームワーク選択肢：\nVanilla（素のJS） Vue React Svelte その他 3.3 プロジェクト構造の確認 # # 作成されたディレクトリに移動 cd my-vite-app # 構造を確認 ls -la 生成されるファイル構造 # my-vite-app/ ├── index.html # エントリーHTML ├── package.json # プロジェクト設定 ├── public/ # 静的ファイル │ └── vite.svg ├── src/ # ソースコード │ ├── counter.js │ ├── javascript.svg │ ├── main.js │ └── style.css └── vite.config.js # Vite設定（オプション） 3.4 依存関係のインストールと起動 # # 依存関係をインストール npm install # 開発サーバーを起動 npm run dev -- --host --hostオプション：Dockerコンテナ外からアクセス可能にする\n期待される出力 # VITE v5.x.x ready in xxx ms ➜ Local: http://localhost:5173/ ➜ Network: http://172.x.x.x:5173/ ブラウザで http://localhost:5173 にアクセス。\n3.5 HMR（Hot Module Replacement）の体験 # 開発サーバーを起動したまま、別のターミナルでファイルを編集：\n# 別のターミナルでコンテナに入る docker exec -it $(docker ps -q) bash # ファイルを編集 cd /work/my-vite-app cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; src/main.js import \u0026#39;./style.css\u0026#39; document.querySelector(\u0026#39;#app\u0026#39;).innerHTML = ` \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Hello Vite!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;ファイルを編集すると自動で反映されます\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;現在時刻: ${new Date().toLocaleString()}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ` EOF ブラウザを確認：ページをリロードせずに変更が反映されます。\n3.6 本番用ビルド # # 開発サーバーを停止（Ctrl + C）後 npm run build 期待される出力 # vite v5.x.x building for production... ✓ 2 modules transformed. dist/index.html 0.xx kB │ gzip: 0.xx kB dist/assets/index-xxxxx.css 0.xx kB │ gzip: 0.xx kB dist/assets/index-xxxxx.js 0.xx kB │ gzip: 0.xx kB ✓ built in xxxms # ビルド結果を確認 ls dist/ # 出力: assets index.html vite.svg 3.7 ビルド結果のプレビュー # # プレビューサーバーを起動 npm run preview -- --host ブラウザで http://localhost:4173 にアクセス。\n3.8 package.jsonのスクリプト確認 # cat package.json { \u0026#34;name\u0026#34;: \u0026#34;my-vite-app\u0026#34;, \u0026#34;private\u0026#34;: true, \u0026#34;version\u0026#34;: \u0026#34;0.0.0\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;module\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;dev\u0026#34;: \u0026#34;vite\u0026#34;, // 開発サーバー起動 \u0026#34;build\u0026#34;: \u0026#34;vite build\u0026#34;, // 本番用ビルド \u0026#34;preview\u0026#34;: \u0026#34;vite preview\u0026#34; // ビルド結果のプレビュー }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;vite\u0026#34;: \u0026#34;^5.0.0\u0026#34; } } 3.9 コンテナ終了 # exit ✅ このセクションで学んだこと # ViteはWebpackより高速な次世代ビルドツール ESModulesを活用し、必要なファイルだけを処理するため起動が速い npm run devで開発サーバー、npm run buildで本番ビルド HMR（Hot Module Replacement）でファイル変更が即座に反映 Section 4: ツール比較と使い分け # 4.1 各ツールの役割まとめ # ツール カテゴリ 主な役割 Babel トランスパイラ 新しいJS→古いJS変換 Webpack バンドラー 複数ファイルを1つにまとめる Vite ビルドツール 高速な開発環境 + ビルド 4.2 組み合わせパターン # 【パターン1: Webpack + Babel（従来型）】 - 大規模プロジェクト - 細かい設定が必要な場合 - レガシーブラウザ対応が必須 【パターン2: Vite（モダン型）】 - 新規プロジェクト - 高速な開発体験を重視 - モダンブラウザがターゲット 【パターン3: フレームワークのCLI】 - React: Create React App / Next.js - Vue: Vue CLI / Nuxt.js - 内部でWebpackやViteを使用 4.3 学習の優先順位 # Vite（推奨）：新規プロジェクトならこれから始める Webpack：既存プロジェクトで使われていることが多い Babel：Webpackと組み合わせて使う、または単体で学ぶ まとめ # 🎯 学んだこと # Babel # コマンド 用途 npx babel src -d dist srcをdistにトランスパイル npx babel src -d dist --watch 変更を監視して自動変換 Webpack # コマンド 用途 npx webpack バンドル実行 npx webpack --mode development 開発モードでビルド npx webpack --mode production 本番モードでビルド npx webpack --watch 変更を監視 Vite # コマンド 用途 npm create vite@latest プロジェクト作成 npm run dev 開発サーバー起動 npm run build 本番用ビルド npm run preview ビルド結果プレビュー 📚 次のステップ # Part 3: コード品質ツール編（ESLint、Prettier） Part 4: その他ツール編（yarn、Sass、nvm/nodenv） 🗑️ クリーンアップ # # 学習ディレクトリを削除 rm -rf babel-study webpack-study vite-study 参考資料 # Babel公式ドキュメント Webpack公式ドキュメント Vite公式ドキュメント ","date":"2025年 11月 30日","externalUrl":null,"permalink":"/posts/251130070132_docker-environment-nodejs-frontend-dev-tools/","section":"Posts","summary":"","title":"Docker環境でNode.jsを学ぼう_Part2_フロントエンド開発ツール編","type":"posts"},{"content":"","date":"2025年 11月 30日","externalUrl":null,"permalink":"/tags/vite/","section":"Tags","summary":"","title":"Vite","type":"tags"},{"content":"","date":"2025年 11月 30日","externalUrl":null,"permalink":"/tags/webpack/","section":"Tags","summary":"","title":"Webpack","type":"tags"},{"content":" はじめに # 🎯 このメモで理解すべき3つの要点 # Dockerによる使い捨て学習環境の構築\nローカル環境を汚さずにNode.jsを学習 docker run --rmで終了時に自動削除される環境 Node.jsの基本概念と役割\nサーバーサイドJavaScript実行環境 フロントエンド開発ツールの基盤 npmを使ったプロジェクト管理の基礎\npackage.jsonによる依存関係管理 パッケージのインストールと実行 ⚠️ よくある初心者の間違い # ❌ Dockerコンテナ内でファイルを作成したが、マウントしていないので消えてしまう ❌ コンテナをexitした後、--rmオプションでコンテナが削除されたことに気づかない ❌ node_modulesフォルダの肥大化を知らずにローカルにインストールしてしまう ✅ この学習方法のメリット # 🧹 クリーンな環境維持：ローカルPCにNode.jsをインストール不要 🔄 再現性：同じ環境を何度でも再構築可能 🗑️ 使い捨て：学習後はディレクトリ削除で完全クリーンアップ 🔒 隔離：他のプロジェクトへの影響なし 前提条件 # 必要なもの # Docker Desktopがインストールされていること ターミナル（コマンドプロンプト、PowerShell、Terminal.app等）の基本操作 Dockerのインストール確認 # # Dockerのバージョン確認 docker --version # 出力例: Docker version 24.0.7, build afdd53b # Dockerが動作しているか確認 docker run hello-world Part 1: Docker基礎（使い捨て環境の理解） # 1.1 使い捨てコンテナの基本形 # # 基本形：対話モードで起動し、終了時に自動削除 docker run -it --rm \u0026lt;イメージ名\u0026gt; bash オプションの意味 # オプション 意味 重要度 -it 対話モード（ターミナルで操作可能） ⭐⭐⭐ --rm コンテナ終了時に自動削除 ⭐⭐⭐ -v $(pwd):/work カレントディレクトリをマウント ⭐⭐⭐ -w /work 作業ディレクトリを指定 ⭐⭐ 1.2 ファイルを残すパターン # # ローカルファイルをコンテナ内にマウント docker run -it --rm -v $(pwd):/work -w /work \u0026lt;イメージ名\u0026gt; bash 重要：マウントしたディレクトリ（/work）で作成したファイルは、コンテナ終了後もローカルに残ります。\n✅ このセクションで学んだこと # docker run -it --rmで使い捨てコンテナを起動 -v $(pwd):/workでローカルディレクトリをマウント（ファイルを永続化） --rmオプションでコンテナ終了時に自動削除 Part 2: Node.js概要 # 2.1 Node.jsとは？ # Node.jsは、JavaScriptをサーバーサイドで実行するための実行環境（ランタイム）です。\nJavaScriptの実行環境の変遷 # 【従来】 JavaScript → ブラウザでのみ実行可能（クライアントサイド） 【Node.js登場後】 JavaScript → ブラウザ + サーバー + CLI + 開発ツール Node.jsの特徴 # 特徴 説明 V8エンジン Google Chromeと同じ高速JavaScriptエンジン ノンブロッキングI/O 非同期処理による高いパフォーマンス シングルスレッド イベントループによる効率的な処理 npm 世界最大のパッケージエコシステム 2.2 なぜNode.jsを学ぶのか？ # フロントエンド開発における必要性 # 現代のフロントエンド開発では、以下のツールがNode.js上で動作します：\nツール 用途 npm / yarn パッケージ管理 Webpack / Vite バンドル・ビルド Babel トランスパイル（新しいJS→古いJS変換） ESLint 静的コード解析 Prettier コードフォーマット Sass CSSプリプロセッサ バックエンド開発での活用 # フレームワーク 用途 Express WebアプリケーションAPI NestJS エンタープライズ向けフレームワーク Next.js React SSR/SSGフレームワーク ✅ このセクションで学んだこと # Node.jsはJavaScriptをサーバーサイドで実行する環境 V8エンジン、ノンブロッキングI/O、npmが主な特徴 フロントエンド開発ツール（Webpack、Babel、ESLintなど）の基盤 Part 3: ハンズオン① 最初のNode.js体験 # 3.1 学習用ディレクトリの作成 # # 作業ディレクトリを作成 mkdir nodejs-study \u0026amp;\u0026amp; cd nodejs-study 3.2 Node.jsコンテナの起動 # # Node.js 20のコンテナを起動（ファイルをマウント） docker run -it --rm -v $(pwd):/work -w /work node:20 bash 期待される結果：\nroot@コンテナID:/work# プロンプトが変わり、コンテナ内に入ったことがわかります。\n3.3 Node.jsのバージョン確認 # # コンテナ内で実行 node -v # 出力例: v20.x.x npm -v # 出力例: 10.x.x 3.4 Node.jsでHello World # 方法1: 対話モード（REPL） # # Node.js REPLを起動 node # 以下をREPL内で入力 \u0026gt; console.log(\u0026#34;Hello, Node.js!\u0026#34;); Hello, Node.js! undefined \u0026gt; 1 + 2 3 \u0026gt; const message = \u0026#34;Docker + Node.js 学習中！\u0026#34;; undefined \u0026gt; message \u0026#39;Docker + Node.js 学習中！\u0026#39; # REPLを終了 \u0026gt; .exit 方法2: スクリプトファイル実行 # # ファイルを作成 echo \u0026#39;console.log(\u0026#34;Hello from script!\u0026#34;);\u0026#39; \u0026gt; hello.js # スクリプトを実行 node hello.js # 出力: Hello from script! 3.5 コンテナの終了 # # コンテナから抜ける exit 確認ポイント：ローカルディレクトリにhello.jsが残っていることを確認\n# ローカルで確認 ls # 出力: hello.js cat hello.js # 出力: console.log(\u0026#34;Hello from script!\u0026#34;); ✅ このセクションで学んだこと # node:20イメージでNode.js環境を起動 nodeコマンドでREPL（対話モード）を起動 node \u0026lt;file.js\u0026gt;でスクリプトファイルを実行 マウントしたディレクトリに作成したファイルはコンテナ終了後も残る Part 4: ハンズオン② npmプロジェクトの初期化 # 4.1 コンテナの再起動 # # 同じディレクトリで docker run -it --rm -v $(pwd):/work -w /work node:20 bash 4.2 package.jsonの作成 # # 対話形式で初期化 npm init # または、デフォルト設定で一括作成 npm init -y 対話形式での質問と回答例 # package name: (work) my-first-nodejs version: (1.0.0) description: Node.js学習用プロジェクト entry point: (index.js) test command: git repository: keywords: nodejs, learning author: Your Name license: (ISC) MIT 生成されるpackage.json # { \u0026#34;name\u0026#34;: \u0026#34;my-first-nodejs\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Node.js学習用プロジェクト\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34; }, \u0026#34;keywords\u0026#34;: [ \u0026#34;nodejs\u0026#34;, \u0026#34;learning\u0026#34; ], \u0026#34;author\u0026#34;: \u0026#34;Your Name\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;MIT\u0026#34; } 4.3 package.jsonの重要な項目 # フィールド 役割 例 name プロジェクト名 my-first-nodejs version バージョン 1.0.0 main エントリーポイント index.js scripts npmスクリプト { \u0026quot;start\u0026quot;: \u0026quot;node index.js\u0026quot; } dependencies 本番用パッケージ { \u0026quot;express\u0026quot;: \u0026quot;^4.18.0\u0026quot; } devDependencies 開発用パッケージ { \u0026quot;nodemon\u0026quot;: \u0026quot;^3.0.0\u0026quot; } ✅ このセクションで学んだこと # npm init -yでpackage.jsonを作成 package.jsonはプロジェクトの設定ファイル（名前、バージョン、依存関係など） scriptsフィールドでnpmスクリプトを定義 Part 5: ハンズオン③ パッケージのインストール # 5.1 パッケージのインストール体験 # # 人気のユーティリティライブラリをインストール npm install lodash 実行結果の例 # added 1 package, and audited 2 packages in 1s found 0 vulnerabilities 5.2 インストール後の変化を確認 # # package.jsonの確認 cat package.json { \u0026#34;name\u0026#34;: \u0026#34;my-first-nodejs\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;lodash\u0026#34;: \u0026#34;^4.17.21\u0026#34; // ← 追加された！ } } # node_modulesディレクトリの確認 ls node_modules/ # 出力: lodash 5.3 インストールしたパッケージを使う # # index.jsファイルを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; index.js // lodashをインポート const _ = require(\u0026#39;lodash\u0026#39;); // 配列操作の例 const numbers = [1, 2, 3, 4, 5]; const doubled = _.map(numbers, n =\u0026gt; n * 2); console.log(\u0026#39;元の配列:\u0026#39;, numbers); console.log(\u0026#39;2倍にした配列:\u0026#39;, doubled); // オブジェクト操作の例 const users = [ { name: \u0026#39;Alice\u0026#39;, age: 25 }, { name: \u0026#39;Bob\u0026#39;, age: 30 }, { name: \u0026#39;Charlie\u0026#39;, age: 25 } ]; const grouped = _.groupBy(users, \u0026#39;age\u0026#39;); console.log(\u0026#39;年齢でグループ化:\u0026#39;, grouped); EOF # 実行 node index.js 期待される出力 # 元の配列: [ 1, 2, 3, 4, 5 ] 2倍にした配列: [ 2, 4, 6, 8, 10 ] 年齢でグループ化: { \u0026#39;25\u0026#39;: [ { name: \u0026#39;Alice\u0026#39;, age: 25 }, { name: \u0026#39;Charlie\u0026#39;, age: 25 } ], \u0026#39;30\u0026#39;: [ { name: \u0026#39;Bob\u0026#39;, age: 30 } ] } 5.4 npmスクリプトの設定 # # package.jsonのscriptsを編集 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; package.json { \u0026#34;name\u0026#34;: \u0026#34;my-first-nodejs\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Node.js学習用プロジェクト\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node index.js\u0026#34;, \u0026#34;hello\u0026#34;: \u0026#34;echo \u0026#39;Hello from npm script!\u0026#39;\u0026#34; }, \u0026#34;dependencies\u0026#34;: { \u0026#34;lodash\u0026#34;: \u0026#34;^4.17.21\u0026#34; } } EOF # スクリプトを実行 npm run hello # 出力: Hello from npm script! npm start # index.jsの実行結果が表示される ✅ このセクションで学んだこと # npm install \u0026lt;pkg\u0026gt;でパッケージをインストール インストールしたパッケージはnode_modules/に配置 require()でパッケージをインポートして使用 npm run \u0026lt;script\u0026gt;でnpmスクリプトを実行 Part 6: ハンズオン④ 開発用パッケージ # 6.1 devDependenciesとは # 種類 用途 インストールコマンド dependencies 本番環境で必要 npm install \u0026lt;pkg\u0026gt; devDependencies 開発時のみ必要 npm install -D \u0026lt;pkg\u0026gt; 6.2 nodemonのインストール # # 開発用パッケージとしてインストール npm install -D nodemon package.jsonの変化 # { \u0026#34;dependencies\u0026#34;: { \u0026#34;lodash\u0026#34;: \u0026#34;^4.17.21\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;nodemon\u0026#34;: \u0026#34;^3.0.0\u0026#34; // ← 追加された！ } } 6.3 nodemonを使った開発体験 # # package.jsonのscriptsを更新 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; package.json { \u0026#34;name\u0026#34;: \u0026#34;my-first-nodejs\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node index.js\u0026#34;, \u0026#34;dev\u0026#34;: \u0026#34;nodemon index.js\u0026#34; }, \u0026#34;dependencies\u0026#34;: { \u0026#34;lodash\u0026#34;: \u0026#34;^4.17.21\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;nodemon\u0026#34;: \u0026#34;^3.0.0\u0026#34; } } EOF # nodemonで起動（ファイル変更を監視） npm run dev nodemonの特徴：\nファイルの変更を検知して自動で再起動 開発効率が大幅に向上 Ctrl + Cで終了 6.4 コンテナを終了 # exit ✅ このセクションで学んだこと # npm install -D \u0026lt;pkg\u0026gt;で開発用パッケージをインストール dependenciesは本番環境で必要、devDependenciesは開発時のみ必要 nodemonはファイル変更を検知して自動再起動するツール Part 7: ハンズオン⑤ 依存関係の再インストール # 7.1 node_modulesを削除してみる # # ローカルで実行（コンテナの外） rm -rf node_modules ls # 出力: hello.js index.js package-lock.json package.json 7.2 npm installで復元 # # コンテナを起動 docker run -it --rm -v $(pwd):/work -w /work node:20 bash # 依存関係を再インストール npm install 実行結果 # added 2 packages, and audited 3 packages in 2s found 0 vulnerabilities 重要：package.jsonがあれば、npm installで依存パッケージを完全に復元できます。\n7.3 package-lock.jsonの役割 # ファイル 役割 package.json 必要なパッケージとバージョン範囲を記録 package-lock.json 実際にインストールされた正確なバージョンを記録 ベストプラクティス：\n✅ package.jsonとpackage-lock.jsonはGitにコミット ❌ node_modulesはGitにコミットしない ✅ このセクションで学んだこと # node_modulesを削除してもnpm installで復元可能 package-lock.jsonは正確なバージョンを記録 node_modulesはGitにコミットしない（package.jsonから復元可能） Part 8: ハンズオン⑥ 簡単なWebサーバー # 8.1 Expressのインストール # # コンテナ内で npm install express 8.2 Webサーバーの作成 # # server.jsを作成 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; server.js const express = require(\u0026#39;express\u0026#39;); const app = express(); const PORT = 3000; // ルートパスへのGETリクエスト app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.send(\u0026#39;Hello from Express in Docker!\u0026#39;); }); // JSONを返すAPI app.get(\u0026#39;/api/info\u0026#39;, (req, res) =\u0026gt; { res.json({ message: \u0026#39;Docker + Node.js + Express\u0026#39;, timestamp: new Date().toISOString(), nodeVersion: process.version }); }); // サーバー起動 app.listen(PORT, () =\u0026gt; { console.log(`Server running at http://localhost:${PORT}`); }); EOF 8.3 ポートを公開してコンテナを起動 # # 一度exitしてから、ポート指定で再起動 exit # ポート3000を公開してコンテナを起動 docker run -it --rm -v $(pwd):/work -w /work -p 3000:3000 node:20 bash # サーバーを起動 node server.js 8.4 動作確認 # 別のターミナルを開いて：\n# curlで確認 curl http://localhost:3000 # 出力: Hello from Express in Docker! curl http://localhost:3000/api/info # 出力: {\u0026#34;message\u0026#34;:\u0026#34;Docker + Node.js + Express\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;...\u0026#34;,\u0026#34;nodeVersion\u0026#34;:\u0026#34;v20.x.x\u0026#34;} またはブラウザで http://localhost:3000 にアクセス\n8.5 サーバーの停止 # # Ctrl + C でサーバー停止 # exitでコンテナ終了 exit ✅ このセクションで学んだこと # Expressは人気のWebアプリケーションフレームワーク -p 3000:3000でコンテナのポートをホストに公開 app.get()でルーティングを定義、res.send()/res.json()でレスポンス Part 9: 後片付けと学習の振り返り # 9.1 学習ファイルの確認 # # ローカルで確認 ls -la # 出力: # hello.js # index.js # node_modules/ # package-lock.json # package.json # server.js 9.2 クリーンアップ # # 学習ディレクトリを削除 cd .. rm -rf nodejs-study # または、node_modulesだけ削除して軽量化 rm -rf nodejs-study/node_modules ✅ このセクションで学んだこと # 学習後はrm -rf \u0026lt;directory\u0026gt;でクリーンアップ node_modulesだけ削除すればディスク容量を節約できる 必要になったらnpm installで復元可能 まとめ # 🎯 学んだこと # Docker関連 # コマンド 用途 docker run -it --rm 使い捨てコンテナを起動 -v $(pwd):/work ディレクトリをマウント -w /work 作業ディレクトリを設定 -p 3000:3000 ポートを公開 Node.js関連 # コマンド 用途 node -v バージョン確認 node \u0026lt;file.js\u0026gt; スクリプト実行 node REPL起動 npm関連 # コマンド 用途 npm init -y プロジェクト初期化 npm install \u0026lt;pkg\u0026gt; パッケージインストール npm install -D \u0026lt;pkg\u0026gt; 開発用パッケージインストール npm install 依存関係を再インストール npm run \u0026lt;script\u0026gt; スクリプト実行 📚 次のステップ # npm / yarn の深掘り\nセマンティックバージョニング グローバルインストール vs ローカルインストール フロントエンド開発ツール\nWebpack / Vite でのバンドル Babel でのトランスパイル ESLint / Prettier でのコード品質管理 バックエンド開発\nExpress での REST API 構築 データベース連携 Node.jsバージョン管理\nnvm / nodenv でのバージョン切り替え 💡 Tips: 学習用コマンドチートシート # # Node.js学習環境を一発で起動 mkdir study \u0026amp;\u0026amp; cd study docker run -it --rm -v $(pwd):/work -w /work node:20 bash # ポート公開付き（Webサーバー学習用） docker run -it --rm -v $(pwd):/work -w /work -p 3000:3000 node:20 bash # プロジェクト初期化からパッケージインストールまで npm init -y \u0026amp;\u0026amp; npm install express # 学習終了後のクリーンアップ cd .. \u0026amp;\u0026amp; rm -rf study 参考資料 # Docker公式ドキュメント Node.js公式ドキュメント npm公式ドキュメント Express公式ドキュメント ","date":"2025年 11月 30日","externalUrl":null,"permalink":"/posts/251130065841_docker-environment-nodejs-basics-part1/","section":"Posts","summary":"","title":"Docker環境でNode.jsを学ぼう_Part1_Node.js基礎編","type":"posts"},{"content":"","date":"2025年 11月 30日","externalUrl":null,"permalink":"/tags/node.js/","section":"Tags","summary":"","title":"Node.js","type":"tags"},{"content":" 今日学んだこと # 前回の記事でファイルレイアウトによる環境分離を学んだが、ステージングと本番で同じコードを重複して書く問題が残っていた。今回はTerraformモジュールを使って、DRY原則をインフラコードに適用する方法を学んだ。\nモジュール化で得られるメリット # メリット 説明 DRY原則 同じコードを複数環境で再利用 保守性 1箇所の修正で全環境に反映 柔軟性 入力変数で環境ごとのカスタマイズ 安全性 バージョン管理でテスト済みコードのみ本番適用 モジュールとは # フォルダ内にあるTerraform設定ファイル（.tfファイル）の集まり = モジュール\nつまり、これまで作成してきたディレクトリも「モジュール」といえる。\n種類 説明 ルートモジュール terraform applyを直接実行するフォルダ 再利用可能なモジュール 他のモジュールから呼び出されるフォルダ 基本構文 # module \u0026#34;\u0026lt;NAME\u0026gt;\u0026#34; { source = \u0026#34;\u0026lt;SOURCE\u0026gt;\u0026#34; # 設定（入力変数など） } sourceにはローカルパス、GitHub URL、Terraform Registryなどを指定できる。\nディレクトリ構成の変更 # 前回のstage/のみの構成から、モジュールを分離した構成に変更。\n├── modules/ # 再利用可能なモジュール │ └── services/ │ └── webserver-cluster/ │ ├── main.tf │ ├── variables.tf │ ├── outputs.tf │ └── user-data.sh │ └── live/ ├── stage/ # ステージング環境 │ └── services/ │ └── webserver-cluster/ │ └── main.tf └── prod/ # 本番環境 └── services/ └── webserver-cluster/ └── main.tf ディレクトリ 役割 modules/ 環境に依存しない再利用可能コード live/stage/ ステージング環境のルートモジュール live/prod/ 本番環境のルートモジュール モジュールの構成要素 # プログラミングの関数と対比すると理解しやすい。\nTerraformモジュール プログラミング 説明 モジュール 関数 再利用可能なコードの塊 variable 引数 モジュールに値を渡す locals ローカル変数 モジュール内部の計算・定数 output 戻り値 モジュールから値を返す 以降のセクションで、それぞれの詳細と使い方を見ていく。\n入力変数（variable） # なぜ必要か # 前回のコードにはハードコードされた値が多い。\nハードコード 問題 instance_type = \u0026quot;t2.micro\u0026quot; prodでは大きいインスタンスが必要 min_size = 2 環境ごとにスケールを変えたい key = \u0026quot;stage/...\u0026quot; prodで使うとstageのDBを参照 定義例 # modules/services/webserver-cluster/variables.tf\nvariable \u0026#34;cluster_name\u0026#34; { description = \u0026#34;クラスターリソースの名前\u0026#34; type = string } variable \u0026#34;instance_type\u0026#34; { description = \u0026#34;起動するEC2タイプの種類\u0026#34; type = string } variable \u0026#34;min_size\u0026#34; { description = \u0026#34;EC2インスタンスのASGの最小値\u0026#34; type = number } variable \u0026#34;max_size\u0026#34; { description = \u0026#34;EC2インスタンスのASGの最大値\u0026#34; type = number } variable \u0026#34;db_remote_state_bucket\u0026#34; { description = \u0026#34;S3バケットの名前（データベースのリモートステート）\u0026#34; type = string } variable \u0026#34;db_remote_state_key\u0026#34; { description = \u0026#34;S3でのデータベースのリモートステートのパス\u0026#34; type = string } 呼び出し側での値の指定 # live/stage/services/webserver-cluster/main.tf\nprovider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } module \u0026#34;webserver_cluster\u0026#34; { source = \u0026#34;../../../modules/services/webserver-cluster\u0026#34; cluster_name = \u0026#34;webservers-stage\u0026#34; db_remote_state_bucket = \u0026#34;tf-state-backend-20251128\u0026#34; db_remote_state_key = \u0026#34;stage/data-stores/mysql/terraform.tfstate\u0026#34; instance_type = \u0026#34;t2.micro\u0026#34; min_size = 2 max_size = 2 } live/prod/services/webserver-cluster/main.tf\nmodule \u0026#34;webserver_cluster\u0026#34; { source = \u0026#34;../../../modules/services/webserver-cluster\u0026#34; cluster_name = \u0026#34;webservers-prod\u0026#34; db_remote_state_bucket = \u0026#34;tf-state-backend-20251128\u0026#34; db_remote_state_key = \u0026#34;prod/data-stores/mysql/terraform.tfstate\u0026#34; instance_type = \u0026#34;m4.large\u0026#34; # より大きいインスタンス min_size = 2 max_size = 10 # スケールアウト可能 } ローカル値（locals） # variable との違い # 種類 外部から設定 用途 variable 可能 モジュールのAPI（外部に公開） locals 不可 モジュール内部の定数・計算 ポート番号など変更されたくない値はlocalsで定義する。\nlocals { http_port = 80 any_port = 0 any_protocol = \u0026#34;-1\u0026#34; tcp_protocol = \u0026#34;tcp\u0026#34; all_ips = [\u0026#34;0.0.0.0/0\u0026#34;] } resource \u0026#34;aws_security_group_rule\u0026#34; \u0026#34;allow_http_inbound\u0026#34; { type = \u0026#34;ingress\u0026#34; security_group_id = aws_security_group.alb.id from_port = local.http_port # 80 to_port = local.http_port protocol = local.tcp_protocol cidr_blocks = local.all_ips } マジックナンバー 80 より local.http_port の方が意図が明確。\n出力（output） # なぜ必要か # 本番環境のみにスケジュール設定を追加したい場合、モジュール内のASG名を外部から参照する必要がある。\nmodules/services/webserver-cluster/outputs.tf\noutput \u0026#34;asg_name\u0026#34; { value = aws_autoscaling_group.example.name description = \u0026#34;The name of the Auto Scaling Group\u0026#34; } output \u0026#34;alb_security_group_id\u0026#34; { value = aws_security_group.alb.id description = \u0026#34;ALBのセキュリティグループID\u0026#34; } live/prod/main.tf（本番のみスケジュール追加）\nresource \u0026#34;aws_autoscaling_schedule\u0026#34; \u0026#34;scale_out_during_business_hours\u0026#34; { scheduled_action_name = \u0026#34;scale-out-during-business-hours\u0026#34; min_size = 2 max_size = 10 desired_capacity = 10 recurrence = \u0026#34;0 9 * * *\u0026#34; # 毎日9時 autoscaling_group_name = module.webserver_cluster.asg_name # 出力を参照 } 注意点1: ファイルパス # 問題 # 相対パス \u0026quot;user-data.sh\u0026quot; はルートモジュールからの相対パスとして解釈される。モジュール内のファイルを参照できない。\n解決策: path.module # # Before（動かない） user_data = base64encode(templatefile(\u0026#34;user-data.sh\u0026#34;, { ... })) # After（正しく動く） user_data = base64encode(templatefile(\u0026#34;${path.module}/user-data.sh\u0026#34;, { ... })) パス参照 指す場所 path.module モジュール定義があるディレクトリ path.root ルートモジュールのディレクトリ path.cwd terraform applyを実行したディレクトリ 注意点2: インラインブロック # 問題 # セキュリティグループのingress/egressには2つの書き方がある。\nインラインブロック\nresource \u0026#34;aws_security_group\u0026#34; \u0026#34;alb\u0026#34; { name = \u0026#34;${var.cluster_name}-alb\u0026#34; ingress { # リソース内に直接書く from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } 別リソース\nresource \u0026#34;aws_security_group\u0026#34; \u0026#34;alb\u0026#34; { name = \u0026#34;${var.cluster_name}-alb\u0026#34; } resource \u0026#34;aws_security_group_rule\u0026#34; \u0026#34;allow_http\u0026#34; { type = \u0026#34;ingress\u0026#34; security_group_id = aws_security_group.alb.id from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } モジュールでは別リソースを推奨 # 方法 柔軟性 理由 インラインブロック 低 呼び出し側でルール追加不可 別リソース 高 呼び出し側で追加ルール定義可能 別リソースにすれば、ステージング環境のみテスト用ポートを追加、といったカスタマイズが可能。\n# live/stage/main.tf - テスト用ポートを追加 resource \u0026#34;aws_security_group_rule\u0026#34; \u0026#34;allow_testing\u0026#34; { type = \u0026#34;ingress\u0026#34; security_group_id = module.webserver_cluster.alb_security_group_id from_port = 12345 to_port = 12345 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } モジュールのバージョン管理 # 問題 # ローカルパス参照では、モジュールを変更すると全環境に即座に影響する。\n解決策: GitリポジトリとSemVer # モジュールを別リポジトリに分離 Gitタグでバージョンを付与 git tag -a \u0026#34;v0.0.1\u0026#34; -m \u0026#34;First release\u0026#34; git push --follow-tags 環境ごとに異なるバージョンを参照 # stage: 新バージョンをテスト source = \u0026#34;github.com/user/modules//services/webserver-cluster?ref=v0.0.2\u0026#34; # prod: 安定版を維持 source = \u0026#34;github.com/user/modules//services/webserver-cluster?ref=v0.0.1\u0026#34; GitHubでソースURL指定方法：github.com/user/repo\nセマンティックバージョニング # 変更内容 バージョン バグ修正 PATCH（v0.0.1 → v0.0.2） 後方互換のある機能追加 MINOR（v0.0.2 → v0.1.0） 破壊的変更 MAJOR（v0.1.0 → v1.0.0） エラー対応メモ # terraform init の実行場所 # Terraform initialized in an empty directory! → .tfファイルがあるディレクトリ（ルートモジュール）で実行すること。\nbackend設定がモジュール内に残っている # Error: Failed to get existing workspaces: S3 bucket does not exist. → providerとterraform { backend }はルートモジュールのみに書く。再利用可能なモジュールからは削除。\nモジュールに含めるべきもの # 設定 modules/ live/ provider - 必須 terraform { backend } - 必須 resource 必須 任意 variable 必須 任意 output 必須 任意 locals 任意 任意 参照方法の比較 # ここまで学んだ各要素の参照方法をまとめる。\n種類 文法 例 入力変数 var.\u0026lt;NAME\u0026gt; var.cluster_name ローカル値 local.\u0026lt;NAME\u0026gt; local.http_port モジュール出力 module.\u0026lt;MODULE\u0026gt;.\u0026lt;OUTPUT\u0026gt; module.webserver_cluster.asg_name パス参照 path.\u0026lt;TYPE\u0026gt; path.module まとめ # 学んだこと 内容 モジュールの基礎 フォルダ = モジュール 入力変数（variable） 環境ごとの違いを吸収 ローカル値（locals） 変更されたくない内部定数 出力（output） 外部から参照可能な値 ファイルパス path.moduleで正しく参照 インラインブロック 別リソースの方が柔軟 バージョン管理 Git + SemVerで安全なデプロイ モジュール化のメリット # DRY原則: 同じコードを複数環境で再利用 保守性: 1箇所の修正で全環境に反映 柔軟性: 入力変数で環境ごとのカスタマイズ 安全性: バージョン管理でテスト済みコードのみ本番適用 参考 # 詳解 Terraform 第3版 - Yevgeniy Brikman著、松浦隼人訳、オライリージャパン、2023年 Terraform公式ドキュメント 前回の記事: ファイルレイアウトとterraform_remote_state ","date":"2025年 11月 29日","externalUrl":null,"permalink":"/posts/251129154214_terraform-reusable-infrastructure-modules/","section":"Posts","summary":"","title":"Terraformモジュールで再利用可能なインフラを作る","type":"posts"},{"content":" キャッシュメモリのアドレスマッピング方式とは？ # 主記憶上の格納位置とキャッシュメモリ上の格納位置とをどのように対応させるかを決める方式として、ダイレクトマップ、フルアソシエイティブ、セットアソシエイティブがある。\nダイレクトマップ # 主記憶のアドレスからキャッシュメモリ上の格納位置（ブロック番号）が一意に決まる方式\n主記憶のアドレスの一部（下位ビット）をインデックスとして使用し、格納先を決定 回路構成が単純でコストが低い 主記憶上の異なるアドレスが、キャッシュメモリ上の同じ場所に割り当てられる「コンフリクト」が発生する可能性がある コンフリクトはキャッシュヒット率が低下する原因にもなる フルアソシエイティブ # 主記憶のブロックをキャッシュメモリ上のどのブロックにも格納することができる方式\nコンフリクトが発生しにくく、キャッシュヒット率が高い 検索にCAM（Content Addressable Memory：連想メモリ）を使用するため、回路が非常に複雑で高コスト 小容量のキャッシュ（TLBなど）で使用されることが多い セットアソシエイティブ # キャッシュメモリをいくつかの「セット」と呼ばれるグループに分け、主記憶のアドレスからはまず特定のセットが決定される。そのセットの中であれば、どのブロックにでも格納することができる。\nダイレクトマップとフルアソシエイティブの中間的な存在 現在の主流の方式（コストとパフォーマンスのバランスが良い） n-way セットアソシエイティブ: 1つのセット内に格納できるブロック数を「n」で表す 2-way: 1セットに2ブロック格納可能 4-way: 1セットに4ブロック格納可能 nが大きいほどフルアソシエイティブに近づき、ヒット率は上がるがコストも増加 3方式の比較 # 方式 格納位置の自由度 回路の複雑さ コスト ヒット率 ダイレクトマップ 低（1箇所固定） 単純 低 低 フルアソシエイティブ 高（どこでも可） 複雑 高 高 セットアソシエイティブ 中（セット内で自由） 中程度 中 中 参考リンク # 応用情報技術者過去問道場：令和4年春期 問10 出典：応用情報技術者：令和4年春期 問10 ","date":"2025年 11月 29日","externalUrl":null,"permalink":"/posts/251129115424_cache-memory-address-mapping/","section":"Posts","summary":"","title":"キャッシュメモリのアドレスマッピング方式","type":"posts"},{"content":" 問題 # 出典：応用情報技術者平成26年春期問18 仮想記憶方式において、論理アドレスから物理アドレスへの変換を行うのはいつか。\n選択肢\nページを補助記憶にページアウトするとき ページフォールトが発生したとき 主記憶に存在するページをアクセスするとき ページを主記憶にページインするとき 正解：主記憶に存在するページをアクセスするとき # 基本的な仕組み # 論理アドレスから物理アドレスへの変換は、CPUがメモリアクセスを行うたびに実行されます。\n担当ハードウェア: MMU（メモリ管理ユニット） 使用する対応表: ページテーブル 実行タイミング: 主記憶上のページへアクセスするとき（毎回） 処理速度: 高速（ハードウェア処理） 他の選択肢が不正解な理由 # ページアウト # 主記憶の空き容量確保のため、使用頻度の低いページを補助記憶に退避する処理 OSによるメモリ管理動作であり、アドレス変換処理そのものではない ページフォールト # アドレス変換を試みた結果、失敗したときに発生する例外（割り込み） 変換が行われるタイミングではなく、変換失敗の結果発生する事象 ページイン # ページフォールト発生後、補助記憶から主記憶にページを読み込む処理 ページイン完了後に、改めてアドレス変換が行われる Q\u0026amp;A：よくある誤解 # Q1. ページイン・ページアウトでも変換が発生する？ # A. いいえ、厳密には異なります。\nアドレス変換はCPUの命令実行に伴う処理であり、ページイン・ページアウトの最中に行われるわけではありません。\nQ2. アドレス変換が失敗したらどうなる？ # A. 以下の流れで処理されます。\nアドレス変換失敗 ↓ ページフォールト発生 ↓ OS介入（ページイン処理） ↓ 変換成功（メモリアクセス実行） 詳細：各処理とアドレス変換の関係 # アドレス変換が行われるタイミング # CPUがプログラムを実行し、メモリアクセスするたびにMMUが論理アドレスを物理アドレスに変換します。これは主記憶上のページが存在する場合に毎回実行される高速処理です。\nページインとアドレス変換 # ページインはアドレス変換の失敗がきっかけで発生します。\nCPUが論理アドレスにアクセス → MMUがアドレス変換を試行 ページが主記憶に存在しない → 変換失敗 → ページフォールト発生 OSが補助記憶装置から必要なページを主記憶に読み込む（ページイン） ページテーブル更新 中断していた命令を再開 → MMUが再度アドレス変換を試行 → 成功 ページアウトとアドレス変換 # ページアウトは、ページインのための空き領域確保を目的としたOSのメモリ管理動作です。\nページフォールト発生 → ページイン必要 → 主記憶に空きがない OSがページの置き換え対象を決定 選ばれたページを補助記憶装置に書き出す（ページアウト） CPUによるアドレス変換処理そのものではありません。\nまとめ # 処理 役割 アドレス変換との関係 アドレス変換 MMUによる論理→物理アドレス変換 主記憶アクセス時に毎回実行 ページフォールト アドレス変換失敗時の例外 変換失敗の結果 ページイン 補助記憶→主記憶へのページ読み込み 完了後に変換が再実行される ページアウト 主記憶→補助記憶へのページ退避 変換処理ではない（メモリ管理） 仮想記憶の処理フロー # 1. アドレス変換の試行 ├─ 成功 → メモリアクセス実行 └─ 失敗 → 2へ 2. ページフォールト発生（例外割り込み） └─ OSに制御移行 3. OS処理 ├─ ページ検索（補助記憶装置） ├─ 空き領域確保（必要なら4へ） └─ ページイン実行 4. ページアウト（空き容量不足時） ├─ 置き換え対象選択 └─ 補助記憶へ退避 5. ページテーブル更新 6. 処理再開 → 1へ戻る（今度は成功） 重要ポイント: ページイン・ページアウトは、アドレス変換を円滑に動かすためのOSによる裏方の管理作業です。\n","date":"2025年 11月 29日","externalUrl":null,"permalink":"/posts/251129114929_virtual-memory-address-translation/","section":"Posts","summary":"","title":"仮想記憶のアドレス変換","type":"posts"},{"content":" VSCode マルチカーソル編集とは？ # 複数箇所を同時編集できる便利機能。 変数名の一括変更やインデント調整など、繰り返し作業を大幅に効率化できる。\nショートカット一覧 # 操作 Windows Mac 任意の位置にカーソル追加 Alt + クリック Option + クリック 上下に連続カーソル追加 Ctrl + Alt + ↑/↓ Cmd + Option + ↑/↓ 矩形（ボックス）選択 Alt + Shift + ドラッグ Option + Shift + ドラッグ 行頭へ移動 Home Cmd + ← 同じ単語を全選択 Ctrl + Shift + L Cmd + Shift + L 使い分け # シーン 推奨操作 飛び飛びの行を編集 Alt + クリック 連続した行を編集 Ctrl + Alt + ↓ で一気に追加 縦に揃った範囲を編集 矩形選択 実践例 # 連続行の先頭にコメント追加\n最初の行の先頭にカーソルを置く Ctrl + Alt + ↓ で下方向にカーソルを増やす // を入力 → 全行に一括挿入 練習用テキスト # 下記のテキストでマルチカーソル編集を試してみよう：\n例1: 行頭に const を追加してみよう\nname = \u0026#34;Alice\u0026#34; age = 25 city = \u0026#34;Tokyo\u0026#34; email = \u0026#34;alice@example.com\u0026#34; 例2: 行末に ; を追加してみよう\nimport React from \u0026#39;react\u0026#39; import useState from \u0026#39;react\u0026#39; import useEffect from \u0026#39;react\u0026#39; 例3: 各行を console.log() で囲んでみよう\nuser.name user.age user.email ","date":"2025年 11月 29日","externalUrl":null,"permalink":"/posts/251129112924_vscode-multi-cursor-editing/","section":"Posts","summary":"","title":"VSCode_マルチカーソル編集","type":"posts"},{"content":" 今日学んだこと # 前回の記事でワークスペースによるステート分離を学んだが、本番環境の分離には不十分だった。今回はファイルレイアウトによる分離を実践し、RDSとWebサーバーを別々に管理しながらterraform_remote_stateで連携させる方法を学んだ。\n前回の振り返り: ワークスペースの限界 # Part1でワークスペースの欠点を確認した。\n欠点 説明 同一バックエンド 全環境が同じS3/DynamoDBを使用（権限分離が困難） 可視性が低い 今どのワークスペースにいるか分かりにくい 誤操作リスク terraform workspace select prod を忘れて本番を破壊する可能性 これらの問題を解決するのがファイルレイアウトによる分離。\nファイルレイアウトによる分離とは # 環境ごと・コンポーネントごとに別のディレクトリで管理する方法。\nterraform-project/ ├── stage/ # ステージング環境 │ ├── data-stores/mysql/ # DB層（変更頻度: 低） │ └── services/webserver-cluster/ # App層（変更頻度: 高） └── prod/ # 本番環境（完全に別管理） ├── data-stores/mysql/ └── services/webserver-cluster/ なぜコンポーネントも分離するのか # レイヤー 変更頻度 リスク VPC/ネットワーク 月1回程度 高（全体に影響） データベース 週1回程度 高（データ損失） Webサーバー 1日数回 低（再デプロイ可能） 頻繁に変更するWebサーバーと、めったに変更しないDBを同じステートで管理すると、Webサーバーの変更時に誤ってDBを破壊するリスクがある。\n分離されたコンポーネント間の連携 # 問題: RDSとWebサーバーが別プロジェクトになると、WebサーバーはRDSの接続情報をどうやって知るのか？\n解決: terraform_remote_stateで別プロジェクトのステートからoutputを参照する。\n[mysql/] [webserver-cluster/] │ │ └── outputs.tf で address/port を出力 │ │ │ └──────────────────────────────┼──→ terraform_remote_state で参照 Step 1: RDSの構築 # ディレクトリ構成 # mkdir -p stage/data-stores/mysql cd stage/data-stores/mysql variables.tf # variable \u0026#34;db_name\u0026#34; { description = \u0026#34;データベース名\u0026#34; type = string default = \u0026#34;example_database\u0026#34; } variable \u0026#34;db_username\u0026#34; { description = \u0026#34;データベースのユーザー名\u0026#34; type = string sensitive = true } variable \u0026#34;db_password\u0026#34; { description = \u0026#34;データベースのパスワード\u0026#34; type = string sensitive = true } sensitive = trueを指定すると、terraform planやterraform applyの出力でマスクされる。\nmain.tf # provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } terraform { backend \u0026#34;s3\u0026#34; { # 重要: keyはRDS専用のパスにする key = \u0026#34;stage/data-stores/mysql/terraform.tfstate\u0026#34; bucket = \u0026#34;tf-state-backend-20251128\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true } } resource \u0026#34;aws_db_instance\u0026#34; \u0026#34;example\u0026#34; { identifier_prefix = \u0026#34;terraform-up-and-running\u0026#34; engine = \u0026#34;mysql\u0026#34; allocated_storage = 10 instance_class = \u0026#34;db.t3.micro\u0026#34; skip_final_snapshot = true db_name = var.db_name username = var.db_username password = var.db_password } outputs.tf（重要） # Webサーバーから参照するために、接続情報をoutputとして公開する。\noutput \u0026#34;address\u0026#34; { value = aws_db_instance.example.address description = \u0026#34;データベースの接続エンドポイント\u0026#34; } output \u0026#34;port\u0026#34; { value = aws_db_instance.example.port description = \u0026#34;データベースのポート番号\u0026#34; } デプロイ # terraform init terraform apply # var.db_username: admin # var.db_password: yourpassword123 RDSの作成には5-10分かかる。完了したらterraform outputで接続情報を確認できる。\nStep 2: Webサーバークラスタの構築 # ディレクトリ構成 # mkdir -p stage/services/webserver-cluster cd stage/services/webserver-cluster terraform_remote_stateとは # なぜ必要なのか # ファイルレイアウトで分離すると、RDSとWebサーバーは別々のTerraformプロジェクトになる。それぞれが独自のステートファイルを持つため、通常の方法では互いのリソース情報にアクセスできない。\n[mysql/] [webserver-cluster/] terraform.tfstate terraform.tfstate │ │ └── RDSのaddress/portを保持 └── RDSの情報が必要だが...？ WebサーバーがRDSに接続するには、RDSのエンドポイント（address/port）が必要。これを解決するのがterraform_remote_state。\n仕組み # terraform_remote_stateは読み取り専用のデータソースで、別プロジェクトのステートファイルからoutputで公開された値を取得する。\n[mysql/] [webserver-cluster/] │ │ ├── outputs.tf で address/port を公開 │ │ │ │ │ ▼ │ │ S3に保存されたステート ◀─────────────────────┤ │ (stage/data-stores/mysql/ │ │ terraform.tfstate) │ │ │ │ │ │ terraform_remote_state で読み取り │ │ └──────────────────────────────────────▶ db_address, db_port として使用 重要: terraform_remote_stateで読み取れるのはoutputで明示的に公開された値のみ。ステートファイル内の全リソース情報にアクセスできるわけではない。\n基本構文 # data \u0026#34;terraform_remote_state\u0026#34; \u0026#34;db\u0026#34; { backend = \u0026#34;s3\u0026#34; # バックエンドの種類 config = { bucket = \u0026#34;tf-state-backend-20251128\u0026#34; key = \u0026#34;stage/data-stores/mysql/terraform.tfstate\u0026#34; # RDSのステートのkey region = \u0026#34;ap-northeast-1\u0026#34; } } 属性 説明 backend 参照先のバックエンド種類（s3, gcs, azurerm等） config.bucket S3バケット名 config.key 参照先プロジェクトのステートファイルのkey config.region S3バケットのリージョン 参照方法 # # outputs.address を参照 data.terraform_remote_state.db.outputs.address # outputs.port を参照 data.terraform_remote_state.db.outputs.port ハードコードとの比較 # 方式 コード例 問題点 ハードコード db_address = \u0026quot;terraform-xxx.rds.amazonaws.com\u0026quot; RDS再作成時に手動更新が必要 terraform_remote_state db_address = data.terraform_remote_state.db.outputs.address 自動的に最新値を取得 # NG: ハードコード db_address = \u0026#34;terraform-xxx.rds.amazonaws.com\u0026#34; # → RDSを再作成するとアドレスが変わり、手動更新が必要 # → 複数環境で異なる値を管理する必要がある # OK: terraform_remote_state db_address = data.terraform_remote_state.db.outputs.address # → RDSが変わっても terraform plan/apply 時に最新のアドレスを取得 # → 環境ごとにkeyを変えるだけで対応可能 注意点 # 注意点 説明 keyの一致 terraform_remote_stateのkeyは、参照先プロジェクトのbackend設定と完全に一致させること outputの公開 参照したい値は参照先でoutputとして定義する必要がある 依存関係 参照先（RDS）を先にデプロイしてからWebサーバーをデプロイすること 読み取り専用 ステートの読み取りのみ可能。変更はできない templatefile関数 # 外部ファイルを読み込み、変数を埋め込む関数。\nuser_data = base64encode(templatefile(\u0026#34;user-data.sh\u0026#34;, { server_port = var.server_port db_address = data.terraform_remote_state.db.outputs.address db_port = data.terraform_remote_state.db.outputs.port })) HCLとbashを分離することで可読性が向上し、スクリプト単体でのテストも可能になる。\nuser-data.sh # #!/bin/bash cd /home/ec2-user cat \u0026gt; index.html \u0026lt;\u0026lt;EOF \u0026lt;h1\u0026gt;Hello, World\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;DB address: ${db_address}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;DB port: ${db_port}\u0026lt;/p\u0026gt; EOF nohup python3 -m http.server ${server_port} \u0026amp; 注意: このコードは terraform_remote_state の動作確認用サンプルです。ブラウザでアクセスするとDBの接続情報が画面に表示されます。実際の運用環境では、このような機密情報をHTMLページに表示せず、アプリケーション内部でのみ使用してください。\nvariables.tf # variable \u0026#34;server_port\u0026#34; { description = \u0026#34;HTTPリクエストを受け付けるポート番号\u0026#34; type = number default = 8080 } variable \u0026#34;alb_name\u0026#34; { description = \u0026#34;ALBの名前\u0026#34; type = string default = \u0026#34;terraform-asg-example\u0026#34; } variable \u0026#34;alb_security_group_name\u0026#34; { description = \u0026#34;ALB用セキュリティグループの名前\u0026#34; type = string default = \u0026#34;terraform-example-alb\u0026#34; } variable \u0026#34;instance_security_group_name\u0026#34; { description = \u0026#34;EC2インスタンス用セキュリティグループの名前\u0026#34; type = string default = \u0026#34;terraform-example-instance\u0026#34; } main.tf # provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } terraform { backend \u0026#34;s3\u0026#34; { bucket = \u0026#34;tf-state-backend-20251128\u0026#34; key = \u0026#34;stage/services/webserver-cluster/terraform.tfstate\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true } } # ----------------------------------------------------------------------------- # Data Sources # ----------------------------------------------------------------------------- data \u0026#34;aws_vpc\u0026#34; \u0026#34;default\u0026#34; { default = true } data \u0026#34;aws_subnets\u0026#34; \u0026#34;default\u0026#34; { filter { name = \u0026#34;vpc-id\u0026#34; values = [data.aws_vpc.default.id] } } # RDSの状態をリモートステートから取得 data \u0026#34;terraform_remote_state\u0026#34; \u0026#34;db\u0026#34; { backend = \u0026#34;s3\u0026#34; config = { bucket = \u0026#34;tf-state-backend-20251128\u0026#34; key = \u0026#34;stage/data-stores/mysql/terraform.tfstate\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; } } # ----------------------------------------------------------------------------- # Launch Template \u0026amp; Auto Scaling Group # ----------------------------------------------------------------------------- resource \u0026#34;aws_launch_template\u0026#34; \u0026#34;example\u0026#34; { image_id = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; instance_type = \u0026#34;t2.micro\u0026#34; vpc_security_group_ids = [aws_security_group.instance.id] user_data = base64encode(templatefile(\u0026#34;user-data.sh\u0026#34;, { server_port = var.server_port db_address = data.terraform_remote_state.db.outputs.address db_port = data.terraform_remote_state.db.outputs.port })) } resource \u0026#34;aws_autoscaling_group\u0026#34; \u0026#34;example\u0026#34; { vpc_zone_identifier = data.aws_subnets.default.ids launch_template { id = aws_launch_template.example.id version = \u0026#34;$Latest\u0026#34; } target_group_arns = [aws_lb_target_group.asg.arn] health_check_type = \u0026#34;ELB\u0026#34; min_size = 2 max_size = 10 tag { key = \u0026#34;Name\u0026#34; value = \u0026#34;terraform-asg-example\u0026#34; propagate_at_launch = true } } # ----------------------------------------------------------------------------- # Security Groups # ----------------------------------------------------------------------------- resource \u0026#34;aws_security_group\u0026#34; \u0026#34;instance\u0026#34; { name = var.instance_security_group_name ingress { from_port = var.server_port to_port = var.server_port protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } resource \u0026#34;aws_security_group\u0026#34; \u0026#34;alb\u0026#34; { name = var.alb_security_group_name ingress { from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } # ----------------------------------------------------------------------------- # Application Load Balancer # ----------------------------------------------------------------------------- resource \u0026#34;aws_lb\u0026#34; \u0026#34;example\u0026#34; { name = var.alb_name load_balancer_type = \u0026#34;application\u0026#34; subnets = data.aws_subnets.default.ids security_groups = [aws_security_group.alb.id] } resource \u0026#34;aws_lb_listener\u0026#34; \u0026#34;http\u0026#34; { load_balancer_arn = aws_lb.example.arn port = 80 protocol = \u0026#34;HTTP\u0026#34; default_action { type = \u0026#34;fixed-response\u0026#34; fixed_response { content_type = \u0026#34;text/plain\u0026#34; message_body = \u0026#34;404: page not found\u0026#34; status_code = 404 } } } resource \u0026#34;aws_lb_target_group\u0026#34; \u0026#34;asg\u0026#34; { name = var.alb_name port = var.server_port protocol = \u0026#34;HTTP\u0026#34; vpc_id = data.aws_vpc.default.id health_check { path = \u0026#34;/\u0026#34; protocol = \u0026#34;HTTP\u0026#34; matcher = \u0026#34;200\u0026#34; interval = 15 timeout = 3 healthy_threshold = 2 unhealthy_threshold = 2 } } resource \u0026#34;aws_lb_listener_rule\u0026#34; \u0026#34;asg\u0026#34; { listener_arn = aws_lb_listener.http.arn priority = 100 condition { path_pattern { values = [\u0026#34;*\u0026#34;] } } action { type = \u0026#34;forward\u0026#34; target_group_arn = aws_lb_target_group.asg.arn } } outputs.tf # output \u0026#34;alb_dns_name\u0026#34; { value = aws_lb.example.dns_name description = \u0026#34;ロードバランサーのDNS名\u0026#34; } output \u0026#34;asg_name\u0026#34; { value = aws_autoscaling_group.example.name description = \u0026#34;Auto Scaling Groupの名前\u0026#34; } デプロイ # terraform init terraform apply Step 3: 動作確認 # terraform consoleで確認 # terraform console \u0026gt; data.terraform_remote_state.db.outputs { \u0026#34;address\u0026#34; = \u0026#34;terraform-up-and-running-xxx.rds.amazonaws.com\u0026#34; \u0026#34;port\u0026#34; = 3306 } \u0026gt; exit ブラウザで確認 # # ALBのDNS名を取得 terraform output alb_dns_name # curlで確認 curl http://\u0026lt;ALB_DNS_NAME\u0026gt; 「Hello, World」と「DB address」「DB port」が表示されれば成功。\nクリーンアップ: 依存関係と削除順序 # なぜ削除順序が重要なのか # Terraformリソースには依存関係がある。依存されているリソースを先に削除しようとするとエラーになる。\n[Webサーバー] ──依存──→ [RDS] │ │ │ └── 接続情報（address/port）を参照 │ └── terraform_remote_state でRDSのステートを参照 [S3/DynamoDB] │ └── 全プロジェクトのステートを保管・ロック 正しい削除順序: 依存する側 → 依存される側\n# 1. Webサーバー（RDSに依存） cd stage/services/webserver-cluster terraform destroy # 2. RDS cd ../../../stage/data-stores/mysql terraform destroy # 3. S3/DynamoDB（全体のバックエンド）- 必要な場合のみ 逆順で削除しようとした場合:\nS3を先に削除 → Webサーバーのステートにアクセスできずエラー RDSを先に削除 → Webサーバーの terraform_remote_state がエラー 構築したアーキテクチャ # ┌─────────────────────────────────────────────────────────────────┐ │ S3 Backend │ │ ├── stage/data-stores/mysql/terraform.tfstate ← RDSの状態 │ │ └── stage/services/webserver-cluster/terraform.tfstate │ └────────────────────────────────────────────────────────────────┘ │ │ terraform_remote_state で参照 ▼ ┌─────────────────────────────────────────────────────────────────┐ │ Webサーバー │ │ ┌──────────────────┐ ┌──────────────────┐ │ │ │ ALB (port 80) │───▶│ ASG (EC2 x2) │ │ │ └──────────────────┘ └──────────────────┘ │ │ │ │ │ │ DB接続情報を取得 │ │ ▼ │ │ ┌──────────────────┐ │ │ │ RDS (MySQL) │ │ │ └──────────────────┘ │ └─────────────────────────────────────────────────────────────────┘ 完成形のコード # ディレクトリ構成 # stage/ ├── data-stores/ │ └── mysql/ │ ├── main.tf │ ├── variables.tf │ └── outputs.tf └── services/ └── webserver-cluster/ ├── main.tf ├── variables.tf ├── outputs.tf └── user-data.sh stage/data-stores/mysql/ main.tf\nprovider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } terraform { backend \u0026#34;s3\u0026#34; { key = \u0026#34;stage/data-stores/mysql/terraform.tfstate\u0026#34; bucket = \u0026#34;tf-state-backend-20251128\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true } } resource \u0026#34;aws_db_instance\u0026#34; \u0026#34;example\u0026#34; { identifier_prefix = \u0026#34;terraform-up-and-running\u0026#34; engine = \u0026#34;mysql\u0026#34; allocated_storage = 10 instance_class = \u0026#34;db.t3.micro\u0026#34; skip_final_snapshot = true db_name = var.db_name username = var.db_username password = var.db_password } variables.tf\nvariable \u0026#34;db_name\u0026#34; { description = \u0026#34;データベース名\u0026#34; type = string default = \u0026#34;example_database\u0026#34; } variable \u0026#34;db_username\u0026#34; { description = \u0026#34;データベースのユーザー名\u0026#34; type = string sensitive = true } variable \u0026#34;db_password\u0026#34; { description = \u0026#34;データベースのパスワード\u0026#34; type = string sensitive = true } outputs.tf\noutput \u0026#34;address\u0026#34; { value = aws_db_instance.example.address description = \u0026#34;データベースの接続エンドポイント\u0026#34; } output \u0026#34;port\u0026#34; { value = aws_db_instance.example.port description = \u0026#34;データベースのポート番号\u0026#34; } stage/services/webserver-cluster/ main.tf\nprovider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } terraform { backend \u0026#34;s3\u0026#34; { bucket = \u0026#34;tf-state-backend-20251128\u0026#34; key = \u0026#34;stage/services/webserver-cluster/terraform.tfstate\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true } } # ----------------------------------------------------------------------------- # Data Sources # ----------------------------------------------------------------------------- data \u0026#34;aws_vpc\u0026#34; \u0026#34;default\u0026#34; { default = true } data \u0026#34;aws_subnets\u0026#34; \u0026#34;default\u0026#34; { filter { name = \u0026#34;vpc-id\u0026#34; values = [data.aws_vpc.default.id] } } data \u0026#34;terraform_remote_state\u0026#34; \u0026#34;db\u0026#34; { backend = \u0026#34;s3\u0026#34; config = { bucket = \u0026#34;tf-state-backend-20251128\u0026#34; key = \u0026#34;stage/data-stores/mysql/terraform.tfstate\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; } } # ----------------------------------------------------------------------------- # Launch Template \u0026amp; Auto Scaling Group # ----------------------------------------------------------------------------- resource \u0026#34;aws_launch_template\u0026#34; \u0026#34;example\u0026#34; { image_id = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; instance_type = \u0026#34;t2.micro\u0026#34; vpc_security_group_ids = [aws_security_group.instance.id] user_data = base64encode(templatefile(\u0026#34;user-data.sh\u0026#34;, { server_port = var.server_port db_address = data.terraform_remote_state.db.outputs.address db_port = data.terraform_remote_state.db.outputs.port })) } resource \u0026#34;aws_autoscaling_group\u0026#34; \u0026#34;example\u0026#34; { vpc_zone_identifier = data.aws_subnets.default.ids launch_template { id = aws_launch_template.example.id version = \u0026#34;$Latest\u0026#34; } target_group_arns = [aws_lb_target_group.asg.arn] health_check_type = \u0026#34;ELB\u0026#34; min_size = 2 max_size = 10 tag { key = \u0026#34;Name\u0026#34; value = \u0026#34;terraform-asg-example\u0026#34; propagate_at_launch = true } } # ----------------------------------------------------------------------------- # Security Groups # ----------------------------------------------------------------------------- resource \u0026#34;aws_security_group\u0026#34; \u0026#34;instance\u0026#34; { name = var.instance_security_group_name ingress { from_port = var.server_port to_port = var.server_port protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } resource \u0026#34;aws_security_group\u0026#34; \u0026#34;alb\u0026#34; { name = var.alb_security_group_name ingress { from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } # ----------------------------------------------------------------------------- # Application Load Balancer # ----------------------------------------------------------------------------- resource \u0026#34;aws_lb\u0026#34; \u0026#34;example\u0026#34; { name = var.alb_name load_balancer_type = \u0026#34;application\u0026#34; subnets = data.aws_subnets.default.ids security_groups = [aws_security_group.alb.id] } resource \u0026#34;aws_lb_listener\u0026#34; \u0026#34;http\u0026#34; { load_balancer_arn = aws_lb.example.arn port = 80 protocol = \u0026#34;HTTP\u0026#34; default_action { type = \u0026#34;fixed-response\u0026#34; fixed_response { content_type = \u0026#34;text/plain\u0026#34; message_body = \u0026#34;404: page not found\u0026#34; status_code = 404 } } } resource \u0026#34;aws_lb_target_group\u0026#34; \u0026#34;asg\u0026#34; { name = var.alb_name port = var.server_port protocol = \u0026#34;HTTP\u0026#34; vpc_id = data.aws_vpc.default.id health_check { path = \u0026#34;/\u0026#34; protocol = \u0026#34;HTTP\u0026#34; matcher = \u0026#34;200\u0026#34; interval = 15 timeout = 3 healthy_threshold = 2 unhealthy_threshold = 2 } } resource \u0026#34;aws_lb_listener_rule\u0026#34; \u0026#34;asg\u0026#34; { listener_arn = aws_lb_listener.http.arn priority = 100 condition { path_pattern { values = [\u0026#34;*\u0026#34;] } } action { type = \u0026#34;forward\u0026#34; target_group_arn = aws_lb_target_group.asg.arn } } variables.tf\nvariable \u0026#34;server_port\u0026#34; { description = \u0026#34;HTTPリクエストを受け付けるポート番号\u0026#34; type = number default = 8080 } variable \u0026#34;alb_name\u0026#34; { description = \u0026#34;ALBの名前\u0026#34; type = string default = \u0026#34;terraform-asg-example\u0026#34; } variable \u0026#34;alb_security_group_name\u0026#34; { description = \u0026#34;ALB用セキュリティグループの名前\u0026#34; type = string default = \u0026#34;terraform-example-alb\u0026#34; } variable \u0026#34;instance_security_group_name\u0026#34; { description = \u0026#34;EC2インスタンス用セキュリティグループの名前\u0026#34; type = string default = \u0026#34;terraform-example-instance\u0026#34; } outputs.tf\noutput \u0026#34;alb_dns_name\u0026#34; { value = aws_lb.example.dns_name description = \u0026#34;ロードバランサーのDNS名\u0026#34; } output \u0026#34;asg_name\u0026#34; { value = aws_autoscaling_group.example.name description = \u0026#34;Auto Scaling Groupの名前\u0026#34; } user-data.sh\n#!/bin/bash cd /home/ec2-user cat \u0026gt; index.html \u0026lt;\u0026lt;EOF \u0026lt;h1\u0026gt;Hello, World\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;DB address: ${db_address}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;DB port: ${db_port}\u0026lt;/p\u0026gt; EOF nohup python3 -m http.server ${server_port} \u0026amp; まとめ # 学んだこと # 項目 内容 ファイルレイアウト分離 環境・コンポーネントごとにディレクトリを分けて完全分離 outputs.tf 他プロジェクトに公開したい値を定義 terraform_remote_state 別プロジェクトのoutputを参照 templatefile 外部ファイルに変数を埋め込む 削除順序 依存する側 → 依存される側の順で削除 ワークスペース vs ファイルレイアウト # 観点 ワークスペース ファイルレイアウト 設定の手軽さ 簡単 ディレクトリ構成が必要 権限分離 困難（同一バックエンド） 可能（別バックエンド） 可視性 低い 高い（ディレクトリ名で明確） コード重複 なし あり（ch4のモジュールで解決） 推奨用途 個人開発・実験 本番環境・チーム開発 チェックリスト # 各コンポーネントのkeyは一意か RDSのoutputs.tfでaddress/portを出力しているか terraform_remote_stateのkeyはRDSと一致しているか 削除は依存関係の逆順で行っているか 参考 # 詳解 Terraform 第3版 ―Infrastructure as Codeを実現する 著者：Yevgeniy Brikman 訳者：松浦 隼人 出版社：オライリージャパン 出版年：2023年 Terraform公式ドキュメント Terraformステート管理 Part1 - S3リモートバックエンドとワークスペース ","date":"2025年 11月 28日","externalUrl":null,"permalink":"/posts/251128193149_terraform-file-layout-separation/","section":"Posts","summary":"","title":"Terraformステート管理 Part2 - ファイルレイアウトとterraform_remote_state","type":"posts"},{"content":" 今日学んだこと # Terraformのステート管理について、S3リモートバックエンドの構築からワークスペースによる環境分離まで実践した。途中でステートファイルの上書き事故も経験し、その復旧作業から多くの教訓を得た。\nTerraformステートとは # Terraformはインフラの現在状態をterraform.tfstateというファイルに記録している。terraform planやterraform applyを実行すると、このステートファイルとAWSの実際の状態を比較して差分を検出する。\n{ \u0026#34;version\u0026#34;: 4, \u0026#34;terraform_version\u0026#34;: \u0026#34;1.6.0\u0026#34;, \u0026#34;serial\u0026#34;: 42, \u0026#34;resources\u0026#34;: [] } 個人開発ではローカル保存で問題ないが、チーム開発では以下の課題が発生する\n課題 問題点 共有 メンバー間でステートを共有できない ロック 同時編集で競合が発生する セキュリティ 機密情報がローカルに残る これを解決するのがリモートバックエンド。\nStep 1: リモートバックエンド用のS3・DynamoDBを作成 # ディレクトリ作成 # mkdir -p ~/terraform-state-study cd ~/terraform-state-study main.tfを作成 # # main.tf provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } # S3バケット（ステートファイル保管用） resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;terraform_state\u0026#34; { # 重要: バケット名はAWS全体でグローバルに一意にすること bucket = \u0026#34;tf-state-backend-20251128\u0026#34; # 誤削除防止（学習時はコメントアウト） # lifecycle { # prevent_destroy = true # } } # バージョニング有効化（ロールバック可能に） resource \u0026#34;aws_s3_bucket_versioning\u0026#34; \u0026#34;enabled\u0026#34; { bucket = aws_s3_bucket.terraform_state.id versioning_configuration { status = \u0026#34;Enabled\u0026#34; } } # サーバーサイド暗号化 resource \u0026#34;aws_s3_bucket_server_side_encryption_configuration\u0026#34; \u0026#34;default\u0026#34; { bucket = aws_s3_bucket.terraform_state.id rule { apply_server_side_encryption_by_default { sse_algorithm = \u0026#34;AES256\u0026#34; } } } # パブリックアクセスブロック resource \u0026#34;aws_s3_bucket_public_access_block\u0026#34; \u0026#34;public_access\u0026#34; { bucket = aws_s3_bucket.terraform_state.id block_public_acls = true block_public_policy = true ignore_public_acls = true restrict_public_buckets = true } # DynamoDBテーブル（ロック用） resource \u0026#34;aws_dynamodb_table\u0026#34; \u0026#34;terraform_locks\u0026#34; { name = \u0026#34;tf-state-locks\u0026#34; billing_mode = \u0026#34;PAY_PER_REQUEST\u0026#34; hash_key = \u0026#34;LockID\u0026#34; # 大文字小文字を完全一致させること attribute { name = \u0026#34;LockID\u0026#34; type = \u0026#34;S\u0026#34; } } デプロイ # terraform init terraform validate terraform apply 最初にtf-state-backendというバケット名で試したところ、既に他のユーザーに使われていてエラーになった。S3バケット名はグローバルで一意である必要があるため、日付を追加して解決した。\nlifecycleは誤削除を防止することが目的なので、リソース削除時はコメントアウトが必要。\nlifecycle { prevent_destroy = true } Step 2: ステートをS3に移行 # この時点ではステートはまだローカルに保存されている。S3に移行するためにbackend設定を追加する。\nbackend.hclを作成（部分設定） # backendブロックでは変数が使えないため、共通設定を外部ファイルに切り出す。\n# backend.hcl bucket = \u0026#34;tf-state-backend-20251128\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true main.tfにbackend設定を追加 # terraform { backend \u0026#34;s3\u0026#34; { key = \u0026#34;global/s3/terraform.tfstate\u0026#34; } } ステートを移行 # terraform init -backend-config=backend.hcl 「既存のステートをS3にコピーするか？」と聞かれるのでyesを入力。\nS3コンソールでglobal/s3/terraform.tfstateが作成されていることを確認できた。\nStep 3: ワークスペースによる分離を体験 # 同じコードで複数の環境（default、staging、prodなど）を管理する仕組み。\nワークスペース用ディレクトリ作成 # mkdir -p ~/terraform-state-study-workspace cd ~/terraform-state-study-workspace main.tfを作成 # provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } resource \u0026#34;aws_instance\u0026#34; \u0026#34;example\u0026#34; { ami = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; instance_type = \u0026#34;t2.micro\u0026#34; } terraform { backend \u0026#34;s3\u0026#34; { # 重要: Step 1（リモートバックエンド用）と異なるkeyを使用すること！ key = \u0026#34;workspace-example/terraform.tfstate\u0026#34; bucket = \u0026#34;tf-state-backend-20251128\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true } } ワークスペースの操作 # terraform init terraform apply # 現在のワークスペース確認 terraform workspace show # =\u0026gt; default # 新しいワークスペース作成 terraform workspace new example1 terraform apply # 別のEC2が作成される # さらに作成 terraform workspace new example2 terraform apply # 一覧確認 terraform workspace list # default # example1 # * example2 # 切り替え terraform workspace select example1 S3には以下のパスでステートが保存される：\ns3://bucket/ ├── workspace-example/terraform.tfstate # default └── env:/ ├── example1/workspace-example/terraform.tfstate └── example2/workspace-example/terraform.tfstate クリーンアップ # # 各ワークスペースでdestroy terraform workspace select example1 \u0026amp;\u0026amp; terraform destroy terraform workspace select example2 \u0026amp;\u0026amp; terraform destroy terraform workspace select default \u0026amp;\u0026amp; terraform destroy 実際に起きたトラブルと教訓 # 事故: 同じkeyを使い回してステートが上書きされた # Step 3（ワークスペース）でterraform applyを実行した際、最初はStep 1と同じkey（global/s3/terraform.tfstate）を使ってしまった。\nその結果：\nStep 1で作成したS3・DynamoDBリソースのステートが上書きされた Step 3のコードにはDynamoDBの定義がないため、Terraformは「削除すべきリソース」と判断 DynamoDBテーブルが削除された 以降のTerraform操作でロックが取れずエラー Error: Error acquiring the state lock ResourceNotFoundException: Requested resource not found 復旧方法 # # 緊急時のみ: ロックをスキップしてdestroy terraform destroy -lock=false S3バケットはバージョニングが有効なため、全オブジェクトバージョンを削除しないと削除できない：\n# オブジェクトバージョン確認 aws s3api list-object-versions --bucket \u0026lt;バケット名\u0026gt; --region ap-northeast-1 # 全バージョン削除後、バケット削除 aws s3 rb s3://\u0026lt;バケット名\u0026gt; 教訓 # 教訓 対策 keyは必ず一意にする 各プロジェクトでproject-name/terraform.tfstateのように分ける バックエンドのインフラは慎重に S3・DynamoDBが破壊されると全てに影響する -lock=falseは緊急時のみ 競合リスクがあるため通常は使用しない ファイルレイアウトによる分離（概要） # ワークスペースには以下の欠点がある：\n全環境で同じバックエンドを使用（権限分離が困難） どのワークスペースにいるか分かりにくい 誤操作で本番環境を破壊するリスク より堅牢な分離には、環境ごとにディレクトリを分ける方法が推奨される：\nterraform-project/ ├── stage/ # ステージング環境 │ ├── data-stores/mysql/ # DB層 │ └── services/webserver-cluster/ # App層 └── prod/ # 本番環境（完全に別管理） 分離したコンポーネント間（例: RDSとWebサーバー）で情報を共有するには、terraform_remote_stateデータソースを使用する。\n詳細な実装手順（RDS構築、terraform_remote_stateによる連携、templatefile関数の活用）はPart2で解説。\n完成形のコード # ディレクトリ構成 # ~/terraform-state-study/ # Step 1: リモートバックエンド用 ├── main.tf └── backend.hcl ~/terraform-state-study-workspace/ # Step 3: ワークスペース検証用 └── main.tf Step 1: リモートバックエンド用（~/terraform-state-study/） main.tf\nprovider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } # S3バケット（ステートファイル保管用） resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;terraform_state\u0026#34; { bucket = \u0026#34;tf-state-backend-20251128\u0026#34; # lifecycle { # prevent_destroy = true # } } # バージョニング有効化 resource \u0026#34;aws_s3_bucket_versioning\u0026#34; \u0026#34;enabled\u0026#34; { bucket = aws_s3_bucket.terraform_state.id versioning_configuration { status = \u0026#34;Enabled\u0026#34; } } # サーバーサイド暗号化 resource \u0026#34;aws_s3_bucket_server_side_encryption_configuration\u0026#34; \u0026#34;default\u0026#34; { bucket = aws_s3_bucket.terraform_state.id rule { apply_server_side_encryption_by_default { sse_algorithm = \u0026#34;AES256\u0026#34; } } } # パブリックアクセスブロック resource \u0026#34;aws_s3_bucket_public_access_block\u0026#34; \u0026#34;public_access\u0026#34; { bucket = aws_s3_bucket.terraform_state.id block_public_acls = true block_public_policy = true ignore_public_acls = true restrict_public_buckets = true } # DynamoDBテーブル（ロック用） resource \u0026#34;aws_dynamodb_table\u0026#34; \u0026#34;terraform_locks\u0026#34; { name = \u0026#34;tf-state-locks\u0026#34; billing_mode = \u0026#34;PAY_PER_REQUEST\u0026#34; hash_key = \u0026#34;LockID\u0026#34; attribute { name = \u0026#34;LockID\u0026#34; type = \u0026#34;S\u0026#34; } } terraform { backend \u0026#34;s3\u0026#34; { key = \u0026#34;global/s3/terraform.tfstate\u0026#34; } } backend.hcl\nbucket = \u0026#34;tf-state-backend-20251128\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true Step 3: ワークスペース用（~/terraform-state-study-workspace/） main.tf\nprovider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } resource \u0026#34;aws_instance\u0026#34; \u0026#34;example\u0026#34; { ami = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; instance_type = \u0026#34;t2.micro\u0026#34; } terraform { backend \u0026#34;s3\u0026#34; { key = \u0026#34;workspace-example/terraform.tfstate\u0026#34; bucket = \u0026#34;tf-state-backend-20251128\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; dynamodb_table = \u0026#34;tf-state-locks\u0026#34; encrypt = true } } まとめ # 学んだこと # リモートバックエンド: S3 + DynamoDBでステート管理とロックを実現 部分設定: backend.hclで共通設定を切り出してコピペを削減 ワークスペース: 簡易な環境分離だが、可視性が低く誤操作リスクあり ファイルレイアウト: 本番環境の分離には環境ごとのディレクトリ分割が推奨（Part2で実践） チェックリスト # S3バケット名はグローバルで一意か DynamoDBのプライマリキーはLockID（大文字小文字一致）か 各プロジェクトのkeyは一意か 参考 # 詳解 Terraform 第3版 ―Infrastructure as Codeを実現する 著者：Yevgeniy Brikman 訳者：松浦 隼人 出版社：オライリージャパン 出版年：2023年 Terraform公式ドキュメント Terraformステート管理 Part2 - ファイルレイアウトとterraform_remote_state ","date":"2025年 11月 28日","externalUrl":null,"permalink":"/posts/251128185824_terraform-state-management-intro/","section":"Posts","summary":"","title":"Terraformステート管理 Part1 - S3リモートバックエンドとワークスペース","type":"posts"},{"content":" はじめに # 本記事は「詳解Terraform」のch2で学んだ内容を参考にしてハンズオン形式でまとめたものです。 Terraformを使って、ゼロからAWS環境を構築し、最後にすべて削除するまでを一気に体験します。\n最終的に作るもの # [ユーザー] → [ALB:80] → [ASG] → [EC2 × 2台:8080] ALB（Application Load Balancer）でトラフィックを受け付け Auto Scaling Group（ASG）で2台のEC2を管理 各EC2はポート8080でWebサーバを起動 1. 事前準備 # 1-1. AWSアカウントの作成 # AWSアカウントがない場合は、AWS公式サイトから作成してください。\n作業用のIAMユーザーを作成し、適切な権限を付与することを推奨します。\n1-2. AWS CLIの設定 # # AWS CLIをインストール（Ubuntu/WSL） sudo apt update sudo apt install -y unzip curl curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install # バージョン確認 aws --version # 認証情報を設定 aws configure # → Access Key ID, Secret Access Key, Region(ap-northeast-1)を入力 1-3. Terraformのインストール # # Ubuntu/WSL sudo apt update \u0026amp;\u0026amp; sudo apt install -y gnupg software-properties-common # HashiCorpのGPGキーを追加 wget -O- https://apt.releases.hashicorp.com/gpg | \\ gpg --dearmor | \\ sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg \u0026gt; /dev/null # リポジトリを追加 echo \u0026#34;deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] \\ https://apt.releases.hashicorp.com $(lsb_release -cs) main\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/hashicorp.list # Terraformをインストール sudo apt update \u0026amp;\u0026amp; sudo apt install -y terraform # バージョン確認 terraform version 1-4. 作業ディレクトリの作成 # mkdir terraform-handson cd terraform-handson 2. サーバ1台だけデプロイ # まずは最もシンプルな構成から。EC2インスタンス1台をデプロイします。\nなぜこの工程から始めるのか？ Terraformの基本であるprovider（どのクラウドを使うか）とresource（何を作るか）の概念を理解するため。また、init → plan → applyという基本ワークフローを体験することで、IaCの「コードでインフラを定義し、コマンドで構築する」流れを掴む。\n2-1. main.tfを作成 # provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } resource \u0026#34;aws_instance\u0026#34; \u0026#34;example\u0026#34; { ami = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; # Amazon Linux 2023（2025年11月時点） instance_type = \u0026#34;t2.micro\u0026#34; tags = { Name = \u0026#34;terraform-example\u0026#34; } } 2-2. Terraformの基本コマンド # # プロバイダのダウンロード（初回のみ） terraform init # 実行計画を確認（何が作られるか） terraform plan # 実際に作成 terraform apply # → \u0026#34;yes\u0026#34; と入力 2-3. 確認 # aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:Name,Values=terraform-example\u0026#34; \\ --query \u0026#34;Reservations[].Instances[].{ID:InstanceId,State:State.Name}\u0026#34; \\ --output table ここまでで学んだこと # 要素 説明 provider どのクラウドを使うか resource 何を作るか terraform init 初期化（プロバイダのダウンロード） terraform plan 実行計画の確認 terraform apply 実際に適用 3. Webサーバ1台のデプロイ # EC2を起動しただけではアクセスできません。セキュリティグループを追加し、Webサーバを動かします。\nなぜセキュリティグループが必要なのか？ AWSのEC2はデフォルトでインバウンド・アウトバウンドの両方のトラフィックを許可していない。外部からWebサーバにアクセスするには、セキュリティグループで明示的にポートを開放する必要がある。\nなぜポート8080を使うのか？ 1024以下のポート（80など）でリッスンするにはroot権限が必要。セキュリティ上、一般ユーザー権限で起動できる8080を使用する。\nなぜuser_dataを使うのか？ EC2起動時に自動でスクリプトを実行できる。手動でSSH接続してコマンドを打つ必要がなく、インフラ構築を完全に自動化できる。\n3-1. main.tfを更新 # provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } resource \u0026#34;aws_instance\u0026#34; \u0026#34;example\u0026#34; { ami = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; # Amazon Linux 2023（2025年11月時点） instance_type = \u0026#34;t2.micro\u0026#34; vpc_security_group_ids = [aws_security_group.instance.id] user_data = \u0026lt;\u0026lt;-EOF #!/bin/bash cd /home/ec2-user echo \u0026#34;Hello, World\u0026#34; \u0026gt; index.html nohup python3 -m http.server 8080 \u0026amp; EOF user_data_replace_on_change = true tags = { Name = \u0026#34;terraform-example\u0026#34; } } resource \u0026#34;aws_security_group\u0026#34; \u0026#34;instance\u0026#34; { name = \u0026#34;terraform-example-instance\u0026#34; ingress { from_port = 8080 to_port = 8080 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } 3-2. 適用と確認 # terraform apply # パブリックIPを取得 PUBLIC_IP=$(aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:Name,Values=terraform-example\u0026#34; \u0026#34;Name=instance-state-name,Values=running\u0026#34; \\ --query \u0026#34;Reservations[].Instances[].PublicIpAddress\u0026#34; \\ --output text) # アクセス確認 curl http://$PUBLIC_IP:8080 # → \u0026#34;Hello, World\u0026#34; が表示されればOK ここまでで学んだこと # 要素 説明 user_data 起動時に実行するスクリプト aws_security_group ファイアウォール設定 リソース参照 aws_security_group.instance.idのように他リソースを参照 4. 設定変更可能なWebサーバのデプロイ # ポート番号がコード内に散らばっています。変数化してDRY原則を守ります。\nなぜ変数化が必要なのか？ 現状、ポート番号8080がセキュリティグループとuser_dataの2箇所に書かれている。これはDRY原則（Don\u0026rsquo;t Repeat Yourself）に違反しており、変更時に片方だけ修正し忘れるリスクがある。変数化することで、1箇所の変更ですべてに反映される。\n出力変数（output）の用途は？ terraform apply後にパブリックIPなどの情報を自動表示できる。AWS CLIで毎回確認する手間が省け、他のTerraform構成の入力としても利用可能。\n4-1. 変数を追加 # variable \u0026#34;server_port\u0026#34; { description = \u0026#34;The port the server will use for HTTP requests\u0026#34; type = number default = 8080 } 4-2. 変数を使う # セキュリティグループを修正：\nresource \u0026#34;aws_security_group\u0026#34; \u0026#34;instance\u0026#34; { name = \u0026#34;terraform-example-instance\u0026#34; ingress { from_port = var.server_port to_port = var.server_port protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } user_dataも修正：\nuser_data = \u0026lt;\u0026lt;-EOF #!/bin/bash cd /home/ec2-user echo \u0026#34;Hello, World\u0026#34; \u0026gt; index.html nohup python3 -m http.server ${var.server_port} \u0026amp; EOF 4-3. 出力変数を追加 # output \u0026#34;public_ip\u0026#34; { value = aws_instance.example.public_ip description = \u0026#34;The public IP of the web server\u0026#34; } 4-4. 適用と確認 # terraform apply # 出力変数を確認 terraform output public_ip ここまでで学んだこと # 要素 説明 variable 入力変数の定義 var.xxx 変数の参照 ${var.xxx} 文字列内での補間 output 出力変数（apply後に表示） 5. Webサーバのクラスタのデプロイ # 1台だけでは単一障害点です。Auto Scaling Group（ASG）で複数台を管理します。\nなぜASGが必要なのか？ サーバ1台のみの運用は単一障害点（SPOF）となり、障害発生時にサービスが完全停止するリスクがある。ASGを使えば、複数台のEC2を自動管理し、障害時も自動復旧できる。\nなぜデータソース（data）を使うのか？ ASGはEC2を複数のサブネット（アベイラビリティゾーン）に分散配置する。既存のVPC/サブネット情報をTerraformで取得するためにdataブロックを使用する。これにより、1つのAZに障害が発生しても他のAZで稼働を継続できる。\nLaunch Templateとは？ ASGが新しいEC2を起動する際のテンプレート。AMI、インスタンスタイプ、セキュリティグループ、user_dataなどを定義する。\n5-1. データソースを追加 # VPCとサブネットの情報を取得：\ndata \u0026#34;aws_vpc\u0026#34; \u0026#34;default\u0026#34; { default = true } data \u0026#34;aws_subnets\u0026#34; \u0026#34;default\u0026#34; { filter { name = \u0026#34;vpc-id\u0026#34; values = [data.aws_vpc.default.id] } } 5-2. Launch Templateを追加 # ASGが起動するインスタンスの設定：\nresource \u0026#34;aws_launch_template\u0026#34; \u0026#34;example\u0026#34; { image_id = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; # Amazon Linux 2023（2025年11月時点） instance_type = \u0026#34;t2.micro\u0026#34; vpc_security_group_ids = [aws_security_group.instance.id] user_data = base64encode(\u0026lt;\u0026lt;-EOF #!/bin/bash cd /home/ec2-user echo \u0026#34;Hello, World\u0026#34; \u0026gt; index.html nohup python3 -m http.server ${var.server_port} \u0026amp; EOF ) } 5-3. ASGを追加 # resource \u0026#34;aws_autoscaling_group\u0026#34; \u0026#34;example\u0026#34; { vpc_zone_identifier = data.aws_subnets.default.ids launch_template { id = aws_launch_template.example.id version = \u0026#34;$Latest\u0026#34; } min_size = 2 max_size = 10 tag { key = \u0026#34;Name\u0026#34; value = \u0026#34;terraform-asg-example\u0026#34; propagate_at_launch = true } } 5-4. 古いEC2リソースを削除 # aws_instance \u0026quot;example\u0026quot; ブロックは削除してください。ASGがEC2を管理するようになります。\n5-5. 適用と確認 # terraform apply # 2台のインスタンスを確認 aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:Name,Values=terraform-asg-example\u0026#34; \u0026#34;Name=instance-state-name,Values=running\u0026#34; \\ --query \u0026#34;Reservations[].Instances[].{ID:InstanceId,IP:PublicIpAddress}\u0026#34; \\ --output table ここまでで学んだこと # 要素 説明 data 既存リソースの情報を取得（読み取り専用） aws_launch_template EC2の起動設定 aws_autoscaling_group 自動スケーリング設定 6. ロードバランサのデプロイ # 複数台のEC2に1つのエンドポイントでアクセスできるよう、ALBを追加します。\nなぜロードバランサが必要なのか？ ASGで複数台のEC2を起動しても、ユーザーは各EC2のIPアドレスを知らない。ロードバランサを使えば、ユーザーは1つのDNS名（エンドポイント）にアクセスするだけで、トラフィックが自動的に複数のEC2に分散される。\nALBの構成要素\nリスナ：特定のポート（80）とプロトコル（HTTP）でリクエストを受け付ける ターゲットグループ：リクエストを転送する先のEC2群。ヘルスチェックで正常なインスタンスのみに転送 リスナルール：リクエストのパスやホストに基づいて、どのターゲットグループに転送するか決定 なぜALB用のセキュリティグループが別途必要なのか？ ALBもAWSリソースなので、デフォルトでトラフィックを許可しない。ユーザーからのHTTPアクセス（インバウンド80）と、EC2へのヘルスチェック（アウトバウンド全ポート）を許可する設定が必要。\n6-1. ALB用の変数を追加 # variable \u0026#34;alb_name\u0026#34; { description = \u0026#34;The name of the ALB\u0026#34; type = string default = \u0026#34;terraform-asg-example\u0026#34; } variable \u0026#34;alb_security_group_name\u0026#34; { description = \u0026#34;The name of the security group for the ALB\u0026#34; type = string default = \u0026#34;terraform-example-alb\u0026#34; } 6-2. ALB用セキュリティグループを追加 # resource \u0026#34;aws_security_group\u0026#34; \u0026#34;alb\u0026#34; { name = var.alb_security_group_name # インバウンド：HTTP許可 ingress { from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } # アウトバウンド：すべて許可 egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } 6-3. ALB本体を追加 # resource \u0026#34;aws_lb\u0026#34; \u0026#34;example\u0026#34; { name = var.alb_name load_balancer_type = \u0026#34;application\u0026#34; subnets = data.aws_subnets.default.ids security_groups = [aws_security_group.alb.id] } 6-4. ターゲットグループを追加 # resource \u0026#34;aws_lb_target_group\u0026#34; \u0026#34;asg\u0026#34; { name = var.alb_name port = var.server_port protocol = \u0026#34;HTTP\u0026#34; vpc_id = data.aws_vpc.default.id health_check { path = \u0026#34;/\u0026#34; protocol = \u0026#34;HTTP\u0026#34; matcher = \u0026#34;200\u0026#34; interval = 15 timeout = 3 healthy_threshold = 2 unhealthy_threshold = 2 } } 6-5. リスナとルールを追加 # resource \u0026#34;aws_lb_listener\u0026#34; \u0026#34;http\u0026#34; { load_balancer_arn = aws_lb.example.arn port = 80 protocol = \u0026#34;HTTP\u0026#34; default_action { type = \u0026#34;fixed-response\u0026#34; fixed_response { content_type = \u0026#34;text/plain\u0026#34; message_body = \u0026#34;404: page not found\u0026#34; status_code = 404 } } } resource \u0026#34;aws_lb_listener_rule\u0026#34; \u0026#34;asg\u0026#34; { listener_arn = aws_lb_listener.http.arn priority = 100 condition { path_pattern { values = [\u0026#34;*\u0026#34;] } } action { type = \u0026#34;forward\u0026#34; target_group_arn = aws_lb_target_group.asg.arn } } 6-6. ASGにターゲットグループを紐付け # ASGリソースに2行追加：\nresource \u0026#34;aws_autoscaling_group\u0026#34; \u0026#34;example\u0026#34; { vpc_zone_identifier = data.aws_subnets.default.ids launch_template { id = aws_launch_template.example.id version = \u0026#34;$Latest\u0026#34; } target_group_arns = [aws_lb_target_group.asg.arn] # 追加 health_check_type = \u0026#34;ELB\u0026#34; # 追加 min_size = 2 max_size = 10 tag { key = \u0026#34;Name\u0026#34; value = \u0026#34;terraform-asg-example\u0026#34; propagate_at_launch = true } } 6-7. 出力変数を追加 # output \u0026#34;alb_dns_name\u0026#34; { value = aws_lb.example.dns_name description = \u0026#34;The domain name of the load balancer\u0026#34; } 6-8. 適用と確認 # terraform apply # ALBのDNS名を取得 terraform output alb_dns_name # アクセス確認（ALB起動に数分かかる） curl http://$(terraform output -raw alb_dns_name) # → \u0026#34;Hello, World\u0026#34; が表示されればOK ここまでで学んだこと # 要素 説明 aws_lb Application Load Balancer aws_lb_listener どのポートでリクエストを受けるか aws_lb_target_group リクエスト転送先のグループ aws_lb_listener_rule ルーティングルール 7. 後片付け（環境削除） # IaCの大きなメリット：作った環境を一発で削除できます。\nなぜterraform destroyが重要なのか？ AWSリソースは起動している限り課金が発生する。学習やテスト後は必ず削除してコストを抑える。手動で削除すると関連リソースの削除漏れが発生しやすいが、terraform destroyならTerraformが依存関係を考慮して正しい順序で全リソースを削除してくれる。\nIaCの真価 main.tfさえあれば、terraform applyでいつでも同じ環境を再構築できる。「環境構築手順書」が不要になり、環境の作成・削除が数分で完了する。\n7-1. 全リソースを削除 # terraform destroy # → \u0026#34;yes\u0026#34; と入力 7-2. 確認 # aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:Name,Values=terraform-asg-example\u0026#34; \\ --query \u0026#34;Reservations[].Instances[].{ID:InstanceId,State:State.Name}\u0026#34; \\ --output table # → terminated または空 まとめ # Terraformの基本ワークフロー # terraform init → terraform plan → terraform apply → terraform destroy (初期化) (計画確認) (適用) (削除) 今回構築したリソース # リソース 用途 EC2 Webサーバ Security Group ファイアウォール Launch Template EC2の起動設定 Auto Scaling Group EC2の自動管理 ALB ロードバランサ Target Group ALBの転送先 IaC（Infrastructure as Code）のメリット # 再現性：main.tfがあればいつでも同じ環境を構築可能 可視性：インフラ構成がコードとして明確 効率性：環境の作成・削除が数分で完了 バージョン管理：Gitで変更履歴を管理可能 コマンドチートシート # コマンド 用途 terraform init 初期化 terraform plan 実行計画確認 terraform apply 適用 terraform destroy 全削除 terraform output 出力変数表示 terraform validate 構文チェック 完成版コード # クリックして展開：最終的なmain.tf provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; } # --- 変数 --- variable \u0026#34;server_port\u0026#34; { description = \u0026#34;The port the server will use for HTTP requests\u0026#34; type = number default = 8080 } variable \u0026#34;alb_name\u0026#34; { description = \u0026#34;The name of the ALB\u0026#34; type = string default = \u0026#34;terraform-asg-example\u0026#34; } variable \u0026#34;alb_security_group_name\u0026#34; { description = \u0026#34;The name of the security group for the ALB\u0026#34; type = string default = \u0026#34;terraform-example-alb\u0026#34; } # --- データソース --- data \u0026#34;aws_vpc\u0026#34; \u0026#34;default\u0026#34; { default = true } data \u0026#34;aws_subnets\u0026#34; \u0026#34;default\u0026#34; { filter { name = \u0026#34;vpc-id\u0026#34; values = [data.aws_vpc.default.id] } } # --- セキュリティグループ --- resource \u0026#34;aws_security_group\u0026#34; \u0026#34;instance\u0026#34; { name = \u0026#34;terraform-example-instance\u0026#34; ingress { from_port = var.server_port to_port = var.server_port protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } resource \u0026#34;aws_security_group\u0026#34; \u0026#34;alb\u0026#34; { name = var.alb_security_group_name ingress { from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } } # --- Launch Template \u0026amp; ASG --- resource \u0026#34;aws_launch_template\u0026#34; \u0026#34;example\u0026#34; { image_id = \u0026#34;ami-03852a41f1e05c8e4\u0026#34; # Amazon Linux 2023（2025年11月時点） instance_type = \u0026#34;t2.micro\u0026#34; vpc_security_group_ids = [aws_security_group.instance.id] user_data = base64encode(\u0026lt;\u0026lt;-EOF #!/bin/bash cd /home/ec2-user echo \u0026#34;Hello, World\u0026#34; \u0026gt; index.html nohup python3 -m http.server ${var.server_port} \u0026amp; EOF ) } resource \u0026#34;aws_autoscaling_group\u0026#34; \u0026#34;example\u0026#34; { vpc_zone_identifier = data.aws_subnets.default.ids launch_template { id = aws_launch_template.example.id version = \u0026#34;$Latest\u0026#34; } target_group_arns = [aws_lb_target_group.asg.arn] health_check_type = \u0026#34;ELB\u0026#34; min_size = 2 max_size = 10 tag { key = \u0026#34;Name\u0026#34; value = \u0026#34;terraform-asg-example\u0026#34; propagate_at_launch = true } } # --- ALB --- resource \u0026#34;aws_lb\u0026#34; \u0026#34;example\u0026#34; { name = var.alb_name load_balancer_type = \u0026#34;application\u0026#34; subnets = data.aws_subnets.default.ids security_groups = [aws_security_group.alb.id] } resource \u0026#34;aws_lb_target_group\u0026#34; \u0026#34;asg\u0026#34; { name = var.alb_name port = var.server_port protocol = \u0026#34;HTTP\u0026#34; vpc_id = data.aws_vpc.default.id health_check { path = \u0026#34;/\u0026#34; protocol = \u0026#34;HTTP\u0026#34; matcher = \u0026#34;200\u0026#34; interval = 15 timeout = 3 healthy_threshold = 2 unhealthy_threshold = 2 } } resource \u0026#34;aws_lb_listener\u0026#34; \u0026#34;http\u0026#34; { load_balancer_arn = aws_lb.example.arn port = 80 protocol = \u0026#34;HTTP\u0026#34; default_action { type = \u0026#34;fixed-response\u0026#34; fixed_response { content_type = \u0026#34;text/plain\u0026#34; message_body = \u0026#34;404: page not found\u0026#34; status_code = 404 } } } resource \u0026#34;aws_lb_listener_rule\u0026#34; \u0026#34;asg\u0026#34; { listener_arn = aws_lb_listener.http.arn priority = 100 condition { path_pattern { values = [\u0026#34;*\u0026#34;] } } action { type = \u0026#34;forward\u0026#34; target_group_arn = aws_lb_target_group.asg.arn } } # --- 出力 --- output \u0026#34;alb_dns_name\u0026#34; { value = aws_lb.example.dns_name description = \u0026#34;The domain name of the load balancer\u0026#34; } 参考 # 詳解 Terraform 第3版 ―Infrastructure as Codeを実現する 著者：Yevgeniy Brikman 訳者：松浦 隼人 出版社：オライリージャパン 出版年：2023年 Terraform公式ドキュメント AWSプロバイダドキュメント ","date":"2025年 11月 28日","externalUrl":null,"permalink":"/posts/251128004323_terraform-aws-environment-setup-and-teardown-hands-on/","section":"Posts","summary":"","title":"TerraformでAWS環境を構築して削除するまで - 入門ハンズオン","type":"posts"},{"content":" はじめに：Terraformとは？ # TerraformはHashiCorp社が開発したオープンソースのInfrastructure as Code（IaC）ツール。\nサーバ、ネットワーク、データベースなどのインフラをコードで定義し、自動的に構築・変更・バージョン管理できる。\nTerraformはIaCツールの中でどこに位置するか # IaCツールは大きく5つに分類される\n分類 主な用途 代表例 アドホックなスクリプト シンプルな自動化 Bash, Python 設定管理ツール 既存サーバの設定 Ansible, Chef サーバテンプレーティング イメージからサーバ構築 Docker, Packer オーケストレーション コンテナ管理 Kubernetes プロビジョニングツール インフラ全体の作成 Terraform, CloudFormation Terraformはプロビジョニングツールに分類される。\nサーバ「上」に何かをインストールするのではなく、サーバ「自体」を作成するツール。\nTerraformの特徴 # 動作の仕組み # TerraformはGo言語で書かれたOSS。\n各端末のterraformバイナリから、AWSやAzureなどのクラウドプロバイダへAPIコールして動作する。\n他のIaCツールとの違い # 比較軸 Terraform Ansible CloudFormation ツール種別 プロビジョニング 設定管理 プロビジョニング インフラの扱い イミュータブル ミュータブル イミュータブル 言語スタイル 宣言型 手続き型/宣言型 宣言型 言語 HCL（DSL） YAML JSON/YAML マスタサーバ 不要 不要 不要（AWS管理） エージェント 不要 不要 不要 マルチクラウド ◯ ◯ ✕（AWS専用） Terraformを選ぶ理由 # エージェントレス：クラウドプロバイダのAPIを直接呼び出すため、各サーバにエージェントをインストールする必要がない マスタレス：マスタサーバの運用・メンテナンスが不要 宣言型言語：「こうなってほしい」を書くだけで、Terraformが差分を計算して適用してくれる マルチクラウド対応：AWS、Azure、GCPなど複数のプロバイダを同じ言語で管理できる 実際の使われ方 # Terraformは単体で使うこともあるが、他のツールと組み合わせることが多い：\nPacker + Terraform：Packerでサーバイメージを作成 → Terraformでそのイメージを使ってインフラ構築 Docker + Kubernetes + Terraform：Terraformでインフラ構築（K8sクラスタ含む） → Kubernetesでコンテナ管理 まとめ # Terraformはインフラをコードで管理するプロビジョニングツール 宣言型・マスタレス・エージェントレスという特徴を持つ クラウドプロバイダのAPIを直接呼び出すシンプルな仕組み 他のIaCツール（Docker、Kubernetesなど）と組み合わせて使われることが多い 参考資料 # 詳解 Terraform 第3版 ―Infrastructure as Codeを実現する 著者：Yevgeniy Brikman 訳者：松浦 隼人 出版社：オライリージャパン 出版年：2023年 ","date":"2025年 11月 27日","externalUrl":null,"permalink":"/posts/251127233855_what-is-terraform/","section":"Posts","summary":"","title":"Terraformとは？","type":"posts"},{"content":"","date":"2025年 11月 26日","externalUrl":null,"permalink":"/tags/chrome/","section":"Tags","summary":"","title":"Chrome","type":"tags"},{"content":" はじめに # 仕事の効率化のために、Googleドライブ内の検索をもっとスマートにできないかなと考えて、 Chromeのアドレスバーから直接検索できる機能を実装しました。 その結果、資料へのアクセスが劇的に向上したので、設定方法をメモします。\nChromeカスタム検索エンジンの設定手順 # ステップ1：設定画面を開く # 以下のいずれかの方法で設定画面を開きます\n方法A：URLchrome://settings/searchEnginesへ直接アクセス\n方法B：メニューから操作\nChromeの右上の「⋮」（3点メニュー）をクリック 「設定」を選択 左側メニューから「検索エンジン」を選択 「検索エンジンとサイト内検索を管理する」をクリック 注意：Chromeのバージョンによって表記が「サイト検索を管理」など微妙に異なる場合があります\nステップ2：検索エンジンを追加 # 「サイト内検索」セクションの「追加」ボタンをクリックし、以下の項目を入力します\n項目 説明 例 検索エンジン名 管理用の名前（任意） Drive Title Search ショートカット アドレスバーで使う短縮コマンド d URL（%s=検索語句） 検索用URL（%sが検索キーワードに置き換わる） https://drive.google.com/drive/search?q=title:%s ステップ3：動作確認 # Chromeのアドレスバーにショートカット（例：d）を入力 スペースまたはTabを押す → 検索モードに切り替わる 検索キーワードを入力してEnter カスタム検索一覧 # 自分が実際に登録した設定一覧が下記です。\nGoogleドライブ検索 # コマンド 設定名 URL 用途 d Drive Title Search https://drive.google.com/drive/search?q=title:%s タイトル検索 da Drive All Search https://drive.google.com/drive/search?q=%s 全文検索 ds Drive Sheets https://drive.google.com/drive/search?q=type:spreadsheet+%s スプレッドシート限定 dd Drive Docs https://drive.google.com/drive/search?q=type:document+%s ドキュメント限定 URL内の+はスペース扱いになります（例：type:spreadsheet+%s → type:spreadsheet 検索語）\nAI検索・開発ツール # ショートカット 検索エンジン名 URL 用途 pa Perplexity AI https://www.perplexity.ai/?q=%s AI対話型検索 gh GitHub https://github.com/search?q=%s リポジトリ・コード検索 qi Qiita https://qiita.com/search?q=%s 技術記事検索 wiki Wikipedia https://ja.wikipedia.org/wiki/Special:Search?search=%s Wikipedia内検索 検索演算子の活用 # 以下の演算子を組み合わせることで検索の精度を上げることができます。\ntitle: - タイトル限定検索 title:VPN：ファイル名に「VPN」を含むものだけを表示 \u0026quot;\u0026quot; - 完全一致検索（フレーズ検索） \u0026quot;エラー 503\u0026quot;：その並び順のフレーズしかヒットしない - - 除外検索 VPN -旧手順 -2023：「旧手順」「2023」を含むファイルを除外 他のサービスをカスタム検索に追加する方法 # URLの調べ方 # 追加したいサイトで実際に検索を実行（例：「test」で検索） 検索結果ページのURLをコピー URL内の検索キーワード部分（testなど）を%sに置き換える まとめ # Chromeのカスタム検索エンジン機能を活用することで、アドレスバーから直接検索できる環境を構築しました。\n実現できたこと # Googleドライブ検索の高速化\nタイトル検索（d）、全文検索（da）、ファイル種別検索（ds, dd）を設定 資料へのアクセス時間を体感10～15秒短縮 AI検索・開発ツールへの即座アクセス\nPerplexity AI、GitHub、Qiita、Wikipediaなどを登録 情報収集・技術調査の効率化 検索演算子との組み合わせ\ntitle:, \u0026quot;\u0026quot;, - を活用して検索精度を向上 ノイズの多い検索結果から必要な情報を素早く抽出 ","date":"2025年 11月 26日","externalUrl":null,"permalink":"/posts/251126031004_implement-custom-search-feature-in-chrome/","section":"Posts","summary":"","title":"Chromeにカスタム検索機能を実装する方法","type":"posts"},{"content":" はじめに # Terraformの勉強のために「詳解Terraform」を購入。 すこしずつ内容をTILとしてアウトプットして知識を定着させます。 今回のテーマは「IaC（Infrastructure as Code）の5つの分類」 ※IaCとは、インフラなどの環境をコードで記述できるようにしたツール全般を指す。\n書籍情報 # 詳解 Terraform 第3版 ―Infrastructure as Codeを実現する 著者：Yevgeniy Brikman 訳者：松浦 隼人 出版社：オライリージャパン 出版年：2023年 5つの分類 # IaCツールは以下の5つのカテゴリに分類されます。これらは対立するものではなく、それぞれ異なる役割を持ち、実際の開発現場では組み合わせて使用することが一般的です。\nアドホックなスクリプト 設定管理ツール サーバテンプレーティングツール オーケストレーションツール プロビジョニングツール アドホックなスクリプト # 作業や処理をpythonやshファイルとして作成して実行するスクリプト\n最もシンプルな自動化の方法 単純な処理を実装するなら向いているが、サーバ設定からデプロイまで処理するような複雑な 処理を実装する場合は、一から自力でコードを書く必要があるため、労力がかかる。\n設定管理ツール # 既存のサーバ上にソフトウェアなどをインストールするためのツール\n例：Chef・Puppet・Ansible コーディング規約によりファイル内容に一貫性を持たせることが可能 冪等性がある 1回限りの処理であればアドホックなスクリプトでも十分だが、何度実行しても同じ結果をもたらす冪等性が必要な場合は、Ansibleなどの設定管理ツールのほうが向いている Ansibleのモジュールには冪等性が組み込まれているため 配布 コードの配布により、ローリングデプロイなど複数のリモートサーバをまとめて管理することが可能。 サーバテンプレーティングツール # OSやソフトウェアをパッケージ化したイメージを作成し、そのイメージから環境を構築するツール\n例：Docker・Packer・Vagrant 「スナップショット」と呼ばれるOSやソフトウェアなどを含んだイメージを作成して、このスナップショットを使ってサーバ環境を構築する イメージを扱うツールには大別すると2つのカテゴリがある。\n仮想マシン\nハードウェアを含むコンピュータシステム全体をエミュレートする仕組み 例：VMware・VirtualBox ハイパーバイザを動かしてCPUやメモリなどを仮想化する これによりハイパーバイザ上で動かす仮想マシンイメージからは仮想化されてハードウェアのみ見えるようになる。 仮想環境とホストマシンを分離することが可能 仮想マシンイメージはPackerやVagrantなどのツールで定義可能 コンテナ\nOSのユーザスペースをエミュレートする仕組み プロセスやメモリなどを分離するためにDockerなどのコンテナエンジンを動作させる必要がある コンテナはユーザスペースのみ見えるようになる。 仮想マシンとコンテナの違い\n仮想マシン：ハードウェアレベルで仮想化・高度な分離性があり、セキュリティやコンプライアンス面で有利 コンテナ：OSレベルで仮想化・メモリ消費が少ない イミュータブルインフラ 一度構築・デプロイされたインフラ環境（サーバやコンテナなど）を変更せず、更新が必要な場合は新しい環境を丸ごと作り直して既存環境と入れ替える運用思想\nサーバテンプレーティングツールにおいて重要な考え プロビジョニングツール（Terraformなど）と組み合わせることで、インフラ全体のイミュータブル化も実現可能 オーケストレーションツール # 複数のシステムやサービス、アプリケーション間で行われる多数のタスクや ワークフローを自動的に統合・管理し、効率的に実行するためのソフトウェア\n例：Kubernetes プロビジョニングツール # サーバ自体を作成するようなツール\nインフラに関係しているたいていのものを作成できる（サーバ、データベース、ネットワーク構成、ロードバランサーなど） 例：Terraform・CloudFormation まとめ：IaCの概要 # IaCとは、インフラ環境をコードで記述・管理できるツール全般を指す。大別すると5つのカテゴリがある。\n各ツールの特徴と使い分け # ツール分類 主な用途 代表例 向いている場面 アドホックなスクリプト シンプルな自動化 Bash, Python 1回限りの処理、単純な作業の自動化 設定管理ツール 既存サーバの設定・ソフトウェアインストール Ansible, Chef, Puppet 複数サーバへのソフトウェアデプロイ、冪等性が必要な設定作業 サーバテンプレーティングツール イメージからサーバ環境を構築 Docker, Packer, Vagrant 環境の再現性確保、イミュータブルインフラの実現 オーケストレーションツール 複数システム・サービスの統合管理 Kubernetes コンテナの起動・停止・スケーリング、マイクロサービス管理 プロビジョニングツール インフラ全体の作成・管理 Terraform, CloudFormation サーバ・ネットワーク・DB等のインフラリソース作成 ツール選択の基本方針 # シンプルな自動化：アドホックなスクリプト 既存環境の設定変更：設定管理ツール 環境の再現性重視：サーバテンプレーティングツール コンテナ管理：オーケストレーションツール インフラ全体の構築：プロビジョニングツール（Terraform等） 実際の開発現場では、これらのツールを組み合わせて使用することが多い。 例：Terraformでインフラを構築 → Ansibleでソフトウェアをインストール → Dockerでアプリケーションを動かす → Kubernetesで管理\n","date":"2025年 11月 24日","externalUrl":null,"permalink":"/posts/251124162641_iac-five-classifications/","section":"Posts","summary":"","title":"IaC（Infrastructure as Code）の5つの分類","type":"posts"},{"content":" はじめに # 本屋で何気なく読んでみて、成長しないケースとして「スキルマニア」が紹介されていた。思いっきり自分に当てはまるなと考え、刺さった。この成長しないスキルマニアからどうすれば成長するようになれるかを知りたくてこの本を購入した。\nこのメモの目的：成長しないスキルマニアから成長できる人物へ変わるための具体的なアクションを知る\n書籍情報 # BCGの育つ力・育てる力 著者：木村亮示・木山聡 出版社：日経BP 出版年：2024年 BCGとは？ # アメリカを本拠地としている有名なコンサルティンググループ\n基本情報技術者試験でも出題される「PPM」はここが発案したらしい そもそもスキルマニアとは？ # 技術や資格だけを集めて、満足しているタイプの人\nいわゆる優等生タイプがなりやすい コレクション型：いろいろな資格を入手する 突き詰め型：特定の分野を深堀りしつづける 自分の振り返り：コレクション型だと思う。資格を集めているが、実務に活かせているかとなると疑問点がある 成長するために必要なのは？ # マインドセットとスキルの2つが必要。 スキルが不要というわけではない。ただし、スキルだけでは不足。\n具体的なマインドセット # 思いやり：自分だけを満足させることでは直ぐに限界が来る 素直さ：自分の行動を分析・反省して行動する 折れない心：できるかできないか不安でも、やるしかない 本の例え話（野球のピッチャー） # 球速を上げたり、変化球を覚えるだけでは勝てない。使い方を学ぶべき。 実務経験を積みながら試行錯誤して成長していく必要がある。 中身となるアイデアや思いがないといくらスキルがあっても意味ない。\n実践に向けたアクション # 実務での試行錯誤を重視する\n資格勉強で得た知識を実務で試し、反省と改善を繰り返す 職場の実際の課題に対して学んだスキルを適用してみる 資格・学習の位置づけを見直す\n資格勉強はあくまで知識やスキルの入門として位置づける 「資格を取ること」ではなく「学んだことを活かすこと」を目標にする 他者への貢献を意識する\nチームや組織の課題を見つけ、解決に取り組む 学んだ知識を同僚と共有し、チーム全体のレベルアップに貢献する 参考資料 # Wikipedia：ボストン・コンサルティング・グループ ","date":"2025年 11月 23日","externalUrl":null,"permalink":"/posts/251123232747_bcg-ikiru-chikara-sodateru-chikara-skill-mania-karano-dasshutsu/","section":"Posts","summary":"","title":"【読書メモ】BCGの育つ力・育てる力：スキルマニアからの脱却","type":"posts"},{"content":" はじめに # ヘルプデスク・監視運用でTeratermを使ってログ調査を行う際のコマンドを備忘録としてまとめる。\n前提条件 # サービスログは.logファイルとして保管 1日経過したログは.gz形式で圧縮保存 実施したこと # 特定のエラーメッセージ(ERROR)がログに含まれているか確認したい。\nサンプルファイルの内容 # service.log (通常のログファイル) # 2024-11-20 10:15:32 INFO Application started successfully 2024-11-20 10:15:45 INFO User login: user_id=12345 2024-11-20 10:16:03 WARN High memory usage detected: 85% 2024-11-20 10:16:15 INFO Processing request: /api/users 2024-11-20 10:16:28 ERROR Database connection timeout 2024-11-20 10:16:30 ERROR Failed to execute query: SELECT * FROM users 2024-11-20 10:17:12 INFO Request completed: status=200 2024-11-20 10:18:45 WARN Response time exceeded threshold: 3.5s 2024-11-20 10:19:03 INFO User logout: user_id=12345 2024-11-20 10:20:15 ERROR Network unreachable: host=192.168.1.100 2024-11-20 10:21:30 INFO Backup process started 2024-11-20 10:22:45 INFO Backup completed successfully ファイルの一覧表示 # $ ls -lh service.log* -rw-r--r-- 1 root root 696 Nov 23 13:03 service.log -rw-r--r-- 1 root root 375 Nov 23 13:03 service.log.gz 使用コマンドと実行例 # 1. 通常のログファイル(.log)からERRORを検索 # コマンド:\ngrep ERROR service.log 実行結果:\n2024-11-20 10:16:28 ERROR Database connection timeout 2024-11-20 10:16:30 ERROR Failed to execute query: SELECT * FROM users 2024-11-20 10:20:15 ERROR Network unreachable: host=192.168.1.100 2. 圧縮ログファイル(.gz)からERRORを検索 # コマンド:\nzgrep ERROR service.log.gz 実行結果:\n2024-11-20 10:16:28 ERROR Database connection timeout 2024-11-20 10:16:30 ERROR Failed to execute query: SELECT * FROM users 2024-11-20 10:20:15 ERROR Network unreachable: host=192.168.1.100 💡 .logでも.gzでも同じ結果が得られる!\n3. 行番号付きで検索 # コマンド:\ngrep -n ERROR service.log 実行結果:\n5:2024-11-20 10:16:28 ERROR Database connection timeout 6:2024-11-20 10:16:30 ERROR Failed to execute query: SELECT * FROM users 10:2024-11-20 10:20:15 ERROR Network unreachable: host=192.168.1.100 4. 複数パターンを同時に検索 (ERROR または WARN) # コマンド:\ngrep -E \u0026#34;ERROR|WARN\u0026#34; service.log 実行結果:\n2024-11-20 10:16:03 WARN High memory usage detected: 85% 2024-11-20 10:16:28 ERROR Database connection timeout 2024-11-20 10:16:30 ERROR Failed to execute query: SELECT * FROM users 2024-11-20 10:18:45 WARN Response time exceeded threshold: 3.5s 2024-11-20 10:20:15 ERROR Network unreachable: host=192.168.1.100 5. 検索結果の件数をカウント # コマンド:\ngrep -c ERROR service.log 実行結果:\n3 よく使うgrepオプション # オプション 説明 使用例 -n 行番号を表示 grep -n ERROR service.log -i 大文字小文字を区別しない grep -i error service.log -c マッチした行数をカウント grep -c ERROR service.log -v マッチしない行を表示 grep -v INFO service.log -A 数字 マッチ行の後ろN行も表示 grep -A 3 ERROR service.log -B 数字 マッチ行の前N行も表示 grep -B 2 ERROR service.log -C 数字 マッチ行の前後N行を表示 grep -C 2 ERROR service.log -E 拡張正規表現を使用 grep -E \u0026quot;ERROR|WARN\u0026quot; service.log moreとlessの違い # 項目 more less スクロール方向 前方のみ(下方向) 前後自由(上下両方向) 検索機能 限定的 充実(前方/後方検索可能) ファイル読み込み 全体を読み込む 必要な部分のみ読み込む 大容量ファイル 遅い 高速 操作 シンプル 高機能(viライク) 終了時の表示 画面に残る 画面から消える 主な操作方法 # more:\nSpace: 次のページ Enter: 1行進む q: 終了 less:\nSpace/f: 次のページ b: 前のページ ↑/↓: 1行ずつ移動 /文字列: 前方検索 ?文字列: 後方検索 n: 次の検索結果 N: 前の検索結果 q: 終了 lessでの検索実例 # less service.log less内で:\n/ERROR # 「ERROR」を前方検索 n # 次のERRORへジャンプ N # 前のERRORへ戻る 使い分けのポイント # more: シンプルに前から順に見たい場合 less: 大きなログファイルの調査、検索が必要な場合 💡 豆知識: \u0026ldquo;less is more\u0026quot;という言葉遊びから、moreの改良版としてlessが誕生した\n各コマンドの説明 # コマンド 説明 対象ファイル grep テキストファイルから文字列を検索 .logなど zgrep 圧縮ファイルを一時的に解凍して検索（解凍ファイルは作成しない） .gz less ページ単位でファイルを表示(検索機能付き) .logなど zless 圧縮ファイルをlessで表示 .gz more シンプルなページャー(前方スクロールのみ) .logなど よくある間違い # ❌ パイプの誤用\nmore service.log | zgrep ERROR → zgrepは圧縮ファイル専用。パイプで渡されたデータは圧縮されていない\n⭕ 正しい使い方\n# 通常ファイル grep ERROR service.log # 圧縮ファイル zgrep ERROR service.log.gz ❌ 大きなログファイルにmore\nmore huge_file.log # 読み込みが遅い ⭕ lessを使う\nless huge_file.log # 高速に起動 学んだこと # 圧縮ファイルにはz系コマンド(zgrep, zless)を直接使う方が効率的 lessはmoreより高機能で検索も可能 ログ調査ではlessの方が実用的(前後に移動できるため) grep -nで行番号を表示すると、lessで該当行にジャンプしやすい -A, -B, -Cオプションで前後の文脈も確認できる 参考: よく使うログ調査パターン # # パターン1: エラーログを抽出して別ファイルに保存 grep ERROR service.log \u0026gt; error_only.log # パターン2: 最新のエラーを確認 grep ERROR service.log | tail -5 # パターン3: エラーとその前後2行を表示 grep -C 2 ERROR service.log # パターン4: 複数ファイルからエラーを検索 grep ERROR service*.log # パターン5: 圧縮ファイルも含めて検索 zgrep ERROR service.log.gz ","date":"2025年 11月 23日","externalUrl":null,"permalink":"/posts/251123221331_log-investigation-more-less-grep-zgrep/","section":"Posts","summary":"","title":"ログ調査_more・less・grep・zgrep","type":"posts"},{"content":" はじめに # オブジェクト指向について、講師役として解説する機会があるため、 振り返りとしてオブジェクト指向を再学習する。\nオブジェクト指向とは？ # データと関連する処理を「オブジェクト」という単位にまとめて管理するソフトウェア開発手法 オブジェクトは、クラスから生成される実体（インスタンス） （一部のプログラミング言語（Python、Rubyなど）ではクラス自体もオブジェクトとして扱われるが、このメモではオブジェクト=インスタンスとする） オブジェクト指向が誕生した経緯 # 1960～1970年代は「手続き型プログラミング」が主流。 データと処理を別々で記述する手法で、各データや処理のコーディングに集中できる反面、プログラムが大規模化すると、データと処理の関係性を把握するのに多大なエネルギーを必要としていた。 構造化プログラミングは制御構造（順次・選択・反復）を整理する手法として同時期に発展したが、データと処理の管理については別の課題として残っていた。 この問題を解決するために「データ」と「処理」をまとめて管理する「オブジェクト」が誕生。このオブジェクトの管理に主眼を置いたのがオブジェクト指向である。 クラス・インスタンス # オブジェクト指向を成立させるための基本的な概念がクラスとインスタンス\nクラス：設計図やテンプレート インスタンス：クラスから生成される実体（オブジェクト） 車で例えると、設計図から車を製造するようなイメージ\nクラス：車の設計図 インスタンス：製造された車 基本用語 # オブジェクト指向を理解する上で重要な基本用語を説明します。\nプロパティ（属性） # オブジェクトが持つデータ・状態を表す変数 車の例：色、速度、走行距離、燃料残量など 例：car.color = \u0026quot;red\u0026quot; （車の色は赤） メソッド # オブジェクトができる動作・処理を表す関数 車の例：走る、止まる、クラクションを鳴らす、給油するなど 例：car.drive() （車を運転する） コンストラクタ # オブジェクトを生成する際に初期化処理を行う特別なメソッド 新しい車を製造する際の初期設定のようなもの 車の例：製造時に色、エンジンタイプ、シート数などを設定 例：car = Car(\u0026quot;red\u0026quot;, \u0026quot;hybrid\u0026quot;, 5) （赤いハイブリッド5人乗りの車を作る） オブジェクト指向の3大要素 # 継承 カプセル化 ポリモーフィズム クラスとインスタンスを使って上記の3要素が実現できる。\n継承 # 親クラスから内容を引き継いで新しい子クラスを作成する。\n例えば、親クラスとして「車」があるとした場合、子クラスとして「乗用車」「トラック」「バス」を設定可能。 さらに「乗用車」から「タクシー」や「パトカー」を作ることもできる。 このとき、「トラック」には「荷物を積む」、「バス」には「乗客を乗せる」などの個別機能を実装できる。\nカプセル化 # データと処理を外部から隠蔽して保護する機能\n車の例を引き続き利用すると、「車の走行距離記録（オドメーター）」がある。 このオドメーターは手動でいじることは違法行為にあたる。走行距離をしっかり測定する必要があるので、 「車の走行距離記録（オドメーター）」に対して、直接アクセスできないようにして、「車で運転」した場合のみ 「オドメーター」に追加するようにする。この処理をカプセル化で実現できる。\nポリモーフィズム # 同じ命令で、対象によって異なる動作をする機能\n車の例：「サイレンを鳴らす」という同じ命令でも\nパトカー → 「ウーウー」 救急車 → 「ピーポーピーポー」 消防車 → 「ウーカンカン」 それぞれ違う音が鳴る。\nこれが便利な理由は、「サイレンを鳴らす」という共通の命令を覚えるだけで、 車種ごとの細かい違いを意識せずに使えることである。\nオブジェクト指向のメリット・デメリット # メリット # 再利用しやすい\n一度作った「車」クラスから、何台でも車を作れる 修正が楽\n「車」クラスを修正すれば、全ての車に反映される 現実世界に近い\n車、人、建物など、身近なモノとして考えられる デメリット # 小さなプログラムには大げさ\n簡単な計算だけなら、クラスなしの方が早い 最初は難しい\n概念の理解に時間がかかる 設計ミスの影響が大きい\nクラスの作り方を間違えると、大幅な修正が必要 まとめ # オブジェクト指向 # データと関連する処理を「オブジェクト」という単位にまとめて管理するソフトウェア開発手法\nクラスとインスタンス # クラス：設計図・テンプレート インスタンス：クラスから生成された実物 オブジェクト指向の3大要素 # 継承：既存のクラスを拡張して再利用 カプセル化：データと機能をまとめて、外部から保護 ポリモーフィズム：同じ操作で異なる振る舞い さらに深く学ぶために # オブジェクト指向開発の初期に活躍した「アラン・ケイ」によるオブジェクト指向の解説を読むと オブジェクト指向について深掘りできると思います。内容が難しいので、このメモでは詳細にまとめないが、参考としてリンクを紹介します。\nnote：アラン・ケイのオブジェクト指向プログラミング Dr. Alan Kay on the Meaning of “Object-Oriented Programming” Qiita：アラン・ケイのオブジェクト指向とは何だったか？元哲学者のエンジニアがまとめてみた 参考資料 # いちばんやさしい基本情報技術者 絶対合格の教科書＋出る順問題集 著者：高橋 京介 出版社：SBクリエイティブ 出版年：2024年 Qiita：[Python] Pythonでオブジェクト指向を完全理解してみる ","date":"2025年 11月 23日","externalUrl":null,"permalink":"/posts/251123211627_object-oriented-programming-introduction-memo/","section":"Posts","summary":"","title":"オブジェクト指向の入門用メモ","type":"posts"},{"content":"","date":"2025年 11月 23日","externalUrl":null,"permalink":"/tags/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0/","section":"Tags","summary":"","title":"プログラミング","type":"tags"},{"content":" はじめに # メモをまとめる方法として、「ツェッテルカステン」を勉強するためにこの本で学習。\n書籍情報 # 書籍名: TAKE NOTES!――メモで、あなただけのアウトプットが自然にできるようになる 著者: ズンク・アーレンス（翻訳：二木 夢子） 出版: 日経BP、2021年10月 出版社ページ 本書の要点 # ツェッテルカステンとは # 社会学者ルーマンが実践したメモ術。小さな単位のメモを作り、\n相互にリンクさせることで知識のネットワークを構築する手法。\nメモの処理フロー # 走り書き・文献メモ: 日常のアイデアや読書内容を一時記録 永久保存メモ: 自分の言葉で再構成した独立したメモ 関連づけ: 既存メモとリンクし、知識体系を育てる アウトプット: 蓄積したメモから文章や研究へ展開 重要な考え方 # アウトプット前提のインプット: 常にアウトプットを意識して情報を取り込む 自分の言葉で書く: 理解度を確認し、思考を深める つながりを意識: メモ同士の関連性を整理することが洞察につながる 所感 # メモ術に関する自己啓発書。システマティックにメモを蓄積することで質の高いアウトプットが可能になるという提案は有益だが、具体的なハウツーより概念的な説明が中心。メモの意義を再確認し、モチベーションを高めるのに適している。\n実践する3つのアクション # 日常的なメモ取りの習慣化 メモ間のつながりを意識した整理 自分の言葉での言い換えの徹底 ","date":"2025年 11月 20日","externalUrl":null,"permalink":"/posts/251120230822_take-notes-output-naturally-with-memos/","section":"Posts","summary":"","title":"【読書メモ】TAKE NOTES!――メモで、あなただけのアウトプットが自然にできるようになる","type":"posts"},{"content":"","date":"2025年 11月 20日","externalUrl":null,"permalink":"/tags/claude/","section":"Tags","summary":"","title":"Claude","type":"tags"},{"content":" 前回のセッションは引き継げるのか？ # 回答としては 不可 毎回のセッション毎に新しく会話内容などが更新される。\nもしも前回のセッションの内容を引き継いでほしい場合は\n前回のセッションの内容をメモや議事録にまとめて、\n新しく始めたセッションにて「このメモを読んで続きを」という旨を指示する必要がある。\nセッションのトークン量が少なくなってきたら、メモにまとめて、\n次のセッションで再開できるようにする必要がある。\nTodoWriteツールとは？ # 度々、Claudeにて「TodoWriteツール」という文言がでてくるため、claudeへ質問してみた。 claudeの内部管理用ツールらしい。（claudeにもToDo管理ツールってあるんだ。）\nClaudeより Claudeが内部的に使うタスク管理ツール 複雑なタスクを進める際、進捗を可視化 あなたの画面に □ → ◐ → ✓ で表示される セッション終了で消える（継続したいならメモに転記） あなたは何もしなくていい（Claude が自動で使う）\n","date":"2025年 11月 20日","externalUrl":null,"permalink":"/posts/251120225449_claude-specification-session-continuity-check/","section":"Posts","summary":"","title":"Claudeの仕様確認：前回のセッションは引き継げるのか？","type":"posts"},{"content":"","date":"2025年 11月 20日","externalUrl":null,"permalink":"/tags/%E4%BB%95%E6%A7%98%E7%A2%BA%E8%AA%8D/","section":"Tags","summary":"","title":"仕様確認","type":"tags"},{"content":" はじめに # git commitを実行する際のコミットメッセージを作成するために\n変更内容を確認するコマンドや手順を整理してメモとする。\n状況確認コマンド # # 全体把握 git status # すべての変更を確認 git diff HEAD --stat # まだ git add していない変更を確認 git diff --stat # git add した変更を確認 git diff --staged --stat git diff --cached --stat 変更を確定するコマンド # # コミット git commit -m \u0026#34;...\u0026#34; # リモートリポジトリへプッシュ git push 日本語ファイル名の表示設定 # デフォルトでは日本語ファイル名がエスケープされて表示される問題を解決 実行後、日本語ファイル名が正常に表示される。\n# グローバル設定（全リポジトリに適用） git config --global core.quotePath false # または、このリポジトリだけ設定 git config core.quotePath false その他の有用な設定（オプション） # # 日本語コミットメッセージも正常表示 git config --global core.pager \u0026#34;less -R\u0026#34; # git log で日本語を正しく表示 git config --global i18n.logOutputEncoding utf-8 まとめ # コミット前の変更確認には git diff HEAD \u0026ndash;stat が便利 ステージング済みの変更は \u0026ndash;staged オプションで確認 日本語表示問題は core.quotePath false で解決 ","date":"2025年 11月 20日","externalUrl":null,"permalink":"/posts/251120224617_git-change-check-commands/","section":"Posts","summary":"","title":"Gitコミット前の変更確認ガイド","type":"posts"}]